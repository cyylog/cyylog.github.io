{"meta":{"title":"Cyylog","subtitle":"有些人是山川是河流，唯独不是可停泊的港口","description":"","author":"Cyylog","url":"https://github.com/cyylog","root":"/"},"pages":[],"posts":[{"title":"gitlab-ci 入门","slug":"DevOPs/gitlab-ci入门","date":"2020-09-20T15:30:39.000Z","updated":"2020-09-22T06:27:14.827Z","comments":true,"path":"2020/09/20/DevOPs/gitlab-ci入门/","link":"","permalink":"https://github.com/cyylog/2020/09/20/DevOPs/gitlab-ci%E5%85%A5%E9%97%A8/","excerpt":"","text":"gitlab-ci入门示范：12345678docker run -d --name gitlab-runner \\ -v /data/cyy/gitlab-runner:/etc/gitlab-runner \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /usr/bin/docker:/usr/bin/docker \\ -v /usr/lib64/libltdl.so.7:/usr/lib/x86_64-linux-gnu/libltdl.so.7 \\ gitlab/gitlab-runner在宿主机上执行 ：chmod 666 /var/run/docker.sock 12345678910111213# cat .gitlab-ci.ymlstages: - test - buildjob1: stage: test script: - echo \"it is test\" job2: stage: build script: - echo \"it is build\" 各种参数说明12345678910111213141516171819202122232425262728293031script 由Runner执行的Shell脚本。image 使用docker镜像， image：nameservice 使用docker services镜像, services：namebefore_script 执行作业前运行的脚本after_script 作业完成后运行的脚本stages 定义管道中的步骤，依次运行stage 定义管道中步骤的作业段only 指定作业限制only:refs，only:kubernetes，only:variables，和only:changestags 指定执行作业的runnerallow_failure 允许job失败 when 什么时候开始工作， on_success 只有当前一个阶段的所有工作都成功时（或者因为它们被标记而被认为是成功的allow_failure）才执行工作 。这是默认值。 on_failure 仅当前一阶段的至少一个作业失败时才执行作业。 always 无论先前阶段的工作状态如何，都可以执行工作。 manual 手动执行作业 delayed 延迟作业。后面跟start_in,start_in 30minutes(延迟30分钟)，不加单位，默认为秒。最长可延迟1小时。environment 作业部署到的环境名称 #暂未搞清 cache key：\"$CI_JOB_STAGE-$CI_COMMIT_REF_SLUG\" #为每分支，每步骤启用缓存artifacts job成功时附加到作业的文件或目录dependencies 此job依赖其他jobz,主要作用于作业优先级converage 给定作业代码覆盖率设置 retry 在发生故障时，可以自动重试作业的次数。parallel 应该并行运行多少个作业实例trigger 定义下游管道触发器include 允许此作业包含外部YAMLextends 此作业将继承的配置项pages 上传作业结果用于gitlab pagesvariables 作业级别定义作业变量 案例 1 自动构建 go 程序12345678stages: - testjob1: stage: test script: - docker build -t mygo:v1 . tags: - go 123456789FROM golang:1.14.4-alpine3.12RUN mkdir /src /appADD . ../srcENV GOPROXY=\"https://goproxy.io\"RUN cd /src &amp;&amp; ls &amp;&amp; go build -o ../app/mygo main.go &amp;&amp; cd /app &amp;&amp; chmod +x mygo &amp;&amp; cd /RUN rm src -frWORKDIR /appENTRYPOINT [\"/app/mygo\"] 压缩镜像1234567891011FROM golang:1.14.4-alpine3.12RUN mkdir /src /appADD . ../srcENV GOPROXY=\"https://goproxy.io\"RUN cd /src &amp;&amp; ls &amp;&amp; go build -o ../app/mygo main.go &amp;&amp; cd /app &amp;&amp; chmod +x mygo &amp;&amp; cd /FROM alpine:3.12RUN mkdir /appCOPY --from=0 /app/mygo /appENTRYPOINT [\"/app/mygo\"] 单元测试1234FROM golang:1.14.4-alpine3.12ADD . /srcWORKDIR /srccmd [\"go\",\"test\"] 123456789101112131415161718192021222324252627282930stages: - test - buildGoTest: stage: test script: - docker build -f DockerfileTest -t test-mygo:v1 . - docker run --rm test-mygo:v1 after_script: - docker rmi test-mygo:v1 tags: - goGoBuild: stage: build script: - docker build -t mygo:v1 . after_script: - docker rmi $(docker images -af \"dangling=true\" -q) tags: - goGoDeploy: #使用私有镜像仓库 stage: deploy script: - docker tag mygo:v1 10.0.0.169:5000/mygo:v1 - docker push 10.0.0.169:5000/mygo:v1 after_script: - docker rmi 10.0.0.169:5000/mygo:v1 - docker rmi mygo:v1 tags: - go 1234查看数据curl http://10.0.0.169:5000/v2/_catalog (查看列表)curl http://10.0.0.169:5000/v2/mygo/manifests/v1 (查看redis镜像详情)curl http://10.0.0.169:5000/v2/mygo/tags/list","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://github.com/cyylog/categories/DevOps/"}],"tags":[{"name":"Gitlab","slug":"Gitlab","permalink":"https://github.com/cyylog/tags/Gitlab/"}]},{"title":"搭建 NFS 服务","slug":"Linux/部署NFS服务","date":"2020-09-15T17:55:39.000Z","updated":"2020-09-18T06:54:46.557Z","comments":true,"path":"2020/09/16/Linux/部署NFS服务/","link":"","permalink":"https://github.com/cyylog/2020/09/16/Linux/%E9%83%A8%E7%BD%B2NFS%E6%9C%8D%E5%8A%A1/","excerpt":"","text":"目的：部署 NFS 服务进行跨主机文件共享 Network File System 通过网络，让不同的机器、不同的操作系统可以共享彼此的文件。 1、环境准备1234567891.系统版本：CentOS7.42.NFS版本：nfs-utils （使用当前最新版本）3.初始化系统环境4.关闭防火墙[root@localhost ~]# systemctl stop iptables firewalld[root@localhost ~]# systemctl disable iptables firewalld5.关闭SELinux[root@localhost ~]# sed -ri '/SELINUX=/cSELINUX=disabled' /etc/selinux/config[root@localhost ~]# setenforce 0 # 临时关闭SELinux 2、部署NFS1234567891、sudo yum -y install nfs-utils 2、配置sudo vi /etc/sysconfig/nfs加入 LOCKD_TCPPORT=30001 #TCP锁使用端口LOCKD_UDPPORT=30002 #UDP锁使用端口MOUNTD_PORT=30003 #挂载使用端口STATD_PORT=30004 #状态使用端口 3、启动/重启服务123451、sudo systemctl restart rpcbind.service 2、sudo systemctl restart nfs-server.service开机启动：1、sudo systemctl enable rpcbind.service2、 sudo systemctl enable nfs-server.service 4、编辑共享目录1234编辑/etc/exports sudo vi /etc/exports 写入如下内容 /home/cyy/goapi 10.0.0.0/24(rw,async,insecure,no_root_squash) 参数说明 参数 作用 ro 只读 rw 读写 root_squash 当NFS客户端以root管理员访问时，映射为NFS服务器的匿名用户 no_root_squash 当NFS客户端以root管理员访问时，映射为NFS服务器的root管理员 all_squash 无论NFS客户端使用什么账户访问，均映射为NFS服务器的匿名用户 sync 同时将数据写入到内存与硬盘中，保证不丢失数据 async 优先将数据保存到内存，然后再写入硬盘;这样效率更高，但可能会丢失数据 secure（默认） 限制客户端只能从小于1024的tcp/ip端口连接服务器 insecure 允许客户端从大于1024的tcp/ip端口连接服务器 anonuid 匿名用户的UID值，通常是nobody或nfsnobody，可以在此处自行设定 anongid 匿名用户的GID值 no_subtree_check 如果NFS输出的是一个子目录，则无需检查其父目录的权限（可以提高效率） 5、查看挂载1234567showmount -e localhost发现没有重启nfs服务 (sudo systemctl restart nfs-server.service)接下来 创建刚才的文件夹 来到另外一台服务器上12345678910sudo yum -y install nfs-utils 不需要启动nfs服务直接执行如下：showmount -e 10.0.0.145尝试进行挂载 mount -t nfs 10.0.0.145:/home/cyy/goapi /home/cyy/goapi卸载只需 umount /home/cyy/goapi","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/categories/Linux/"}],"tags":[{"name":"NFS","slug":"NFS","permalink":"https://github.com/cyylog/tags/NFS/"}]},{"title":"Kubernetes组件—介绍002","slug":"容器/Kubernetes组件—介绍002","date":"2020-09-15T11:57:00.000Z","updated":"2020-09-16T13:11:59.236Z","comments":true,"path":"2020/09/15/容器/Kubernetes组件—介绍002/","link":"","permalink":"https://github.com/cyylog/2020/09/15/%E5%AE%B9%E5%99%A8/Kubernetes%E7%BB%84%E4%BB%B6%E2%80%94%E4%BB%8B%E7%BB%8D002/","excerpt":"","text":"本文档描述了 Kubernetes 的组件。 NamespaceNamespace是对一组资源和对象的抽象集合， 用来将系统内部的对象划分为不同的项目组或用户组 常用来隔离不同的用户，比如Kubernetes自带的服务一般运行在kube-system namespace中。 ingressingress 相当于一个7层负载均衡器，理解为进行反代并定义规则的一个api对象ingress Controller 通过监听 Ingress api 转化为各自的配置(常用的有nginx -ingress, trafik-ingress ) PortNodePort​ 在所有节点（虚拟机）上开放一个特定端口，任何发送到该端口的流量都被转发到对应服务 端口范围30000-32767 hostPort直接将容器的端口与所调度的节点上的端口进行映射 ClusterIP 创建集群内的服务， 应用只要在集群内都可以访问,外部（如公网）无法访问它。 k8s-coredns： 在同一个命名空间内： 可以通过 service_name 直接解析 不同命名空间内容： service_name. namespace_name PVC 和 PVPersistent Volume Claim(PVC)和Persistent Volume（PV） PV： 定义Volume的类型、挂载目录、远程存储服务器等 PVC：定义 Pod想要使用的持久化属性，比如存储大小、读写权限等.. StorageClass： PV的模板，自动为PVC创建PV","categories":[{"name":"容器","slug":"容器","permalink":"https://github.com/cyylog/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://github.com/cyylog/tags/Kubernetes/"}]},{"title":"[xshell突出显示集]","slug":"[xshell突出显示集]","date":"2020-09-04T01:51:31.137Z","updated":"2020-09-04T01:52:11.327Z","comments":true,"path":"2020/09/04/[xshell突出显示集]/","link":"","permalink":"https://github.com/cyylog/2020/09/04/[xshell%E7%AA%81%E5%87%BA%E6%98%BE%E7%A4%BA%E9%9B%86]/","excerpt":"","text":"[xshell突出显示集]xshell突出显示集（参考mobaxterm，直接拷贝过来不行，应该是xshell对正则表达式的支持不够好）:Underline: 1\\b(http(s)?://[A-Za-z0-9_./&amp;?=%~#&#123;&#125;()@+-]+)\\b Red: 1(\\b((bad|wrong|incorrect|improper|invalid|unsupported|bad)( file| memory)? (descriptor|alloc(ation)?|addr(ess)?|owner(ship)?|arg(ument)?|param(eter)?|setting|length|filename)|not properly|improperly|(operation |connection |authentication |access |permission )?(false|no|ko|denied|disallowed|not allowed|refused|problem|failed|failure|not permitted)|no [A-Za-z]+( [A-Za-z]+)? found|invalid|unsupported|not supported|seg(mentation )?fault|corruption|corrupted|corrupt|overflow|underrun|not ok|unimplemented|unsuccessfull|not implemented|permerrors?|fehlers?|errore|errors?|erreurs?|fejl|virhe|greška|erro|fel|\\(ee\\)|\\(ni\\))\\b) Green: 1(\\b(true|yes|ok|accepted|allowed|enabled|connected|erfolgreich|exitoso|successo|sucedido|framgångsrik|successfully|successful|succeeded|success)\\b) Yellow: 1(\\b(\\[\\-w[A-Za-z-]+\\]|caught signal [0-9]+|cannot|(connection (to (remote host|[a-z0-9.]+) )?)?(closed|terminated|stopped|not responding)|exited|no more [A-Za-z] available|unexpected|(command |binary |file )?not found|(o)+ps|out of (space|memory)|low (memory|disk)|unknown|disabled|disconnected|deprecated|refused|disconnect(ion)?|advertencia|avvertimento|attention|warnings?|achtung|exclamation|alerts?|warnungs?|advarsel|pedwarn|aviso|varoitus|upozorenje|peringatan|uyari|varning|avertissement|\\(ww\\)|\\(\\?\\?\\)|could not|unable to)\\b) shellMagenta: 1(\\b(localhost|([1-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-4])\\.[0-9]+\\.[0-9]+\\.[0-9]+|null|none)\\b) Cyan: 1(\\b(last (failed )?login:|launching|checking|loading|creating|building|important|booting|starting|notice|informational|informationen|informazioni|informação|oplysninger|informations?|info|información|informasi|note|\\(ii\\)|\\(\\!\\!\\))\\b)","categories":[],"tags":[]},{"title":"分布式见解--undone","slug":"Interview/分布式见解","date":"2020-08-21T17:55:39.000Z","updated":"2020-09-14T02:48:30.548Z","comments":true,"path":"2020/08/22/Interview/分布式见解/","link":"","permalink":"https://github.com/cyylog/2020/08/22/Interview/%E5%88%86%E5%B8%83%E5%BC%8F%E8%A7%81%E8%A7%A3/","excerpt":"","text":"三大 协议raft zab gossip raft是etcd用的. zab是zookeepr用的 gossip是redis集群用的 raft 一言以蔽之 就是 状态机+ 操作日志 +快照 见解： 所谓的分布式 最关键的 就是 各个节点之间“产生关联”，所谓的分布式 最关键的 就是 各个节点之间“产生关联” 所谓的分布式 最关键的 就是 各个节点之间“产生关联” 如果 没有“关联” 那么 这只能叫做分开部署 一旦有了关联 才叫 “分布式“ 分布式 有简单的 场景 最基础的是 主从 譬如MySQL主从 redis主从 后来逐步演化为 选主。 一旦有了选主 那么就真正叫做集群了","categories":[{"name":"Interview","slug":"Interview","permalink":"https://github.com/cyylog/categories/Interview/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://github.com/cyylog/tags/Go/"}]},{"title":"Interview System_001--undone","slug":"Interview/Interview_System_001","date":"2020-08-15T14:09:12.831Z","updated":"2020-09-14T02:48:25.656Z","comments":true,"path":"2020/08/15/Interview/Interview_System_001/","link":"","permalink":"https://github.com/cyylog/2020/08/15/Interview/Interview_System_001/","excerpt":"","text":"操作系统： 进程、线程、协程有什么区别？4个线程执行3个文件句柄是共享这3个文件么？","categories":[{"name":"Interview","slug":"Interview","permalink":"https://github.com/cyylog/categories/Interview/"}],"tags":[{"name":"System","slug":"System","permalink":"https://github.com/cyylog/tags/System/"}]},{"title":"Interview Network_001--undone","slug":"Interview/Interview_Network_001","date":"2020-08-15T14:05:23.519Z","updated":"2020-09-14T02:48:21.810Z","comments":true,"path":"2020/08/15/Interview/Interview_Network_001/","link":"","permalink":"https://github.com/cyylog/2020/08/15/Interview/Interview_Network_001/","excerpt":"","text":"网络 http的3次握手 https的连接过程？双方使用的加密套件是由客户端决定的，还是服务端决定的？","categories":[{"name":"Interview","slug":"Interview","permalink":"https://github.com/cyylog/categories/Interview/"}],"tags":[{"name":"Network","slug":"Network","permalink":"https://github.com/cyylog/tags/Network/"}]},{"title":"Interview Go_001--undone","slug":"Interview/Interview_Go_001","date":"2020-08-15T14:02:17.872Z","updated":"2020-09-14T02:49:25.489Z","comments":true,"path":"2020/08/15/Interview/Interview_Go_001/","link":"","permalink":"https://github.com/cyylog/2020/08/15/Interview/Interview_Go_001/","excerpt":"","text":"go： 超时退出 context的初始形态？怎么使用contenxt？ wait group的使用？不加add直接wait是否会panic？ new和make有什么区别？哪个可以初始化内存为0？ runtime是什么？runtime属于线程还是协程 项目： 什么是JWT？JWT有几部分组成？用什么签名算法？如何实现把一个用户从登陆状态踢出？JWT和session什么区别？ 什么是前缀树？ gin中间件原理？中间件用到了什么设计模式？ 跨域 gin文件传送的时候怎么接收？http头部的content-type写什么","categories":[{"name":"Interview","slug":"Interview","permalink":"https://github.com/cyylog/categories/Interview/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://github.com/cyylog/tags/Go/"}]},{"title":"Interview MySQL_001--undone","slug":"Interview/Interview_MySQL_001","date":"2020-08-15T13:54:15.126Z","updated":"2020-09-14T02:48:17.214Z","comments":true,"path":"2020/08/15/Interview/Interview_MySQL_001/","link":"","permalink":"https://github.com/cyylog/2020/08/15/Interview/Interview_MySQL_001/","excerpt":"","text":"mysql： mysql事务的隔离级别 什么是乐观锁和悲观锁？乐观锁的一致性怎么保证","categories":[{"name":"Interview","slug":"Interview","permalink":"https://github.com/cyylog/categories/Interview/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://github.com/cyylog/tags/MySQL/"}]},{"title":"Mysql 游标","slug":"SQL/Mysql游标","date":"2020-07-16T03:54:04.000Z","updated":"2020-08-15T13:54:34.922Z","comments":true,"path":"2020/07/16/SQL/Mysql游标/","link":"","permalink":"https://github.com/cyylog/2020/07/16/SQL/Mysql%E6%B8%B8%E6%A0%87/","excerpt":"","text":"[mysql游标的用法及作用]例子： 当前有三张表A、B、C其中A和B是一对多关系，B和C是一对多关系，现在需要将B中A表的主键存到C中；常规思路就是将B中查询出来然后通过一个update语句来更新C表就可以了，但是B表中有2000多条数据，难道要执行2000多次？显然是不现实的；最终找到写一个存储过程然后通过循环来更新C表，然而存储过程中的写法用的就是游标的形式。 【简介】​ 游标实际上是一种能从包括多条数据记录的结果集中每次提取一条记录的机制。 ​ 游标充当指针的作用。 ​ 尽管游标能遍历结果中的所有行，但他一次只指向一行。 ​ 游标的作用就是用于对查询数据库所返回的记录进行遍历，以便进行相应的操作。 【用法】​ 一、声明一个游标: declare 游标名称 CURSOR for table;(这里的table可以是你查询出来的任意集合)​ 二、打开定义的游标:open 游标名称;​ 三、获得下一行数据:FETCH 游标名称 into testrangeid,versionid;​ 四、需要执行的语句(增删改查):这里视具体情况而定​ 五、释放游标:CLOSE 游标名称; 注:mysql存储过程每一句后面必须用;结尾，使用的临时字段需要在定义游标之前进行声明。 【实例】123456789101112131415161718192021222324252627282930- BEGIN --定义变量 declare testrangeid BIGINT; declare versionid BIGINT; declare done int; --创建游标，并存储数据 declare cur_test CURSOR for select id as testrangeid,version_id as versionid from tp_testrange; --游标中的内容执行完后将done设置为1 DECLARE CONTINUE HANDLER FOR NOT FOUND SET done=1; --打开游标 open cur_test; --执行循环 posLoop:LOOP --判断是否结束循环 IF done=1 THEN LEAVE posLoop; END IF; --取游标中的值 FETCH cur_test into testrangeid,versionid; --执行更新操作 update tp_data_execute set version_id=versionid where testrange_id = testrangeid; END LOOP posLoop; --释放游标 CLOSE cur_test; END - 例子2： 我们现在要用存储过程做一个功能，统计iphone的总库存是多少，并把总数输出到控制台。 12345678910111213141516171819202122232425262728293031323334353637383940--在windows系统中写存储过程时，如果需要使用declare声明变量，需要添加这个关键字，否则会报错。 delimiter // drop procedure if exists StatisticStore; CREATE PROCEDURE StatisticStore() BEGIN --创建接收游标数据的变量 declare c int; declare n varchar(20); --创建总数变量 declare total int default 0; --创建结束标志变量 declare done int default false; --创建游标 declare cur cursor for select name,count from store where name = 'iphone'; --指定游标循环结束时的返回值 declare continue HANDLER for not found set done = true; --设置初始值 set total = 0; --打开游标 open cur; --开始循环游标里的数据 read_loop:loop --根据游标当前指向的一条数据 fetch cur into n,c; --判断游标的循环是否结束 if done then leave read_loop; --跳出游标循环 end if; --获取一条数据时，将count值进行累加操作，这里可以做任意你想做的操作， set total = total + c; --结束游标循环 end loop; --关闭游标 close cur; --输出结果 select total; END; --调用存储过程 call StatisticStore(); fetch是获取游标当前指向的数据行，并将指针指向下一行，当游标已经指向最后一行时继续执行会造成游标溢出。使用loop循环游标时，他本身是不会监控是否到最后一条数据了，像下面代码这种写法，就会造成死循环； 1234read_loop:loop fetch cur into n,c; set total = total+c; end loop; 在MySql中，造成游标溢出时会引发mysql预定义的NOT FOUND错误，所以在上面使用下面的代码指定了当引发not found错误时定义一个continue 的事件，指定这个事件发生时修改done变量的值。 1declare continue HANDLER for not found set done = true; 所以在循环时加上了下面这句代码： 1234--判断游标的循环是否结束 if done then leave read_loop; --跳出游标循环 end if; 如果done的值是true，就结束循环。继续执行下面的代码 使用方式 游标有三种使用方式：第一种就是上面的实现，使用loop循环；第二种方式如下，使用while循环： 12345678910111213141516171819202122drop procedure if exists StatisticStore1; CREATE PROCEDURE StatisticStore1() BEGIN declare c int; declare n varchar(20); declare total int default 0; declare done int default false; declare cur cursor for select name,count from store where name = 'iphone'; declare continue HANDLER for not found set done = true; set total = 0; open cur; fetch cur into n,c; while(not done) do set total = total + c; fetch cur into n,c; end while; close cur; select total; END; call StatisticStore1(); 第三种方式是使用repeat执行： 12345678910111213141516171819202122drop procedure if exists StatisticStore2; CREATE PROCEDURE StatisticStore2() BEGIN declare c int; declare n varchar(20); declare total int default 0; declare done int default false; declare cur cursor for select name,count from store where name = 'iphone'; declare continue HANDLER for not found set done = true; set total = 0; open cur; repeat fetch cur into n,c; if not done then set total = total + c; end if; until done end repeat; close cur; select total; END; call StatisticStore2(); 游标嵌套在mysql中，每个begin end 块都是一个独立的scope区域，由于MySql中同一个error的事件只能定义一次，如果多定义的话在编译时会提示Duplicate handler declared in the same block。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859drop procedure if exists StatisticStore3; CREATE PROCEDURE StatisticStore3() BEGIN declare _n varchar(20); declare done int default false; declare cur cursor for select name from store group by name; declare continue HANDLER for not found set done = true; open cur; read_loop:loop fetch cur into _n; if done then leave read_loop; end if; begin declare c int; declare n varchar(20); declare total int default 0; declare done int default false; declare cur cursor for select name,count from store where name = 'iphone'; declare continue HANDLER for not found set done = true; set total = 0; open cur; iphone_loop:loop fetch cur into n,c; if done then leave iphone_loop; end if; set total = total + c; end loop; close cur; select _n,n,total; end; begin declare c int; declare n varchar(20); declare total int default 0; declare done int default false; declare cur cursor for select name,count from store where name = 'android'; declare continue HANDLER for not found set done = true; set total = 0; open cur; android_loop:loop fetch cur into n,c; if done then leave android_loop; end if; set total = total + c; end loop; close cur; select _n,n,total; end; begin end; end loop; close cur; END; call StatisticStore3(); 上面就是实现一个嵌套循环，当然这个例子比较牵强。凑合看看就行。 动态SQLMysql 支持动态SQL的功能 123456set @sqlStr='select * from table where condition1 = ?'; prepare s1 for @sqlStr; --如果有多个参数用逗号分隔 execute s1 using @condition1; --手工释放，或者是 connection 关闭时， server 自动回收 deallocate prepare s1;","categories":[{"name":"SQL","slug":"SQL","permalink":"https://github.com/cyylog/categories/SQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://github.com/cyylog/tags/MySQL/"}]},{"title":"Prometheus学习笔记_01","slug":"监控/Prometheus学习笔记（1）","date":"2020-06-17T16:48:56.000Z","updated":"2020-06-17T16:53:18.893Z","comments":true,"path":"2020/06/18/监控/Prometheus学习笔记（1）/","link":"","permalink":"https://github.com/cyylog/2020/06/18/%E7%9B%91%E6%8E%A7/Prometheus%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89/","excerpt":"","text":"Prometheus 监控一、介绍本文介绍Prometheus 监控及在k8s集群中使用node-exporter、prometheus、grafana对集群进行监控。实现原理类似ELK、EFK组合。node-exporter组件负责收集节点上的metrics监控数据，并将数据推送给prometheus, prometheus负责存储这些数据，grafana将这些数据通过网页以图形的形式展现给用户。 在开始之前有必要了解下Prometheus是什么? Prometheus （中文名：普罗米修斯）是由 SoundCloud 开发的开源监控报警系统和时间序列数据库(TSDB).自2012年起,许多公司及组织已经采用 Prometheus,并且该项目有着非常活跃的开发者和用户社区.现在已经成为一个独立的开源项目。Prometheus 在2016加入 CNCF ( Cloud Native Computing Foundation 云原生计算基金会 ), 作为在 kubernetes 之后的第二个由基金会主持的项目。 Prometheus 的实现参考了Google内部的监控实现，与源自Google的Kubernetes结合起来非常合适。另外相比influxdb的方案，性能更加突出，而且还内置了报警功能。它针对大规模的集群环境设计了拉取式的数据采集方式，只需要在应用里面实现一个metrics接口，然后把这个接口告诉Prometheus就可以完成数据采集了，下图为prometheus的架构图。 ​ promethues是一套开源的系统监控报警框架。Prometheus 所有采集的监控数据均以指标（metric）的形式保存在内置的时间序列数据库当中（TSDB）：属于同一指标名称，同一标签集合的、有时间戳标记的数据流。除了存储的时间序列，Prometheus 还可以根据查询请求产生临时的、衍生的时间序列作为返回结果。包含了以下组件 prometheus server: 主要负责数据采集和存储，提供promQL查询语言支持。prometheus是一个时序数据库，将采集到的监控数据按照时间序列的方式存储到本地磁盘。 Push Gateway: 支持临时性job主动推送指标的中间网关。 PromDash： 使用rails开发的dashboard，用于可视化指标数据。 Exporters: 负责监控机器运行状态，提供被监控组件信息的 HTTP 接口被叫做 exporter。 直接采集： exporter内置了prometheus支持，直接向prometheus暴露数据端点。 间接采集：原不支持prometheus。通过prometheus提供的clien library编写的目标监控采集程序。 Altermanager: 从 Prometheus server 端接收到 alerts 后，会进行去除重复数据，分组，并路由到对收的接受方式，发出报警。常见的接收方式有：电子邮件，企业微信，钉钉 , webhook WebUI: Prometheus内置一个简单的Web控制台，可以查询指标，查看配置信息或者Service Discovery等，实际工作中，查看指标或者创建仪表盘通常使用Grafana，Prometheus作为Grafana的数据源；9090提供图形化界面功能。 promethues 的各个组件基本都是用 golang 编写,对编译和部署十分友好.并且没有特殊依赖.基本都是独立工作。 二、基本工作原理 Prometheus server 定期从配置好的 jobs 或者 exporters 中拉 metrics，或者接收来自 Pushgateway 发过来的 metrics，或者从其他的 Prometheus server 中拉 metrics。 Prometheus server 在本地存储收集到的 metrics，并运行已定义好的 alert.rules，记录新的时间序列或者向 Alertmanager 推送警报。 Alertmanager 根据配置文件，对接收到的警报进行处理，发出告警。 在图形界面中，可视化采集数据。 三、Prometheus 的优势和不足1、prometheus 的优势 强大的多维度数据模型：时间序列数据通过 metric 名和键值对来区分。所有的 metrics 都可以设置任意的多维标签。数据模型更随意，不需要刻意设置为以点分隔的字符串。可以对数据模型进行聚合，切割和切片操作。支持双精度浮点类型，标签可以设为全 unicode。 灵活而强大的查询语句（PromQL）：在同一个查询语句，可以对多个 metrics 进行乘法、加法、连接、取分数位等操作。 易于管理：Prometheus server 是一个单独的二进制文件，可直接在本地工作，不依赖于分布式存储。 高效：平均每个采样点仅占 3.5 bytes，且一个 Prometheus server 可以处理数百万的 metrics。使用 pull 模式采集时间序列数据，这样不仅有利于本机测试而且可以避免有问题的服务器推送坏的 metrics。 可以采用 push gateway 的方式把时间序列数据推送至 Prometheus server 端。 可以通过服务发现或者静态配置去获取监控的 targets。 有多种可视化图形界面。 易于伸缩。 2、prometheus 的不足 有待于改进 不支持集群化 (这个是当前最迫切的需求) 被监控集群过大后 本身性能有一定瓶颈(如果有集群 就可以解决这个问题) 偶尔发生数据丢失(这个问题 在2.0之前 会偶尔发生几次， 2.0之后貌似已经彻底解决 ) 中文支持不好 中文资料也很少(这个问题 也是老生常谈了 往往新的 很牛的国外工具都不太支持中文) 注： 由于数据采集可能会有丢失，所以 Prometheus 不适用对采集数据要 100% 准确的情形。但如果用于记录时间序列数据，Prometheus 具有很大的查询优势，此外，Prometheus 适用于微服务的体系架构。 四、prometheus 的基本概念1、数据模型 prometheus中存储的数据为时间序列，是由Metric的名字和一系列的标签（键值对）唯一标识的，不同的标签代表不同的时间序列。 样本：实际时间序列，每个序列包括一个float64的值和一个毫秒级的时间戳。（指标+时间戳+样本值） metric名字： 具有语义，表示功能：例如：http_requeststotal, 表示 http 请求的总数。其中，metric 名字由 ASCII 字符，数字，下划线，以及冒号组成，且必须满足正则表达式[a-zA-Z:][a-zA-Z0-9_:]*。 标签：使一个时间序列有不同未读的识别。例如 http_requeststotal{method=”Get”} 表示所有 http 请求中的 Get 请求。当 method=”post” 时，则为新的一个 metric。标签中的键由 ASCII 字符，数字，以及下划线组成，且必须满足正则表达式[a-zA-Z:][a-zA-Z0-9_:]*。 格式：{=, …}，例如：http_requests_total{method=”POST”,endpoint=”/api/tracks”}。 2、Metric类型Prometheus 客户端库主要提供四种主要的 metric 类型： 1、Counter（累加性metirc）一种累加的 metric，典型的应用如： 请求的个数 结束的任务数 出现的错误数 。。。 例如： 查询 promhttp_metric_handler_requests_total{code=”200”,instance=”localhost:9090”,job=”prometheus”} 返回 8，10 秒后再次查询，则返回 14。 2、Gauge（可增减性metric）一种常规的 metric，典型的应用如： 温度 运行的 go routines 的个数可以任意加减。 例如： go_goroutines{instance=”localhost:9090”,job=”prometheus”} 返回值 147，10 秒后返回 124。 注： routines: go的日常工作？ 3、Histogram（树状图）注： histogram 英[ˈhɪstəɡræm] 美[ˈhɪstəɡræm] 直方图；矩形图 可以理解为柱状图，典型的应用如： 请求持续时间 响应大小 可以对观察结果采样，分组及统计。 例如： 查询 go_gc_duration_seconds_sum{instance=”localhost:9090”,job=”prometheus”}时 返回结果如下：Histogram metric 返回结果图 4、Summary（汇总）类似于 Histogram，典型的应用如： 请求持续时间 响应大小提供观测值的 count 和 sum 功能。提供百分位的功能，即可以按百分比划分跟踪结果。 instance 和 jobsinstance: 一个单独 scrape(抓取) 的目标， 一般对应于一个进程。 jobs: 一组同种类型的 instances（主要用于保证可扩展性和可靠性），例如：注： scrape 英[skreɪp] 美[skreɪp] 刮掉; 削去; 擦坏; 擦伤; 刮坏; 蹭破; (使) 发出刺耳的刮擦声 当 scrape 目标时，Prometheus 会自动给这个 scrape 的时间序列附加一些标签以便更好的分别例如： instance，job。 下面以实际的 metric 为例，对上述概念进行说明：Metrics 示例 如图所示，这三个 metric 的名字都一样，他们仅凭 handler 不同而被标识为不同的 metrics。这类 metrics 只会向上累加，是属于 Counter 类型的 metric，且 metrics 中都含有 instance 和 job 这两个标签。","categories":[{"name":"监控","slug":"监控","permalink":"https://github.com/cyylog/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://github.com/cyylog/tags/Prometheus/"}]},{"title":"python之fabric模块","slug":"DevOPs/python之fabric模块","date":"2020-05-31T08:20:44.000Z","updated":"2020-05-31T08:24:59.471Z","comments":true,"path":"2020/05/31/DevOPs/python之fabric模块/","link":"","permalink":"https://github.com/cyylog/2020/05/31/DevOPs/python%E4%B9%8Bfabric%E6%A8%A1%E5%9D%97/","excerpt":"","text":"python 之 fabric 模块Fabric 是一个用 Python 开发的部署工具，最大特点是不用登录远程服务器，在本地运行远程命令，几行 Python 脚本就可以轻松部署。 12# doc http:&#x2F;&#x2F;docs.fabfile.org&#x2F;en&#x2F;2.5&#x2F;getting-started.html# pip install fabric -i http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;pypi&#x2F;simple&#x2F; G站部署脚本 参考 示范12345678910111213141516from fabric import Connection, taskfrom fabric.api import env,hosts,run,execute@taskdef deploy(c): with Connection('root@x.x.x.x') as c: c.run(\"rm -rf giligili\") c.run(\"git clone https://github.com/bydmm/giligili.git\", pty=True) c.put(\"docker-compose.yml\", \"giligili/docker-compose.yml\") c.run(\"cd giligili &amp;&amp; docker-compose build &amp;&amp; docker-compose rm -fsv &amp;&amp; docker-compose up --build -d\", pty=True) c.run(\"sleep 15 &amp;&amp; docker logs -f gili-api\")# doc http://docs.fabfile.org/en/2.5/getting-started.html# apt install python-pip# pip install fabric -i http://mirrors.aliyun.com/pypi/simple/# fab deploy 以上定义了pack和deploy两个任务，如果我们用Fabric部署，只需简单地输入两条命令： 12$ fab pack$ fab deploy Fabric提供几个简单的API来完成所有的部署，最常用的是local()和run()，分别在本地和远程执行命令，put()可以把本地文件上传到远程，当需要在远程指定当前目录时，只需用with cd(‘/path/to/dir/‘):即可。 默认情况下，当命令执行失败时，Fabric会停止执行后续命令。有时，我们允许忽略失败的命令继续执行，比如run(‘rm /tmp/abc’)在文件不存在的时候有可能失败，这时可以用with settings(warn_only=True):执行命令，这样Fabric只会打出警告信息而不会中断执行。 Fabric是如何在远程执行命令的呢？其实Fabric所有操作都是基于SSH执行的，必要时它会提示输入口令，所以非常安全。更好的办法是在指定的部署服务器上用证书配置无密码的ssh连接。 如果是基于团队开发，可以让Fabric利用版本库自动检出代码，自动执行测试、打包、部署的任务。由于Fabric运行的命令都是基本的Linux命令，所以根本不需要用Fabric本身来扩展，会敲Linux命令就能用Fabric部署。 利用Fabric部署Python、Ruby、PHP这样的非编译型网站应用非常方便，而对于编译型的Java、C#等就麻烦了，编译本身就是一个极其复杂的大工程，需要依赖特定工具或者IDE，很难做到自动化。 fab命令常用参数12345678910111213# fab --help 查看帮助 ## 常用参数-l 显示定义好的任务函数名-f 指定fab入口文件，默认入口文件名为fabfile.py.. 即指定fabfile文件-g 指定网关（中转）设备，即HOST逗号分隔要操作的主机, 比如堡垒机环境，填写堡垒机IP即可.-H 指定目标主机，多台主机用‘,’号分隔-p 远程账号的密码，fab执行时默认使用root账户-P 以异步并行方式运行多主机任务，默认为串行运行-R 指定role（角色），以角色名区分不同业务组设备-t 设置设备连接超时时间（秒）-T 设置远程主机命令执行超时时间（秒）-w 当命令执行失败，发出警告，而非默认中止任务。 12345678910111213141516其他参数:--set=KEY=VALUE,... 逗号分隔，设置环境变量--shortlist 简短打印可用命令-c PATH 指定本地配置文件-D 不加载用户known_hosts文件-i PATH 指定私钥文件-k 不加载来自~/.``ssh``下的私钥文件--port=PORT 指定SSH连接端口-R ROLES 根据角色操作，逗号分隔-s SHELL 指定新shell，默认是``'/bin/bash -l -c'--show=LEVELS 以逗号分隔的输出--ssh-config-path=PATH SSH配置文件路径-T N 设置远程命令超时时间，单位秒-u USER 连接远程主机用户名-x HOSTS 以逗号分隔排除主机-z INT 并发进程数 fabfile全局属性 (env对象)","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://github.com/cyylog/categories/DevOps/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://github.com/cyylog/tags/Python/"}]},{"title":"Vue之入门篇_001","slug":"DevOPs/Vue入门之001","date":"2020-05-31T08:20:44.000Z","updated":"2020-09-14T06:34:03.579Z","comments":true,"path":"2020/05/31/DevOPs/Vue入门之001/","link":"","permalink":"https://github.com/cyylog/2020/05/31/DevOPs/Vue%E5%85%A5%E9%97%A8%E4%B9%8B001/","excerpt":"","text":"文档https://cli.vuejs.org/zh/ 以文档为主 安装https://cli.vuejs.org/zh/guide/installation.html 1. 开始 1、打开终端执行 npm install -g @vue/cli 接下来可以用vue -V 看版本，或where vue 看下装到哪了 2. 创建项目https://cli.vuejs.org/zh/guide/creating-a-project.html#vue-create 在你的当前文件夹下执行 1vue create myvue 1、具体看文档操作（使用默认选项） 2、创建好后，会出现一个myvue文件夹，然后用webstorm打开它 运行和配置 首先运行在当前项目目录下执行 npm run serve 默认会启动webpack –devserver(仅仅开发使用),默认端口是 8080 配置进入https://cli.vuejs.org/zh/config/#vue-config-js 创建vue.config.js （注意和package.json同级、同级、同级） 写入如下内容 12345module.exports &#x3D; &#123; devServer: &#123; port: 3000 &#125;&#125; 或者看https://cn.vuejs.org/v2/api/#%E5%AE%9E%E4%BE%8B%E5%B1%9E%E6%80%A7 123new Vue(&#123; data:&#123;name:&quot;lisi&quot;&#125; &#125;).$mount(&#39;#app&#39;); 使用template1234567new Vue(&#123; data:&#123; name:&quot;aa&quot; &#125;, template:&quot;&lt;h1&gt;&#123;&#123;name&#125;&#125;&lt;&#x2F;h1&gt;&quot; &#125; ).$mount(&#39;#app&#39;); 使用渲染函数123456789101112131415161718new Vue(&#123; data:&#123; name:&quot;aa&quot; &#125;, template:&quot;&lt;h1&gt;&#123;&#123;name&#125;&#125;&lt;&#x2F;h1&gt;&quot; &#125; ).$mount(&#39;#app&#39;);已及new Vue(&#123; data:&#123; name:&quot;lisi&quot; &#125;, render(c)&#123; return c(&quot;h1&quot;,&#123;style:&#123;color:&#39;red&#39;&#125;&#125;,this.name) &#125; &#125; ).$mount(&#39;#app&#39;); 路由入门1、安装https://router.vuejs.org/zh/installation.html 2、使用引导https://router.vuejs.org/zh/guide/#html 在项目目录下执行 1npm install vue-router iview文档http://iview.talkingdata.com/#/components/guide/start 12345首先 搞一个 文件夹 ，执行 1、vue create myui 2、用webstorm 打开这个文件夹3、npm install iview --save 安装iview框架4 、 npm install --save vue-router 安装vue路由","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://github.com/cyylog/categories/DevOps/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"https://github.com/cyylog/tags/Vue/"}]},{"title":"计划任务及日志管理","slug":"Linux/计划任务及日志管理","date":"2020-05-30T15:33:41.000Z","updated":"2020-05-30T15:34:52.084Z","comments":true,"path":"2020/05/30/Linux/计划任务及日志管理/","link":"","permalink":"https://github.com/cyylog/2020/05/30/Linux/%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1%E5%8F%8A%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/","excerpt":"","text":"循环调度执行cron1.1简介cron1crond的概念和crontab是不可分割的。crontab是一个命令，常见于Unix和类Unix的操作系统之中，用于设置周期性被执行的指令。该命令从标准输入设备读取指令，并将其存放于“crontab”文件中，以供之后读取和执行 1.2认识crond进程123456789101112131415161718[root@JX01 ~]# systemctl status crond● crond.service - Command Scheduler Loaded: loaded (/usr/lib/systemd/system/crond.service; enabled; vendor preset: enabled) Active: active (running) since 三 2018-08-01 07:03:23 CST; 17min ago Main PID: 671 (crond) CGroup: /system.slice/crond.service └─671 /usr/sbin/crond -n8月 01 07:03:23 JX01 systemd[1]: Started Command Scheduler.8月 01 07:03:23 JX01 systemd[1]: Starting Command Scheduler...8月 01 07:03:23 JX01 crond[671]: (CRON) INFO (RANDOM_DELAY will be scaled with factor 2% if used.)8月 01 07:03:23 JX01 crond[671]: (CRON) INFO (running with inotify support)[root@JX01 ~]#[root@JX01 ~]# ps aux | grep crondroot 671 0.0 0.0 126280 1668 ? Ss 07:03 0:00 /usr/sbin/crond -nroot 1440 0.0 0.0 112720 980 pts/0 R+ 07:21 0:00 grep --color=auto crond[root@JX01 ~]# 1.3创建计划任务12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#计划任务存储的位置[root@JX01 ~]# ls /var/spool/cron/root jack alice#管理计划任务的命令crontab: -l Displays the current crontab on standard output. -r Removes the current crontab. -e Edits the current crontab using the editor specified.#计划任务书写的格式.---------------- minute (0 - 59)| .-------------- hour (0 - 23)| | .------------ day of month (1 - 31)| | | .---------- month (1 - 12) OR jan,feb,mar,apr ...| | | | .-------- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat| | | | |* * * * * command#计划任务案例00 02 * * * ls //每天2:00整00 02 1 * * ls //每月1号2:00整00 02 14 2 * ls //每年2月14号2:00整00 02 * * 7 ls //每周日2:00整00 02 * 6 5 ls //每年6月的周五2:00整（特殊）00 02 14 * 7 ls //每月14号2:00整 或者 每周日2:00整，这两个时间都执行00 02 14 2 7 ls //每年2月14号2:00整 或者 每周日2:00整，这两个时间都执行00 02 * * * ls //每天2:00整* 02 * * * ls //每天2:00中的每一分钟* * * * * ls //每分钟执行ls* * 14 2 * ls //2月14号的每分钟 1440分钟*/5 * * * * ls //每隔5分钟00 02 1,5,8 * * ls //每月1,5,8号的2:00整00 02 1-8 * * ls //每月1到8号的2:00整00 02 * 1-10 * ls#测试计划任务的执行效果1 编写执行脚本.vim /crontab.sh touch /root/`date +%F-%X`.txt2 编排任务计划[root@localhost ~]# crontab -e* * 1 1 * bash /crontab.sh3 修改日期时间为1月2日3点4分date 01020304修改时间为1点2分3秒date -s 01:02:034 监控当前目录watch -n 0.5 'ls /root/*.txt'5 测试目标* * * * 1 //每周1 每分钟会执行* * * 1 * //1月每日 每分钟会执行* * * 1 1 //1月的周1 每分钟会执行* * 1 * * //每月1日 每分钟会执行* * 1 * 1 //每月1日和每月周1 每分钟会执行* * 1 1 * //1月1日 每分钟会执行* * 1 1 1 //1月1日和1月的周1 每分钟都会执行 日志管理12345678910111213141516171819 日志：在现代社会里,为了维护自身系统资源的运行状况,计算机系统一般都会有相应的日志记录系统有关日常事件或者误操作警报的日期及时间戳信息。这些日志信息对计算机犯罪调查人员非常有用,但计算机日记是按正常工作状态记录的,所以冗余量很大,对查找与分析有用信息造成很大困难。#Linux系统中存在的日志都在哪里？&#x2F;var&#x2F;log&#x2F; # tail &#x2F;var&#x2F;log&#x2F;messages &#x2F;&#x2F;系统主日志文件 # tail -20 &#x2F;var&#x2F;log&#x2F;messages # tail -f &#x2F;var&#x2F;log&#x2F;messages &#x2F;&#x2F;动态查看日志文件的尾部 # tailf &#x2F;var&#x2F;log&#x2F;secure &#x2F;&#x2F;认证、安全 # tail &#x2F;var&#x2F;log&#x2F;maillog &#x2F;&#x2F;跟邮件postfix相关 prefix # tail &#x2F;var&#x2F;log&#x2F;cron &#x2F;&#x2F;crond、at进程产生的日志 # tail &#x2F;var&#x2F;log&#x2F;dmesg &#x2F;&#x2F;和系统启动相关 # tail &#x2F;var&#x2F;log&#x2F;audit&#x2F;audit.log &#x2F;&#x2F;系统审计日志 # tail &#x2F;var&#x2F;log&#x2F;yum.log &#x2F;&#x2F;yum # tail &#x2F;var&#x2F;log&#x2F;mysqld.log &#x2F;&#x2F;MySQL # tail &#x2F;var&#x2F;log&#x2F;xferlog &#x2F;&#x2F;和访问FTP服务器相关 # tail &#x2F;var&#x2F;log&#x2F;wtmp &#x2F;&#x2F;当前登录的用户（命令：w） # tail &#x2F;var&#x2F;log&#x2F;btmp &#x2F;&#x2F;最近登录的用户（命令last） # tail &#x2F;var&#x2F;log&#x2F;lastlog &#x2F;&#x2F;所有用户的登录情况（命令lastlog）#Linux系统是什么进程程序在管理日志？rsyslog 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051##rsyslogrsyslog：linux系统中管理日志的服务所产生的进程是: rsyslogd -nlinux中的配置文件: linux中所有的服务或者工具,都是由配置文件驱动工作的; Linux中的工具或服务都是遵循配置文件中的规则工作的;/etc/rsyslog.conf: 这个文件定义了系统中所有的服务或者工具,它们所产生的日志,根据特定的级别需要存储在特定的位置日志等级: 等级由低到高：debug&lt;info&lt;warn&lt;Error&lt;Fatal系统或服务的排错: 根据配置文件的对错有一下两种方案供给选择: 1. 查看rsyslog的 journalctl -xe 找出服务或系统的报错信息 2. 根据服务自身的检测机制,去检查配置文件的语法 3. 系统常用排错指令 journalctl -xe\\\\ systemctl status service.name\\\\ 服务自带检测工具bash -nx 检测shell脚本的语法问题httpd -t 检测apache web服务的配置文件语法问题nginx -t 检测nginx web服务的配置文件语法问题[root@JX02 ~]# vim /etc/rsyslog.conf#### RULES ##### Log all kernel messages to the console.# Logging much else clutters up the screen.#kern.* /dev/console# Log anything (except mail) of level info or higher.# Don't log private authentication messages!*.info;mail.none;authpriv.none;cron.none /var/log/messages# The authpriv file has restricted access.authpriv.* /var/log/secure# Log all the mail messages in one place.mail.* -/var/log/maillog# Log cron stuffcron.* /var/log/cron# Everybody gets emergency messages*.emerg :omusrmsg:*# Save news errors of level crit and higher in a special file.uucp,news.crit /var/log/spooler# Save boot messages also to boot.loglocal7.* /var/log/boot.log 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127##logrotate#认识一下logrotate为了节省空间和整理方便，日志文件经常需要按！时间或！大小等维度分成多份，删除时间久远的日志文件。这就是通常说的日志滚动(log rotation)logrotate本身不是系统守护进程，它是通过计划任务crond每天执行#logrotate配置文件：主文件：/etc/logrotate.conf (决定每个日志文件如何轮转)子文件夹：/etc/logrotate.d/*#认识logrotate的选项含义==================全局设置==================weekly //轮转周期，一周轮转rotate 4 //保留4份create //轮转后创建新文件dateext //使用日期作为后缀compress //是否压缩include /etc/logrotate.d //包含该目录下的文件/var/log/wtmp &#123; //对该日志文件设置轮转的方法 monthly //一个月轮转一次 create 0664 root utmp //轮转后创建新文件，并设置权限 minsize 1M //最小达到1M才轮转 rotate 1 //保留一份&#125;/var/log/btmp &#123; missingok //丢失不提示 monthly create 0600 root utmp rotate 1&#125;=========================================参数========================================compress 通过gzip 压缩转储以后的日志nocompress 不做gzip压缩处理copytruncate 用于还在打开中的日志文件，把当前日志备份并截断；是先拷贝再清空的方式，拷贝和清空之间有一个时间差，可能会丢失部分日志数据。nocopytruncate 备份日志文件不过不截断create mode owner group 轮转时指定创建新文件的属性，如create 0777 nobody nobodynocreate 不建立新的日志文件delaycompress 和compress 一起使用时，转储的日志文件到下一次转储时才压缩nodelaycompress 覆盖 delaycompress 选项，转储同时压缩missingok 如果日志丢失，不报错继续滚动下一个日志errors address 专储时的错误信息发送到指定的Email 地址ifempty 即使日志文件为空文件也做轮转，这个是logrotate的缺省选项notifempty 当日志文件为空时，不进行轮转mail address 把转储的日志文件发送到指定的E-mail 地址nomail 转储时不发送日志文件olddir directory 转储后的日志文件放入指定的目录，必须和当前日志文件在同一个文件系统noolddir 转储后的日志文件和当前日志文件放在同一个目录下sharedscripts运行postrotate脚本，作用是在所有日志都轮转后统一执行一次脚本。如果没有配置这个，那么每个日志轮转后都会执行一次脚本prerotate 在logrotate转储之前需要执行的指令，例如修改文件的属性等动作；必须独立成行postrotate 在logrotate转储之后需要执行的指令，例如重新启动 (kill -HUP) 某个服务！必须独立成行daily 指定转储周期为每天weekly 指定转储周期为每周monthly 指定转储周期为每月rotate count 指定日志文件删除之前转储的次数，0 指没有备份，5 指保留5 个备份dateext 使用当期日期作为命名格式dateformat .%s配合dateext使用，紧跟在下一行出现，定义文件切割后的文件名，必须配合dateext使用，只支持 %Y %m %d %s 这四个参数size(或minsize) log-size当日志文件到达指定的大小时才轮转，log-size能指定bytes(缺省)及KB (sizek)或MB(sizem).当日志文件 &gt;= log-size 的时候就转储。 以下为合法格式：（其他格式的单位大小写没有试过）size = 5 或 size 5 （&gt;= 5 个字节就转储）size = 100k 或 size 100ksize = 100M 或 size 100M=================================================================================#案例一:普通切割[root@JX02 ~]# vim /etc/logrotate.d/yum/var/log/yum.log &#123;missingok //丢失不执行# notifempty //空文件不轮转# size 30k //达到30k轮转, daily or size# yearly //或者一年一轮转daily //缩小周期到1天rotate 3 //轮转保留3次create 0777 root root&#125;[root@JX02 ~]# /usr/sbin/logrotate -f /etc/logrotate.conf //强制轮转日志[root@JX02 ~]# ll /var/log/yum* //发现日志已经被切割了#案例二:切割前后执行动作[root@JX02 ~]# vim /etc/logrotate.d/httpd/var/log/httpd/* &#123;prerotatechattr -a /var/log/httpdendscript#notifemptydailycreate 0600 root rootmissingokrotate 5postrotatechattr +a /var/log/httpdendscript&#125;[root@JX02 logrotate.d]# /usr/sbin/logrotate -f /etc/logrotate.conf#案例三:切割多个日志文件[root@JX02 ~]# vim /etc/logrotate.d/web/var/log/httpd_test.log/var/log/nginx_test.log/var/log/tomcat_test.log&#123;dailycreate 0600 root rootmissingokrotate 5&#125;[root@JX02 ~]# /usr/sbin/logrotate -f /etc/logrotate.conf#案例四:切割一个文件夹下的所有日志[root@JX02 ~]# vim /etc/logrotate.d/apache/var/log/apache/*log &#123;dailycreate 0600 root rootmissingokrotate 5&#125;[root@JX02 logrotate.d]# /usr/sbin/logrotate -f /etc/logrotate.conf","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/tags/Linux/"}]},{"title":"Jenkins_流水线语法_002","slug":"DevOPs/Jenkins-流水线语法-002","date":"2020-05-30T04:43:37.000Z","updated":"2020-05-30T13:56:43.585Z","comments":true,"path":"2020/05/30/DevOPs/Jenkins-流水线语法-002/","link":"","permalink":"https://github.com/cyylog/2020/05/30/DevOPs/Jenkins-%E6%B5%81%E6%B0%B4%E7%BA%BF%E8%AF%AD%E6%B3%95-002/","excerpt":"","text":"参数parameters 指令提供了一个用户在触发流水线时应该提供的参数列表。这些用户指定参数的值可通过 params 对象提供给流水线步骤, 了解更多请参考示例。 Required No Parameters None Allowed Only once, inside the pipeline block. 可用参数 string 字符串类型的参数, 例如: parameters { string(name: &#39;DEPLOY_ENV&#39;, defaultValue: &#39;staging&#39;, description: &#39;&#39;) } booleanParam 布尔参数, 例如: parameters { booleanParam(name: &#39;DEBUG_BUILD&#39;, defaultValue: true, description: &#39;&#39;) } 示例Jenkinsfile (Declarative Pipeline) 12345678910111213pipeline &#123; agent any parameters &#123; string(name: 'PERSON', defaultValue: 'Mr Jenkins', description: 'Who should I say hello to?') &#125; stages &#123; stage('Example') &#123; steps &#123; echo \"Hello $&#123;params.PERSON&#125;\" &#125; &#125; &#125;&#125; 一份完整的可用参数列表正在等待 INFRA-1503的完成。 触发器triggers 指令定义了流水线被重新触发的自动化方法。对于集成了源（ 比如 GitHub 或 BitBucket）的流水线, 可能不需要 triggers ，因为基于 web 的集成很肯能已经存在。 当前可用的触发器是 cron, pollSCM 和 upstream。 Required No Parameters None Allowed Only once, inside the pipeline block. cron 接收 cron 样式的字符串来定义要重新触发流水线的常规间隔 ,比如: triggers { cron(&#39;H */4 * * 1-5&#39;) } pollSCM 接收 cron 样式的字符串来定义一个固定的间隔，在这个间隔中，Jenkins 会检查新的源代码更新。如果存在更改, 流水线就会被重新触发。例如: triggers { pollSCM(&#39;H */4 * * 1-5&#39;) } upstream 接受逗号分隔的工作字符串和阈值。 当字符串中的任何作业以最小阈值结束时，流水线被重新触发。例如: triggers { upstream(upstreamProjects: &#39;job1,job2&#39;, threshold: hudson.model.Result.SUCCESS) } pollSCM 只在Jenkins 2.22 及以上版本中可用。 示例Jenkinsfile (Declarative Pipeline) 12345678910111213pipeline &#123; agent any triggers &#123; cron('H */4 * * 1-5') &#125; stages &#123; stage('Example') &#123; steps &#123; echo 'Hello World' &#125; &#125; &#125;&#125; stagestage 指令在 stages 部分进行，应该包含一个 实际上, 流水巷所做的所有实际工作都将封装进一个或多个 stage 指令中。 Required At least one Parameters One mandatory parameter, a string for the name of the stage. Allowed Inside the stages section. 示例Jenkinsfile (Declarative Pipeline) 12345678910pipeline &#123; agent any stages &#123; stage('Example') &#123; steps &#123; echo 'Hello World' &#125; &#125; &#125;&#125; 工具定义自动安装和放置 PATH 的工具的一部分。如果 agent none 指定，则忽略该操作。 Required No Parameters None Allowed Inside the pipeline block or a stage block. 支持工具 maven jdk gradle 示例Jenkinsfile (Declarative Pipeline) 12345678910111213pipeline &#123; agent any tools &#123; maven 'apache-maven-3.0.1' &#125; stages &#123; stage('Example') &#123; steps &#123; sh 'mvn --version' &#125; &#125; &#125;&#125; The tool name must be pre-configured in Jenkins under Manage Jenkins → Global Tool Configuration. 工具名称必须在Jenkins中的Manage Jenkins→全局工具配置下预先配置。 inputstage 的 input 指令允许你使用 input step提示输入。 在应用了 options 后，进入 stage 的 agent 或评估 when 条件前， stage 将暂停。 如果 input 被批准, stage 将会继续。 作为 input 提交的一部分的任何参数都将在环境中用于其他 stage。 配置项 message 必需的。 这将在用户提交 input 时呈现给用户。 id input 的可选标识符， 默认为 stage 名称。 ok input表单上的”ok” 按钮的可选文本。 submitter 可选的以逗号分隔的用户列表或允许提交 input 的外部组名。默认允许任何用户。 submitterParameter 环境变量的可选名称。如果存在，用 submitter 名称设置。 parameters 提示提交者提供的一个可选的参数列表。 更多信息参见 [parameters]。 示例Jenkinsfile (Declarative Pipeline) 123456789101112131415161718pipeline &#123; agent any stages &#123; stage('Example') &#123; input &#123; message \"Should we continue?\" ok \"Yes, we should.\" submitter \"alice,bob\" parameters &#123; string(name: 'PERSON', defaultValue: 'Mr Jenkins', description: 'Who should I say hello to?') &#125; &#125; steps &#123; echo \"Hello, $&#123;PERSON&#125;, nice to meet you.\" &#125; &#125; &#125;&#125; whenwhen 指令允许流水线根据给定的条件决定是否应该执行阶段。 when 指令必须包含至少一个条件。 如果 when 指令包含多个条件, 所有的子条件必须返回True，阶段才能执行。 这与子条件在 allOf 条件下嵌套的情况相同 (参见下面的示例)。 使用诸如 not, allOf, 或 anyOf 的嵌套条件可以构建更复杂的条件结构 can be built 嵌套条件刻意潜逃到任意深度。 Required No Parameters None Allowed Inside a stage directive 内置条件 branch 当正在构建的分支与模式给定的分支匹配时，执行这个阶段, 例如: when { branch &#39;master&#39; }。注意，这只适用于多分支流水线。 environment 当指定的环境变量是给定的值时，执行这个步骤, 例如: when { environment name: &#39;DEPLOY_TO&#39;, value: &#39;production&#39; } expression 当指定的Groovy表达式评估为true时，执行这个阶段, 例如: when { expression { return params.DEBUG_BUILD } } not 当嵌套条件是错误时，执行这个阶段,必须包含一个条件，例如: when { not { branch &#39;master&#39; } } allOf 当所有的嵌套条件都正确时，执行这个阶段,必须包含至少一个条件，例如: when { allOf { branch &#39;master&#39;; environment name: &#39;DEPLOY_TO&#39;, value: &#39;production&#39; } } anyOf 当至少有一个嵌套条件为真时，执行这个阶段,必须包含至少一个条件，例如: when { anyOf { branch &#39;master&#39;; branch &#39;staging&#39; } } 在进入 stage 的 agent 前评估 when默认情况下, 如果定义了某个阶段的代理，在进入该stage 的 agent 后该 stage 的 when 条件将会被评估。但是, 可以通过在 when 块中指定 beforeAgent 选项来更改此选项。 如果 beforeAgent 被设置为 true, 那么就会首先对 when 条件进行评估 , 并且只有在 when 条件验证为真时才会进入 agent 。 示例Jenkinsfile (Declarative Pipeline) 123456789101112131415161718pipeline &#123; agent any stages &#123; stage('Example Build') &#123; steps &#123; echo 'Hello World' &#125; &#125; stage('Example Deploy') &#123; when &#123; branch 'production' &#125; steps &#123; echo 'Deploying' &#125; &#125; &#125;&#125; Jenkinsfile (Declarative Pipeline) 12345678910111213141516171819pipeline &#123; agent any stages &#123; stage('Example Build') &#123; steps &#123; echo 'Hello World' &#125; &#125; stage('Example Deploy') &#123; when &#123; branch 'production' environment name: 'DEPLOY_TO', value: 'production' &#125; steps &#123; echo 'Deploying' &#125; &#125; &#125;&#125; Jenkinsfile (Declarative Pipeline) 123456789101112131415161718192021pipeline &#123; agent any stages &#123; stage('Example Build') &#123; steps &#123; echo 'Hello World' &#125; &#125; stage('Example Deploy') &#123; when &#123; allOf &#123; branch 'production' environment name: 'DEPLOY_TO', value: 'production' &#125; &#125; steps &#123; echo 'Deploying' &#125; &#125; &#125;&#125; Jenkinsfile (Declarative Pipeline) 12345678910111213141516171819202122pipeline &#123; agent any stages &#123; stage('Example Build') &#123; steps &#123; echo 'Hello World' &#125; &#125; stage('Example Deploy') &#123; when &#123; branch 'production' anyOf &#123; environment name: 'DEPLOY_TO', value: 'production' environment name: 'DEPLOY_TO', value: 'staging' &#125; &#125; steps &#123; echo 'Deploying' &#125; &#125; &#125;&#125; Jenkinsfile (Declarative Pipeline) 12345678910111213141516171819202122pipeline &#123; agent any stages &#123; stage('Example Build') &#123; steps &#123; echo 'Hello World' &#125; &#125; stage('Example Deploy') &#123; when &#123; expression &#123; BRANCH_NAME ==~ /(production|staging)/ &#125; anyOf &#123; environment name: 'DEPLOY_TO', value: 'production' environment name: 'DEPLOY_TO', value: 'staging' &#125; &#125; steps &#123; echo 'Deploying' &#125; &#125; &#125;&#125; Jenkinsfile (Declarative Pipeline) 12345678910111213141516171819202122pipeline &#123; agent none stages &#123; stage('Example Build') &#123; steps &#123; echo 'Hello World' &#125; &#125; stage('Example Deploy') &#123; agent &#123; label \"some-label\" &#125; when &#123; beforeAgent true branch 'production' &#125; steps &#123; echo 'Deploying' &#125; &#125; &#125;&#125; 并行声明式流水线的阶段可以在他们内部声明多隔嵌套阶段, 它们将并行执行。 注意，一个阶段必须只有一个 steps 或 parallel 的阶段。 嵌套阶段本身不能包含进一步的 parallel 阶段, 但是其他的阶段的行为与任何其他 stage 相同。任何包含 parallel 的阶段不能包含 agent 或 tools 阶段, 因为他们没有相关 steps。 另外, 通过添加 failFast true 到包含 parallel的 stage 中， 当其中一个进程失败时，你可以强制所有的 parallel 阶段都被终止。 示例Jenkinsfile (Declarative Pipeline) 12345678910111213141516171819202122232425262728293031323334pipeline &#123; agent any stages &#123; stage('Non-Parallel Stage') &#123; steps &#123; echo 'This stage will be executed first.' &#125; &#125; stage('Parallel Stage') &#123; when &#123; branch 'master' &#125; failFast true parallel &#123; stage('Branch A') &#123; agent &#123; label \"for-branch-a\" &#125; steps &#123; echo \"On Branch A\" &#125; &#125; stage('Branch B') &#123; agent &#123; label \"for-branch-b\" &#125; steps &#123; echo \"On Branch B\" &#125; &#125; &#125; &#125; &#125;&#125; 步骤声明式流水线可能使用在 流水线步骤引用中记录的所有可用的步骤, 它包含一个完整的步骤列表, 其中添加了下面列出的步骤，这些步骤只在声明式流水线中 only supported 。 脚本script 步骤需要 [scripted-pipeline]块并在声明式流水线中执行。 对于大多数用例来说,应该声明式流水线中的“脚本”步骤是不必要的， 但是它可以提供一个有用的”逃生出口”。 非平凡的规模和/或复杂性的 script 块应该被转移到 共享库 。 示例Jenkinsfile (Declarative Pipeline) 1234567891011121314151617pipeline &#123; agent any stages &#123; stage('Example') &#123; steps &#123; echo 'Hello World' script &#123; def browsers = ['chrome', 'firefox'] for (int i = 0; i &lt; browsers.size(); ++i) &#123; echo \"Testing the $&#123;browsers[i]&#125; browser\" &#125; &#125; &#125; &#125; &#125;&#125; 脚本化流水线脚本化流水线, 与[declarative-pipeline]一样的是, 是建立在底层流水线的子系统上的。与声明式不同的是, 脚本化流水线实际上是由 Groovy构建的通用 DSL [2]。 Groovy 语言提供的大部分功能都可以用于脚本化流水线的用户。这意味着它是一个非常有表现力和灵活的工具，可以通过它编写持续交付流水线。 流控制脚本化流水线从 Jenkinsfile 的顶部开始向下串行执行, 就像 Groovy 或其他语言中的大多数传统脚本一样。 因此，提供流控制取决于 Groovy 表达式, 比如 if/else 条件, 例如: Jenkinsfile (Scripted Pipeline) 123456789node &#123; stage('Example') &#123; if (env.BRANCH_NAME == 'master') &#123; echo 'I only execute on the master branch' &#125; else &#123; echo 'I execute elsewhere' &#125; &#125;&#125; 另一种方法是使用Groovy的异常处理支持来管理脚本化流水线流控制。当 步骤 失败 ，无论什么原因，它们都会抛出一个异常。处理错误的行为必须使用Groovy中的 try/catch/finally 块 , 例如: Jenkinsfile (Scripted Pipeline) 1234567891011node &#123; stage('Example') &#123; try &#123; sh 'exit 1' &#125; catch (exc) &#123; echo 'Something failed, I should sound the klaxons!' throw &#125; &#125;&#125; 步骤正如 本章开始所讨论的, 流水线最基础的部分是”步骤”。从根本上说, 步骤告诉 Jenkins要做 what ，并作为声明式和脚本化流水线已发的基本构建块。 脚本化流水线 not 不引入任何特定于其语法的步骤; 流水线步骤引用 包括流水线和插件提供的步骤的完整列表。 区别普通 Groovy为了提供 durability, 这意味着运行流水线可以在Jenkins master 重启后继续运行，脚本化的流水线序列化数据到主服务器。由于这个设计需求, 一些Groovy 习惯用语，比如 collection.each { item -&gt; /* perform operation */ } 都不完全支持。详情参见 JENKINS-27421 和 JENKINS-26481。 语法比较当Jenkins 流水线第一次构建时, Groovy 被选为基础。 Jenkins长期使用嵌入式 Groovy引擎来为管理员和用户提供 高级脚本功能。另外, Jenkins流水线的实现者发现 Groovy是 构建现在成为 “脚本化流水线” DSL的坚实基础 [2]。 由于它是一个功能齐全的编程环境, 脚本化流水线为Jenkins用户提供了 大量的灵活性性和可扩展性。 Groovy学习曲线通常不适合给定团队的所有成员, 因此创造了声明式流水线来为编写Jenkins流水线提供一种更简单、更有主见的语法。 两者本质上是相同的流水线子系统。 underneath. 他们都是 “流水线即代码” 的持久实现。它们都能够使用构建到流水线中或插件提供的步骤。它们都能够使用 共享库 但是它们的区别在于语法和灵活性。 声明式限制了用户使用更严格和预定义的结构， 使其成为更简单的持续交付流水线的理想选择。 脚本化提供了很少的限制, 以至于对脚本和语法的唯一限制往往是由Groovy子集本身定义的，而不是任何特定于流水线的系统, 这使他成为权利用户和那些有更复杂需求的人的理想选择。 顾名思义, 声明式流水线鼓励 声明式编程模型。 [3] 而脚本化流水线遵循一个更命令式的编程模型 [4]","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://github.com/cyylog/categories/DevOps/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://github.com/cyylog/tags/Jenkins/"}]},{"title":"Jenkins_流水线语法_001","slug":"DevOPs/Jenkins-流水线语法-001","date":"2020-05-28T13:43:32.000Z","updated":"2020-05-30T13:54:45.129Z","comments":true,"path":"2020/05/28/DevOPs/Jenkins-流水线语法-001/","link":"","permalink":"https://github.com/cyylog/2020/05/28/DevOPs/Jenkins-%E6%B5%81%E6%B0%B4%E7%BA%BF%E8%AF%AD%E6%B3%95-001/","excerpt":"","text":"流水线语法本节是建立在 流水线入门内容的基础上，而且，应当被当作一个参考。 对于在实际示例中如何使用流水线语法的更多信息, 请参阅本章在流水线插件的2.5版本中的 使用 Jenkinsfile部分, 流水线支持两种离散的语法，具体如下对于每种的优缺点, 参见语法比较。 正如 本章开始讨论的, 流水线最基础的部分是 “步骤”。基本上, 步骤告诉 Jenkins 要做什么，以及作为声明式和脚本化流水线语法的基本构建块。 对于可用步骤的概述, 请参考 流水线步骤引用，它包含了一个构建到流水线的步骤和 插件提供的步骤的全面的列表。 声明式流水线声明式流水线是最近添加到 Jenkins 流水线的 [1]，它在流水线子系统之上提供了一种更简单，更有主见的语法。 所有有效的声明式流水线必须包含在一个 pipeline 块中, 比如: 123pipeline &#123; &#x2F;* insert Declarative Pipeline here *&#x2F;&#125; 在声明式流水线中有效的基本语句和表达式遵循与 Groovy的语法同样的规则， 有以下例外: 流水线顶层必须是一个 block, 特别地: pipeline { } 没有分号作为语句分隔符，，每条语句都必须在自己的行上。 块只能由 节段, 指令, 步骤, 或赋值语句组成。 *属性引用语句被视为无参方法调用。 例如, input被视为 input() 节段声明式流水线中的节段通常包含一个或多个 指令 或 步骤。 代理agent 部分指定了整个流水线或特定的部分, 将会在Jenkins环境中执行的位置，这取决于 agent 区域的位置。该部分必须在 pipeline 块的顶层被定义, 但是 stage 级别的使用是可选的。 Required Yes Parameters Described below Allowed In the top-level pipeline block and each stage block. 参数为了支持作者可能有的各种各样的用例流水线, agent 部分支持一些不同类型的参数。这些参数应用在pipeline块的顶层, 或 stage 指令内部。 any 在任何可用的代理上执行流水线或阶段。例如: agent any none 当在 pipeline 块的顶部没有全局代理， 该参数将会被分配到整个流水线的运行中并且每个 stage 部分都需要包含他自己的 agent 部分。比如: agent none label 在提供了标签的 Jenkins 环境中可用的代理上执行流水线或阶段。 例如: agent { label &#39;my-defined-label&#39; } node agent { node { label &#39;labelName&#39; } } 和 agent { label &#39;labelName&#39; } 一样, 但是 node 允许额外的选项 (比如 customWorkspace )。 docker 使用给定的容器执行流水线或阶段。该容器将在预置的 node上，或在匹配可选定义的label 参数上，动态的供应来接受基于Docker的流水线。 docker 也可以选择的接受 args 参数，该参数可能包含直接传递到 docker run 调用的参数, 以及 alwaysPull 选项, 该选项强制 docker pull ，即使镜像名称已经存在。 比如: 1234567agent &#123; docker &#123; image &#39;maven:3-alpine&#39; label &#39;my-defined-label&#39; args &#39;-v &#x2F;tmp:&#x2F;tmp&#39; &#125;&#125; dockerfile 执行流水线或阶段, 使用从源代码库包含的 Dockerfile 构建的容器。为了使用该选项， Jenkinsfile 必须从多个分支流水线中加载, 或者加载 “Pipeline from SCM.” 通常，这是源代码仓库的根目录下的 Dockerfile : agent { dockerfile true }. 如果在另一个目录下构建 Dockerfile , 使用 dir 选项: agent { dockerfile {dir &#39;someSubDir&#39; } }。如果 Dockerfile 有另一个名称, 你可以使用 filename 选项指定该文件名。你可以传递额外的参数到 docker build ... 使用 additionalBuildArgs 选项提交, 比如 agent { dockerfile {additionalBuildArgs &#39;--build-arg foo=bar&#39; } }。 例如, 一个带有 build/Dockerfile.build 的仓库,期望一个构建参数 version: 123456789agent &#123; &#x2F;&#x2F; Equivalent to &quot;docker build -f Dockerfile.build --build-arg version&#x3D;1.0.2 .&#x2F;build&#x2F; dockerfile &#123; filename &#39;Dockerfile.build&#39; dir &#39;build&#39; label &#39;my-defined-label&#39; additionalBuildArgs &#39;--build-arg version&#x3D;1.0.2&#39; &#125;&#125; 常见选项有一些应用于两个或更多 agent 的实现的选项。他们不被要求，除非特别规定。 label 一个字符串。该标签用于运行流水线或个别的 stage。该选项对 node, docker 和 dockerfile 可用, node要求必须选择该选项。 customWorkspace 一个字符串。在自定义工作区运行应用了 agent 的流水线或个别的 stage, 而不是默认值。 它既可以是一个相对路径, 在这种情况下，自定义工作区会存在于节点工作区根目录下, 或者一个绝对路径。比如: 123456agent &#123; node &#123; label &#39;my-defined-label&#39; customWorkspace &#39;&#x2F;some&#x2F;other&#x2F;path&#39; &#125;&#125; 该选项对 node, docker 和 dockerfile 有用 。 reuseNode 一个布尔值, 默认为false。 如果是true, 则在流水线的顶层指定的节点上运行该容器, 在同样的工作区, 而不是在一个全新的节点上。这个选项对 docker 和 dockerfile 有用, 并且只有当 使用在个别的 stage 的 agent 上才会有效。 示例Jenkinsfile (Declarative Pipeline) 12345678910pipeline &#123; agent &#123; docker 'maven:3-alpine' &#125; stages &#123; stage('Example Build') &#123; steps &#123; sh 'mvn -B clean verify' &#125; &#125; &#125;&#125; 在一个给定名称和标签(maven:3-alpine)的新建的容器上执行定义在流水线中的所有步骤 。 阶段级别的 agent 部分Jenkinsfile (Declarative Pipeline) 12345678910111213141516171819pipeline &#123; agent none stages &#123; stage('Example Build') &#123; agent &#123; docker 'maven:3-alpine' &#125; steps &#123; echo 'Hello, Maven' sh 'mvn --version' &#125; &#125; stage('Example Test') &#123; agent &#123; docker 'openjdk:8-jre' &#125; steps &#123; echo 'Hello, JDK' sh 'java -version' &#125; &#125; &#125;&#125; 在流水线顶层定义 agent none 确保 an Executor 没有被分配。 使用 agent none 也会强制 stage 部分包含他自己的 agent 部分。 使用镜像在一个新建的容器中执行该阶段的该步骤。 使用一个与之前阶段不同的镜像在一个新建的容器中执行该阶段的该步骤。 postpost 部分定义一个或多个steps ，这些阶段根据流水线或阶段的完成情况而 运行(取决于流水线中 post 部分的位置). post 支持以下 post-condition 块中的其中之一: always, changed, failure, success, unstable, 和 aborted。这些条件块允许在 post 部分的步骤的执行取决于流水线或阶段的完成状态。 Required No Parameters None Allowed In the top-level pipeline block and each stage block. Conditions always 无论流水线或阶段的完成状态如何，都允许在 post 部分运行该步骤。 changed 只有当前流水线或阶段的完成状态与它之前的运行不同时，才允许在 post 部分运行该步骤。 failure 只有当前流水线或阶段的完成状态为”failure”，才允许在 post 部分运行该步骤, 通常web UI是红色。 success 只有当前流水线或阶段的完成状态为”success”，才允许在 post 部分运行该步骤, 通常web UI是蓝色或绿色。 unstable 只有当前流水线或阶段的完成状态为”unstable”，才允许在 post 部分运行该步骤, 通常由于测试失败,代码违规等造成。通常web UI是黄色。 aborted 只有当前流水线或阶段的完成状态为”aborted”，才允许在 post 部分运行该步骤, 通常由于流水线被手动的aborted。通常web UI是灰色。 示例Jenkinsfile (Declarative Pipeline) 123456789101112131415pipeline &#123; agent any stages &#123; stage('Example') &#123; steps &#123; echo 'Hello World' &#125; &#125; &#125; post &#123; always &#123; echo 'I will always say Hello again!' &#125; &#125;&#125; 按照惯例, post 部分应该放在流水线的底部。 Post-condition 块包含与 steps 部分相同的steps。 stages包含一系列一个或多个 stage 指令, stages 部分是流水线描述的大部分”work” 的位置。 建议 stages 至少包含一个 stage 指令用于连续交付过程的每个离散部分,比如构建, 测试, 和部署。 Required Yes Parameters None Allowed Only once, inside the pipeline block. 示例Jenkinsfile (Declarative Pipeline) 12345678910pipeline &#123; agent any stages &#123; stage('Example') &#123; steps &#123; echo 'Hello World' &#125; &#125; &#125;&#125; stages 部分通常会遵循诸如 agent, options 等的指令。 stepssteps 部分在给定的 stage 指令中执行的定义了一系列的一个或多个steps。 Required Yes Parameters None Allowed Inside each stage block. 示例Jenkinsfile (Declarative Pipeline) 12345678910pipeline &#123; agent any stages &#123; stage('Example') &#123; steps &#123; echo 'Hello World' &#125; &#125; &#125;&#125; steps 部分必须包含一个或多个步骤。 指令environmentenvironment 指令制定一个 键-值对序列，该序列将被定义为所有步骤的环境变量，或者是特定于阶段的步骤， 这取决于 environment 指令在流水线内的位置。 该指令支持一个特殊的助手方法 credentials() ，该方法可用于在Jenkins环境中通过标识符访问预定义的凭证。对于类型为 “Secret Text”的凭证, credentials() 将确保指定的环境变量包含秘密文本内容。对于类型为 “SStandard username and password”的凭证, 指定的环境变量指定为 username:password ，并且两个额外的环境变量将被自动定义 :分别为 MYVARNAME_USR 和 MYVARNAME_PSW 。 Required No Parameters None Allowed Inside the pipeline block, or within stage directives. 示例Jenkinsfile (Declarative Pipeline) 12345678910111213141516pipeline &#123; agent any environment &#123; CC = 'clang' &#125; stages &#123; stage('Example') &#123; environment &#123; AN_ACCESS_KEY = credentials('my-prefined-secret-text') &#125; steps &#123; sh 'printenv' &#125; &#125; &#125;&#125; 顶层流水线块中使用的 environment 指令将适用于流水线中的所有步骤。 在一个 stage 中定义的 environment 指令只会将给定的环境变量应用于 stage 中的步骤。 environment 块有一个 助手方法 credentials() 定义，该方法可以在 Jenkins 环境中用于通过标识符访问预定义的凭证。 optionsoptions 指令允许从流水线内部配置特定于流水线的选项。 流水线提供了许多这样的选项, 比如 buildDiscarder,但也可以由插件提供, 比如 timestamps. Required No Parameters None Allowed Only once, inside the pipeline block. 可用选项 buildDiscarder 为最近的流水线运行的特定数量保存组件和控制台输出。例如: options { buildDiscarder(logRotator(numToKeepStr: &#39;1&#39;)) } disableConcurrentBuilds 不允许同时执行流水线。 可被用来防止同时访问共享资源等。 例如: options { disableConcurrentBuilds() } overrideIndexTriggers 允许覆盖分支索引触发器的默认处理。 如果分支索引触发器在多分支或组织标签中禁用, options { overrideIndexTriggers(true) } 将只允许它们用于促工作。否则, options { overrideIndexTriggers(false) } 只会禁用改作业的分支索引触发器。 skipDefaultCheckout 在agent 指令中，跳过从源代码控制中检出代码的默认情况。例如: options { skipDefaultCheckout() } skipStagesAfterUnstable 一旦构建状态变得UNSTABLE，跳过该阶段。例如: options { skipStagesAfterUnstable() } checkoutToSubdirectory 在工作空间的子目录中自动地执行源代码控制检出。例如: options { checkoutToSubdirectory(&#39;foo&#39;) } timeout 设置流水线运行的超时时间, 在此之后，Jenkins将中止流水线。例如: options { timeout(time: 1, unit: &#39;HOURS&#39;) } retry 在失败时, 重新尝试整个流水线的指定次数。 For example: options { retry(3) } timestamps 预谋所有由流水线生成的控制台输出，与该流水线发出的时间一致。 例如: options { timestamps() } ExampleJenkinsfile (Declarative Pipeline) 12345678910111213pipeline &#123; agent any options &#123; timeout(time: 1, unit: 'HOURS') &#125; stages &#123; stage('Example') &#123; steps &#123; echo 'Hello World' &#125; &#125; &#125;&#125; 指定一个小时的全局执行超时, 在此之后，Jenkins 将中止流水线运行。 一个完整的可用选项列表正在等待完成第 INFRA-1503次。 阶段选项stage 的 options 指令类似于流水线根目录上的 options 指令。然而， stage -级别 options 只能包括 retry, timeout, 或 timestamps 等步骤, 或与 stage 相关的声明式选项，如 skipDefaultCheckout。 在stage, options 指令中的步骤在进入 agent 之前被调用或在 when 条件出现时进行检查。 可选的阶段选项 skipDefaultCheckout 在 agent 指令中跳过默认的从源代码控制中检出代码。例如: options { skipDefaultCheckout() } timeout 设置此阶段的超时时间, 在此之后， Jenkins 会终止该阶段。 例如: options { timeout(time: 1, unit: &#39;HOURS&#39;) } retry 在失败时, 重试此阶段指定次数。 例如: options { retry(3) } timestamps 预谋此阶段生成的所有控制台输出以及该行发出的时间一致。例如: options { timestamps() } 示例Jenkinsfile (Declarative Pipeline) 12345678910111213pipeline &#123; agent any stages &#123; stage('Example') &#123; options &#123; timeout(time: 1, unit: 'HOURS') &#125; steps &#123; echo 'Hello World' &#125; &#125; &#125;&#125; 指定 Example 阶段的执行超时时间, 在此之后，Jenkins 将中止流水线运行。","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://github.com/cyylog/categories/DevOps/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://github.com/cyylog/tags/Jenkins/"}]},{"title":"Kubernetes组件—介绍001","slug":"容器/Kubernetes组件—介绍001","date":"2020-04-04T11:57:00.000Z","updated":"2020-09-16T06:01:52.488Z","comments":true,"path":"2020/04/04/容器/Kubernetes组件—介绍001/","link":"","permalink":"https://github.com/cyylog/2020/04/04/%E5%AE%B9%E5%99%A8/Kubernetes%E7%BB%84%E4%BB%B6%E2%80%94%E4%BB%8B%E7%BB%8D001/","excerpt":"","text":"本文档描述了 Kubernetes 的主要组件。 Master组件Master组件是集群的控制平台（control plane）： master 组件负责集群中的全局决策（例如，调度） master 组件探测并响应集群事件（例如，当 Deployment 的实际 Pod 副本数未达到 replicas 字段的规定时，启动一个新的 Pod） Master组件可以运行于集群中的任何机器上。但是，为了简洁性，通常在同一台机器上运行所有的 master 组件，且不在此机器上运行用户的容器。参考 安装Kubernetes高可用。 kube-apiserver此 master 组件提供 Kubernetes API。这是Kubernetes控制平台的前端（front-end），可以水平扩展（通过部署更多的实例以达到性能要求）。kubectl / kubernetes dashboard / kuboard 等Kubernetes管理工具就是通过 kubernetes API 实现对 Kubernetes 集群的管理。 etcd支持一致性和高可用的名值对存储组件，Kubernetes集群的所有配置信息都存储在 etcd 中。请确保您 备份 了 etcd 的数据。关于 etcd 的更多信息，可参考 etcd 官方文档 kube-scheduler此 master 组件监控所有新创建尚未分配到节点上的 Pod，并且自动选择为 Pod 选择一个合适的节点去运行。 影响调度的因素有： 单个或多个 Pod 的资源需求 硬件、软件、策略的限制 亲和与反亲和（affinity and anti-affinity）的约定 数据本地化要求 工作负载间的相互作用 kube-controller-manager此 master 组件运行了所有的控制器 逻辑上来说，每一个控制器是一个独立的进程，但是为了降低复杂度，这些控制器都被合并运行在一个进程里。 kube-controller-manager 中包含的控制器有： 节点控制器： 负责监听节点停机的事件并作出对应响应 副本控制器： 负责为集群中每一个 副本控制器对象（Replication Controller Object）维护期望的 Pod 副本数 端点（Endpoints）控制器：负责为端点对象（Endpoints Object，连接 Service 和 Pod）赋值 Service Account &amp; Token控制器： 负责为新的名称空间创建 default Service Account 以及 API Access Token cloud-controller-managercloud-controller-manager 中运行了与具体云基础设施供应商互动的控制器。这是 Kubernetes 1.6 版本中引入的特性，尚处在 alpha 阶段。 cloud-controller-manager 只运行特定于云基础设施供应商的控制器。如果您参考 www.kuboard.cn 上提供的文档安装 Kubernetes 集群，默认不安装 cloud-controller-manager。 cloud-controller-manager 使得云供应商的代码和 Kubernetes 的代码可以各自独立的演化。在此之前的版本中，Kubernetes的核心代码是依赖于云供应商的代码的。在后续的版本中，特定于云供应商的代码将由云供应商自行维护，并在运行Kubernetes时链接到 cloud-controller-manager。 以下控制器中包含与云供应商相关的依赖： 节点控制器：当某一个节点停止响应时，调用云供应商的接口，以检查该节点的虚拟机是否已经被云供应商删除 译者注：私有化部署Kubernetes时，我们不知道节点的操作系统是否删除，所以在移除节点后，要自行通过 kubectl delete node 将节点对象从 Kubernetes 中删除 路由控制器：在云供应商的基础设施中设定网络路由 译者注：私有化部署Kubernetes时，需要自行规划Kubernetes的拓扑结构，并做好路由配置，例如 安装Kubernetes单Master节点 中所作的 服务（Service）控制器：创建、更新、删除云供应商提供的负载均衡器 译者注：私有化部署Kubernetes时，不支持 LoadBalancer 类型的 Service，如需要此特性，需要创建 NodePort 类型的 Service，并自行配置负载均衡器 数据卷（Volume）控制器：创建、绑定、挂载数据卷，并协调云供应商编排数据卷 译者注：私有化部署Kubernetes时，需要自行创建和管理存储资源，并通过Kubernetes的存储类、存储卷、数据卷等与之关联 译者注：通过 cloud-controller-manager，Kubernetes可以更好地与云供应商结合，例如，在阿里云的 Kubernetes 服务里，您可以在云控制台界面上轻松点击鼠标，即可完成 Kubernetes 集群的创建和管理。在私有化部署环境时，您必须自行处理更多的内容。幸运的是，通过合适的教程指引，这些任务的达成并不困难。 Node 组件Node 组件运行在每一个节点上（包括 master 节点和 worker 节点），负责维护运行中的 Pod 并提供 Kubernetes 运行时环境。 kubelet此组件是运行在每一个集群节点上的代理程序。它确保 Pod 中的容器处于运行状态。Kubelet 通过多种途径获得 PodSpec 定义，并确保 PodSpec 定义中所描述的容器处于运行和健康的状态。Kubelet不管理不是通过 Kubernetes 创建的容器。 kube-proxykube-proxy 是一个网络代理程序，运行在集群中的每一个节点上，是实现 Kubernetes Service 概念的重要部分。 kube-proxy 在节点上维护网络规则。这些网络规则使得您可以在集群内、集群外正确地与 Pod 进行网络通信。如果操作系统中存在 packet filtering layer，kube-proxy 将使用这一特性（iptables代理模式），否则，kube-proxy将自行转发网络请求（User space代理模式） 容器引擎容器引擎负责运行容器。Kubernetes支持多种容器引擎：Docker、containerd、cri-o、rktlet 以及任何实现了 Kubernetes容器引擎接口 的容器引擎 AddonsAddons 使用 Kubernetes 资源（DaemonSet、Deployment等）实现集群的功能特性。由于他们提供集群级别的功能特性，addons使用到的Kubernetes资源都放置在 kube-system 名称空间下。 下面描述了一些经常用到的 addons，参考 Addons 查看更多列表。 DNS除了 DNS Addon 以外，其他的 addon 都不是必须的，所有 Kubernetes 集群都应该有 Cluster DNS Cluster DNS 是一个 DNS 服务器，是对您已有环境中其他 DNS 服务器的一个补充，存放了 Kubernetes Service 的 DNS 记录。 Kubernetes 启动容器时，自动将该 DNS 服务器加入到容器的 DNS 搜索列表中。 如果您参考 www.kuboard.cn 上提供的文档安装 Kubernetes，默认已经安装了 Core DNS Web UI（Dashboard）Dashboard 是一个Kubernetes集群的 Web 管理界面。用户可以通过该界面管理集群。 KuboardKuboard 是一款基于Kubernetes的微服务管理界面，相较于 Dashboard，Kuboard 强调： 无需手工编写 YAML 文件 微服务参考架构 上下文相关的监控 场景化的设计 导出配置 导入配置 ContainerResource MonitoringContainer Resource Monitoring 将容器的度量指标（metrics）记录在时间序列数据库中，并提供了 UI 界面查看这些数据 Cluster-level LoggingCluster-level logging 机制负责将容器的日志存储到一个统一存储中，并提供搜索浏览的界面","categories":[{"name":"容器","slug":"容器","permalink":"https://github.com/cyylog/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://github.com/cyylog/tags/Kubernetes/"}]},{"title":"Tomcat__05_JVM_排障工具","slug":"Linux/Tomcat/Tomcat-05","date":"2020-04-01T16:36:51.000Z","updated":"2020-05-25T13:58:25.372Z","comments":true,"path":"2020/04/02/Linux/Tomcat/Tomcat-05/","link":"","permalink":"https://github.com/cyylog/2020/04/02/Linux/Tomcat/Tomcat-05/","excerpt":"","text":"JVM 运维实用排障工具1、jps12345678用来查看Java进程的具体状态, 包括进程ID，进程启动的路径及启动参数等等，与unix上的ps类似，只不过jps是用来显示java进程，可以把jps理解为ps的一个子集。常用参数如下:-q：忽略输出的类名、Jar名以及传递给main方法的参数，只输出pid-m：输出传递给main方法的参数，如果是内嵌的JVM则输出为null-l：输出完全的包名，应用主类名，jar的完全路径名-v：输出传给jvm的参数注意: 使用jps 时的运行账户要和JVM 虚拟机启动的账户一致。若启动JVM虚拟机是运行的账户为www，那使用jps指令时，也要使用www 用户去指定。 sudo -u www jps Example 1234// 查看已经运行的JVM 进程的实际启动参数[root@mouse03 bin]# jps -v38372 Jps -Dapplication.home=/usr/local/jdk -Xms8m38360 Bootstrap -Djava.util.logging.config.file=/data0/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Xms4096m -Xmx4096m -XX:PermSize=1024m -XX:MaxPermSize=2048m -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dignore.endorsed.dirs= -Dcatalina.base=/data0/tomcat -Dcatalina.home=/data0/tomcat -Djava.io.tmpdir=/data0/tomcat/temp 2、jstack12345jstack用于打印出给定的java进程ID或core file或远程调试服务的Java堆栈信息。如果现在运行的java程序呈现hung的状态，jstack是非常有用的。此信息通常在运维的过程中被保存起来(保存故障现场)，以供RD们去分析故障。常用参数如下:jstack &lt;pid&gt;jstack [-l] &lt;pid&gt; &#x2F;&#x2F;长列表. 打印关于锁的附加信息jstack [-F] &lt;pid&gt; &#x2F;&#x2F;当’jstack [-l] pid’没有响应的时候强制打印栈信息 Example 12// 打印JVM 的堆栈信息，以供问题排查[root@mouse03 ~]# jstack -F 38360 &gt; /tmp/jstack.log 3、jinfo123456789可以查看或修改运行时的JVM进程的参数。常用参数:jinfo [option] pid where &lt;option&gt; is one of: -flag &lt;name&gt; to print the value of the named VM flag -flag [+|-]&lt;name&gt; to enable or disable the named VM flag -flag &lt;name&gt;&#x3D;&lt;value&gt; to set the named VM flag to the given value -flags to print VM flags Example 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// 根据 PID 查看目前分配的最大堆栈[root@mouse03 ~]# jinfo -flag MaxHeapSize 38360-XX:MaxHeapSize=4294967296// 动态更改 JVM 的最大堆栈值[root@mouse03 ~]# jinfo -flag MaxHeapSize=4294967296 38360Exception in thread \"main\" com.sun.tools.attach.AttachOperationFailedException: flag 'MaxHeapSize' cannot be changed at sun.tools.attach.LinuxVirtualMachine.execute(LinuxVirtualMachine.java:229) at sun.tools.attach.HotSpotVirtualMachine.executeCommand(HotSpotVirtualMachine.java:261) at sun.tools.attach.HotSpotVirtualMachine.setFlag(HotSpotVirtualMachine.java:234) at sun.tools.jinfo.JInfo.flag(JInfo.java:134) at sun.tools.jinfo.JInfo.main(JInfo.java:81)// jinfo 并不能动态的改变所有的JVM 参数。 那到底有哪些参数能够被动态的改变呢?// java -XX:+PrintFlagsFinal -version 答应JVM 的所有参数// java -XX:+PrintFlagsFinal -version | grep manageable[root@mouse03 ~]# java -XX:+PrintFlagsFinal -version | grep manageable intx CMSAbortablePrecleanWaitMillis = 100 &#123;manageable&#125; intx CMSTriggerInterval = -1 &#123;manageable&#125; intx CMSWaitDuration = 2000 &#123;manageable&#125; bool HeapDumpAfterFullGC = false &#123;manageable&#125; bool HeapDumpBeforeFullGC = false &#123;manageable&#125; bool HeapDumpOnOutOfMemoryError = false &#123;manageable&#125; ccstr HeapDumpPath = &#123;manageable&#125; uintx MaxHeapFreeRatio = 70 &#123;manageable&#125; uintx MinHeapFreeRatio = 40 &#123;manageable&#125; bool PrintClassHistogram = false &#123;manageable&#125; bool PrintClassHistogramAfterFullGC = false &#123;manageable&#125; bool PrintClassHistogramBeforeFullGC = false &#123;manageable&#125; bool PrintConcurrentLocks = false &#123;manageable&#125; bool PrintGC = false &#123;manageable&#125; bool PrintGCDateStamps = false &#123;manageable&#125; bool PrintGCDetails = false &#123;manageable&#125; bool PrintGCID = false &#123;manageable&#125; bool PrintGCTimeStamps = false &#123;manageable&#125; // 也只有以上这些值才能够动态的被改变[root@mouse03 ~]# jinfo -flag CMSWaitDuration=1900 38360# 查看， jinfo -flags 查看 JVM 的 flags [root@mouse03 ~]# jinfo -flags 38360Attaching to process ID 38360, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.91-b14Non-default VM flags: -XX:CICompilerCount=2 -XX:CMSWaitDuration=1900 -XX:InitialHeapSize=4294967296 -XX:MaxHeapSize=4294967296 -XX:MaxNewSize=1431633920 -XX:MinHeapDeltaBytes=196608 -XX:NewSize=1431633920 -XX:OldSize=2863333376 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStampsCommand line: -Djava.util.logging.config.file=/data0/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Xms4096m -Xmx4096m -XX:PermSize=1024m -XX:MaxPermSize=2048m -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dignore.endorsed.dirs= -Dcatalina.base=/data0/tomcat -Dcatalina.home=/data0/tomcat -Djava.io.tmpdir=/data0/tomcat/temp 4、jstat123// 监控JVM 的状态，常用指令:# jstat -gc 113059 1000 10 // 打印PID 为 113059 JVM 状态，一共打印10次，每次间隔时间为1s(1000ms)// 注 jstat 的用法超级强大， 我们这里只是列举出列其中一个简单的应用。 Example 123456789101112# jstat -gc 113059 1000 10 S0C S1C S0U S1U EC EU OC OU PC PU YGC YGCT FGC FGCT GCT195904.0 195904.0 0.0 21610.3 1567680.0 1516721.9 8526272.0 3557507.8 1048576.0 163148.4 2577 92.033 0 0.000 92.033195904.0 195904.0 23600.9 0.0 1567680.0 142541.6 8526272.0 3558435.8 1048576.0 163148.4 2578 92.060 0 0.000 92.060195904.0 195904.0 23600.9 0.0 1567680.0 266338.1 8526272.0 3558435.8 1048576.0 163148.4 2578 92.060 0 0.000 92.060195904.0 195904.0 23600.9 0.0 1567680.0 413941.8 8526272.0 3558435.8 1048576.0 163148.4 2578 92.060 0 0.000 92.060195904.0 195904.0 23600.9 0.0 1567680.0 642390.6 8526272.0 3558435.8 1048576.0 163148.4 2578 92.060 0 0.000 92.060195904.0 195904.0 23600.9 0.0 1567680.0 813957.3 8526272.0 3558435.8 1048576.0 163148.4 2578 92.060 0 0.000 92.060195904.0 195904.0 23600.9 0.0 1567680.0 984223.2 8526272.0 3558435.8 1048576.0 163148.4 2578 92.060 0 0.000 92.060195904.0 195904.0 23600.9 0.0 1567680.0 1155472.7 8526272.0 3558435.8 1048576.0 163148.4 2578 92.060 0 0.000 92.060195904.0 195904.0 23600.9 0.0 1567680.0 1399228.5 8526272.0 3558435.8 1048576.0 163148.4 2578 92.060 0 0.000 92.060195904.0 195904.0 0.0 23866.6 1567680.0 38005.6 8526272.0 3559196.7 1048576.0 163148.4 2579 92.092 0 0.000 92.092 字段意义如下 列名 说明 S0C 新生代中Survivor space中S0当前容量的大小（KB） S1C 新生代中Survivor space中S1当前容量的大小（KB） S0U 新生代中Survivor space中S0容量使用的大小（KB） S1U 新生代中Survivor space中S1容量使用的大小（KB） EC Eden space当前容量的大小（KB） EU Eden space容量使用的大小（KB） OC Old space当前容量的大小（KB） OU Old space使用容量的大小（KB） PC Permanent space当前容量的大小（KB） PU Permanent space使用容量的大小（KB） YGC 从应用程序启动到采样时发生 Young GC 的次数 YGCT 从应用程序启动到采样时 Young GC 所用的时间(秒) FGC 从应用程序启动到采样时发生 Full GC 的次数 FGCT 从应用程序启动到采样时 Full GC 所用的时间(秒) GCT T从应用程序启动到采样时用于垃圾回收的总时间(单位秒)，它的值等于YGC+FGC 5、jvmtop1234以上介绍的jps、jstack、jinfo等都是安装JDK 时自带的系统分析工具，而jvmtop是一款开源的JVM工具。它的下载地址如下: https:&#x2F;&#x2F;github.com&#x2F;patric-r&#x2F;jvmtop顾名思义，它是一个只针对JVM的工具，展示的方式和unix的top命令相似.jvmtop 提供了两个视图，一个是概览视图，可以展示出当前机器的所有的 JVM 的情况. 还有一个视图是详情视图，展示一个 JVM 的详细情况. 概览视图 1jvmtop.sh 12345678910111213其中，各个字段的意义分别如下：PID：进程 IDMAIN-CLASS：main 类的名字HPCUR：当前被使用的 heap 的大小HPMAX：最大可用的 heap 的大小NHCUR：当前被使用的非 heap 大小（比如：perm gen）NHMAX：最大可用的非 heap 大小CPU：CPU 的使用情况GC：消耗在 GC 上的时间比例VM：JVM 的提供者，大版本号，小版本号，图中的意思是 Apple 提供的 JDK 6U51 版本。USERNAME：当前的用户名#T：线程数量DL：是否有现成发生死锁 详情视图 1jvmtop.sh &lt;pid&gt; 1234567其中，各个字段的意义如下：TID：线程 IDNAME：线程名STATE：线程状态CPU：线程当前的 CPU 占用情况TOTALCPU：从线程被创建开始总体的 CPU 占用情况BLOCKBY：阻塞这个线程的线程 ID","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/categories/Linux/"}],"tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"https://github.com/cyylog/tags/Tomcat/"}]},{"title":"Tomcat_04_安全优化","slug":"Linux/Tomcat/Tomcat-04","date":"2020-03-29T16:36:31.000Z","updated":"2020-05-25T13:58:16.512Z","comments":true,"path":"2020/03/30/Linux/Tomcat/Tomcat-04/","link":"","permalink":"https://github.com/cyylog/2020/03/30/Linux/Tomcat/Tomcat-04/","excerpt":"","text":"10、Tomcat安全优化1、telnet管理端口保护（强制） 类别 配置内容及说明 标准配置 备注 telnet管理端口保护 1.修改默认的8005管理端口为不易猜测的端口（大于1024）；2.修改SHUTDOWN指令为其他字符串； 1.以上配置项的配置内容只是建议配置，可以按照服务实际情况进行合理配置，但要求端口配置在8000~8999之间； 2、 ajp连接端口保护（推荐） 类别 配置内容及说明 标准配置 备注 Ajp 连接端口保护 1.修改默认的ajp 8009端口为不易冲突的大于1024端口；2.通过iptables规则限制ajp端口访问的权限仅为线上机器； &lt;Connector port=”8528“protocol=”AJP/1.3” /&gt; 以上配置项的配置内容仅为建议配置，请按照服务实际情况进行合理配置，但要求端口配置在8000~8999之间；；保护此端口的目的在于防止线下的测试流量被mod_jk转发至线上tomcat服务器； 3、禁用管理端（强制） 类别 配置内容及说明 标准配置 备注 禁用管理端 1. 删除默认的{Tomcat安装目录}/conf/tomcat-users.xml文件，重启tomcat后将会自动生成新的文件；2. 删除{Tomcat安装目录}/webapps下默认的所有目录和文件；3.将tomcat 应用根目录配置为tomcat安装目录以外的目录； &lt;Context path=”” docBase=”/home/work/local/tomcat**_webapps**”debug=”0”reloadable=”false”crossContext=”true”/&gt; 对于前段web模块，Tomcat管理端属于tomcat的高危安全隐患，一旦被攻破，黑客通过上传web shell的方式将会直接取得服务器的控制权，后果极其严重； 4、降权启动（强制） 类别 配置内容及说明 标准配置 备注 降权启动 1.tomcat启动用户权限必须为非root权限，尽量降低tomcat启动用户的目录访问权限；2.如需直接对外使用80端口，可通过普通账号启动后，配置iptables规则进行转发； 避免一旦tomcat 服务被入侵，黑客直接获取高级用户权限危害整个server的安全； 1234567891011[root@web03 ~]# useradd tomcat[root@web03 ~]# cp -a &#x2F;application&#x2F;tools&#x2F;tomcat8_1 &#x2F;home&#x2F;tomcat&#x2F;[root@web03 ~]# chown -R tomcat.tomcat &#x2F;home&#x2F;tomcat&#x2F;tomcat8_1&#x2F;[root@web03 ~]# su -c &#39;&#x2F;home&#x2F;tomcat&#x2F;tomcat8_1&#x2F;bin&#x2F;startup.sh&#39; tomcatUsing CATALINA_BASE: &#x2F;home&#x2F;tomcat&#x2F;tomcat8_1Using CATALINA_HOME: &#x2F;home&#x2F;tomcat&#x2F;tomcat8_1Using CATALINA_TMPDIR: &#x2F;home&#x2F;tomcat&#x2F;tomcat8_1&#x2F;tempUsing JRE_HOME: &#x2F;application&#x2F;jdkUsing CLASSPATH: &#x2F;home&#x2F;tomcat&#x2F;tomcat8_1&#x2F;bin&#x2F;bootstrap.jar:&#x2F;home&#x2F;tomcat&#x2F;tomcat8_1&#x2F;bin&#x2F;tomcat-juli.jarTomcat started.[root@web03 ~]# ps -ef|grep tomcat 5、文件列表访问控制（强制） 类别 配置内容及说明 标准配置 备注 文件列表访问控制 1.conf/web.xml文件中default部分listings的配置必须为false； listingsfalse false为不列出目录文件，true为允许列出，默认为false； 6、版本信息隐藏（强制） 类别 配置内容及说明 标准配置 备注 版本信息隐藏 1.修改conf/web.xml，重定向403、404以及500等错误到指定的错误页面；2.也可以通过修改应用程序目录下的WEB-INF/web.xml下的配置进行错误页面的重定向； 403/forbidden.jsp404/notfound.jsp500/systembusy.jsp 在配置中对一些常见错误进行重定向，避免当出现错误时tomcat默认显示的错误页面暴露服务器和版本信息；必须确保程序根目录下的错误页面已经存在； 7、Server header重写（推荐） 类别 配置内容及说明 标准配置 备注 Server header重写 在HTTP Connector配置中加入server的配置； server=”webserver“ 当tomcat HTTP端口直接提供web服务时此配置生效，加入此配置，将会替换http 响应Server header部分的默认配置，默认是Apache-Coyote/1.1 8、访问限制（可选） 类别 配置内容及说明 标准配置或操作 备注 访问限制 通过配置，限定访问的ip来源 &lt;Valve className=”org.apache.catalina.valves.RemoteAddrValve” allow=”61.148.18.138,61.135.165.*“ deny=”*.*.*.*“/&gt; 通过配置信任ip的白名单，拒绝非白名单ip的访问，此配置主要是针对高保密级别的系统，一般产品线不需要； 9、起停脚本权限回收（推荐） 类别 配置内容及说明 标准配置或操作 备注 起停脚本权限回收 去除其他用户对Tomcat的bin目录下shutdown.sh、startup.sh、catalina.sh的可执行权限； chmod -R 744 tomcat/bin/* 防止其他用户有起停线上Tomcat的权限； 10、 访问日志格式规范（推荐） 类别 配置内容及说明 标准配置或操作 备注 访问日志格式规范 开启Tomcat默认访问日志中的Referer和User-Agent记录 开启Referer和User-Agent是为了一旦出现安全问题能够更好的根据日志进行问题排查； 11、 附录：建议配置及标准执行方案1. 配置部分（**${ CATALINA_HOME }conf/server.xml**） 1234567891011121314&lt;Server port&#x3D;&quot;8527&quot; shutdown&#x3D;&quot; dangerous&quot;&gt;&lt;!-- Define a non-SSL HTTP&#x2F;1.1 Connector on port 8080 --&gt;&lt;Connector port&#x3D;&quot;8080&quot; server&#x3D;&quot;webserver&quot;&#x2F;&gt; &lt;!-- Define an AJP 1.3 Connector on port 8528 --&gt;&lt;!--Define an accesslog --&gt; &lt;Valve className&#x3D;&quot;org.apache.catalina.valves.AccessLogValve&quot; directory&#x3D;&quot;logs&quot; prefix&#x3D;&quot;localhost_access_log.&quot; suffix&#x3D;&quot;.txt&quot; pattern&#x3D;&quot;%h %l %u %t %r %s %b %&#123;Referer&#125;i %&#123;User-Agent&#125;i %D&quot; resolveHosts&#x3D;&quot;false&quot;&#x2F;&gt; &lt;Connector port&#x3D;&quot;8528&quot; protocol&#x3D;&quot;AJP&#x2F;1.3&quot; &#x2F;&gt;&lt;Context path&#x3D;&quot;&quot; docBase&#x3D;&quot;&#x2F;home&#x2F;work&#x2F;local&#x2F;tomcat_webapps&quot; debug&#x3D;&quot;0&quot; reloadable&#x3D;&quot;false&quot; crossContext&#x3D;&quot;true&quot;&#x2F;&gt; 2. 配置部分（**${ CATALINA_HOME }conf/web.xml或者WEB-INF/web.xml**） 1234567891011121314151617&lt;init-param&gt; &lt;param-name&gt;listings&lt;&#x2F;param-name&gt; &lt;param-value&gt;false&lt;&#x2F;param-value&gt;&lt;&#x2F;init-param&gt;&lt;error-page&gt; &lt;error-code&gt;403&lt;&#x2F;error-code&gt; &lt;location&gt;&#x2F;forbidden.jsp&lt;&#x2F;location&gt;&lt;&#x2F;error-page&gt;&lt;error-page&gt; &lt;error-code&gt;404&lt;&#x2F;error-code&gt; &lt;location&gt;&#x2F;notfound.jsp&lt;&#x2F;location&gt;&lt;&#x2F;error-page&gt;&lt;error-page&gt; &lt;error-code&gt;500&lt;&#x2F;error-code&gt; &lt;location&gt;&#x2F;systembusy.jsp&lt;&#x2F;location&gt;&lt;&#x2F;error-page&gt; 3. 删除如下**tomcat**的默认目录和默认文件 12tomcat&#x2F;webapps&#x2F;*tomcat&#x2F;conf&#x2F;tomcat-user.xml 4. 去除其他用户对**tomcat** 起停脚本的执行权限 1chmod 744 –R tomcat&#x2F;bin&#x2F;* 11、Tomcat性能优化tomcat性能取决于 内存大小 上策：优化代码 该项需要开发经验足够丰富，对开发人员要求较高 中策：jvm**优化机制** 垃圾回收机制 把不需要的内存回收 ​ 优化jvm–优化垃圾回收策略 优化catalina.sh配置文件。在catalina.sh配置文件中添加以下代码 1234567# tomcat分配1G内存模板JAVA_OPTS&#x3D;&quot;-Djava.awt.headless&#x3D;true -Dfile.encoding&#x3D;UTF-8 -server -Xms1024m -Xmx1024m -XX:NewSize&#x3D;512m -XX:MaxNewSize&#x3D;512m -XX:PermSize&#x3D;512m -XX:MaxPermSize&#x3D;512m&quot; JAVA_OPTS&#x3D;&quot;-Djava.awt.headless&#x3D;true -Dfile.encoding&#x3D;UTF-8 -server -Xms800m -Xmx800m -XX:NewSize&#x3D;400m -XX:MaxNewSize&#x3D;400m -XX:PermSize&#x3D;400m -XX:MaxPermSize&#x3D;400m&quot; # 重启服务su -c &#39;&#x2F;home&#x2F;tomcat&#x2F;tomcat8_1&#x2F;bin&#x2F;shutdown.sh&#39; tomcatsu -c &#39;&#x2F;home&#x2F;tomcat&#x2F;tomcat8_1&#x2F;bin&#x2F;startup.sh&#39; tomcat ​ 修改之前 ​ 修改之后 下策：加足够大的内存 该项的资金投入较大 下下策：每天0**点定时重启tomcat** 使用较为广泛","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/categories/Linux/"}],"tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"https://github.com/cyylog/tags/Tomcat/"}]},{"title":"Kubernetes常用命令","slug":"容器/Kubernetes常用命令","date":"2020-03-28T17:21:16.000Z","updated":"2020-05-25T13:43:46.812Z","comments":true,"path":"2020/03/29/容器/Kubernetes常用命令/","link":"","permalink":"https://github.com/cyylog/2020/03/29/%E5%AE%B9%E5%99%A8/Kubernetes%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"常用命令Kubernetes Cheat SheetViewing Resource Information //查看资源信息 Nodes1234567$ kubectl get no$ kubectl get no -o wide$ kubectl describe no$ kubectl get no - o yaml$ kubectl get node - - sel ect or &#x3D;[ l abel _name]$ kubectl get nodes -o jsonpath&#x3D;&#39; &#123;.items[*].status.addresses [?(@.type&#x3D;&#x3D;&quot;ExternalIP&quot;)].address&#125;&#39;$ kubectl top node [node_name] Pods123456789$ kubectl get po -o wide$ kubectl describe po$ kubectl get po$ kubectl get po --show-labels$ kubectl get po -l app&#x3D;nginx$ kubectl get po -o yaml$ kubectl get pod [pod_name] - o yaml --export$ kubect l get pod [ pod_name] - o yaml --export &gt; nameoffile.yaml$ kubectl get pods -- field-selector status.phase&#x3D;Running Namespaces123$ kubectl get ns$ kubectl get ns - o yaml$ kubectl describe ns Deployments1234$ kubectl get deploy$ kubectl describe deploy$ kubectl get deploy - o wide$ kubectl get deploy - o yaml Services12345$ kubectl get svc$ kubectl describe svc$ kubectl get svc - o wide$ kubectl get svc - o yaml$ kubectl get svc --show-labels DaemonSets1234$ kubectl get ds$ kubectl get ds --all-namespaces$ kubectl describe ds [daemonset_name] - n [namespce_name]$ kubectl get ds [ds_name] -n [ns_name] -o yaml Events123$ kubectl get events$ kubectl get events -n kube-system$ kubectl get events -w logs12345$ kubectl logs [pod_name]$ kubectl logs --since&#x3D;1h [pod_name]$ kubectl logs --tail &#x3D;20 [pod_name]$ kubectl logs -f -c [container_name] [pod_name]$ kubectl logs [pod_name] &gt; pod.log Service Accounts1234$ kubectl get sa$ kubectl get sa -o yaml$ kubectl get serviceaccounts default -o yaml &gt;.&#x2F;sa.yaml$ kubectl replace serviceaccount default -f .&#x2F;sa.yaml ReplicaSets1234$ kubectl get rs$ kubectl describe rs$ kubectl get rs -o wide$ kubectl get rs -o yaml Roles12$ kubectl get roles --all -namespaces$ kubectl get roles --all -namespaces -o yaml Secrets123$ kubectl get secrets$ kubectl get secrets --all -namespaces$ kubectl get secrets -o yaml ConfigMaps123$ kubectl get cm$ kubectl get cm --all-namespaces$ kubectl get cm --all-namespaces -o yaml Ingress12$ kubectl get ing$ kubectl get ing --all-namespaces PersistentVolume12$ kubectl get pv$ kubectl describe pv PersistentVolumeClaim12$ kubectl get pvc$ kubectl describe pvc StorageClass12$ kubectl get sc$ kubectl get sc -o yaml Multiple Resources1234$ kubectl get svc,po$ kubectl get deploy,no$ kubectl get all$ kubectl get all --all -namespaces Changing Resource Attributes //改变资源属性 Taint1$ kubectl taint [node_name] [taint_name] Labels12$ kubectl label [node_name] disktype&#x3D;ssd$ kubectl label [pod_name] env&#x3D;prod Cordon/Uncordon12$ kubectl cordon [node_name]$ kunectl uncordon [node_name] Drain1$ kubectl drain [node_name] Nodes/Pods1234$ kubectl delet enode [node_name]$ kubectl delet epod [pod_name]$ kubectl edit node [node_name]$ kubectl edit pod [pod_name] Deployments/Namespaces123456$ kubectl edit deploy [deploy_name]$ kubectl delete deploy [deploy_name]$ kubectl expse deploy [deploy_name] --por&#x3D;80 -type&#x3D;NodePort$ kubectl scale deploy [deploy_name] --repicas&#x3D;5$ kubectl delete ns $ kubectl edit ns [ns_name] Services12$ kubectl edit svc [svc_name]$ kubectl delete svc [svc_name] DaemonSets12$ kubectl edit ds [ds_name] -n kube-system$ kubectl delete ds [ds_name] Service Accounts12$ kubectl edit sa [sa_name]$ kubectl delete sa [sa_name] Annotate12$ kubectl annotate po [pod_name] [annotation]$ kubectl annotate no [node_name] Adding Resources //添加资源 Creating a Pod12345$ kubectl create -f [name_of_file]$ kubectl apply -f [name_of_file]$ kubectl run [pod_name] --image&#x3D;nginx --resart&#x3D;Never$ kubectl run [pod_name] --geneator&#x3D;run-pod&#x2F;v1 --image&#x3D;nginx$ kubectl run [pod_name] --image&#x3D;nginx --restart&#x3D;Never Creating a Service1$ kubectl create svc nodeport [svc_name] --tcp&#x3D;8080: 80 Creating a Deployment123$ kubectl create -f [name_of_file]$ kubectl apply -f [name_of_file]$ kubectl create deploy [deploy_name] --image&#x3D;ngi nx Interactive Pod1$ kubectl run [pod_name] --image&#x3D;busybox --rm -it --restart&#x3D;Never -- sh Output YAML to a File12$ kubectl create deploy [deploy_name] --image&#x3D;nginx --dry-run -o yaml &gt; depl oy. yaml$ kubectl get po [pod_name] -o yaml --export &gt; pod. yaml Getting Help1234$ kubectl -h $ kubectl create -h$ kubectl run -h$ kubectl explain deploy.spec Requests //请求 API Call1$ kubectl get --raw &#x2F;apis&#x2F;metrics.k8s.io&#x2F; Cluster Info123$ kubectl config $ kubectl cluster-info$ kubectl get componentstatuses","categories":[{"name":"容器","slug":"容器","permalink":"https://github.com/cyylog/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://github.com/cyylog/tags/Kubernetes/"}]},{"title":"Tomcat_03_监控","slug":"Linux/Tomcat/Tomcat-03","date":"2020-03-26T16:36:10.000Z","updated":"2020-05-25T13:58:04.737Z","comments":true,"path":"2020/03/27/Linux/Tomcat/Tomcat-03/","link":"","permalink":"https://github.com/cyylog/2020/03/27/Linux/Tomcat/Tomcat-03/","excerpt":"","text":"9、监控tomcat集群状态1、方法一：开发java监控页面12345678910111213[root@web03 tomcat8_1]# cat &#x2F;application&#x2F;tomcat&#x2F;webapps&#x2F;memtest&#x2F;meminfo.jsp &lt;%Runtime rtm &#x3D; Runtime.getRuntime();long mm &#x3D; rtm.maxMemory()&#x2F;1024&#x2F;1024;long tm &#x3D; rtm.totalMemory()&#x2F;1024&#x2F;1024;long fm &#x3D; rtm.freeMemory()&#x2F;1024&#x2F;1024;out.println(&quot;JVM memory detail info :&lt;br&gt;&quot;);out.println(&quot;Max memory:&quot;+mm+&quot;MB&quot;+&quot;&lt;br&gt;&quot;);out.println(&quot;Total memory:&quot;+tm+&quot;MB&quot;+&quot;&lt;br&gt;&quot;);out.println(&quot;Free memory:&quot;+fm+&quot;MB&quot;+&quot;&lt;br&gt;&quot;);out.println(&quot;Available memory can be used is :&quot;+(mm+fm-tm)+&quot;MB&quot;+&quot;&lt;br&gt;&quot;);%&gt; 2、方法二：使用jps命令进行监控123456789[root@web03 ~]# jps -lvm31906 org.apache.catalina.startup.Bootstrap start -Djava.util.logging.config.file&#x3D;&#x2F;application&#x2F;tomcat8_1&#x2F;conf&#x2F;logging.properties -Djava.util.logging.manager&#x3D;org.apache.juli.ClassLoaderLogManager -Djava.endorsed.dirs&#x3D;&#x2F;application&#x2F;tomcat8_1&#x2F;endorsed -Dcatalina.base&#x3D;&#x2F;application&#x2F;tomcat8_1 -Dcatalina.home&#x3D;&#x2F;application&#x2F;tomcat8_1 -Djava.io.tmpdir&#x3D;&#x2F;application&#x2F;tomcat8_1&#x2F;temp31812 org.apache.catalina.startup.Bootstrap start -Djava.util.logging.config.file&#x3D;&#x2F;application&#x2F;tomcat&#x2F;conf&#x2F;logging.properties -Djava.util.logging.manager&#x3D;org.apache.juli.ClassLoaderLogManager -Djava.endorsed.dirs&#x3D;&#x2F;application&#x2F;tomcat&#x2F;endorsed -Dcatalina.base&#x3D;&#x2F;application&#x2F;tomcat -Dcatalina.home&#x3D;&#x2F;application&#x2F;tomcat -Djava.io.tmpdir&#x3D;&#x2F;application&#x2F;tomcat&#x2F;temp31932 org.apache.catalina.startup.Bootstrap start -Djava.util.logging.config.file&#x3D;&#x2F;application&#x2F;tomcat8_2&#x2F;conf&#x2F;logging.properties -Djava.util.logging.manager&#x3D;org.apache.juli.ClassLoaderLogManager -Djava.endorsed.dirs&#x3D;&#x2F;application&#x2F;tomcat8_2&#x2F;endorsed -Dcatalina.base&#x3D;&#x2F;application&#x2F;tomcat8_2 -Dcatalina.home&#x3D;&#x2F;application&#x2F;tomcat8_2 -Djava.io.tmpdir&#x3D;&#x2F;application&#x2F;tomcat8_2&#x2F;temp32079 sun.tools.jps.Jps -lvm -Denv.class.path&#x3D;.:&#x2F;application&#x2F;jdk&#x2F;lib:&#x2F;application&#x2F;jdk&#x2F;jre&#x2F;lib:&#x2F;application&#x2F;jdk&#x2F;lib&#x2F;tools.jar -Dapplication.home&#x3D;&#x2F;application&#x2F;jdk1.8.0_60 -Xms8m 3、Tomcat远程监控功能修改配置文件，开启远程监控 12345678vim &#x2F;application&#x2F;tomcat8_1&#x2F;bin&#x2F;catalina.sh +97CATALINA_OPTS&#x3D;&quot;$CATALINA_OPTS-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port&#x3D;12345 -Dcom.sun.management.jmxremote.authenticate&#x3D;false -Dcom.sun.management.jmxremote.ssl&#x3D;false -Djava.rmi.server.hostname&#x3D;10.0.0.17&quot; ​ 重启服务，检查12345端口是否开启 123&#x2F;application&#x2F;tomcat8_1&#x2F;bin&#x2F;shutdown.sh &#x2F;application&#x2F;tomcat8_1&#x2F;bin&#x2F;startup.sh netstat -tunlp|grep 12345 ​ 检查端口 12[root@web03 ~]# netstat -tunlp|grep 12345tcp6 0 0 :::12345 :::* LISTEN 33158&#x2F;java 在windows**上监控tomcat** 注意：windwos**需要安装jdk**环境！ 查考：http://www.oracle.com/technetwork/java/javase/downloads/index.html 4、zabbix监控tomcat程序zabbix搭建详情参考：https://www.toutiao.com/i6808897883299906059/ 若是有问题，请移步官网 ： https://www.zabbix.com/documentation/4.0/zh/manual/installation 服务端安装配置java**监控服务** 1[root@m01 ~]# yum install zabbix-java-gateway -y 查看配置文件 12配置文件路径：&#x2F;etc&#x2F;zabbix&#x2F;zabbix_java_gateway.confsed -i -e &#39;220a JavaGateway&#x3D;127.0.0.1&#39; -e &#39;236a StartJavaPollers&#x3D;5&#39; &#x2F;etc&#x2F;zabbix&#x2F;zabbix_server.conf 启动zabbix-java-gateway服务，与zabbix服务 12systemctl start zabbix-java-gateway.servicesystemctl restart zabbix-server.service 检查java端口是否开启 12[root@m01 ~]# netstat -lntup |grep javatcp6 0 0 :::10052 :::* LISTEN 72971&#x2F;java ​ 检查java进程是否存在 1234567[root@m01 ~]# ps -ef |grep [j]avazabbix 72971 1 0 11:29 ? 00:00:00 java -server -Dlogback.configurationFile&#x3D;&#x2F;etc&#x2F;zabbix&#x2F;zabbix_java_gateway_logback.xml -classpath lib:lib&#x2F;android-json-4.3_r3.1.jar:lib&#x2F;logback-classic-0.9.27.jar:lib&#x2F;logback-core-0.9.27.jar:lib&#x2F;slf4j-api-1.6.1.jar:bin&#x2F;zabbix-java-gateway-3.0.13.jar -Dzabbix.pidFile&#x3D;&#x2F;var&#x2F;run&#x2F;zabbix&#x2F;zabbix_java.pid -Dzabbix.timeout&#x3D;3 -Dsun.rmi.transport.tcp.responseTimeout&#x3D;3000 com.zabbix.gateway.JavaGatewayzabbix 73255 73226 0 11:35 ? 00:00:00 &#x2F;usr&#x2F;sbin&#x2F;zabbix_server: java poller #1 [got 0 values in 0.000002 sec, idle 5 sec]zabbix 73256 73226 0 11:35 ? 00:00:00 &#x2F;usr&#x2F;sbin&#x2F;zabbix_server: java poller #2 [got 0 values in 0.000002 sec, idle 5 sec]zabbix 73257 73226 0 11:35 ? 00:00:00 &#x2F;usr&#x2F;sbin&#x2F;zabbix_server: java poller #3 [got 0 values in 0.000002 sec, idle 5 sec]zabbix 73258 73226 0 11:35 ? 00:00:00 &#x2F;usr&#x2F;sbin&#x2F;zabbix_server: java poller #4 [got 0 values in 0.000002 sec, idle 5 sec]zabbix 73259 73226 0 11:35 ? 00:00:00 &#x2F;usr&#x2F;sbin&#x2F;zabbix_server: java poller #5 [got 0 values in 0.000004 sec, idle 5 sec] web**界面添加** ​ 添加主机 ​ 主机管理模板，注意是JMX模板 监控完成 5、排除tomcat故障步骤a. 查看catalina.out b. 使用sh show-busy-java-threads.sh脚本进行检测 脚本下载地址 https://files.cnblogs.com/files/clsn/show-busy-java-threads.sh","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/categories/Linux/"}],"tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"https://github.com/cyylog/tags/Tomcat/"}]},{"title":"Tomcat_02_应用部署","slug":"Linux/Tomcat/Tomcat-02","date":"2020-03-24T16:36:05.000Z","updated":"2020-05-25T13:57:56.521Z","comments":true,"path":"2020/03/25/Linux/Tomcat/Tomcat-02/","link":"","permalink":"https://github.com/cyylog/2020/03/25/Linux/Tomcat/Tomcat-02/","excerpt":"","text":"6、WEB站点部署上线的代码有两种方式： 第一种方式是直接将程序目录放在webapps目录下面，这种方式大家已经明白了，就不多说了。 第二种方式是使用开发工具将程序打包成war包，然后上传到webapps目录下面。 1、使用war包部署web站点123[root@web03 webapps]# pwd&#x2F;application&#x2F;tomcat&#x2F;webapps[root@web03 webapps]# wget http:&#x2F;&#x2F;10.0.0.1&#x2F;apache&#x2F;tomcat&#x2F;memtest.war 站点主动解压部署 12[root@web03 webapps]# lsdocs examples host-manager logs manager memtest memtest.war ROOT 浏览器访问： http://10.0.0.17:8080//memtest/meminfo.jsp 2、自定义默认网站目录上面访问的网址为 http://10.0.0.3:8080/memtest/meminfo.jsp 现在想访问格式为http://10.0.0.3:8080/meminfo.jsp 方法一 将meminfo.jsp或其他程序放在tomcat/webapps/ROOT目录下即可。因为默认网站根目录为tomcat/webapps/ROOT 方法二 12345[root@web03 ~]# vim &#x2F;application&#x2F;tomcat&#x2F;conf&#x2F;server.xml +125…… #添加上这两行 &lt;Context path&#x3D;&quot;&quot; docBase&#x3D;&quot;&#x2F;application&#x2F;tomcat&#x2F;webapps&#x2F;memtest&quot; debug&#x3D;&quot;0&quot; reloadable&#x3D;&quot;false&quot; crossContext&#x3D;&quot;true&quot;&#x2F;&gt; &lt;Context path&#x3D;&quot;&#x2F;40team&quot; docBase&#x3D;&quot;&#x2F;application&#x2F;tomcat&#x2F;webapps&#x2F;memtest&quot; debug&#x3D;&quot;0&quot; reloadable&#x3D;&quot;false&quot; crossContext&#x3D;&quot;true&quot;&#x2F;&gt;…… 修改配置文件后，要重启服务 12[root@web03 ~]# &#x2F;application&#x2F;tomcat&#x2F;bin&#x2F;shutdown.sh [root@web03 ~]# &#x2F;application&#x2F;tomcat&#x2F;bin&#x2F;startup.sh 3、部署开源站点（jpress）jpress官网：http://jpress.io 下载地址：https://github.com/JpressProjects/jpress ​ 第一个里程碑：安装配置数据库 12yum -y install mariadb-serversystemctl start mariadb.service ​ #配置数据库 1234mysqlcreate database jpress DEFAULT CHARACTER SET utf8;grant all on jpress.* to jpress@&#39;localhost&#39; identified by &#39;123456&#39;;exit ​ 第二个里程碑：jpress站点上线 123[root@web03 webapps]# pwd&#x2F;application&#x2F;tomcat&#x2F;webapps[root@web03 webapps]# wget http:&#x2F;&#x2F;10.0.0.1&#x2F;apache&#x2F;tomcat&#x2F;jpress-web-newest.war ​ 第三个里程碑：浏览器访问 浏览器访问： http://10.0.0.17:8080/jpress-web-newest/install 填写数据库信息 设置站点名称等 安装完成 重启tomcat服务 12[root@web03 ~]# &#x2F;application&#x2F;tomcat&#x2F;bin&#x2F;shutdown.sh [root@web03 ~]# &#x2F;application&#x2F;tomcat&#x2F;bin&#x2F;startup.sh 7、Tomcat多实例配置多虚拟主机：nginx 多个Server标签（域名，ip，端口） 进程数量固定 master+worker 多实例（多进程）：同一个程序启动多次，分为两种情况: 第一种：一台机器跑多个站点； 第二种：一个机器跑一个站点多个实例，配合负载均衡 1、复制程序文件1234cd &#x2F;application&#x2F;tools&#x2F;tar xf apache-tomcat-8.0.27.tar.gzcp -a apache-tomqcat-8.0.27 tomcat8_1cp -a apache-tomcat-8.0.27 tomcat8_2 修改端口，以启动多实例。多实例之间端口不能一致 12345678910111213141516171819sed -i &#39;s#8005#8011#;s#8080#8081#&#39; tomcat8_1&#x2F;conf&#x2F;server.xmlsed -i &#39;s#8005#8012#;s#8080#8082#&#39; tomcat8_2&#x2F;conf&#x2F;server.xml[root@web03 application]# diff tomcat8_1&#x2F;conf&#x2F;server.xml tomcat8_2&#x2F;conf&#x2F;server.xml22c22&lt; &lt;Server port&#x3D;&quot;8011&quot; shutdown&#x3D;&quot;SHUTDOWN&quot;&gt;---&gt; &lt;Server port&#x3D;&quot;8012&quot; shutdown&#x3D;&quot;SHUTDOWN&quot;&gt;67c67&lt; Define a non-SSL&#x2F;TLS HTTP&#x2F;1.1 Connector on port 8081---&gt; Define a non-SSL&#x2F;TLS HTTP&#x2F;1.1 Connector on port 808269c69&lt; &lt;Connector port&#x3D;&quot;8081&quot; protocol&#x3D;&quot;HTTP&#x2F;1.1&quot;---&gt; &lt;Connector port&#x3D;&quot;8082&quot; protocol&#x3D;&quot;HTTP&#x2F;1.1&quot;75c75&lt; port&#x3D;&quot;8081&quot; protocol&#x3D;&quot;HTTP&#x2F;1.1&quot;---&gt; port&#x3D;&quot;8082&quot; protocol&#x3D;&quot;HTTP&#x2F;1.1&quot; 将配置好的tomcat程序打包，以备之后使用 1tar zcf muti_tomcat8.tar.gz .&#x2F;tomcat8_1 .&#x2F;tomcat8_2 启动tomcat多实例 12&#x2F;application&#x2F;tomcat8_1&#x2F;bin&#x2F;startup.sh &#x2F;application&#x2F;tomcat8_2&#x2F;bin&#x2F;startup.sh 检查端口是否启动 12345678[root@web03 tomcat8_1]# netstat -lntup |grep javatcp6 0 0 127.0.0.1:8011 :::* LISTEN 31906&#x2F;javatcp6 0 0 127.0.0.1:8012 :::* LISTEN 31932&#x2F;javatcp6 0 0 :::8080 :::* LISTEN 31812&#x2F;javatcp6 0 0 :::8081 :::* LISTEN 31906&#x2F;javatcp6 0 0 :::8082 :::* LISTEN 31932&#x2F;javatcp6 0 0 127.0.0.1:8005 :::* LISTEN 31812&#x2F;javatcp6 0 0 :::8009 :::* LISTEN 31812&#x2F;java 将每个实例的网页进行区分 12echo 8081 &gt;&gt;&#x2F;application&#x2F;tomcat8_1&#x2F;webapps&#x2F;ROOT&#x2F;index.jsp echo 8082 &gt;&gt;&#x2F;application&#x2F;tomcat8_2&#x2F;webapps&#x2F;ROOT&#x2F;index.jsp 2、在浏览器访问，进行测试检查多实例的启动 ​ http://10.0.0.17:8082 http://10.0.0.17:8081 8、tomcat反向代理集群1、负载均衡器说明12345678[root@lb01 ~]# cat &#x2F;etc&#x2F;redhat-release CentOS release 6.9 (Final)[root@lb01 ~]# uname -aLinux lb01 2.6.32-696.el6.x86_64 #1 SMP Tue Mar 21 19:29:05 UTC 2017 x86_64 x86_64 x86_64 GNU&#x2F;Linux[root@lb01 ~]# getenforce Disabled[root@lb01 ~]# &#x2F;etc&#x2F;init.d&#x2F;iptables statusiptables: Firewall is not running. 负载均衡软件使用nginx，详情参照 http://www.cnblogs.com/clsn/p/7750615.html 2、配置负载均衡器备份原配置文件 12mv &#x2F;application&#x2F;nginx&#x2F;conf&#x2F;nginx.conf&#123;,.20171127&#125; egrep -v &#39;#|^$&#39; &#x2F;application&#x2F;nginx&#x2F;conf&#x2F;nginx.conf.default &gt; &#x2F;application&#x2F;nginx&#x2F;conf&#x2F;nginx.conf ​ 配置文件内容 1234567891011121314151617181920212223242526272829[root@lb01 ~]# cat &#x2F;application&#x2F;nginx&#x2F;conf&#x2F;nginx.confworker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application&#x2F;octet-stream; sendfile on; keepalive_timeout 65; upstream web_pools &#123; server 10.0.0.17:8081; server 10.0.0.17:8082; &#125; server &#123; listen 80; server_name localhost; location &#x2F; &#123; root html; index index.jsp index.htm; proxy_pass http:&#x2F;&#x2F;web_pools; &#125; error_page 500 502 503 504 &#x2F;50x.html; location &#x3D; &#x2F;50x.html &#123; root html; &#125; &#125;&#125; ​ 配置完成后重启nginx服务 12&#x2F;application&#x2F;nginx&#x2F;sbin&#x2F;nginx -s stop &#x2F;application&#x2F;nginx&#x2F;sbin&#x2F;nginx 3、使用命令进行访问测试使用curl 命令进行测试，tail进行关键字提取 1234[root@lb01 ~]# curl -s 10.0.0.5|tail -18081[root@lb01 ~]# curl -s 10.0.0.5|tail -18082 使用curl 命令进行测试，awk进行关键字提取 1234[root@lb01 ~]# curl -s 10.0.0.5|awk &#39;END&#123;print&#125;&#39;8082[root@lb01 ~]# curl -s 10.0.0.5|awk &#39;END&#123;print&#125;&#39;8081 使用curl 命令进行测试，sed进行关键字提取 1234[root@lb01 ~]# curl -s 10.0.0.5|sed -n &#39;$p&#39;8082[root@lb01 ~]# curl -s 10.0.0.5|sed -n &#39;$p&#39;8081 4、在浏览器上进行访问测试 ​ 建议使用google浏览器chrome 的隐身模式进行访问，使用ctrl+f5 进行强制刷新","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/categories/Linux/"}],"tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"https://github.com/cyylog/tags/Tomcat/"}]},{"title":"Tomcat_01_简介","slug":"Linux/Tomcat/Tomcat-01","date":"2020-03-20T16:35:55.000Z","updated":"2020-05-25T13:57:47.342Z","comments":true,"path":"2020/03/21/Linux/Tomcat/Tomcat-01/","link":"","permalink":"https://github.com/cyylog/2020/03/21/Linux/Tomcat/Tomcat-01/","excerpt":"","text":"1、Tomcat 简介Tomcat是Apache软件基金会（Apache Software Foundation）的Jakarta 项目中的一个核心项目，由Apache、Sun和其他一些公司及个人共同开发而成。 Tomcat服务器是一个免费的开放源代码的Web应用服务器，属于轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试JSP程序的首选。 Tomcat和Nginx、Apache(httpd)、lighttpd等Web服务器一样，具有处理HTML页面的功能，另外它还是一个Servlet和JSP容器，独立的Servlet容器是Tomcat的默认模式。不过，Tomcat处理静态HTML的能力不如Nginx/Apache服务器。 目前Tomcat最新版本为9.0。Java容器还有resin、weblogic等。 Tomcat**官网：** http://tomcat.apache.org 1、Tomcat好帮手—JDKJDK是 Java 语言的软件开发工具包，主要用于移动设备、嵌入式设备上的java应用程序。JDK是整个java开发的核心，它包含了JAVA的运行环境（JVM+Java系统类库）和JAVA工具。 JDK**包含了一批用于Java**开发的组件，其中包括： 123456789101112131415161718192021javac：编译器，将后缀名为.java的源代码编译成后缀名为“.class”的字节码java：运行工具，运行.class的字节码jar：打包工具，将相关的类文件打包成一个文件javadoc：文档生成器，从源码注释中提取文档，注释需匹配规范jdb debugger：调试工具jps：显示当前java程序运行的进程状态javap：反编译程序appletviewer：运行和调试applet程序的工具，不需要使用浏览器javah：从Java类生成C头文件和C源文件。这些文件提供了连接胶合，使Java和C代码可进行交互。javaws：运行JNLP程序extcheck：一个检测jar包冲突的工具apt：注释处理工具 jhat：java堆分析工具jstack：栈跟踪程序jstat：JVM检测统计工具jstatd：jstat守护进程jinfo：获取正在运行或崩溃的java程序配置信息jmap：获取java进程内存映射信息idlj：IDL-to-Java编译器。将IDL语言转化为java文件 policytool：一个GUI的策略文件创建和管理工具jrunscript：命令行脚本运行 JDK中还包括完整的JRE（Java Runtime Environment），Java运行环境，也被称为private runtime。包括了用于产品环境的各种库类，如基础类库rt.jar，以及给开发人员使用的补充库，如国际化与本地化的类库、IDL库等等。 JDK中还包括各种样例程序，用以展示Java API中的各部分。 JDK**下载面页： **http://www.oracle.com/technetwork/java/javase/downloads/index.html ** 2、安装Tomcat &amp; JDK安装时候选择tomcat软件版本要与程序开发使用的版本一致。jdk版本要进行与tomcat保持一致。 1、系统环境说明1234567891011[root@web03 ~]# cat &#x2F;etc&#x2F;redhat-release CentOS Linux release 7.4.1708 (Core) [root@web03 ~]# uname -a Linux web03 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU&#x2F;Linux[root@web03 ~]# getenforce Disabled[root@web03 ~]# systemctl status firewalld.service● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;firewalld.service; disabled; vendor preset: enabled) Active: inactive (dead) Docs: man:firewalld(1) 2 、安装JDK命令集： 12345tar xf jdk-8u60-linux-x64.tar.gz -C &#x2F;application&#x2F;ln -s &#x2F;application&#x2F;jdk1.8.0_60 &#x2F;application&#x2F;jdk# 设置环境变量sed -i.ori &#39;$a export JAVA_HOME&#x3D;&#x2F;application&#x2F;jdk\\nexport PATH&#x3D;$JAVA_HOME&#x2F;bin:$JAVA_HOME&#x2F;jre&#x2F;bin:$PATH\\nexport CLASSPATH&#x3D;.:$JAVA_HOME&#x2F;lib:$JAVA_HOME&#x2F;jre&#x2F;lib:$JAVA_HOME&#x2F;lib&#x2F;tools.jar&#39; &#x2F;etc&#x2F;profilesource &#x2F;etc&#x2F;profile 测试jdk是否安装成功↓ 1234[root@web03 ~]# java -versionjava version &quot;1.8.0_60&quot;Java(TM) SE Runtime Environment (build 1.8.0_60-b27)Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode) 3、安装Tomcat命令集： 1234567tar xf apache-tomcat-8.0.27.tar.gz -C &#x2F;application&#x2F;ln -s &#x2F;application&#x2F;apache-tomcat-8.0.27 &#x2F;application&#x2F;tomcat# 设置环境变量echo &#39;export TOMCAT_HOME&#x3D;&#x2F;application&#x2F;tomcat&#39;&gt;&gt;&#x2F;etc&#x2F;profilesource &#x2F;etc&#x2F;profile# 注意授权，统一权限chown -R root.root &#x2F;application&#x2F;jdk&#x2F; &#x2F;application&#x2F;tomcat&#x2F; 检查tomcat是否安装成功 1234567891011121314[root@web03 ~]# &#x2F;application&#x2F;tomcat&#x2F;bin&#x2F;version.shUsing CATALINA_BASE: &#x2F;application&#x2F;tomcatUsing CATALINA_HOME: &#x2F;application&#x2F;tomcatUsing CATALINA_TMPDIR: &#x2F;application&#x2F;tomcat&#x2F;tempUsing JRE_HOME: &#x2F;application&#x2F;jdkUsing CLASSPATH: &#x2F;application&#x2F;tomcat&#x2F;bin&#x2F;bootstrap.jar:&#x2F;application&#x2F;tomcat&#x2F;bin&#x2F;tomcat-juli.jarServer version: Apache Tomcat&#x2F;8.0.27Server built: Sep 28 2015 08:17:25 UTCServer number: 8.0.27.0OS Name: LinuxOS Version: 3.10.0-693.el7.x86_64Architecture: amd64JVM Version: 1.8.0_60-b27JVM Vendor: Oracle Corporation 2、Tomcat目录介绍1、tomcat主目录介绍12345678910111213141516[root@web03 ~]# cd &#x2F;application&#x2F;tomcat&#x2F;[root@web03 tomcat]# tree -L 1.├── bin #存放tomcat管理脚本├── conf # tomcat 配置文件存放目录├── lib # web应用调用的jar包存放路径├── LICENSE├── logs # tomcat 日志存放目录，catalina.out 为主要输出日志├── NOTICE├── RELEASE-NOTES├── RUNNING.txt├── temp # 存放临时文件├── webapps # web程序存放目录└── work # 存放编译产生的.java 与 .class文件7 directories, 4 files 2、webapps目录介绍12345678910[root@web03 tomcat]# cd webapps&#x2F;[root@web03 webapps]# tree -L 1.├── docs # tomcat 帮助文档├── examples # web应用实例├── host-manager # 主机管理├── manager # 管理└── ROOT # 默认站点根目录5 directories, 0 files 3、Tomcat配置文件目录介绍（conf）12345678910111213141516[root@web03 conf]# tree -L 1.├── Catalina├── catalina.policy├── catalina.properties├── context.xml├── logging.properties├── logs├── server.xml # tomcat 主配置文件├── server.xml.bak├── server.xml.bak2├── tomcat-users.xml # tomcat 管理用户配置文件├── tomcat-users.xsd└── web.xml2 directories, 10 files 4、Tomcat的管理12# 启动程序&#x2F;application&#x2F;tomcat&#x2F;bin&#x2F;startup.sh# 关闭程序&#x2F;application&#x2F;tomcat&#x2F;bin&#x2F;shutdown.sh 启动停止 12345678910111213[root@web03 ~]# &#x2F;application&#x2F;tomcat&#x2F;bin&#x2F;shutdown.sh Using CATALINA_BASE: &#x2F;application&#x2F;tomcatUsing CATALINA_HOME: &#x2F;application&#x2F;tomcatUsing CATALINA_TMPDIR: &#x2F;application&#x2F;tomcat&#x2F;tempUsing JRE_HOME: &#x2F;application&#x2F;jdkUsing CLASSPATH: &#x2F;application&#x2F;tomcat&#x2F;bin&#x2F;bootstrap.jar:&#x2F;application&#x2F;tomcat&#x2F;bin&#x2F;tomcat-juli.jar[root@web03 ~]# &#x2F;application&#x2F;tomcat&#x2F;bin&#x2F;startup.sh Using CATALINA_BASE: &#x2F;application&#x2F;tomcatUsing CATALINA_HOME: &#x2F;application&#x2F;tomcatUsing CATALINA_TMPDIR: &#x2F;application&#x2F;tomcat&#x2F;tempUsing JRE_HOME: &#x2F;application&#x2F;jdkUsing CLASSPATH: &#x2F;application&#x2F;tomcat&#x2F;bin&#x2F;bootstrap.jar:&#x2F;application&#x2F;tomcat&#x2F;bin&#x2F;tomcat-juli.jarTomcat started. ​ 注意：tomcat未启动的情况下使用shutdown脚本，会有大量的输出信息。 检查tomcat是否启动正常 1234[root@web03 ~]# netstat -lntup |grep javatcp6 0 0 :::8080 :::* LISTEN 30560&#x2F;java tcp6 0 0 127.0.0.1:8005 :::* LISTEN 30560&#x2F;java tcp6 0 0 :::8009 :::* LISTEN 30560&#x2F;java 说明：所有与java相关的，服务启动都是java命名的进程 启动完成浏览器进行访问 http://10.0.0.17:8080/ 3、Tomcat日志说明1、查看日志1234[root@web03 ~]# tailf &#x2F;application&#x2F;tomcat&#x2F;logs&#x2F;catalina.out24-Nov-2017 15:09:51.654 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;http-nio-8080&quot;]24-Nov-2017 15:09:51.665 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;ajp-nio-8009&quot;]24-Nov-2017 15:09:51.670 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 60037 ms ​ 发现启动时间较长，其中有一项的启动时间占据了绝大多数 124-Nov-2017 15:09:50.629 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployWAR Deployment of web application archive &#x2F;application&#x2F;apache-tomcat-8.0.27&#x2F;webapps&#x2F;memtest.war has finished in 58,892 ms ​ 发现耗时在这里：是session引起的随机数问题导致的。Tocmat的Session ID是通过SHA1算法计算得到的，计算Session ID的时候必须有一个密钥。为了提高安全性Tomcat在启动的时候会通过随机生成一个密钥。 2、解决Tomcat启动慢的方法Tomcat启动慢主要原因是生成随机数的时候卡住了,导致tomcat启动不了。 是否有足够的熵来用于产生随机数，可以通过如下命令来查看 12[root@web03 ~]# cat &#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;random&#x2F;entropy_avail6 为了加速/dev/random提供随机数的速度，你可以通过操作设备的外设，让其产生大量的中断，网络传输数据，按键，移动鼠标，在命令行敲几个不同的命令，俗称聚气。 cat /dev/random 会消耗能量 方法1**：** 12vim $JAVA_HOME&#x2F;jre&#x2F;lib&#x2F;security&#x2F;java.securitysecurerandom.source&#x3D;file:&#x2F;dev&#x2F;random 改为 1securerandom.source&#x3D;file:&#x2F;dev&#x2F;urandom 方法2**：** 1234vim $TOMCAT_HOME&#x2F;bin&#x2F;catalina.shif [[ &quot;$JAVA_OPTS&quot; !&#x3D; *-Djava.security.egd&#x3D;* ]]; then JAVA_OPTS&#x3D;&quot;$JAVA_OPTS -Djava.security.egd&#x3D;file:&#x2F;dev&#x2F;urandom&quot;fi 这个系统属性egd表示熵收集守护进程(entropy gathering daemon) 方法3**：（推荐）** 12yum install rng-tools # 安装rngd服务（熵服务，增大熵池）systemctl start rngd # 启动服务 4、Tomcat管理功能使用注意：测试功能，生产环境不要用 Tomcat管理功能用于对Tomcat自身以及部署在Tomcat上的应用进行管理的web应用。在默认情况下是处于禁用状态的。如果需要开启这个功能，就需要配置管理用户，即配置tomcat-users.xml 文件。 123456[root@web03 ~]# vim &#x2F;application&#x2F;tomcat&#x2F;conf&#x2F;tomcat-users.xml……39 &lt;role rolename&#x3D;&quot;manager-gui&quot;&#x2F;&gt; 40 &lt;role rolename&#x3D;&quot;admin-gui&quot;&#x2F;&gt; 41 &lt;user username&#x3D;&quot;tomcat&quot; password&#x3D;&quot;tomcat&quot; roles&#x3D;&quot;manager-gui,admin-gui&quot;&#x2F;&gt; 42 &lt;&#x2F;tomcat-users&gt; # 在此行前加入上面三行 未修改文件前进行访问 12&lt;role rolename&#x3D;&quot;manager-gui&quot;&#x2F;&gt;&lt;user username&#x3D;&quot;tomcat&quot; password&#x3D;&quot;s3cret&quot; roles&#x3D;&quot;manager-gui&quot;&#x2F;&gt; 12&lt;role rolename&#x3D;&quot;admin-gui&quot;&#x2F;&gt;&lt;user username&#x3D;&quot;tomcat&quot; password&#x3D;&quot;s3cret&quot; roles&#x3D;&quot;admin-gui&quot;&#x2F;&gt; ​ 从而得出上面的配置文件信息。 1、在web界面访问管理界面 ​ 输入之前配置的账户与密码即可 5、Tomcat主配置文件详解1、server.xml组件类别顶级组件：位于整个配置的顶层，如server。 容器类组件：可以包含其它组件的组件，如service、engine、host、context。 连接器组件：连接用户请求至tomcat，如connector。 被嵌套类组件：位于一个容器当中，不能包含其他组件，如Valve、logger。 12345678910111213&lt;server&gt; &lt;service&gt; &lt;connector &#x2F;&gt; &lt;engine&gt; &lt;host&gt; &lt;context&gt;&lt;&#x2F;context&gt; &lt;&#x2F;host&gt; &lt;host&gt; &lt;context&gt;&lt;&#x2F;context&gt; &lt;&#x2F;host&gt; &lt;&#x2F;engine&gt; &lt;&#x2F;service&gt;&lt;&#x2F;server&gt; 2、组件介绍 组件名称 功能介绍 engine 核心容器组件，catalina引擎，负责通过connector接收用户请求，并处理请求，将请求转至对应的虚拟主机host。 host 类似于httpd中的虚拟主机，一般而言支持基于FQDN的虚拟主机。 context 定义一个应用程序，是一个最内层的容器类组件（不能再嵌套）。配置context的主要目的指定对应对的webapp的根目录，类似于httpd的alias，其还能为webapp指定额外的属性，如部署方式等。 connector 接收用户请求，类似于httpd的listen配置监听端口的。 service**（服务）** 将connector关联至engine，因此一个service内部可以有多个connector，但只能有一个引擎engine。service内部有两个connector，一个engine。因此，一般情况下一个server内部只有一个service，一个service内部只有一个engine，但一个service内部可以有多个connector。 server 表示一个运行于JVM中的tomcat实例。 Valve 阀门，拦截请求并在将其转至对应的webapp前进行某种处理操作，可以用于任何容器中，比如记录日志(access log valve)、基于IP做访问控制(remote address filter valve)。 logger 日志记录器，用于记录组件内部的状态信息，可以用于除context外的任何容器中。 realm 可以用于任意容器类的组件中，关联一个用户认证库，实现认证和授权。可以关联的认证库有两种：UserDatabaseRealm、MemoryRealm和JDBCRealm。 UserDatabaseRealm 使用JNDI自定义的用户认证库。 MemoryRealm 认证信息定义在tomcat-users.xml中。 JDBCRealm 认证信息定义在数据库中，并通过JDBC连接至数据库中查找认证用户。 3、server.xml配置文件注释1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version&#x3D;&#39;1.0&#39; encoding&#x3D;&#39;utf-8&#39;?&gt;&lt;!--&lt;Server&gt;元素代表整个容器,是Tomcat实例的顶层元素.由org.apache.catalina.Server接口来定义.它包含一个&lt;Service&gt;元素.并且它不能做为任何元素的子元素. port指定Tomcat监听shutdown命令端口.终止服务器运行时,必须在Tomcat服务器所在的机器上发出shutdown命令.该属性是必须的. shutdown指定终止Tomcat服务器运行时,发给Tomcat服务器的shutdown监听端口的字符串.该属性必须设置--&gt;&lt;Server port&#x3D;&quot;8005&quot; shutdown&#x3D;&quot;SHUTDOWN&quot;&gt; &lt;Listener className&#x3D;&quot;org.apache.catalina.startup.VersionLoggerListener&quot; &#x2F;&gt; &lt;Listener className&#x3D;&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine&#x3D;&quot;on&quot; &#x2F;&gt; &lt;Listener className&#x3D;&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot; &#x2F;&gt; &lt;Listener className&#x3D;&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot; &#x2F;&gt; &lt;Listener className&#x3D;&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot; &#x2F;&gt; &lt;GlobalNamingResources&gt; &lt;Resource name&#x3D;&quot;UserDatabase&quot; auth&#x3D;&quot;Container&quot; type&#x3D;&quot;org.apache.catalina.UserDatabase&quot; description&#x3D;&quot;User database that can be updated and saved&quot; factory&#x3D;&quot;org.apache.catalina.users.MemoryUserDatabaseFactory&quot; pathname&#x3D;&quot;conf&#x2F;tomcat-users.xml&quot; &#x2F;&gt; &lt;&#x2F;GlobalNamingResources&gt; &lt;!--service服务组件--&gt; &lt;Service name&#x3D;&quot;Catalina&quot;&gt; &lt;!-- Connector主要参数说明（见下表） --&gt; &lt;Connector port&#x3D;&quot;8080&quot; protocol&#x3D;&quot;HTTP&#x2F;1.1&quot; connectionTimeout&#x3D;&quot;20000&quot; redirectPort&#x3D;&quot;8443&quot; &#x2F;&gt; &lt;Connector port&#x3D;&quot;8009&quot; protocol&#x3D;&quot;AJP&#x2F;1.3&quot; redirectPort&#x3D;&quot;8443&quot; &#x2F;&gt; &lt;!--engine,核心容器组件,catalina引擎,负责通过connector接收用户请求,并处理请求,将请求转至对应的虚拟主机host defaultHost指定缺省的处理请求的主机名，它至少与其中的一个host元素的name属性值是一样的 --&gt; &lt;Engine name&#x3D;&quot;Catalina&quot; defaultHost&#x3D;&quot;localhost&quot;&gt; &lt;!--Realm表示存放用户名，密码及role的数据库--&gt; &lt;Realm className&#x3D;&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;Realm className&#x3D;&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName&#x3D;&quot;UserDatabase&quot;&#x2F;&gt; &lt;&#x2F;Realm&gt; &lt;!-- 详情常见下表（host参数详解）--&gt; &lt;Host name&#x3D;&quot;localhost&quot; appBase&#x3D;&quot;webapps&quot; unpackWARs&#x3D;&quot;true&quot; autoDeploy&#x3D;&quot;true&quot;&gt; &lt;!-- 详情常见下表（Context参数说明 ）--&gt; &lt;Context path&#x3D;&quot;&quot; docBase&#x3D;&quot;&quot; debug&#x3D;&quot;&quot;&#x2F;&gt; &lt;Valve className&#x3D;&quot;org.apache.catalina.valves.AccessLogValve&quot; directory&#x3D;&quot;logs&quot; prefix&#x3D;&quot;localhost_access_log&quot; suffix&#x3D;&quot;.txt&quot; pattern&#x3D;&quot;%h %l %u %t &quot;%r&quot; %s %b&quot; &#x2F;&gt; &lt;&#x2F;Host&gt; &lt;&#x2F;Engine&gt; &lt;&#x2F;Service&gt;&lt;&#x2F;Server&gt; 4、Connector主要参数说明 参数 参数说明 connector 接收用户请求，类似于httpd的listen配置监听端口. port 指定服务器端要创建的端口号，并在这个端口监听来自客户端的请求。 address 指定连接器监听的地址，默认为所有地址（即0.0.0.0） protocol 连接器使用的协议，支持HTTP和AJP。AJP（Apache Jserv Protocol）专用于tomcat与apache建立通信的， 在httpd反向代理用户请求至tomcat时使用（可见Nginx反向代理时不可用AJP协议）。 minProcessors 服务器启动时创建的处理请求的线程数 maxProcessors 最大可以创建的处理请求的线程数 enableLookups 如果为true，则可以通过调用request.getRemoteHost()进行DNS查询来得到远程客户端的实际主机名，若为false则不进行DNS查询，而是返回其ip地址 redirectPort 指定服务器正在处理http请求时收到了一个SSL传输请求后重定向的端口号 acceptCount 指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理 connectionTimeout 指定超时的时间数(以毫秒为单位) 5、host参数详解 参数 参数说明 host 表示一个虚拟主机 name 指定主机名 appBase 应用程序基本目录，即存放应用程序的目录.一般为appBase=”webapps”，相对于CATALINA_HOME而言的，也可以写绝对路径。 unpackWARs 如果为true，则tomcat会自动将WAR文件解压，否则不解压，直接从WAR文件中运行应用程序 autoDeploy 在tomcat启动时，是否自动部署。 xmlValidation 是否启动xml的校验功能，一般xmlValidation=”false”。 xmlNamespaceAware 检测名称空间，一般xmlNamespaceAware=”false”。 6、Context参数说明 参数 参数说明 Context 表示一个web应用程序，通常为WAR文件 docBase 应用程序的路径或者是WAR文件存放的路径,也可以使用相对路径，起始路径为此Context所属Host中appBase定义的路径。 path 表示此web应用程序的url的前缀，这样请求的url为http://localhost:8080/path/**** reloadable 这个属性非常重要，如果为true，则tomcat会自动检测应用程序的/WEB-INF/lib和/WEB-INF/classes目录的变化，自动装载新的应用程序，可以在不重启tomcat的情况下改变应用程序","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/categories/Linux/"}],"tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"https://github.com/cyylog/tags/Tomcat/"}]},{"title":"kubeadm快速部署kubernetes集群","slug":"容器/kubeadm快速部署kubernetes集群","date":"2020-03-16T16:14:19.000Z","updated":"2020-05-25T13:55:58.174Z","comments":true,"path":"2020/03/17/容器/kubeadm快速部署kubernetes集群/","link":"","permalink":"https://github.com/cyylog/2020/03/17/%E5%AE%B9%E5%99%A8/kubeadm%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2kubernetes%E9%9B%86%E7%BE%A4/","excerpt":"","text":"kubeadm是官方社区推出的一个用于快速部署kubernetes集群的工具。 这个工具能通过两条指令完成一个kubernetes集群的部署： 12345# 创建一个 Master 节点$ kubeadm init# 将一个 Node 节点加入到当前集群中$ kubeadm join &lt;Master节点的IP和端口 &gt; 1. 安装要求在开始之前，部署Kubernetes集群机器需要满足以下几个条件： 一台或多台机器，操作系统 CentOS7.x-86_x64 硬件配置：2GB或更多RAM，2个CPU或更多CPU，硬盘30GB或更多 集群中所有机器之间网络互通 可以访问外网，需要拉取镜像 禁止swap分区 2. 学习目标 在所有节点上安装Docker和kubeadm 部署Kubernetes Master 部署容器网络插件 部署 Kubernetes Node，将节点加入Kubernetes集群中 部署Dashboard Web页面，可视化查看Kubernetes资源 3. 准备环境 Kubernetes 架构图 Kubernetes 架构图 123456789101112131415161718192021222324关闭防火墙：$ systemctl stop firewalld$ systemctl disable firewalld关闭selinux：$ sed -i &#39;s&#x2F;enforcing&#x2F;disabled&#x2F;&#39; &#x2F;etc&#x2F;selinux&#x2F;config $ setenforce 0关闭swap：$ swapoff -a $ 临时$ vim &#x2F;etc&#x2F;fstab $ 永久添加主机名与IP对应关系（记得设置主机名）：$ cat &#x2F;etc&#x2F;hosts192.168.31.63 k8s-master192.168.31.65 k8s-node1192.168.31.66 k8s-node2将桥接的IPv4流量传递到iptables的链：$ cat &gt; &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf &lt;&lt; EOFnet.bridge.bridge-nf-call-ip6tables &#x3D; 1net.bridge.bridge-nf-call-iptables &#x3D; 1EOF$ sysctl --system 4. 所有节点安装Docker/kubeadm/kubeletKubernetes默认CRI（容器运行时）为Docker，因此先安装Docker。 4.1 安装Docker12345$ wget https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo -O &#x2F;etc&#x2F;yum.repos.d&#x2F;docker-ce.repo$ yum -y install docker-ce-18.06.1.ce-3.el7$ systemctl enable docker &amp;&amp; systemctl start docker$ docker --versionDocker version 18.06.1-ce, build e68fc7a 4.2 添加阿里云YUM软件源123456789$ cat &gt; &#x2F;etc&#x2F;yum.repos.d&#x2F;kubernetes.repo &lt;&lt; EOF[kubernetes]name&#x3D;Kubernetesbaseurl&#x3D;https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;yum&#x2F;repos&#x2F;kubernetes-el7-x86_64enabled&#x3D;1gpgcheck&#x3D;1repo_gpgcheck&#x3D;1gpgkey&#x3D;https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;yum&#x2F;doc&#x2F;yum-key.gpg https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;yum&#x2F;doc&#x2F;rpm-package-key.gpgEOF 4.3 安装kubeadm，kubelet和kubectl由于版本更新频繁，这里指定版本号部署： 12$ yum install -y kubelet-1.14.0 kubeadm-1.14.0 kubectl-1.14.0$ systemctl enable kubelet 5. 部署Kubernetes Master在192.168.31.63（Master）执行。 123456$ kubeadm init \\ --apiserver-advertise-address&#x3D;192.168.31.63 \\ --image-repository registry.aliyuncs.com&#x2F;google_containers \\ --kubernetes-version v1.14.0 \\ --service-cidr&#x3D;10.1.0.0&#x2F;16 \\ --pod-network-cidr&#x3D;10.244.0.0&#x2F;16 由于默认拉取镜像地址k8s.gcr.io国内无法访问，这里指定阿里云镜像仓库地址。 使用kubectl工具： 1234mkdir -p $HOME&#x2F;.kubesudo cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;configsudo chown $(id -u):$(id -g) $HOME&#x2F;.kube&#x2F;config$ kubectl get nodes 6. 安装Pod网络插件（CNI）1$ kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;coreos&#x2F;flannel&#x2F;a70459be0084506e4ec919aa1c114638878db11b&#x2F;Documentation&#x2F;kube-flannel.yml 确保能够访问到quay.io这个registery。 master执行 # kubectl get pods -n kube-system 7. 加入Kubernetes Node在192.168.31.65/66（Node）执行。 向集群添加新节点，执行在kubeadm init输出的kubeadm join命令： 1$ kubeadm join 192.168.31.63:6443 --token l79g5t.6ov4jkddwqki1dxe --discovery-token-ca-cert-hash sha256:4f07f9068c543130461c9db368d62b4aabc22105451057f887defa35f47fa076 8. 测试kubernetes集群在Kubernetes集群中创建一个pod，验证是否正常运行： 1234$ kubectl create deployment nginx --image&#x3D;nginx$ kubectl expose deployment nginx --port&#x3D;80 --type&#x3D;NodePort$ kubectl get pod,svc$ kubectl get pod,svc -o wide 访问地址：http://NodeIP:Port 9. 部署 Dashboard123456789101112$ kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;kubernetes&#x2F;dashboard&#x2F;v1.10.1&#x2F;src&#x2F;deploy&#x2F;recommended&#x2F;kubernetes-dashboard.yaml镜像下载因为网络的原因：镜像难以下载，需要修改以下两个地方 image: tigerfive&#x2F;kubernetes-dashboard-amd64:v1.10.1spec: type: NodePort ports: - port: 443 targetPort: 8443 默认Dashboard只能集群内部访问，修改Service为NodePort类型，暴露到外部： 12345678910111213141516kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kube-systemspec: type: NodePort ports: - port: 443 targetPort: 8443 nodePort: 30001 selector: k8s-app: kubernetes-dashboard$ kubectl apply -f kubernetes-dashboard.yaml 访问地址：http://NodeIP:30001 创建service account并绑定默认cluster-admin管理员集群角色： 123$ kubectl create serviceaccount dashboard-admin -n kube-system$ kubectl create clusterrolebinding dashboard-admin --clusterrole&#x3D;cluster-admin --serviceaccount&#x3D;kube-system:dashboard-admin$ kubectl describe secrets -n kube-system $(kubectl -n kube-system get secret | awk &#39;&#x2F;dashboard-admin&#x2F;&#123;print $1&#125;&#39;) 使用输出的token登录Dashboard。","categories":[{"name":"容器","slug":"容器","permalink":"https://github.com/cyylog/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://github.com/cyylog/tags/Kubernetes/"}]},{"title":"Kubernetes入门","slug":"容器/Kubernetes入门","date":"2020-03-14T12:24:13.000Z","updated":"2020-05-25T13:56:22.504Z","comments":true,"path":"2020/03/14/容器/Kubernetes入门/","link":"","permalink":"https://github.com/cyylog/2020/03/14/%E5%AE%B9%E5%99%A8/Kubernetes%E5%85%A5%E9%97%A8/","excerpt":"","text":"Kubernetes功能​ 官方定义k8s能够对容器化软件进行部署管理，在不停机的前提下提供简单快速的发布和更新方式。换句话说，如果项目需要多机器节点的微服务架构，并且采用Docker image（镜像）进行容器化部署，那么k8s可以帮助我们屏蔽掉集群的复杂性，自动选择最优资源分配方式进行部署。在此基础上，k8s还提供简单的多实例部署及更新方案，仅需几个操作命令就可以轻松实现。 k8s集群简单介绍 Master 负责管理集群 负责协调集群中的所有活动，例如调度应用程序，维护应用程序的状态，扩展和更新应用程序。 Worker节点(即图中的Node)是VM(虚拟机)或物理计算机，充当k8s集群中的工作计算机。 每个Worker节点都有一个Kubelet，它管理该Worker节点并负责与Master节点通信。该Worker节点还应具有用于处理容器操作的工具，例如Docker。 1.部署一个应用程序前提已经 完成 Kubernetes 集群的安装，请参考文档 安装 Kubernetes 单Master节点 目标 使用 kubectl 在 k8s 上部署第一个应用程序。 TIP kubectl 是 k8s 的客户端工具，可以使用命令行管理集群。 如果参考文档 安装 Kubernetes 单Master节点，您可以在 master 节点的 root 用户使用 kubectl 操作您的集群 您也可以尝试 从客户端电脑远程管理 Kubernetes Kubernetes 部署在 k8s 上进行部署前，首先需要了解一个基本概念 Deployment Deployment 译名为 部署。在k8s中，通过发布 Deployment，可以创建应用程序 (docker image) 的实例 (docker container)，这个实例会被包含在称为 Pod 的概念中，Pod 是 k8s 中最小可管理单元。 在 k8s 集群中发布 Deployment 后，Deployment 将指示 k8s 如何创建和更新应用程序的实例，master 节点将应用程序实例调度到集群中的具体的节点上。 创建应用程序实例后，Kubernetes Deployment Controller 会持续监控这些实例。如果运行实例的 worker 节点关机或被删除，则 Kubernetes Deployment Controller 将在群集中资源最优的另一个 worker 节点上重新创建一个新的实例。这提供了一种自我修复机制来解决机器故障或维护问题。 在容器编排之前的时代，各种安装脚本通常用于启动应用程序，但是不能够使应用程序从机器故障中恢复。通过创建应用程序实例并确保它们在集群节点中的运行实例个数，Kubernetes Deployment 提供了一种完全不同的方式来管理应用程序。 在 Kubernetes 上部署第一个应用程序 ​ Deployment 处于 master 节点上，通过发布 Deployment，master 节点会选择合适的 worker 节点创建 Container（即图中的正方体），Container 会被包含在 Pod （即蓝色圆圈）里。 部署 nginx Deployment创建 YAML 文件 创建文件 nginx-deployment.yaml，内容如下： 12345678910111213141516171819apiVersion: apps/v1 #与k8s集群版本有关，使用 kubectl api-versions 即可查看当前集群支持的版本kind: Deployment #该配置的类型，我们使用的是 Deploymentmetadata: #译名为元数据，即 Deployment 的一些基本属性和信息 name: nginx-deployment #Deployment 的名称 labels: #标签，可以灵活定位一个或多个资源，其中key和value均可自定义，可以定义多组，目前不需要理解 app: nginx #为该Deployment设置key为app，value为nginx的标签spec: #这是关于该Deployment的描述，可以理解为你期待该Deployment在k8s中如何使用 replicas: 1 #使用该Deployment创建一个应用程序实例 selector: #标签选择器，与上面的标签共同作用，目前不需要理解 matchLabels: #选择包含标签app:nginx的资源 app: nginx template: #这是选择或创建的Pod的模板 metadata: #Pod的元数据 labels: #Pod的标签，上面的selector即选择包含标签app:nginx的Pod app: nginx spec: #期望Pod实现的功能（即在pod中部署） containers: #生成container，与docker中的container是同一种 - name: nginx #container的名称 image: nginx:1.7.9 #使用镜像nginx:1.7.9创建container，该container默认80端口可访问 应用 YAML 文件 1kubectl apply -f nginx-deployment.yaml 查看部署结果 12345# 查看 Deploymentkubectl get deployments# 查看 Podkubectl get pods 可分别查看到一个名为 nginx-deployment 的 Deployment 和一个名为 nginx-deployment-xxxxxxx 的 Pod 2.查看Pods/NodesKubernetes Pods在 部署第一个应用程序 中创建 Deployment 后，k8s创建了一个 Pod（容器组） 来放置应用程序实例（container 容器）。 Pods概述 Pod 容器组 是一个k8s中一个抽象的概念，用于存放一组 container（可包含一个或多个 container 容器，即图上正方体)，以及这些 container （容器）的一些共享资源。这些资源包括： 共享存储，称为卷(Volumes)，即图上紫色圆柱 网络，每个 Pod（容器组）在集群中有个唯一的 IP，pod（容器组）中的 container（容器）共享该IP地址 container（容器）的基本信息，例如容器的镜像版本，对外暴露的端口等 例如，Pod可能既包含带有Node.js应用程序的 container 容器，也包含另一个非 Node.js 的 container 容器，用于提供 Node.js webserver 要发布的数据。Pod中的容器共享 IP 地址和端口空间（同一 Pod 中的不同 container 端口不能相互冲突），始终位于同一位置并共同调度，并在同一节点上的共享上下文中运行。（同一个Pod内的容器可以使用 localhost + 端口号互相访问）。 Pod（容器组）是 k8s 集群上的最基本的单元。当我们在 k8s 上创建 Deployment 时，会在集群上创建包含容器的 Pod (而不是直接创建容器)。每个Pod都与运行它的 worker 节点（Node）绑定，并保持在那里直到终止或被删除。如果节点（Node）发生故障，则会在群集中的其他可用节点（Node）上运行相同的 Pod（从同样的镜像创建 Container，使用同样的配置，IP 地址不同，Pod 名字 TIP 重要： Pod 是一组容器（可包含一个或多个应用程序容器），以及共享存储（卷 Volumes）、IP 地址和有关如何运行容器的信息。 如果多个容器紧密耦合并且需要共享磁盘等资源，则他们应该被部署在同一个Pod（容器组）中。 Node（节点）下图显示一个 Node（节点）上含有4个 Pod（容器组） Pod（容器组）总是在 Node（节点） 上运行。Node（节点）是 kubernetes 集群中的计算机，可以是虚拟机或物理机。每个 Node（节点）都由 master 管理。一个 Node（节点）可以有多个Pod（容器组），kubernetes master 会根据每个 Node（节点）上可用资源的情况，自动调度 Pod（容器组）到最佳的 Node（节点）上。 每个 Kubernetes Node（节点）至少运行： Kubelet，负责 master 节点和 worker 节点之间通信的进程；管理 Pod（容器组）和 Pod（容器组）内运行的 Container（容器）。 容器运行环境（如Docker）负责下载镜像、创建和运行容器等。 故障排除在部署第一个应用程序 中，我们使用了 kubectl 命令行界面部署了 nginx 并且查看了 Deployment 和 Pod。kubectl 还有如下四个常用命令，在我们排查问题时可以提供帮助： kubectl get - 显示资源列表 12345678910# kubectl get 资源类型#获取类型为Deployment的资源列表kubectl get deployments#获取类型为Pod的资源列表kubectl get pods#获取类型为Node的资源列表kubectl get nodes 名称空间 在命令后增加 -A 或 --all-namespaces 可查看所有 名称空间中 的对象，使用参数 -n 可查看指定名称空间的对象，例如 123456# 查看所有名称空间的 Deploymentkubectl get deployments -Akubectl get deployments --all-namespaces# 查看 kube-system 名称空间的 Deploymentkubectl get deployments -n kube-system 并非所有对象都在名称空间里) kubectl describe - 显示有关资源的详细信息 1234567# kubectl describe 资源类型 资源名称#查看名称为nginx-XXXXXX的Pod的信息kubectl describe pod nginx-XXXXXX #查看名称为nginx的Deployment的信息kubectl describe deployment nginx kubectl logs - 查看pod中的容器的打印日志（和命令docker logs 类似） 12345# kubectl logs Pod名称#查看名称为nginx-pod-XXXXXXX的Pod内的容器打印的日志#本案例中的 nginx-pod 没有输出日志，所以您看到的结果是空的kubectl logs -f nginx-pod-XXXXXXX 尝试在集群中执行一下上述的几个命令，可以了解如何通过 kubectl 操作 kubernetes 集群中的 Node、Pod、Container。 TIP Worker节点是k8s中的工作计算机，可能是VM或物理计算机，具体取决于群集。多个Pod可以在一个节点上运行。 3.公布应用程序Kubernetes Service（服务）概述事实上，Pod（容器组）有自己的 生命周期。当 worker node（节点）故障时，节点上运行的 Pod（容器组）也会消失。然后，Deployment 可以通过创建新的 Pod（容器组）来动态地将群集调整回原来的状态，以使应用程序保持运行。 举个例子，假设有一个图像处理后端程序，具有 3 个运行时副本。这 3 个副本是可以替换的（无状态应用），即使 Pod（容器组）消失并被重新创建，或者副本数由 3 增加到 5，前端系统也无需关注后端副本的变化。由于 Kubernetes 集群中每个 Pod（容器组）都有一个唯一的 IP 地址（即使是同一个 Node 上的不同 Pod），我们需要一种机制，为前端系统屏蔽后端系统的 Pod（容器组）在销毁、创建过程中所带来的 IP 地址的变化。 Kubernetes 中的 Service（服务） 提供了这样的一个抽象层，它选择具备某些特征的 Pod（容器组）并为它们定义一个访问方式。Service（服务）使 Pod（容器组）之间的相互依赖解耦（原本从一个 Pod 中访问另外一个 Pod，需要知道对方的 IP 地址）。一个 Service（服务）选定哪些 Pod（容器组） 通常由 LabelSelector(标签选择器) 来决定。 在创建Service的时候，通过设置配置文件中的 spec.type 字段的值，可以以不同方式向外部暴露应用程序： ClusterIP（默认） 在群集中的内部IP上公布服务，这种方式的 Service（服务）只在集群内部可以访问到 NodePort 使用 NAT 在集群中每个的同一端口上公布服务。这种方式下，可以通过访问集群中任意节点+端口号的方式访问服务 :。此时 ClusterIP 的访问方式仍然可用。 LoadBalancer 在云环境中（需要云供应商可以支持）创建一个集群外部的负载均衡器，并为使用该负载均衡器的 IP 地址作为服务的访问地址。此时 ClusterIP 和 NodePort 的访问方式仍然可用。 TIP Service是一个抽象层，它通过 LabelSelector 选择了一组 Pod（容器组），把这些 Pod 的指定端口公布到到集群外部，并支持负载均衡和服务发现。 公布 Pod 的端口以使其可访问 在多个 Pod 间实现负载均衡 使用 Label 和 LabelSelector 服务和标签下图中有两个服务Service A(黄色虚线)和Service B(蓝色虚线) Service A 将请求转发到 IP 为 10.10.10.1 的Pod上， Service B 将请求转发到 IP 为 10.10.10.2、10.10.10.3、10.10.10.4 的Pod上。 Service 将外部请求路由到一组 Pod 中，它提供了一个抽象层，使得 Kubernetes 可以在不影响服务调用者的情况下，动态调度容器组（在容器组失效后重新创建容器组，增加或者减少同一个 Deployment 对应容器组的数量等）。 Service使用 Labels、LabelSelector(标签和选择器) 匹配一组 Pod。Labels（标签）是附加到 Kubernetes 对象的键/值对，其用途有多种： 将 Kubernetes 对象（Node、Deployment、Pod、Service等）指派用于开发环境、测试环境或生产环境 嵌入版本标签，使用标签区别不同应用软件版本 使用标签对 Kubernetes 对象进行分类 下图体现了 Labels（标签）和 LabelSelector（标签选择器）之间的关联关系 Deployment B 含有 LabelSelector 为 app=B 通过此方式声明含有 app=B 标签的 Pod 与之关联 通过 Deployment B 创建的 Pod 包含标签为 app=B Service B 通过标签选择器 app=B 选择可以路由的 Pod abels（标签）可以在创建 Kubernetes 对象时附加上去，也可以在创建之后再附加上去。任何时候都可以修改一个 Kubernetes 对象的 Labels（标签） 练习：为 nginx Deployment 创建一个 Service 创建nginx的Deployment中定义了Labels，如下： 1234metadata: #译名为元数据，即Deployment的一些基本属性和信息 name: nginx-deployment #Deployment的名称 labels: #标签，可以灵活定位一个或多个资源，其中key和value均可自定义，可以定义多组 app: nginx #为该Deployment设置key为app，value为nginx的标签 创建文件 nginx-service.yaml 1vim nginx-service.yaml 文件内容如下： 12345678910111213141516apiVersion: v1kind: Servicemetadata: name: nginx-service #Service 的名称 labels: #Service 自己的标签 app: nginx #为该 Service 设置 key 为 app，value 为 nginx 的标签spec: #这是关于该 Service 的定义，描述了 Service 如何选择 Pod，如何被访问 selector: #标签选择器 app: nginx #选择包含标签 app:nginx 的 Pod ports: - name: nginx-port #端口的名字 protocol: TCP #协议类型 TCP/UDP port: 80 #集群内的其他容器组可通过 80 端口访问 Service nodePort: 32600 #通过任意节点的 32600 端口访问 Service targetPort: 80 #将请求转发到匹配 Pod 的 80 端口 type: NodePort #Serive的类型，ClusterIP/NodePort/LoaderBalancer 执行命令 1kubectl apply -f nginx-service.yaml 检查执行结果 1kubectl get services -o wide 访问服务 1curl &lt;任意节点的 IP&gt;:32600 4.伸缩应用程序Scaling（伸缩）应用程序在前面，我们创建了一个 Deployment，然后通过 服务 提供访问 Pod 的方式。我们发布的 Deployment 只创建了一个 Pod 来运行我们的应用程序。当流量增加时，我们需要对应用程序进行伸缩操作以满足系统性能需求。 伸缩 的实现可以通过更改 nginx-deployment.yaml 文件中部署的 replicas（副本数）来完成 12spec: replicas: 2 #使用该Deployment创建两个应用程序实例 Scaling（伸缩）概述下图中，Service A 只将访问流量转发到 IP 为 10.0.0.5 的Pod上 ​ 修改了 Deployment 的 replicas 为 4 后，Kubernetes 又为该 Deployment 创建了 3 新的 Pod，这 4 个 Pod 有相同的标签。因此Service A通过标签选择器与新的 Pod建立了对应关系，将访问流量通过负载均衡在 4 个 Pod 之间进行转发。 TIP 通过更改部署中的 replicas（副本数）来完成扩展 练习：将 nginx Deployment 扩容到 4 个副本 修改 nginx-deployment.yaml 文件 将 replicas 修改为 4 执行命令 1kubectl apply -f nginx-deployment.yaml 查看结果 1watch kubectl get pods -o wide 5.执行滚动更新更新应用程序户期望应用程序始终可用，为此开发者/运维者在更新应用程序时要分多次完成。在 Kubernetes 中，这是通过 Rolling Update 滚动更新完成的。Rolling Update滚动更新 通过使用新版本的 Pod 逐步替代旧版本的 Pod 来实现 Deployment 的更新，从而实现零停机。新的 Pod 将在具有可用资源的 Node（节点）上进行调度。 Kubernetes 更新多副本的 Deployment 的版本时，会逐步的创建新版本的 Pod，逐步的停止旧版本的 Pod，以便使应用一直处于可用状态。这个过程中，Service 能够监视 Pod 的状态，将流量始终转发到可用的 Pod 上。 在上一个模块中，我们学习了将应用程序 Scale Up（扩容）为多个实例，这是执行更新而不影响应用程序可用性的前提（如果只有 1 个实例那还玩啥）。默认情况下，Rolling Update 滚动更新 过程中，Kubernetes 逐个使用新版本 Pod 替换旧版本 Pod（最大不可用 Pod 数为 1、最大新建 Pod 数也为 1）。这两个参数可以配置为数字或百分比。在Kubernetes 中，更新是版本化的，任何部署更新都可以恢复为以前的（稳定）版本。 滚动更新概述 原本 Service A 将流量负载均衡到 4 个旧版本的 Pod （当中的容器为 绿色）上 更新完 Deployment 部署文件中的镜像版本后，master 节点选择了一个 worker 节点，并根据新的镜像版本创建 Pod（紫色容器）。新 Pod 拥有唯一的新的 IP。同时，master 节点选择一个旧版本的 Pod 将其移除。 此时，Service A 将新 Pod 纳入到负载均衡中，将旧Pod移除 同步骤2，再创建一个新的 Pod 替换一个原有的 Pod 如此 Rolling Update 滚动更新，直到所有旧版本 Pod 均移除，新版本 Pod 也达到 Deployment 部署文件中定义的副本数，则滚动更新完成 滚动更新允许以下操作： 将应用程序从准上线环境升级到生产环境（通过更新容器镜像） 回滚到以前的版本 持续集成和持续交付应用程序，无需停机 练习：更新 nginx Deployment修改 nginx-deployment.yaml 文件 修改文件中 image 镜像的标签，如下所示 执行命令 1kubectl apply -f nginx-deployment.yaml 查看过程及结果 执行命令，可观察到 pod 逐个被替换的过程。 1watch kubectl get pods -l app=nginx Kubernetes核心概念什么是Kubernetes？Kubernetes（k8s）是自动化容器操作的开源平台，这些操作包括部署，调度和节点集群间扩展。如果你曾经用过Docker容器技术部署容器，那么可以将Docker看成Kubernetes内部使用的低级别组件。Kubernetes不仅仅支持Docker，还支持Rocket，这是另一种容器技术。 使用Kubernetes可以： 自动化容器的部署和复制 随时扩展或收缩容器规模 将容器组织成组，并且提供容器间的负载均衡 很容易地升级应用程序容器的新版本 提供容器弹性，如果容器失效就替换它，等等… 集群集群是一组节点，这些节点可以是物理服务器或者虚拟机，之上安装了Kubernetes平台。下图展示这样的集群。注意该图为了强调核心概念有所简化。这里可以看到一个典型的Kubernetes架构图。 上图可以看到如下组件，使用特别的图标表示Service和Label： PodContainer（容器） Label())（标签） Replication Controller（复制控制器） Service（）（服务） Node（节点） Kubernetes Master（Kubernetes主节点） PodPod（上图绿色方框）安排在节点上，包含一组容器和卷。同一个Pod里的容器共享同一个网络命名空间，可以使用localhost互相通信。Pod是短暂的，不是持续性实体。你可能会有这些问题： 如果Pod是短暂的，那么我怎么才能持久化容器数据使其能够跨重启而存在呢？ 是的，Kubernetes支持 卷 的概念，因此可以使用持久化的卷类型。 是否手动创建Pod，如果想要创建同一个容器的多份拷贝，需要一个个分别创建出来么？可以手动创建单个Pod，但是也可以使用Replication Controller使用Pod模板创建出多份拷贝，下文会详细介绍。 如果Pod是短暂的，那么重启时IP地址可能会改变，那么怎么才能从前端容器正确可靠地指向后台容器呢？这时可以使用Service，下文会详细介绍。 Label正如图所示，一些Pod有Label（）。一个Label是attach到Pod的一对键/值对，用来传递用户定义的属性。比如，你可能创建了一个”tier”和“app”标签，通过Label（tier=frontend, app=myapp）来标记前端Pod容器，使用Label（tier=backend, app=myapp）标记后台Pod。然后可以使用 Selectors 选择带有特定Label的Pod，并且将Service或者Replication Controller应用到上面。 Replication Controller是否手动创建Pod，如果想要创建同一个容器的多份拷贝，需要一个个分别创建出来么，能否将Pods划到逻辑组里？ Replication Controller确保任意时间都有指定数量的Pod“副本”在运行。如果为某个Pod创建了Replication Controller并且指定3个副本，它会创建3个Pod，并且持续监控它们。如果某个Pod不响应，那么Replication Controller会替换它，保持总数为3.如下面的动画所示： 如果之前不响应的Pod恢复了，现在就有4个Pod了，那么Replication Controller会将其中一个终止保持总数为3。如果在运行中将副本总数改为5，Replication Controller会立刻启动2个新Pod，保证总数为5。还可以按照这样的方式缩小Pod，这个特性在执行滚动 升级 时很有用。 当创建Replication Controller时，需要指定两个东西： Pod模板：用来创建Pod副本的模板 Label：Replication Controller需要监控的Pod的标签。现在已经创建了Pod的一些副本，那么在这些副本上如何均衡负载呢？我们需要的是Service。 TIP 最新 Kubernetes 版本里，推荐使用 Deployment Service如果Pods是短暂的，那么重启时IP地址可能会改变，怎么才能从前端容器正确可靠地指向后台容器呢？ Service 抽象 现在，假定有2个后台Pod，并且定义后台Service的名称为‘backend-service’，label选择器为(tier=backend, app=myapp) 的Service会完成如下两件重要的事情： 会为Service创建一个本地集群的DNS入口，因此前端Pod只需要DNS查找主机名为 ‘backend-service’，就能够解析出前端应用程序可用的IP地址。 现在前端已经得到了后台服务的IP地址，但是它应该访问2个后台Pod的哪一个呢？Service在这2个后台Pod之间提供透明的负载均衡，会将请求分发给其中的任意一个（如下面的动画所示）。通过每个Node上运行的代理（kube-proxy）完成。 下述动画展示了Service的功能。注意该图作了很多简化。如果不进入网络配置，那么达到透明的负载均衡目标所涉及的底层网络和路由相对先进。如果有兴趣，有更深入的介绍。 每个节点都运行如下Kubernetes关键组件： Kubelet：是主节点代理。 Kube-proxy：Service使用其将链接路由到Pod，如上文所述。 Docker或Rocket：Kubernetes使用的容器技术来创建容器。 Kubernetes Master集群拥有一个Kubernetes Master（紫色方框）。Kubernetes Master提供集群的独特视角，并且拥有一系列组件，比如Kubernetes API Server。API Server提供可以用来和集群交互的REST端点。master节点包括用来创建和复制Pod的Replication Controller。","categories":[{"name":"容器","slug":"容器","permalink":"https://github.com/cyylog/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://github.com/cyylog/tags/Kubernetes/"}]},{"title":"Docker数据共享与持久化","slug":"容器/Docker数据共享与持久化","date":"2020-01-19T10:11:44.000Z","updated":"2020-06-19T10:36:42.162Z","comments":true,"path":"2020/01/19/容器/Docker数据共享与持久化/","link":"","permalink":"https://github.com/cyylog/2020/01/19/%E5%AE%B9%E5%99%A8/Docker%E6%95%B0%E6%8D%AE%E5%85%B1%E4%BA%AB%E4%B8%8E%E6%8C%81%E4%B9%85%E5%8C%96/","excerpt":"","text":"本文介绍如何在 Docker 内部以及容器之间管理数据，在容器中管理数据主要有两种方式： 数据卷（Data Volumes） 挂载主机目录 (Bind mounts) 数据卷数据卷是一个可供一个或多个容器使用的特殊目录，它绕过UFS，可以提供很多有用的特性： 数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 注意：数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会隐藏掉，能显示看的是挂载的 数据卷。 选择 -v 还是 -–mount 参数： Docker 新用户应该选择--mount参数，经验丰富的 Docker 使用者对-v或者 --volume已经很熟悉了，但是推荐使用--mount参数。 创建一个数据卷： 1$ docker volume create my-vol 查看所有的 数据卷： 12$ docker volume lslocal my-vol 在主机里使用以下命令可以查看指定 数据卷 的信息 1234567891011$ docker volume inspect my-vol[ &#123; \"Driver\": \"local\", \"Labels\": &#123;&#125;, \"Mountpoint\": \"/var/lib/docker/volumes/my-vol/_data\", \"Name\": \"my-vol\", \"Options\": &#123;&#125;, \"Scope\": \"local\" &#125;] 启动一个挂载数据卷的容器：在用docker run命令的时候，使用--mount标记来将 数据卷 挂载到容器里。在一次docker run中可以挂载多个 数据卷。下面创建一个名为 web 的容器，并加载一个 数据卷 到容器的 /webapp 目录。 123456$ docker run -d -P \\ --name web \\ # -v my-vol:/wepapp \\ --mount source=my-vol,target=/webapp \\ training/webapp \\ python app.py 查看数据卷的具体信息：在主机里使用以下命令可以查看 web 容器的信息 123456789101112131415$ docker inspect web...\"Mounts\": [ &#123; \"Type\": \"volume\", \"Name\": \"my-vol\", \"Source\": \"/var/lib/docker/volumes/my-vol/_data\", \"Destination\": \"/app\", \"Driver\": \"local\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"\" &#125;],... 删除数据卷： 1$ docker volume rm my-vol 数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 数据卷。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用docker rm -v这个命令。 无主的数据卷可能会占据很多空间，要清理请使用以下命令 1$ docker volume prune 挂载主机目录选择 -v 还是 -–mount 参数： Docker 新用户应该选择 –mount 参数，经验丰富的 Docker 使用者对 -v 或者 –volume 已经很熟悉了，但是推荐使用 –mount 参数。 挂载一个主机目录作为数据卷：使用 --mount 标记可以指定挂载一个本地主机的目录到容器中去。 123456$ docker run -d -P \\ --name web \\ # -v /src/webapp:/opt/webapp \\ --mount type=bind,source=/src/webapp,target=/opt/webapp \\ training/webapp \\ python app.py 上面的命令加载主机的 /src/webapp 目录到容器的 /opt/webapp目录。这个功能在进行测试的时候十分方便，比如用户可以放置一些程序到本地目录中，来查看容器是否正常工作。本地目录的路径必须是绝对路径，以前使用 -v 参数时如果本地目录不存在 Docker 会自动为你创建一个文件夹，现在使用 –mount 参数时如果本地目录不存在，Docker 会报错。 Docker 挂载主机目录的默认权限是 读写，用户也可以通过增加readonly指定为 只读。 123456$ docker run -d -P \\ --name web \\ # -v /src/webapp:/opt/webapp:ro \\ --mount type=bind,source=/src/webapp,target=/opt/webapp,readonly \\ training/webapp \\ python app.py 加了readonly之后，就挂载为 只读 了。如果你在容器内 /opt/webapp 目录新建文件，会显示如下错误: 12/opt/webapp # touch new.txttouch: new.txt: Read-only file system 查看数据卷的具体信息：在主机里使用以下命令可以查看 web 容器的信息 123456789101112$ docker inspect web...\"Mounts\": [ &#123; \"Type\": \"bind\", \"Source\": \"/src/webapp\", \"Destination\": \"/opt/webapp\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"rprivate\" &#125;], 挂载一个本地主机文件作为数据卷：--mount标记也可以从主机挂载单个文件到容器中 123456789$ docker run --rm -it \\ # -v $HOME/.bash_history:/root/.bash_history \\ --mount type=bind,source=$HOME/.bash_history,target=/root/.bash_history \\ ubuntu:17.10 \\ bashroot@2affd44b4667:/# history1 ls2 diskutil list 这样就可以记录在容器输入过的命令了。","categories":[{"name":"容器","slug":"容器","permalink":"https://github.com/cyylog/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://github.com/cyylog/tags/Docker/"}]},{"title":"zabbix 监控项","slug":"监控/Zabbix监控项","date":"2020-01-04T17:55:39.000Z","updated":"2020-05-30T15:35:43.901Z","comments":true,"path":"2020/01/05/监控/Zabbix监控项/","link":"","permalink":"https://github.com/cyylog/2020/01/05/%E7%9B%91%E6%8E%A7/Zabbix%E7%9B%91%E6%8E%A7%E9%A1%B9/","excerpt":"","text":"Zabbix 监控cyylog 2020-04-07 22:08:29 Zabbix监控什么？ 监控项 Zabbix常用监控项zabbix自带的常用监控项 123456789agent.ping 检测客户端可达性、返回nothing表示不可达。1表示可达system.cpu.load --检测cpu负载。返回浮点数system.cpu.util -- 检测cpu使用率。返回浮点数vfs.dev.read -- 检测硬盘读取数据，返回是sps.ops.bps浮点类型，需要定义1024倍vfs.dev.write -- 检测硬盘写入数据。返回是sps.ops.bps浮点类型，需要定义1024倍net.if.out[br0] --检测网卡流速、流出方向，时间间隔为60Snet-if-in[br0] --检测网卡流速，流入方向（单位：字节） 时间间隔60Sproc.num[] 目前系统中的进程总数，时间间隔60sproc.num[,,run] 目前正在运行的进程总数，时间间隔60S 处理器信息123456789通过zabbix_get 获取负载值合理的控制用户态、系统态、IO等待时间剋保证进程高效率的运行系统态运行时间较高说明进程进行系统调用的次数比较多，一般的程序如果系统态运行时间占用过高就需要优化程序，减少系统调用io等待时间过高则表明硬盘的io性能差，如果是读写文件比较频繁、读写效率要求比较高，可以考虑更换硬盘，或者使用多磁盘做raid的方案system.cpu.swtiches --cpu的进程上下文切换，单位sps，表示每秒采样次数，api中参数history需指定为3system.cpu.intr --cpu中断数量、api中参数history需指定为3system.cpu.load[percpu,avg1] --cpu每分钟的负载值，按照核数做平均值(Processor load (1 min average per core))，api中参数history需指定为0system.cpu.load[percpu,avg5] --cpu每5分钟的负载值，按照核数做平均值(Processor load (5 min average per core))，api中参数history需指定为0system.cpu.load[percpu,avg15] --cpu每5分钟的负载值，按照核数做平均值(Processor load (15 min average per core))，api中参数history需指定为0 zabbix的自定义常用项内存相关12345vim &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc&#x2F;zabbix_agentd.conf.d&#x2F;catcarm.confUserParameter&#x3D;ram.info[*],&#x2F;bin&#x2F;cat &#x2F;proc&#x2F;meminfo |awk &#39;&#x2F;^$1:&#123;print $2&#125;&#39;ram.info[Cached] --检测内存的缓存使用量、返回整数，需要定义1024倍ram.info[MemFree] --检测内存的空余量，返回整数，需要定义1024倍ram.info[Buffers] --检测内存的使用量，返回整数，需要定义1024倍 TCP相关的自定义项12345678910111213141516171819vim &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;share&#x2F;zabbix&#x2F;alertscripts&#x2F;tcp_connection.sh#!&#x2F;bin&#x2F;bashfunction ESTAB &#123; &#x2F;usr&#x2F;sbin&#x2F;ss -ant |awk &#39;&#123;++s[$1]&#125; END &#123;for(k in s) print k,s[k]&#125;&#39; | grep &#39;ESTAB&#39; | awk &#39;&#123;print $2&#125;&#39;&#125;function TIMEWAIT &#123;&#x2F;usr&#x2F;sbin&#x2F;ss -ant | awk &#39;&#123;++s[$1]&#125; END &#123;for(k in s) print k,s[k]&#125;&#39; | grep &#39;TIME-WAIT&#39; | awk &#39;&#123;print $2&#125;&#39;&#125;function LISTEN &#123;&#x2F;usr&#x2F;sbin&#x2F;ss -ant | awk &#39;&#123;++s[$1]&#125; END &#123;for(k in s) print k,s[k]&#125;&#39; | grep &#39;LISTEN&#39; | awk &#39;&#123;print $2&#125;&#39;&#125;$1vim &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc&#x2F;zabbix_agentd.conf.d&#x2F;cattcp.confUserParameter&#x3D;tcp[*],&#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;share&#x2F;zabbix&#x2F;alertscripts&#x2F;tcp_connection.sh $1tcp[TIMEWAIT] --检测TCP的驻留数，返回整数tcp[ESTAB] --检测tcp的连接数、返回整数tcp[LISTEN] --检测TCP的监听数，返回整数 nginx相关的自定义项12345678910111213141516171819202122232425vim &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;default.conf location &#x2F;nginx-status &#123; stub_status on; access_log off; allow 127.0.0.1; deny all; &#125;vim &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc&#x2F;zabbix_agentd.conf.d&#x2F;nginx.confUserParameter&#x3D;Nginx.active,&#x2F;usr&#x2F;bin&#x2F;curl -s &quot;http:&#x2F;&#x2F;127.0.0.1:80&#x2F;nginx-status&quot; | awk &#39;&#x2F;Active&#x2F; &#123;print $NF&#125;&#39;UserParameter&#x3D;Nginx.read,&#x2F;usr&#x2F;bin&#x2F;curl -s &quot;http:&#x2F;&#x2F;127.0.0.1:80&#x2F;nginx-status&quot; | grep &#39;Reading&#39; | cut -d&quot; &quot; -f2UserParameter&#x3D;Nginx.wrie,&#x2F;usr&#x2F;bin&#x2F;curl -s &quot;http:&#x2F;&#x2F;127.0.0.1:80&#x2F;nginx-status&quot; | grep &#39;Writing&#39; | cut -d&quot; &quot; -f4UserParameter&#x3D;Nginx.wait,&#x2F;usr&#x2F;bin&#x2F;curl -s &quot;http:&#x2F;&#x2F;127.0.0.1:80&#x2F;nginx-status&quot; | grep &#39;Waiting&#39; | cut -d&quot; &quot; -f6UserParameter&#x3D;Nginx.accepted,&#x2F;usr&#x2F;bin&#x2F;curl -s &quot;http:&#x2F;&#x2F;127.0.0.1:80&#x2F;nginx-status&quot; | awk &#39;&#x2F;^[ \\t]+[0-9]+[ \\t]+[0-9]+[ \\t]+[0-9]+&#x2F; &#123;print $1&#125;&#39;UserParameter&#x3D;Nginx.handled,&#x2F;usr&#x2F;bin&#x2F;curl -s &quot;http:&#x2F;&#x2F;127.0.0.1:80&#x2F;nginx-status&quot; | awk &#39;&#x2F;^[ \\t]+[0-9]+[ \\t]+[0-9]+[ \\t]+[0-9]+&#x2F; &#123;print $2&#125;&#39;UserParameter&#x3D;Nginx.requests,&#x2F;usr&#x2F;bin&#x2F;curl -s &quot;http:&#x2F;&#x2F;127.0.0.1:80&#x2F;nginx-status&quot; | awk &#39;&#x2F;^[ \\t]+[0-9]+[ \\t]+[0-9]+[ \\t]+[0-9]+&#x2F; &#123;print $3&#125;&#39;PHP.listenqueue --检测PHP队列数，返回整数PHP.idle --检测PHP空闲进程数，返回整数PHP.active --检测PHP活动进程数，返回整数PHP.conn --检测PHP请求数,返回整数PHP.reached --检测PHP达到限制次数，返回整数PHP.requets --检测PHP慢请求书，返回整数 redis相关的自定义项12345678910111213141516171819202122vim &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc&#x2F;zabbix_agentd.conf.d&#x2F;redis.confUserParameter&#x3D;Redis.Status,&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-cli -h 127.0.0.1 -p 6379 ping |grep -c PONGUserParameter&#x3D;Redis_conn[*],&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-cli -h $1 -p $2 info | grep -w &quot;connected_clients&quot; | awk -F&#39;:&#39; &#39;&#123;print $2&#125;&#39;UserParameter&#x3D;Redis_rss_mem[*],&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-cli -h $1 -p $2 info | grep -w &quot;used_memory_rss&quot; | awk -F&#39;:&#39; &#39;&#123;print $2&#125;&#39;UserParameter&#x3D;Redis_lua_mem[*],&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-cli -h $1 -p $2 info | grep -w &quot;used_memory_lua&quot; | awk -F&#39;:&#39; &#39;&#123;print $2&#125;&#39;UserParameter&#x3D;Redis_cpu_sys[*],&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-cli -h $1 -p $2 info | grep -w &quot;used_cpu_sys&quot; | awk -F&#39;:&#39; &#39;&#123;print $2&#125;&#39;UserParameter&#x3D;Redis_cpu_user[*],&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-cli -h $1 -p $2 info | grep -w &quot;used_cpu_user&quot; | awk -F&#39;:&#39; &#39;&#123;print $2&#125;&#39;UserParameter&#x3D;Redis_cpu_sys_cline[*],&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-cli -h $1 -p $2 info | grep -w &quot;used_cpu_sys_children&quot; | awk -F&#39;:&#39; &#39;&#123;print $2&#125;&#39;UserParameter&#x3D;Redis_cpu_user_cline[*],&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-cli -h $1 -p $2 info | grep -w &quot;used_cpu_user_children&quot; | awk -F&#39;:&#39; &#39;&#123;print $2&#125;&#39;UserParameter&#x3D;Redis_keys_num[*],&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-cli -h $1 -p $2 info | grep -w &quot;$$1&quot; | grep -w &quot;keys&quot; | grep db$3 | awk -F&#39;&#x3D;&#39; &#39;&#123;print $2&#125;&#39; | awk -F&#39;,&#39; &#39;&#123;print $1&#125;&#39;UserParameter&#x3D;Redis_loading[*],&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-cli -h $1 -p $2 info | grep loading | awk -F&#39;:&#39; &#39;&#123;print $$2&#125;&#39;Redis.Status --检测Redis运行状态， 返回整数Redis_conn --检测Redis成功连接数，返回整数Redis_rss_mem --检测Redis系统分配内存，返回整数Redis_lua_mem --检测Redis引擎消耗内存，返回整数Redis_cpu_sys --检测Redis主程序核心CPU消耗率，返回整数Redis_cpu_user --检测Redis主程序用户CPU消耗率，返回整数Redis_cpu_sys_cline --检测Redis后台核心CPU消耗率，返回整数Redis_cpu_user_cline --检测Redis后台用户CPU消耗率，返回整数Redis_keys_num --检测库键值数，返回整数Redis_loding --检测Redis持久化文件状态，返回整数 MySQL:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647version:数据库版本key_buffer_size:myisam的索引buffer大小sort_buffer_size:会话的排序空间（每个线程会申请一个）join_buffer_size:这是为链接操作分配的最小缓存大小，这些连接使用普通索引扫描、范围扫描、或者连接不适用索引max_connections:最大允许同时连接的数量max_connect_errors：允许一个主机最多的错误链接次数，如果超过了就会拒绝之后链接（默认100）。可以使用flush hosts命令去解除拒绝open_files_limits:操作系统允许mysql打开的文件数量，可以通过opened_tables状态确定是否需要增大table_open_cache,如果opened_tables比较大且一直还在增大说明需要增大table_open_cachemax-heap_tables_size:建立的内存表的最大大小（默认16M）这个参数和tmp_table_size一起限制内部临时表的最大值(取这两个参数的小的一个），如果超过限制，则表会变为innodb或myisam引擎，（5.7.5之前是默认是myisam，5.7.6开始是innodb，可以通过internal_tmp_disk_storage_engine参数调整）。max_allowed_packet:一个包的最大大小##########GET INNODB INFO#INNODB variablesinnodb_version:innodb_buffer_pool_instances：将innodb缓冲池分为指定的多个（默认为1）innodb_buffer_pool_size:innodb缓冲池大小、5.7.5引入了innodb_buffer_pool_chunk_size,innodb_doublewrite：是否开启doublewrite（默认开启）innodb_read_io_threads:IO读线程的数量innodb_write_io_threads:IO写线程的数量########innodb statusinnodb_buffer_pool_pages_total:innodb缓冲池页的数量、大小等于innodb_buffer_pool_size&#x2F;(16*1024)innodb_buffer_pool_pages_data:innodb缓冲池中包含数据的页的数量########## GET MYSQL HITRATE1、查询缓存命中率如果Qcache_hits+Com_select&lt;&gt;0则为 Qcache_hits&#x2F;（Qcache_hits+Com_select），否则为02、线程缓存命中率如果Connections&lt;&gt;0,则为1-Threads_created&#x2F;Connections，否则为03、myisam键缓存命中率如果Key_read_requests&lt;&gt;0,则为1-Key_reads&#x2F;Key_read_requests，否则为04、myisam键缓存写命中率如果Key_write_requests&lt;&gt;0,则为1-Key_writes&#x2F;Key_write_requests，否则为05、键块使用率如果Key_blocks_used+Key_blocks_unused&lt;&gt;0，则Key_blocks_used&#x2F;（Key_blocks_used+Key_blocks_unused），否则为06、创建磁盘存储的临时表比率如果Created_tmp_disk_tables+Created_tmp_tables&lt;&gt;0,则Created_tmp_disk_tables&#x2F;（Created_tmp_disk_tables+Created_tmp_tables），否则为07、连接使用率如果max_connections&lt;&gt;0，则threads_connected&#x2F;max_connections，否则为08、打开文件比率如果open_files_limit&lt;&gt;0，则open_files&#x2F;open_files_limit，否则为09、表缓存使用率如果table_open_cache&lt;&gt;0，则open_tables&#x2F;table_open_cache，否则为0","categories":[{"name":"监控","slug":"监控","permalink":"https://github.com/cyylog/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"https://github.com/cyylog/tags/zabbix/"}]},{"title":"Go_学习之Docke容器","slug":"DevOPs/Golang/Go-study","date":"2019-12-04T17:55:39.000Z","updated":"2020-06-19T16:48:06.268Z","comments":true,"path":"2019/12/05/DevOPs/Golang/Go-study/","link":"","permalink":"https://github.com/cyylog/2019/12/05/DevOPs/Golang/Go-study/","excerpt":"","text":"mysql容器1234567891011121314151617181920[mysqld]log-error&#x3D;&#x2F;mylog&#x2F;error.logslow_query_log &#x3D; onlong_query_time&#x3D;2slow-query-log-file &#x3D;&#x2F;mylog&#x2F;slow.logdocker run -it --rm --entrypoint&#x3D;&quot;&#x2F;bin&#x2F;bash&quot; mysql:5.7 -c &quot;cat &#x2F;etc&#x2F;group &quot;因为容器默认使用的是mysql用户。 因此我们需要把映射的文件夹修改ownerdocker run --name mysql -d \\-p 3306:3306 \\-v &#x2F;home&#x2F;cyy&#x2F;mysql&#x2F;data:&#x2F;data \\-v &#x2F;home&#x2F;cyy&#x2F;mysql&#x2F;conf&#x2F;my.cnf:&#x2F;etc&#x2F;mysql&#x2F;my.cnf \\-v &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai:&#x2F;etc&#x2F;localtime \\-v &#x2F;home&#x2F;cyy&#x2F;mysql&#x2F;mylog:&#x2F;mylog \\-e MYSQL_ROOT_PASSWORD&#x3D;123456 \\mysql:5.7 alpine容器1234567docker pull alpine docker run --name goserver -d \\-v /home/cyy/web:/server \\-v /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime \\-w /server \\alpine ./gin nginx容器1docker pull nginx:alpine 1234567891011121314151617181920212223242526272829user nginx;worker_processes auto;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; keepalive_timeout 65; upstream gin &#123; server 172.17.0.4:8080; &#125; server&#123; listen 80; location / &#123; proxy_pass http://gin; #Proxy Settings proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125;&#125; 12345docker run -d --name ngx \\-v /home/cyy/ngx/nginx.conf:/etc/nginx/nginx.conf \\-v /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime \\-p 80:80 \\nginx:alpine Redis 容器1docker run --name redis-d -v /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime -p 6379:6379 redis:5-alpine redis-servver","categories":[{"name":"容器","slug":"容器","permalink":"https://github.com/cyylog/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://github.com/cyylog/tags/Docker/"}]},{"title":"Oracle设置开机自启","slug":"SQL/Oracle设置开机自启","date":"2019-11-27T14:48:07.000Z","updated":"2020-05-25T13:57:11.610Z","comments":true,"path":"2019/11/27/SQL/Oracle设置开机自启/","link":"","permalink":"https://github.com/cyylog/2019/11/27/SQL/Oracle%E8%AE%BE%E7%BD%AE%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF/","excerpt":"","text":"步骤： 1：查看ORACLE_HOME是否设置 12$ echo $ORACLE_HOME&#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;11.2.0&#x2F;db_1 2：执行dbstart 数据库自带启动脚本 123456789101112131415[oracle@njdzjkdb ~]$ cd $ORACLE_HOME[oracle@njdzjkdb dbhome_1]$ cd bin&#x2F;[oracle@njdzjkdb bin]$ dbstartORACLE_HOME_LISTNER is not SET, unable to auto-start Oracle Net Listener Usage: &#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;11.2.0&#x2F;db_1&#x2F;bin&#x2F;dbstart ORACLE_HOME错误提示：ORACLE_HOME_LISTNER 没有设置[oracle@njdzjkdb bin]$ ll | grep dbs-rwxr-x---. 1 oracle oinstall 6088 1月 1 2000 dbshut-rwxr-x---. 1 oracle oinstall 13892 12月 11 16:01 dbstart编辑 dbstart，将ORACLE_HOME_LISTNER&#x3D;$1修改成 ORACLE_HOME_LISTNER&#x3D;$ORACLE_HOME 前提是$ORACLE_HOME环境设置正确[oracle@njdzjkdb bin]$ vi dbstart ORACLE_HOME_LISTNER&#x3D;&#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;11.2.0&#x2F;db_1 3：编辑/etc/oratab文件 123dbca建库时都会自动创建&#x2F;etc&#x2F;oratab文件将oracle:&#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;11.2.0&#x2F;db_1:N修改成 oracle:&#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;11.2.0&#x2F;db_1:Y 4：编辑/etc/rc.d/rc.local启动文件，添加数据库启动脚本dbstart 12345678910111213141516[root@njdzjkdb ~]# vi &#x2F;etc&#x2F;rc.d&#x2F;rc.local#!&#x2F;bin&#x2F;bash# THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES## It is highly advisable to create own systemd services or udev rules# to run scripts during boot instead of using this file.## In contrast to previous versions due to parallel execution during boot# this script will NOT be run after all other services.## Please note that you must run &#39;chmod +x &#x2F;etc&#x2F;rc.d&#x2F;rc.local&#39; to ensure# that this script will be executed during boot.touch &#x2F;var&#x2F;lock&#x2F;subsys&#x2F;localsu oracle -lc &quot;&#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;11.2.0&#x2F;db_1&#x2F;bin&#x2F;lsnrctl start&quot;su oracle -lc &#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;11.2.0&#x2F;db_1&#x2F;bin&#x2F;dbstart 5：重启主机，查看数据库和监听是自启动 1netstat -tunlp | grep 1521 6：查看数据库是否处于open状态 1select status from v$instance","categories":[{"name":"SQL","slug":"SQL","permalink":"https://github.com/cyylog/categories/SQL/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://github.com/cyylog/tags/Oracle/"}]},{"title":"CentOS7静默安装oracle11g","slug":"SQL/CentOS7静默安装oracle11g","date":"2019-11-27T14:43:32.000Z","updated":"2020-05-25T13:53:42.553Z","comments":true,"path":"2019/11/27/SQL/CentOS7静默安装oracle11g/","link":"","permalink":"https://github.com/cyylog/2019/11/27/SQL/CentOS7%E9%9D%99%E9%BB%98%E5%AE%89%E8%A3%85oracle11g/","excerpt":"","text":"操作系统： 1234[root@cyylog ~]# uname -mx86_64[root@cyylog ~]# cat &#x2F;etc&#x2F;redhat-release CentOS Linux release 7.2.1511 (Core) 安装前的准备：1. 修改主机名 1#sed -i &quot;s&#x2F;HOSTNAME&#x3D;localhost.localdomain&#x2F;HOSTNAME&#x3D;oracledb&#x2F;&quot; &#x2F;etc&#x2F;sysconfig&#x2F;network 2.添加主机名与IP对应记录 12# vim &#x2F;etc&#x2F;hosts 192.168.0.9 oracledb 3.关闭Selinux 123# sed -i &quot;s&#x2F;SELINUX&#x3D;enforcing&#x2F;SELINUX&#x3D;disabled&#x2F;&quot; &#x2F;etc&#x2F;selinux&#x2F;config # setenforce 0 4.检查是否有swap分区. (我的机器是没有这个,所有后面有报错) Linux一切皆文件,没有就自己造一个 12345678910111213141516171819202122232425262728293031323334353637381、检查 Swap 空间在设置 Swap 文件之前，有必要先检查一下系统里有没有既存的 Swap 文件。运行以下命令：# swapon -s如果返回的信息概要是空的，则表示 Swap 文件不存在。2、检查文件系统在设置 Swap 文件之前，同样有必要检查一下文件系统，看看是否有足够的硬盘空间来设置 Swap 。运行以下命令：# df -hal3、创建并允许 Swap 文件下面使用 dd 命令来创建 Swap 文件。检查返回的信息，还剩余足够的硬盘空间即可。# dd if&#x3D;&#x2F;dev&#x2F;zero of&#x3D;&#x2F;swapfile bs&#x3D;1024 count&#x3D;512k参数解读：if&#x3D;文件名：输入文件名，缺省为标准输入。即指定源文件。&lt; if&#x3D;input file &gt;of&#x3D;文件名：输出文件名，缺省为标准输出。即指定目的文件。&lt; of&#x3D;output file &gt;bs&#x3D;bytes：同时设置读入&#x2F;输出的块大小为bytes个字节count&#x3D;blocks：仅拷贝blocks个块，块大小等于bs指定的字节数。4、格式化并激活 Swap 文件上面已经创建好 Swap 文件，还需要格式化后才能使用。运行命令：# mkswap &#x2F;swapfile激活 Swap ，运行命令：# swapon &#x2F;swapfile以上步骤做完，再次运行命令：# swapon -s 你会发现返回的信息概要：1 Filename Type Size Used Priority2 &#x2F;swapfile file 524284 0 -1 如果要机器重启的时候自动挂载 Swap ，那么还需要修改 fstab 配置。用 vim 打开 &#x2F;etc&#x2F;fstab 文件，在其最后添加如下一行：&#x2F;swapfile swap swap defaults 0 0最后，赋予 Swap 文件适当的权限：# chown root:root &#x2F;swapfile # chmod 0600 &#x2F;swapfile 5.安装常用工具,配置阿里源 (个人习惯,在使用的主机上面配置这些常用工具) 1234567# curl -o &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;Centos-7.repo# curl -o &#x2F;etc&#x2F;yum.repos.d&#x2F;epel.repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;epel-7.repo# yum clean all# yum makecache fast# yum install -y wget ntpdate net-tools vim bash-completion ShellCheck# ntpdate -b ntp1.aliyun.com 安装软件包：参考官方：http://docs.oracle.com/cd/E11882_01/install.112/e24326/toc.htm#BHCCADGD The following or later version of packages for Oracle Linux 7, and Red Hat Enterprise Linux 7 must be installed: 12345678910111213141516171819202122232425262728293031binutils-2.23.52.0.1-12.el7.x86_64 compat-libcap1-1.10-3.el7.x86_64 compat-libstdc++-33-3.2.3-71.el7.i686compat-libstdc++-33-3.2.3-71.el7.x86_64gcc-4.8.2-3.el7.x86_64 gcc-c++-4.8.2-3.el7.x86_64 glibc-2.17-36.el7.i686 glibc-2.17-36.el7.x86_64 glibc-devel-2.17-36.el7.i686 glibc-devel-2.17-36.el7.x86_64 kshlibaio-0.3.109-9.el7.i686 libaio-0.3.109-9.el7.x86_64 libaio-devel-0.3.109-9.el7.i686 libaio-devel-0.3.109-9.el7.x86_64 libgcc-4.8.2-3.el7.i686 libgcc-4.8.2-3.el7.x86_64 libstdc++-4.8.2-3.el7.i686 libstdc++-4.8.2-3.el7.x86_64 libstdc++-devel-4.8.2-3.el7.i686 libstdc++-devel-4.8.2-3.el7.x86_64 libXi-1.7.2-1.el7.i686 libXi-1.7.2-1.el7.x86_64 libXtst-1.2.2-1.el7.i686 libXtst-1.2.2-1.el7.x86_64 make-3.82-19.el7.x86_64 sysstat-10.1.5-1.el7.x86_64unixODBC-2.3.1-6.el7.x86_64 or laterunixODBC-2.3.1-6.el7.i686 or laterunixODBC-devel-2.3.1-6.el7.x86_64 or laterunixODBC-devel-2.3.1-6.el7.i686 or later 12345678910111213141516171819202122232425262728293031binutils-2.23.52.0.1-12.el7.x86_64 compat-libcap1-1.10-3.el7.x86_64 compat-libstdc++-33-3.2.3-71.el7.i686compat-libstdc++-33-3.2.3-71.el7.x86_64gcc-4.8.2-3.el7.x86_64 gcc-c++-4.8.2-3.el7.x86_64 glibc-2.17-36.el7.i686 glibc-2.17-36.el7.x86_64 glibc-devel-2.17-36.el7.i686 glibc-devel-2.17-36.el7.x86_64 kshlibaio-0.3.109-9.el7.i686 libaio-0.3.109-9.el7.x86_64 libaio-devel-0.3.109-9.el7.i686 libaio-devel-0.3.109-9.el7.x86_64 libgcc-4.8.2-3.el7.i686 libgcc-4.8.2-3.el7.x86_64 libstdc++-4.8.2-3.el7.i686 libstdc++-4.8.2-3.el7.x86_64 libstdc++-devel-4.8.2-3.el7.i686 libstdc++-devel-4.8.2-3.el7.x86_64 libXi-1.7.2-1.el7.i686 libXi-1.7.2-1.el7.x86_64 libXtst-1.2.2-1.el7.i686 libXtst-1.2.2-1.el7.x86_64 make-3.82-19.el7.x86_64 sysstat-10.1.5-1.el7.x86_64unixODBC-2.3.1-6.el7.x86_64 or laterunixODBC-2.3.1-6.el7.i686 or laterunixODBC-devel-2.3.1-6.el7.x86_64 or laterunixODBC-devel-2.3.1-6.el7.i686 or later 用yum进行安装 1yum -y install binutils compat-libcap1 compat-libstdc++-33 compat-libstdc++-33*i686 compat-libstdc++-33*.devel compat-libstdc++-33 compat-libstdc++-33*.devel gcc gcc-c++ glibc glibc*.i686 glibc-devel glibc-devel*.i686 ksh libaio libaio*.i686 libaio-devel libaio-devel*.devel libgcc libgcc*.i686 libstdc++ libstdc++*.i686 libstdc++-devel libstdc++-devel*.devel libXi libXi*.i686 libXtst libXtst*.i686 make sysstat unixODBC unixODBC*.i686 unixODBC-devel unixODBC-devel*.i686 检测是否31个包都有安装 开放源码绿色蓝色按钮样式 1234567891011121314151617181920212223242526272829303132[root@cyylog ~]# rpm -q binutils compat-libcap1 compat-libstdc++-33 gcc gcc-c++ glibc glibc-devel ksh libaio libaio-devel libgcc libstdc++ libstdc++-devel libXi libXtst make sysstat unixODBC unixODBC-develbinutils-2.23.52.0.1-55.el7.x86_64compat-libcap1-1.10-7.el7.x86_64compat-libstdc++-33-3.2.3-72.el7.x86_64compat-libstdc++-33-3.2.3-72.el7.i686gcc-4.8.5-4.el7.x86_64gcc-c++-4.8.5-4.el7.x86_64glibc-2.17-106.el7_2.8.x86_64glibc-2.17-106.el7_2.8.i686glibc-devel-2.17-106.el7_2.8.x86_64glibc-devel-2.17-106.el7_2.8.i686ksh-20120801-22.el7_1.3.x86_64libaio-0.3.109-13.el7.x86_64libaio-0.3.109-13.el7.i686libaio-devel-0.3.109-13.el7.x86_64libaio-devel-0.3.109-13.el7.i686libgcc-4.8.5-4.el7.x86_64libgcc-4.8.5-4.el7.i686libstdc++-4.8.5-4.el7.x86_64libstdc++-4.8.5-4.el7.i686libstdc++-devel-4.8.5-4.el7.x86_64libstdc++-devel-4.8.5-4.el7.i686libXi-1.7.2-2.1.el7.x86_64libXi-1.7.4-2.el7.i686libXtst-1.2.2-2.1.el7.x86_64libXtst-1.2.2-2.1.el7.i686make-3.82-21.el7.x86_64sysstat-10.1.5-7.el7.x86_64unixODBC-2.3.1-11.el7.x86_64unixODBC-2.3.1-11.el7.i686unixODBC-devel-2.3.1-11.el7.x86_64unixODBC-devel-2.3.1-11.el7.i686 版本号只能大于规定的版本，不能小于。 创建oinstall和dba组 12# groupadd oinstall# groupadd dba 创建oracle用户 1# useradd -g oinstall -G dba oracle 设置oracle用户密码 1# passwd oracle 验证创建是否正确 12[root@cyylog ~]# id oracleuid&#x3D;1000(oracle) gid&#x3D;1000(oinstall) groups&#x3D;1000(oinstall),1001(dba) 配置内核参数1234567891011121314151617[root@cyylog ~]# vim &#x2F;etc&#x2F;sysctl.conf # System default settings live in &#x2F;usr&#x2F;lib&#x2F;sysctl.d&#x2F;00-system.conf.# To override those settings, enter new settings here, or in an &#x2F;etc&#x2F;sysctl.d&#x2F;&lt;name&gt;.conf file## For more information, see sysctl.conf(5) and sysctl.d(5).fs.aio-max-nr &#x3D; 1048576fs.file-max &#x3D; 6815744kernel.shmall &#x3D; 2097152kernel.shmmax &#x3D; 536870912 #最低：536870912，最大值：比物理内存小1个字节的值，建议超过物理内存的一半kernel.shmmni &#x3D; 4096kernel.sem &#x3D; 250 32000 100 128net.ipv4.ip_local_port_range &#x3D; 9000 65500net.core.rmem_default &#x3D; 262144net.core.rmem_max &#x3D; 4194304net.core.wmem_default &#x3D; 262144net.core.wmem_max &#x3D; 1048576 参数的值不能小于上面的配置，这是oracle官方建议的最小值，生产环境建议调整这些参数，以优化系统性能。 修改后使之生效 1# sysctl -p 修改用户限制 123456789vim &#x2F;etc&#x2F;security&#x2F;limits.conf#在末尾添加oracle soft nproc 2047oracle hard nproc 16384oracle soft nofile 1024oracle hard nofile 65536oracle soft stack 10240oracle hard stack 10240 在/etc/pam.d/login 文件中，使用文本编辑器或vi命令增加或修改以下内容 12session required &#x2F;lib64&#x2F;security&#x2F;pam_limits.sosession required pam_limits.so 在/etc/profile 文件中，使用文本编辑器或vi命令增加或修改以下内容 12345678if [ $USER &#x3D; &quot;oracle&quot; ]; then if [ $SHELL &#x3D; &quot;&#x2F;bin&#x2F;ksh&quot; ]; then ulimit -p 16384 ulimit -n 65536 else ulimit -u 16384 -n 65536 fifi 使之生效 1# source &#x2F;etc&#x2F;profile 创建安装目录 123# mkdir -p &#x2F;u01&#x2F;app&#x2F;# chown -R oracle:oinstall &#x2F;u01&#x2F;app&#x2F;# chmod -R 775 &#x2F;u01&#x2F;app&#x2F; 配置环境变量 1234[oracle@cyylog ~]$ vim ~&#x2F;.bash_profile export ORACLE_BASE&#x3D;&#x2F;u01&#x2F;app&#x2F;oracleexport ORACLE_SID&#x3D;dbsrv2 使之生效 1source ~&#x2F;.bash_profile 解压oracle软件 12[root@cyylog src]# unzip linux.x64_11gR2_database_1of2.zip[root@cyylog src]# unzip linux.x64_11gR2_database_2of2.zip 复制响应文件模板 1234[oracle@cyylog ~]$ mkdir etc[oracle@cyylog ~]$ cp &#x2F;usr&#x2F;local&#x2F;src&#x2F;database&#x2F;response&#x2F;* &#x2F;home&#x2F;oracle&#x2F;etc&#x2F;[oracle@cyylog ~]$ ls etcdbca.rsp db_install.rsp netca.rsp 设置响应文件权限 123[oracle@cyylog ~]$ su - root[root@cyylog ~]# chmod 700 &#x2F;home&#x2F;oracle&#x2F;etc&#x2F;*.rsp 静默安装Oracle软件su - oracle 修改安装Oracle软件的响应文件/home/oracle/etc/db_install.rsp 123456789101112131415161718oracle.install.option&#x3D;INSTALL_DB_SWONLY &#x2F;&#x2F; 安装类型ORACLE_HOSTNAME&#x3D;oracledb &#x2F;&#x2F; 主机名称（hostname查询）UNIX_GROUP_NAME&#x3D;oinstall &#x2F;&#x2F; 安装组INVENTORY_LOCATION&#x3D;&#x2F;u01&#x2F;app&#x2F;oraInventory &#x2F;&#x2F;INVENTORY目录（不填就是默认值）SELECTED_LANGUAGES&#x3D;en,zh_CN,zh_TW &#x2F;&#x2F; 选择语言ORACLE_HOME&#x3D;&#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;11.2.0&#x2F;db_1 &#x2F;&#x2F;oracle_homeORACLE_BASE&#x3D;&#x2F;u01&#x2F;app&#x2F;oracle &#x2F;&#x2F;oracle_baseoracle.install.db.InstallEdition&#x3D;EE &#x2F;&#x2F; oracle版本oracle.install.db.isCustomInstall&#x3D;false &#x2F;&#x2F;自定义安装，否，使用默认组件oracle.install.db.DBA_GROUP&#x3D;dba &#x2F; &#x2F; dba用户组oracle.install.db.OPER_GROUP&#x3D;oinstall &#x2F;&#x2F; oper用户组oracle.install.db.config.starterdb.type&#x3D;GENERAL_PURPOSE &#x2F;&#x2F;数据库类型oracle.install.db.config.starterdb.globalDBName&#x3D;orcl &#x2F;&#x2F;globalDBNameoracle.install.db.config.starterdb.SID&#x3D;dbsrv2 &#x2F;&#x2F;SIDoracle.install.db.config.starterdb.memoryLimit&#x3D;81920 &#x2F;&#x2F;自动管理内存的内存(M)oracle.install.db.config.starterdb.password.ALL&#x3D;oracle &#x2F;&#x2F;设定所有数据库用户使用同一个密码SECURITY_UPDATES_VIA_MYORACLESUPPORT&#x3D;false &#x2F;&#x2F;（手动写了false）DECLINE_SECURITY_UPDATES&#x3D;true &#x2F;&#x2F;设置安全更新（貌似是有bug，这个一定要选true，否则会无限提醒邮件地址有问题，终止安装。PS：不管地址对不对） 123456789101112131415161718oracle.install.option&#x3D;INSTALL_DB_SWONLY &#x2F;&#x2F; 安装类型ORACLE_HOSTNAME&#x3D;oracledb &#x2F;&#x2F; 主机名称（hostname查询）UNIX_GROUP_NAME&#x3D;oinstall &#x2F;&#x2F; 安装组INVENTORY_LOCATION&#x3D;&#x2F;u01&#x2F;app&#x2F;oraInventory &#x2F;&#x2F;INVENTORY目录（不填就是默认值）SELECTED_LANGUAGES&#x3D;en,zh_CN,zh_TW &#x2F;&#x2F; 选择语言ORACLE_HOME&#x3D;&#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;11.2.0&#x2F;db_1 &#x2F;&#x2F;oracle_homeORACLE_BASE&#x3D;&#x2F;u01&#x2F;app&#x2F;oracle &#x2F;&#x2F;oracle_baseoracle.install.db.InstallEdition&#x3D;EE &#x2F;&#x2F; oracle版本oracle.install.db.isCustomInstall&#x3D;false &#x2F;&#x2F;自定义安装，否，使用默认组件oracle.install.db.DBA_GROUP&#x3D;dba &#x2F; &#x2F; dba用户组oracle.install.db.OPER_GROUP&#x3D;oinstall &#x2F;&#x2F; oper用户组oracle.install.db.config.starterdb.type&#x3D;GENERAL_PURPOSE &#x2F;&#x2F;数据库类型oracle.install.db.config.starterdb.globalDBName&#x3D;orcl &#x2F;&#x2F;globalDBNameoracle.install.db.config.starterdb.SID&#x3D;dbsrv2 &#x2F;&#x2F;SIDoracle.install.db.config.starterdb.memoryLimit&#x3D;81920 &#x2F;&#x2F;自动管理内存的内存(M)oracle.install.db.config.starterdb.password.ALL&#x3D;oracle &#x2F;&#x2F;设定所有数据库用户使用同一个密码SECURITY_UPDATES_VIA_MYORACLESUPPORT&#x3D;false &#x2F;&#x2F;（手动写了false）DECLINE_SECURITY_UPDATES&#x3D;true &#x2F;&#x2F;设置安全更新（貌似是有bug，这个一定要选true，否则会无限提醒邮件地址有问题，终止安装。PS：不管地址对不对） 开始静默安装 1[oracle@cyylog database]$ .&#x2F;runInstaller -silent -responseFile &#x2F;home&#x2F;oracle&#x2F;etc&#x2F;db_install.rsp 新开一个终端 查看安装日志 1# tail -f &#x2F;u01&#x2F;app&#x2F;oraInventory&#x2F;logs&#x2F;installActions2016-08-31_06-56-29PM.log 出现类似如下提示表示安装完成： -———————————————————————– The following configuration scripts need to be executed as the “root” user. #!/bin/sh #Root scripts to run /u01/app/oraInventory/orainstRoot.sh /u01/app/oracle/product/11.2.0/db_1/root.sh To execute the configuration scripts: Open a terminal window Log in as “root” Run the scripts Return to this window and hit “Enter” key to continue Successfully Setup Software. -—————————————————————————- 使用root用户执行脚本 123$ su - root# &#x2F;u01&#x2F;app&#x2F;oraInventory&#x2F;orainstRoot.sh# &#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;11.2.0&#x2F;db_1&#x2F;root.sh 增加或修改oracle的环境变量 12# su - oracle# vim ~&#x2F;.bash_profile 12345678910111213141516#for oracleexport ORACLE_BASE&#x3D;&#x2F;u01&#x2F;app&#x2F;oracleexport ORACLE_SID&#x3D;dbsrv2export ROACLE_PID&#x3D;ora11g#export NLS_LANG&#x3D;AMERICAN_AMERICA.AL32UTF8export LD_LIBRARY_PATH&#x3D;$ORACLE_HOME&#x2F;lib:&#x2F;usr&#x2F;libexport ORACLE_HOME&#x3D;&#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;11.2.0&#x2F;db_1export PATH&#x3D;$PATH:$ORACLE_HOME&#x2F;binexport LANG&#x3D;&quot;zh_CN.UTF-8&quot;export NLS_LANG&#x3D;&quot;SIMPLIFIED CHINESE_CHINA.AL32UTF8&quot;export NLS_DATE_FORMAT&#x3D;&#39;yyyy-mm-dd hh24:mi:ss&#39;刷新环境变量# source ~&#x2F;.bash_profile 配置监听程序 123456789101112131415[oracle@cyylog ~]$ netca &#x2F;silent &#x2F;responsefile &#x2F;home&#x2F;oracle&#x2F;etc&#x2F;netca.rspParsing command line arguments:Parameter &quot;silent&quot; &#x3D; trueParameter &quot;responsefile&quot; &#x3D; &#x2F;home&#x2F;oracle&#x2F;etc&#x2F;netca.rspDone parsing command line arguments.Oracle Net Services Configuration:Profile configuration complete.Oracle Net Listener Startup:Running Listener Control: &#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;11.2.0&#x2F;db_1&#x2F;bin&#x2F;lsnrctl start LISTENERListener Control complete.Listener started successfully.Listener configuration complete.Oracle Net Services configuration successful. The exit code is 0 启动监控程序 12345678910111213141516171819202122232425262728293031[oracle@cyylog ~]$ lsnrctl startLSNRCTL for Linux: Version 11.2.0.1.0 - Production on 01-SEP-2016 11:23:31Copyright (c) 1991, 2009, Oracle. All rights reserved.Starting &#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;11.2.0&#x2F;db_1&#x2F;bin&#x2F;tnslsnr: please wait...TNSLSNR for Linux: Version 11.2.0.1.0 - ProductionSystem parameter file is &#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;11.2.0&#x2F;db_1&#x2F;network&#x2F;admin&#x2F;listener.oraLog messages written to &#x2F;u01&#x2F;app&#x2F;oracle&#x2F;diag&#x2F;tnslsnr&#x2F;cyylog&#x2F;listener&#x2F;alert&#x2F;log.xmlListening on: (DESCRIPTION&#x3D;(ADDRESS&#x3D;(PROTOCOL&#x3D;ipc)(KEY&#x3D;EXTPROC1521)))Listening on: (DESCRIPTION&#x3D;(ADDRESS&#x3D;(PROTOCOL&#x3D;tcp)(HOST&#x3D;cyylog)(PORT&#x3D;1521)))Connecting to (DESCRIPTION&#x3D;(ADDRESS&#x3D;(PROTOCOL&#x3D;IPC)(KEY&#x3D;EXTPROC1521)))STATUS of the LISTENER------------------------Alias LISTENERVersion TNSLSNR for Linux: Version 11.2.0.1.0 - ProductionStart Date 01-SEP-2016 11:23:31Uptime 0 days 0 hr. 0 min. 0 secTrace Level offSecurity ON: Local OS AuthenticationSNMP OFFListener Parameter File &#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;11.2.0&#x2F;db_1&#x2F;network&#x2F;admin&#x2F;listener.oraListener Log File &#x2F;u01&#x2F;app&#x2F;oracle&#x2F;diag&#x2F;tnslsnr&#x2F;cyylog&#x2F;listener&#x2F;alert&#x2F;log.xmlListening Endpoints Summary... (DESCRIPTION&#x3D;(ADDRESS&#x3D;(PROTOCOL&#x3D;ipc)(KEY&#x3D;EXTPROC1521))) (DESCRIPTION&#x3D;(ADDRESS&#x3D;(PROTOCOL&#x3D;tcp)(HOST&#x3D;cyylog)(PORT&#x3D;1521)))The listener supports no servicesThe command completed successfully 静默dbca建库 编辑应答文件 123456789[oracle@cyylog ~]$ vi etc&#x2F;dbca.rsp[GENERAL]RESPONSEFILE_VERSION &#x3D; &quot;11.2.0&quot;OPERATION_TYPE &#x3D; &quot;createDatabase&quot;[CREATEDATABASE]GDBNAME &#x3D; &quot;dbsrv2&quot;SID &#x3D; &quot;dbsrv2&quot;TEMPLATENAME &#x3D; &quot;General_Purpose.dbc&quot;CHARACTERSET &#x3D; &quot;AL32UTF8&quot; 建库(我的finashell会闪屏,但是不影响使用，因为这个是因为无图形界面的情况) 123456789101112131415161718192021222324252627282930313233[oracle@cyylog ~]$ dbca -silent -responseFile etc&#x2F;dbca.rspEnter SYS user password: Enter SYSTEM user password: sh: &#x2F;bin&#x2F;ksh: No such file or directorysh: &#x2F;bin&#x2F;ksh: No such file or directoryCopying database files1% complete3% complete11% complete18% complete26% complete37% completeCreating and starting Oracle instance40% complete45% complete50% complete55% complete56% complete57% complete60% complete62% completeCompleting Database Creation66% complete70% complete73% complete74% complete85% complete96% complete100% completeLook at the log file Look at the log file &quot;&#x2F;u01&#x2F;app&#x2F;oracle&#x2F;cfgtoollogs&#x2F;dbca&#x2F;orcl11g&#x2F;orcl11g.log&quot; for further details. 123456789101112131415161718192021222324252627282930313233[oracle@cyylog ~]$ dbca -silent -responseFile etc&#x2F;dbca.rspEnter SYS user password: Enter SYSTEM user password: sh: &#x2F;bin&#x2F;ksh: No such file or directorysh: &#x2F;bin&#x2F;ksh: No such file or directoryCopying database files1% complete3% complete11% complete18% complete26% complete37% completeCreating and starting Oracle instance40% complete45% complete50% complete55% complete56% complete57% complete60% complete62% completeCompleting Database Creation66% complete70% complete73% complete74% complete85% complete96% complete100% completeLook at the log file Look at the log file &quot;&#x2F;u01&#x2F;app&#x2F;oracle&#x2F;cfgtoollogs&#x2F;dbca&#x2F;orcl11g&#x2F;orcl11g.log&quot; for further details. 查看输出日志 12345678910111213141516171819202122232425262728[oracle@cyylog ~]$ tailf &#x2F;u01&#x2F;app&#x2F;oracle&#x2F;cfgtoollogs&#x2F;dbca&#x2F;silent.logCopying database filesDBCA_PROGRESS : 1%DBCA_PROGRESS : 3%DBCA_PROGRESS : 11%DBCA_PROGRESS : 18%DBCA_PROGRESS : 26%DBCA_PROGRESS : 37%Creating and starting Oracle instanceDBCA_PROGRESS : 40%DBCA_PROGRESS : 45%DBCA_PROGRESS : 50%DBCA_PROGRESS : 55%DBCA_PROGRESS : 56%DBCA_PROGRESS : 60%DBCA_PROGRESS : 62%Completing Database CreationDBCA_PROGRESS : 66%DBCA_PROGRESS : 70%DBCA_PROGRESS : 73%DBCA_PROGRESS : 85%DBCA_PROGRESS : 96%DBCA_PROGRESS : 100%Database creation complete. For details check the logfiles at: &#x2F;u01&#x2F;app&#x2F;oracle&#x2F;cfgtoollogs&#x2F;dbca&#x2F;orcl11g.Database Information:Global Database Name:orcl11g.us.oracle.comSystem Identifier(SID):dbsrv2 至此完成数据库实例的创建。 -———————————————————————————- -———————————————————————————- 附： 删除实例： 1[oracle@cyylog ~]$ dbca -silent -deleteDatabase -sourcedb dbsrv2 文章来源:https://www.cnblogs.com/zydev/p/5827207.html","categories":[{"name":"SQL","slug":"SQL","permalink":"https://github.com/cyylog/categories/SQL/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://github.com/cyylog/tags/Oracle/"}]},{"title":"Docker_002","slug":"容器/Dockerfilee-002","date":"2019-11-18T17:55:39.000Z","updated":"2020-05-25T14:01:09.188Z","comments":true,"path":"2019/11/19/容器/Dockerfilee-002/","link":"","permalink":"https://github.com/cyylog/2019/11/19/%E5%AE%B9%E5%99%A8/Dockerfilee-002/","excerpt":"","text":"Dockerfile_redis_5.0123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115FROM debian:buster-slim# add our user and group first to make sure their IDs get assigned consistently, regardless of whatever dependencies get addedRUN groupadd -r -g 999 redis &amp;&amp; useradd -r -g redis -u 999 redis# grab gosu for easy step-down from root# https://github.com/tianon/gosu/releasesENV GOSU_VERSION 1.11RUN set -eux; \\# save list of currently installed packages for later so we can clean up savedAptMark=\"$(apt-mark showmanual)\"; \\ apt-get update; \\ apt-get install -y --no-install-recommends \\ ca-certificates \\ dirmngr \\ gnupg \\ wget \\ ; \\ rm -rf /var/lib/apt/lists/*; \\ \\ dpkgArch=\"$(dpkg --print-architecture | awk -F- '&#123; print $NF &#125;')\"; \\ wget -O /usr/local/bin/gosu \"https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$dpkgArch\"; \\ wget -O /usr/local/bin/gosu.asc \"https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$dpkgArch.asc\"; \\ \\# verify the signature export GNUPGHOME=\"$(mktemp -d)\"; \\ gpg --batch --keyserver hkps://keys.openpgp.org --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4; \\ gpg --batch --verify /usr/local/bin/gosu.asc /usr/local/bin/gosu; \\ gpgconf --kill all; \\ rm -rf \"$GNUPGHOME\" /usr/local/bin/gosu.asc; \\ \\# clean up fetch dependencies apt-mark auto '.*' &gt; /dev/null; \\ [ -z \"$savedAptMark\" ] || apt-mark manual $savedAptMark &gt; /dev/null; \\ apt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant=false; \\ \\ chmod +x /usr/local/bin/gosu; \\# verify that the binary works gosu --version; \\ gosu nobody trueENV REDIS_VERSION 5.0.8ENV REDIS_DOWNLOAD_URL http://download.redis.io/releases/redis-5.0.8.tar.gzENV REDIS_DOWNLOAD_SHA f3c7eac42f433326a8d981b50dba0169fdfaf46abb23fcda2f933a7552ee4ed7RUN set -eux; \\ \\ savedAptMark=\"$(apt-mark showmanual)\"; \\ apt-get update; \\ apt-get install -y --no-install-recommends \\ ca-certificates \\ wget \\ \\ gcc \\ libc6-dev \\ make \\ ; \\ rm -rf /var/lib/apt/lists/*; \\ \\ wget -O redis.tar.gz \"$REDIS_DOWNLOAD_URL\"; \\ echo \"$REDIS_DOWNLOAD_SHA *redis.tar.gz\" | sha256sum -c -; \\ mkdir -p /usr/src/redis; \\ tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1; \\ rm redis.tar.gz; \\ \\# disable Redis protected mode [1] as it is unnecessary in context of Docker# (ports are not automatically exposed when running inside Docker, but rather explicitly by specifying -p / -P)# [1]: https://github.com/antirez/redis/commit/edd4d555df57dc84265fdfb4ef59a4678832f6da grep -q '^#define CONFIG_DEFAULT_PROTECTED_MODE 1$' /usr/src/redis/src/server.h; \\ sed -ri 's!^(#define CONFIG_DEFAULT_PROTECTED_MODE) 1$!\\1 0!' /usr/src/redis/src/server.h; \\ grep -q '^#define CONFIG_DEFAULT_PROTECTED_MODE 0$' /usr/src/redis/src/server.h; \\# for future reference, we modify this directly in the source instead of just supplying a default configuration flag because apparently \"if you specify any argument to redis-server, [it assumes] you are going to specify everything\"# see also https://github.com/docker-library/redis/issues/4#issuecomment-50780840# (more exactly, this makes sure the default behavior of \"save on SIGTERM\" stays functional by default) \\ make -C /usr/src/redis -j \"$(nproc)\" all; \\ make -C /usr/src/redis install; \\ \\# TODO https://github.com/antirez/redis/pull/3494 (deduplicate \"redis-server\" copies) serverMd5=\"$(md5sum /usr/local/bin/redis-server | cut -d' ' -f1)\"; export serverMd5; \\ find /usr/local/bin/redis* -maxdepth 0 \\ -type f -not -name redis-server \\ -exec sh -eux -c ' \\ md5=\"$(md5sum \"$1\" | cut -d\" \" -f1)\"; \\ test \"$md5\" = \"$serverMd5\"; \\ ' -- '&#123;&#125;' ';' \\ -exec ln -svfT 'redis-server' '&#123;&#125;' ';' \\ ; \\ \\ rm -r /usr/src/redis; \\ \\ apt-mark auto '.*' &gt; /dev/null; \\ [ -z \"$savedAptMark\" ] || apt-mark manual $savedAptMark &gt; /dev/null; \\ find /usr/local -type f -executable -exec ldd '&#123;&#125;' ';' \\ | awk '/=&gt;/ &#123; print $(NF-1) &#125;' \\ | sort -u \\ | xargs -r dpkg-query --search \\ | cut -d: -f1 \\ | sort -u \\ | xargs -r apt-mark manual \\ ; \\ apt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant=false; \\ \\ redis-cli --version; \\ redis-server --versionRUN mkdir /data &amp;&amp; chown redis:redis /dataVOLUME /dataWORKDIR /dataCOPY docker-entrypoint.sh /usr/local/bin/ENTRYPOINT [\"docker-entrypoint.sh\"]EXPOSE 6379CMD [\"redis-server\"] Dockerfile_alpine_httpd_2.4123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159FROM alpine:3.11# ensure www-data user existsRUN set -x \\ &amp;&amp; addgroup -g 82 -S www-data \\ &amp;&amp; adduser -u 82 -D -S -G www-data www-data# 82 is the standard uid/gid for \"www-data\" in Alpine# https://git.alpinelinux.org/cgit/aports/tree/main/apache2/apache2.pre-install?h=v3.8.1# https://git.alpinelinux.org/cgit/aports/tree/main/lighttpd/lighttpd.pre-install?h=v3.8.1# https://git.alpinelinux.org/cgit/aports/tree/main/nginx/nginx.pre-install?h=v3.8.1ENV HTTPD_PREFIX /usr/local/apache2ENV PATH $HTTPD_PREFIX/bin:$PATHRUN mkdir -p \"$HTTPD_PREFIX\" \\ &amp;&amp; chown www-data:www-data \"$HTTPD_PREFIX\"WORKDIR $HTTPD_PREFIXENV HTTPD_VERSION 2.4.43ENV HTTPD_SHA256 a497652ab3fc81318cdc2a203090a999150d86461acff97c1065dc910fe10f43# https://httpd.apache.org/security/vulnerabilities_24.htmlENV HTTPD_PATCHES=\"\"# see https://httpd.apache.org/docs/2.4/install.html#requirementsRUN set -eux; \\ \\ runDeps=' \\ apr-dev \\ apr-util-dbm_db \\ apr-util-dev \\ apr-util-ldap \\ perl \\ '; \\ apk add --no-cache --virtual .build-deps \\ $runDeps \\ ca-certificates \\ coreutils \\ dpkg-dev dpkg \\ gcc \\ gnupg \\ libc-dev \\ # mod_md curl-dev \\ jansson-dev \\ # mod_proxy_html mod_xml2enc libxml2-dev \\ # mod_lua lua-dev \\ make \\ # mod_http2 nghttp2-dev \\ # mod_session_crypto openssl \\ openssl-dev \\ pcre-dev \\ tar \\ # mod_deflate zlib-dev \\ # mod_brotli brotli-dev \\ ; \\ \\ ddist() &#123; \\ local f=\"$1\"; shift; \\ local distFile=\"$1\"; shift; \\ local success=; \\ local distUrl=; \\ for distUrl in \\# https://issues.apache.org/jira/browse/INFRA-8753?focusedCommentId=14735394#comment-14735394 'https://www.apache.org/dyn/closer.cgi?action=download&amp;filename=' \\# if the version is outdated (or we're grabbing the .asc file), we might have to pull from the dist/archive :/ https://www-us.apache.org/dist/ \\ https://www.apache.org/dist/ \\ https://archive.apache.org/dist/ \\ ; do \\ if wget -O \"$f\" \"$distUrl$distFile\" &amp;&amp; [ -s \"$f\" ]; then \\ success=1; \\ break; \\ fi; \\ done; \\ [ -n \"$success\" ]; \\ &#125;; \\ \\ ddist 'httpd.tar.bz2' \"httpd/httpd-$HTTPD_VERSION.tar.bz2\"; \\ echo \"$HTTPD_SHA256 *httpd.tar.bz2\" | sha256sum -c -; \\ \\# see https://httpd.apache.org/download.cgi#verify ddist 'httpd.tar.bz2.asc' \"httpd/httpd-$HTTPD_VERSION.tar.bz2.asc\"; \\ export GNUPGHOME=\"$(mktemp -d)\"; \\ for key in \\# gpg: key 791485A8: public key \"Jim Jagielski (Release Signing Key) &lt;jim@apache.org&gt;\" imported A93D62ECC3C8EA12DB220EC934EA76E6791485A8 \\# gpg: key 995E35221AD84DFF: public key \"Daniel Ruggeri (https://home.apache.org/~druggeri/) &lt;druggeri@apache.org&gt;\" imported B9E8213AEFB861AF35A41F2C995E35221AD84DFF \\ ; do \\ gpg --batch --keyserver ha.pool.sks-keyservers.net --recv-keys \"$key\"; \\ done; \\ gpg --batch --verify httpd.tar.bz2.asc httpd.tar.bz2; \\ command -v gpgconf &amp;&amp; gpgconf --kill all || :; \\ rm -rf \"$GNUPGHOME\" httpd.tar.bz2.asc; \\ \\ mkdir -p src; \\ tar -xf httpd.tar.bz2 -C src --strip-components=1; \\ rm httpd.tar.bz2; \\ cd src; \\ \\ patches() &#123; \\ while [ \"$#\" -gt 0 ]; do \\ local patchFile=\"$1\"; shift; \\ local patchSha256=\"$1\"; shift; \\ ddist \"$patchFile\" \"httpd/patches/apply_to_$HTTPD_VERSION/$patchFile\"; \\ echo \"$patchSha256 *$patchFile\" | sha256sum -c -; \\ patch -p0 &lt; \"$patchFile\"; \\ rm -f \"$patchFile\"; \\ done; \\ &#125;; \\ patches $HTTPD_PATCHES; \\ \\ gnuArch=\"$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)\"; \\ ./configure \\ --build=\"$gnuArch\" \\ --prefix=\"$HTTPD_PREFIX\" \\ --enable-mods-shared=reallyall \\ --enable-mpms-shared=all \\# PIE and hardening flags are unnecessary as Alpine enables them automatically (https://alpinelinux.org/about/) ; \\ make -j \"$(nproc)\"; \\ make install; \\ \\ cd ..; \\ rm -r src man manual; \\ \\ sed -ri \\ -e 's!^(\\s*CustomLog)\\s+\\S+!\\1 /proc/self/fd/1!g' \\ -e 's!^(\\s*ErrorLog)\\s+\\S+!\\1 /proc/self/fd/2!g' \\ -e 's!^(\\s*TransferLog)\\s+\\S+!\\1 /proc/self/fd/1!g' \\ \"$HTTPD_PREFIX/conf/httpd.conf\" \\ \"$HTTPD_PREFIX/conf/extra/httpd-ssl.conf\" \\ ; \\ \\ runDeps=\"$runDeps $( \\ scanelf --needed --nobanner --format '%n#p' --recursive /usr/local \\ | tr ',' '\\n' \\ | sort -u \\ | awk 'system(\"[ -e /usr/local/lib/\" $1 \" ]\") == 0 &#123; next &#125; &#123; print \"so:\" $1 &#125;' \\ )\"; \\ apk add --no-network --virtual .httpd-rundeps $runDeps; \\ apk del --no-network .build-deps; \\ \\# smoke test httpd -v# https://httpd.apache.org/docs/2.4/stopping.html#gracefulstopSTOPSIGNAL SIGWINCHCOPY httpd-foreground /usr/local/bin/EXPOSE 80CMD [\"httpd-foreground\"]","categories":[{"name":"容器","slug":"容器","permalink":"https://github.com/cyylog/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://github.com/cyylog/tags/Docker/"}]},{"title":"Docker_001","slug":"容器/Dockerfilee-001","date":"2019-11-17T14:16:23.000Z","updated":"2020-05-25T14:01:00.834Z","comments":true,"path":"2019/11/17/容器/Dockerfilee-001/","link":"","permalink":"https://github.com/cyylog/2019/11/17/%E5%AE%B9%E5%99%A8/Dockerfilee-001/","excerpt":"","text":"Docker_MySQL 5.712345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182FROM debian:buster-slim# add our user and group first to make sure their IDs get assigned consistently, regardless of whatever dependencies get addedRUN groupadd -r mysql &amp;&amp; useradd -r -g mysql mysqlRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends gnupg dirmngr &amp;&amp; rm -rf /var/lib/apt/lists/*# add gosu for easy step-down from rootENV GOSU_VERSION 1.7RUN set -x \\ &amp;&amp; apt-get update &amp;&amp; apt-get install -y --no-install-recommends ca-certificates wget &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; wget -O /usr/local/bin/gosu \"https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$(dpkg --print-architecture)\" \\ &amp;&amp; wget -O /usr/local/bin/gosu.asc \"https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$(dpkg --print-architecture).asc\" \\ &amp;&amp; export GNUPGHOME=\"$(mktemp -d)\" \\ &amp;&amp; gpg --batch --keyserver ha.pool.sks-keyservers.net --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4 \\ &amp;&amp; gpg --batch --verify /usr/local/bin/gosu.asc /usr/local/bin/gosu \\ &amp;&amp; gpgconf --kill all \\ &amp;&amp; rm -rf \"$GNUPGHOME\" /usr/local/bin/gosu.asc \\ &amp;&amp; chmod +x /usr/local/bin/gosu \\ &amp;&amp; gosu nobody true \\ &amp;&amp; apt-get purge -y --auto-remove ca-certificates wgetRUN mkdir /docker-entrypoint-initdb.dRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\# for MYSQL_RANDOM_ROOT_PASSWORD pwgen \\# for mysql_ssl_rsa_setup openssl \\# FATAL ERROR: please install the following Perl modules before executing /usr/local/mysql/scripts/mysql_install_db:# File::Basename# File::Copy# Sys::Hostname# Data::Dumper perl \\# install \"xz-utils\" for .sql.xz docker-entrypoint-initdb.d files xz-utils \\ &amp;&amp; rm -rf /var/lib/apt/lists/*RUN set -ex; \\# gpg: key 5072E1F5: public key \"MySQL Release Engineering &lt;mysql-build@oss.oracle.com&gt;\" imported key='A4A9406876FCBD3C456770C88C718D3B5072E1F5'; \\ export GNUPGHOME=\"$(mktemp -d)\"; \\ gpg --batch --keyserver ha.pool.sks-keyservers.net --recv-keys \"$key\"; \\ gpg --batch --export \"$key\" &gt; /etc/apt/trusted.gpg.d/mysql.gpg; \\ gpgconf --kill all; \\ rm -rf \"$GNUPGHOME\"; \\ apt-key list &gt; /dev/nullENV MYSQL_MAJOR 5.7ENV MYSQL_VERSION 5.7.29-1debian10RUN echo \"deb http://repo.mysql.com/apt/debian/ buster mysql-$&#123;MYSQL_MAJOR&#125;\" &gt; /etc/apt/sources.list.d/mysql.list# the \"/var/lib/mysql\" stuff here is because the mysql-server postinst doesn't have an explicit way to disable the mysql_install_db codepath besides having a database already \"configured\" (ie, stuff in /var/lib/mysql/mysql)# also, we set debconf keys to make APT a little quieterRUN &#123; \\ echo mysql-community-server mysql-community-server/data-dir select ''; \\ echo mysql-community-server mysql-community-server/root-pass password ''; \\ echo mysql-community-server mysql-community-server/re-root-pass password ''; \\ echo mysql-community-server mysql-community-server/remove-test-db select false; \\ &#125; | debconf-set-selections \\ &amp;&amp; apt-get update &amp;&amp; apt-get install -y mysql-server=\"$&#123;MYSQL_VERSION&#125;\" &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; rm -rf /var/lib/mysql &amp;&amp; mkdir -p /var/lib/mysql /var/run/mysqld \\ &amp;&amp; chown -R mysql:mysql /var/lib/mysql /var/run/mysqld \\# ensure that /var/run/mysqld (used for socket and lock files) is writable regardless of the UID our mysqld instance ends up having at runtime &amp;&amp; chmod 777 /var/run/mysqld \\# comment out a few problematic configuration values &amp;&amp; find /etc/mysql/ -name '*.cnf' -print0 \\ | xargs -0 grep -lZE '^(bind-address|log)' \\ | xargs -rt -0 sed -Ei 's/^(bind-address|log)/#&amp;/' \\# don't reverse lookup hostnames, they are usually another container &amp;&amp; echo '[mysqld]\\nskip-host-cache\\nskip-name-resolve' &gt; /etc/mysql/conf.d/docker.cnfVOLUME /var/lib/mysqlCOPY docker-entrypoint.sh /usr/local/bin/RUN ln -s usr/local/bin/docker-entrypoint.sh /entrypoint.sh # backwards compatENTRYPOINT [\"docker-entrypoint.sh\"]EXPOSE 3306 33060CMD [\"mysqld\"] Docker_NGINX_1.17.9123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110FROM alpine:3.10LABEL maintainer=\"NGINX Docker Maintainers &lt;docker-maint@nginx.com&gt;\"ENV NGINX_VERSION 1.17.9ENV NJS_VERSION 0.3.9ENV PKG_RELEASE 1RUN set -x \\# create nginx user/group first, to be consistent throughout docker variants &amp;&amp; addgroup -g 101 -S nginx \\ &amp;&amp; adduser -S -D -H -u 101 -h /var/cache/nginx -s /sbin/nologin -G nginx -g nginx nginx \\ &amp;&amp; apkArch=\"$(cat /etc/apk/arch)\" \\ &amp;&amp; nginxPackages=\" \\ nginx=$&#123;NGINX_VERSION&#125;-r$&#123;PKG_RELEASE&#125; \\ nginx-module-xslt=$&#123;NGINX_VERSION&#125;-r$&#123;PKG_RELEASE&#125; \\ nginx-module-geoip=$&#123;NGINX_VERSION&#125;-r$&#123;PKG_RELEASE&#125; \\ nginx-module-image-filter=$&#123;NGINX_VERSION&#125;-r$&#123;PKG_RELEASE&#125; \\ nginx-module-njs=$&#123;NGINX_VERSION&#125;.$&#123;NJS_VERSION&#125;-r$&#123;PKG_RELEASE&#125; \\ \" \\ &amp;&amp; case \"$apkArch\" in \\ x86_64) \\# arches officially built by upstream set -x \\ &amp;&amp; KEY_SHA512=\"e7fa8303923d9b95db37a77ad46c68fd4755ff935d0a534d26eba83de193c76166c68bfe7f65471bf8881004ef4aa6df3e34689c305662750c0172fca5d8552a *stdin\" \\ &amp;&amp; apk add --no-cache --virtual .cert-deps \\ openssl \\ &amp;&amp; wget -O /tmp/nginx_signing.rsa.pub https://nginx.org/keys/nginx_signing.rsa.pub \\ &amp;&amp; if [ \"$(openssl rsa -pubin -in /tmp/nginx_signing.rsa.pub -text -noout | openssl sha512 -r)\" = \"$KEY_SHA512\" ]; then \\ echo \"key verification succeeded!\"; \\ mv /tmp/nginx_signing.rsa.pub /etc/apk/keys/; \\ else \\ echo \"key verification failed!\"; \\ exit 1; \\ fi \\ &amp;&amp; apk del .cert-deps \\ &amp;&amp; apk add -X \"https://nginx.org/packages/mainline/alpine/v$(egrep -o '^[0-9]+\\.[0-9]+' /etc/alpine-release)/main\" --no-cache $nginxPackages \\ ;; \\ *) \\# we're on an architecture upstream doesn't officially build for# let's build binaries from the published packaging sources set -x \\ &amp;&amp; tempDir=\"$(mktemp -d)\" \\ &amp;&amp; chown nobody:nobody $tempDir \\ &amp;&amp; apk add --no-cache --virtual .build-deps \\ gcc \\ libc-dev \\ make \\ openssl-dev \\ pcre-dev \\ zlib-dev \\ linux-headers \\ libxslt-dev \\ gd-dev \\ geoip-dev \\ perl-dev \\ libedit-dev \\ mercurial \\ bash \\ alpine-sdk \\ findutils \\ &amp;&amp; su nobody -s /bin/sh -c \" \\ export HOME=$&#123;tempDir&#125; \\ &amp;&amp; cd $&#123;tempDir&#125; \\ &amp;&amp; hg clone https://hg.nginx.org/pkg-oss \\ &amp;&amp; cd pkg-oss \\ &amp;&amp; hg up $&#123;NGINX_VERSION&#125;-$&#123;PKG_RELEASE&#125; \\ &amp;&amp; cd alpine \\ &amp;&amp; make all \\ &amp;&amp; apk index -o $&#123;tempDir&#125;/packages/alpine/$&#123;apkArch&#125;/APKINDEX.tar.gz $&#123;tempDir&#125;/packages/alpine/$&#123;apkArch&#125;/*.apk \\ &amp;&amp; abuild-sign -k $&#123;tempDir&#125;/.abuild/abuild-key.rsa $&#123;tempDir&#125;/packages/alpine/$&#123;apkArch&#125;/APKINDEX.tar.gz \\ \" \\ &amp;&amp; cp $&#123;tempDir&#125;/.abuild/abuild-key.rsa.pub /etc/apk/keys/ \\ &amp;&amp; apk del .build-deps \\ &amp;&amp; apk add -X $&#123;tempDir&#125;/packages/alpine/ --no-cache $nginxPackages \\ ;; \\ esac \\# if we have leftovers from building, let's purge them (including extra, unnecessary build deps) &amp;&amp; if [ -n \"$tempDir\" ]; then rm -rf \"$tempDir\"; fi \\ &amp;&amp; if [ -n \"/etc/apk/keys/abuild-key.rsa.pub\" ]; then rm -f /etc/apk/keys/abuild-key.rsa.pub; fi \\ &amp;&amp; if [ -n \"/etc/apk/keys/nginx_signing.rsa.pub\" ]; then rm -f /etc/apk/keys/nginx_signing.rsa.pub; fi \\# Bring in gettext so we can get `envsubst`, then throw# the rest away. To do this, we need to install `gettext`# then move `envsubst` out of the way so `gettext` can# be deleted completely, then move `envsubst` back. &amp;&amp; apk add --no-cache --virtual .gettext gettext \\ &amp;&amp; mv /usr/bin/envsubst /tmp/ \\ \\ &amp;&amp; runDeps=\"$( \\ scanelf --needed --nobanner /tmp/envsubst \\ | awk '&#123; gsub(/,/, \"\\nso:\", $2); print \"so:\" $2 &#125;' \\ | sort -u \\ | xargs -r apk info --installed \\ | sort -u \\ )\" \\ &amp;&amp; apk add --no-cache $runDeps \\ &amp;&amp; apk del .gettext \\ &amp;&amp; mv /tmp/envsubst /usr/local/bin/ \\# Bring in tzdata so users could set the timezones through the environment# variables &amp;&amp; apk add --no-cache tzdata \\# forward request and error logs to docker log collector &amp;&amp; ln -sf /dev/stdout /var/log/nginx/access.log \\ &amp;&amp; ln -sf /dev/stderr /var/log/nginx/error.logEXPOSE 80STOPSIGNAL SIGTERMCMD [\"nginx\", \"-g\", \"daemon off;\"]","categories":[{"name":"容器","slug":"容器","permalink":"https://github.com/cyylog/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://github.com/cyylog/tags/Docker/"}]},{"title":"Docker_000","slug":"容器/Dockerfilee-000","date":"2019-11-15T14:16:23.000Z","updated":"2020-05-25T13:54:17.753Z","comments":true,"path":"2019/11/15/容器/Dockerfilee-000/","link":"","permalink":"https://github.com/cyylog/2019/11/15/%E5%AE%B9%E5%99%A8/Dockerfilee-000/","excerpt":"","text":"Dockerfile构建镜像12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091通过Dockerfile创建镜像虽然可以自己制作 rootfs(见&#39;容器文件系统那些事儿&#39;)，但Docker 提供了一种更便捷的方式，叫作 Dockerfiledocker build命令用于根据给定的Dockerfile和上下文以构建Docker镜像。docker build语法：# docker build [OPTIONS] &lt;PATH | URL | -&gt;1. 常用选项说明--build-arg，设置构建时的变量--no-cache，默认false。设置该选项，将不使用Build Cache构建镜像--pull，默认false。设置该选项，总是尝试pull镜像的最新版本--compress，默认false。设置该选项，将使用gzip压缩构建的上下文--disable-content-trust，默认true。设置该选项，将对镜像进行验证--file, -f，Dockerfile的完整路径，默认值为‘PATH&#x2F;Dockerfile’--isolation，默认--isolation&#x3D;&quot;default&quot;，即Linux命名空间；其他还有process或hyperv--label，为生成的镜像设置metadata--squash，默认false。设置该选项，将新构建出的多个层压缩为一个新层，但是将无法在多个镜像之间共享新层；设置该选项，实际上是创建了新image，同时保留原有image。--tag, -t，镜像的名字及tag，通常name:tag或者name格式；可以在一次构建中为一个镜像设置多个tag--network，默认default。设置该选项，Set the networking mode for the RUN instructions during build--quiet, -q ，默认false。设置该选项，Suppress the build output and print image ID on success--force-rm，默认false。设置该选项，总是删除掉中间环节的容器--rm，默认--rm&#x3D;true，即整个构建过程成功后删除中间环节的容器2. PATH | URL | -说明：给出命令执行的上下文。上下文可以是构建执行所在的本地路径，也可以是远程URL，如Git库、tarball或文本文件等。如果是Git库，如https:&#x2F;&#x2F;github.com&#x2F;docker&#x2F;rootfs.git#container:docker，则隐含先执行git clone --depth 1 --recursive，到本地临时目录；然后再将该临时目录发送给构建进程。构建镜像的进程中，可以通过ADD命令将上下文中的任何文件（注意文件必须在上下文中）加入到镜像中。-表示通过STDIN给出Dockerfile或上下文。示例： docker build - &lt; Dockerfile说明：该构建过程只有Dockerfile，没有上下文 docker build - &lt; context.tar.gz说明：其中Dockerfile位于context.tar.gz的根路径 docker build -t champagne&#x2F;bbauto:latest -t champagne&#x2F;bbauto:v2.1 . docker build -f dockerfiles&#x2F;Dockerfile.debug -t myapp_debug .2.1、 创建镜像所在的文件夹和Dockerfile文件 命令： 1、mkdir sinatra 2、cd sinatra 3、touch Dockerfile 2.2、 在Dockerfile文件中写入指令，每一条指令都会更新镜像的信息例如： # This is a comment FROM ubuntu:14.04 MAINTAINER tiger tiger@localhost.localdomain RUN apt-get update &amp;&amp; apt-get install -y ruby ruby-dev RUN gem install sinatra 格式说明： 每行命令都是以 INSTRUCTION statement 形式，就是命令+ 清单的模式。命令要大写，&quot;#&quot;是注解。 FROM 命令是告诉docker 我们的镜像什么。 MAINTAINER 是描述 镜像的创建人。 RUN 命令是在镜像内部执行。就是说他后面的命令应该是针对镜像可以运行的命令。 2.3、创建镜像 命令：docker build -t tiger&#x2F;sinatra:v2 . docker build 是docker创建镜像的命令 -t 是标识新建的镜像属于 ouruser的 sinatra是仓库的名称 ：v2 是tag &quot;.&quot;是用来指明 我们的使用的Dockerfile文件当前目录的 详细执行过程： [root@master sinatra]# docker build -t tiger&#x2F;sinatra:v2 . Sending build context to Docker daemon 2.048 kB Step 1 : FROM daocloud.io&#x2F;ubuntu:14.04 Trying to pull repository daocloud.io&#x2F;ubuntu ... 14.04: Pulling from daocloud.io&#x2F;ubuntu f3ead5e8856b: Pull complete Digest: sha256:ea2b82924b078d9c8b5d3f0db585297a5cd5b9c2f7b60258cdbf9d3b9181d828 ---&gt; 2ff3b426bbaa Step 2 : MAINTAINER tiger tiger@localhost.localdomain ---&gt; Running in 948396c9edaa ---&gt; 227da301bad8 Removing intermediate container 948396c9edaa Step 3 : RUN apt-get update &amp;&amp; apt-get install -y ruby ruby-dev ... Step 4 : RUN gem install sinatra ---&gt; Running in 89234cb493d9 2.4、创建完成后，从镜像创建容器 #docker run -t -i tiger&#x2F;sinatra:v2 &#x2F;bin&#x2F;bash Dockerfile分为四个部分: 基础镜像信息、维护者信息、镜像操作指令和容器启动指令。 即FROM、MAINTAINER、RUN、CMD四个部分 指令说明123456789101112131415161718FROM 指定所创建镜像的基础镜像MAINTAINER 制定维护者信息RUN 运行命令CMD 容器启动是默认执行的命令LABEL 指定生成镜像的元数据标签信息EXPOSE 声明镜像内服务所监听的端口ENV 指定环境变量ADD 复制指定src路径的内容到容器的dest路径下，如果src为tar文件，则自动解压到dest路径下copy 复制指定src路径的内容到镜像的dest路径下ENTERPOINT 指定镜像的默认入口VOLUME 创建数据卷挂载点USER 指定运行容器是的用户名或UIDWORKDIR 配置工作目录ARG 指定镜像内使用的参数ONBUILD 配置当所创建的镜像作为其他镜像的基础镜像时，所执行创建操作指令STOPSIGAL 容器退出信号值HEALTHCHECK 如何进行健康检查SHELL 指定使用shell的默认shell类型 nginx-dockerfile示例vim Dockerfile 1234567891011121314151617181920212223FROM centos:7.2.1511ENV TZ&#x3D;Asia&#x2F;ShanghaiRUN yum -y install epel* \\ yum -y install gcc openssl openssl-devel pcre-devel zlib-develADD nginx-1.14.2.tar.gz &#x2F;opt&#x2F;WORKDIR &#x2F;opt&#x2F;nginx-1.14.2RUN .&#x2F;configure --prefix&#x3D;&#x2F;opt&#x2F;nginx --http-log-path&#x3D;&#x2F;opt&#x2F;nginx&#x2F;logs&#x2F;access.log --error-log-path&#x3D;&#x2F;opt&#x2F;nginx&#x2F;logs&#x2F;error.log --http-client-body-temp-path&#x3D;&#x2F;opt&#x2F;nginx&#x2F;client&#x2F; --http-proxy-temp-path&#x3D;&#x2F;opt&#x2F;nginx&#x2F;proxy&#x2F; --with-http_stub_status_module --with-file-aio --with-http_flv_module --with-http_gzip_static_module --with-stream --with-threads --user&#x3D;www --group&#x3D;wwwRUN make &amp;&amp; make installRUN groupadd www &amp;&amp; useradd -g www wwwWORKDIR &#x2F;opt&#x2F;nginxRUN rm -rf &#x2F;opt&#x2F;nginx-1.14.2ENV NGINX_HOME&#x3D;&#x2F;opt&#x2F;nginxENV PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;sbin:&#x2F;bin:&#x2F;opt&#x2F;nginx&#x2F;sbinEXPOSE 80 443 CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] 需要先下载nginx-1.14.2.tar.gz在Dockerfile同级目录下，然后执行如下命令 docker build -t nginx_image ./Dockerfile tomcat-dockerfile示例1234567891011121314151617FROM centos:7.4.1708ADD jdk-8u171-linux-x64.tar.gz &#x2F;usr&#x2F;local&#x2F;ADD apache-tomcat-7.0.88.tar.gz &#x2F;usr&#x2F;local&#x2F;WORKDIR &#x2F;usr&#x2F;local&#x2F;RUN mv jdk1.8.0_171 jdk &amp;&amp; mv apache-tomcat-7.0.88 tomcatENV JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;jdkENV CLASS_PATH&#x3D;$JAVA_HOME&#x2F;lib:$JAVA_HOME&#x2F;jre&#x2F;libENV PATH&#x3D;$JAVA_HOME&#x2F;bin:$PATHENV CATALINA_HOME &#x2F;usr&#x2F;local&#x2F;tomcatEXPOSE 8080CMD &#x2F;usr&#x2F;local&#x2F;tomcat&#x2F;bin&#x2F;catalina.sh run 需要先下载jdk和tomcat在dockerfile的同级目录下，然后执行如下命令 docker build -t tomcat_image ./Dockerfile 容器网络 1234567891011121314小规模docker环境大部分运行在单台主机上，如果公司大规模采用docker，那么多个宿主机上的docker如何互联Docker默认的内部ip为172.17.42.0网段，所以必须要修改其中一台的默认网段以免ip冲突。#vim &#x2F;etc&#x2F;sysconfig&#x2F;docker-networkDOCKER_NETWORK_OPTIONS&#x3D; --bip&#x3D;172.18.42.1&#x2F;16#rebootdocker 130上：#route add -net 172.18.0.0&#x2F;16 gw 192.168.18.128docker 128上：#route add -net 172.17.0.0&#x2F;16 gw 192.168.18.130现在两台宿主机里的容器就可以通信了。 容器固定IP1234567891011121314151617181920212223242526docker安装后，默认会创建三种网络类型，bridge、host和none显示当前网络：# docker network listNETWORK ID NAME DRIVER SCOPE90b22f633d2f bridge bridge locale0b365da7fd2 host host localda7b7a090837 none null localbridge:网络桥接默认情况下启动、创建容器都是用该模式，所以每次docker容器重启时会按照顺序获取对应ip地址，这就导致容器每次重启，ip都发生变化none：无指定网络启动容器时，可以通过–network&#x3D;none,docker容器不会分配局域网iphost：主机网络docker容器的网络会附属在主机上，两者是互通的。创建固定ip容器1、创建自定义网络类型，并且指定网段#docker network create --subnet&#x3D;192.168.0.0&#x2F;16 staticnet通过docker network ls可以查看到网络类型中多了一个staticnet2、使用新的网络类型创建并启动容器#docker run -it --name userserver --net staticnet --ip 192.168.0.2 centos:6 &#x2F;bin&#x2F;bash通过docker inspect可以查看容器ip为192.168.0.2，关闭容器并重启，发现容器ip并未发生改变","categories":[{"name":"容器","slug":"容器","permalink":"https://github.com/cyylog/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://github.com/cyylog/tags/Docker/"}]},{"title":"zabbix微信报警设置","slug":"监控/zabbix配置企业微信报警","date":"2019-11-04T17:55:39.000Z","updated":"2020-05-25T13:58:47.500Z","comments":true,"path":"2019/11/05/监控/zabbix配置企业微信报警/","link":"","permalink":"https://github.com/cyylog/2019/11/05/%E7%9B%91%E6%8E%A7/zabbix%E9%85%8D%E7%BD%AE%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%8A%A5%E8%AD%A6/","excerpt":"","text":"zabbix 微信报警设置一、主要获取三个参数:企业ID、用户账号、AgentId,和Secret：1.获取企业ID 2.获取AgentId,和Secret3这里要先点通讯录创建一个部门，然后再点应用小程序创建应用，填写logo、名称、和选择部门就可以了 3.获取用户账号 4.测试gentId,和Secret这个是接口调用测试gentId,和Secret的地址：https://work.weixin.qq.com/api/devtools/devtool.php 这里看到有HTTP/1.1 200 OK 就说明接口有效了，其它的不管。 二、调用的shell脚本方式，脚本如下：这里要注意的是填写正确的通讯录 部门ID，可以点那个下线三个点那里。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768[root@cyy alertscripts]# vim wechat.sh#!/usr/bin/env bash#!/usr/bin/env bash## Author: cyylog# Email: cyylog@aliyun.com# Date: 2019/09/25# Github: https://github.com/cyylog# Usage: Wechat alert script for zabbix# if [ $# -eq 0 ] || [[ \"$1\" == \"-h\" || \"$1\" == \"--help\" ]];then echo \"Usage of $0:\" echo -e \" --CorpID=string\" echo -e \" --Secret=string\" echo -e \" --AgentID=string\" echo -e \" --UserID=string\" echo -e \" --Msg=string\" exitfi#ops=(-c -s -a -u)#args=(CorpID Secret AgentID UserID)#while [ $# -gt 0 ];do# [ \"$1\" == \"-m\" ] &amp;&amp; Msg=\"$2\" &amp;&amp; shift 2# for i in &#123;0..3&#125;;do# [ \"$1\" == \"$&#123;ops[i]&#125;\" ] &amp;&amp; eval $&#123;args[i]&#125;=\"$2\"# done# shift 2#donefor i in \"$@\";do echo $i|grep Msg &amp;&gt; /dev/null &amp;&amp; msg=$(echo $i|sed 's/.*=//') &amp;&amp; Msg=\"$msg\" &amp;&amp; continue eval \"$(echo $i|sed 's/--//')\"done#echo $CorpID#echo $Secret#echo $UserID#echo $AgentID#echo $Msg#GURL=\"https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=$CorpID&amp;corpsecret=$Secret\"Token=$(/usr/bin/curl -s -G $GURL |awk -F \\\" '&#123;print $10&#125;')PURL=\"https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=$Token\"Info()&#123; printf '&#123;\\n' printf '\\t\"touser\": \"'\"$UserID\"\\\"\",\\n\" printf '\\t\"msgtype\": \"text\",\\n' printf '\\t\"agentid\": \"'\"$AgentID\"\\\"\",\\n\" printf '\\t\"text\": &#123;\\n' printf '\\t\\t\"content\": \"'\"$Msg\"\\\"\"\\n\" printf '\\t&#125;,\\n' printf '\\t\"safe\":\"0\"\\n' printf '&#125;\\n'&#125;/usr/bin/curl --data-ascii \"$(Info)\" $PURLecho [root@cyy alertscripts]# chmod +x wechat.sh[root@cyy alertscripts]# ./wechat.sh \"这里一个测试\" //可以这样直接调试，然后登陆到企业微信查看该部门的群成员是否收到此信息脚本测试通过后就是在zabbix控制台上设置了 三、zabbix 控制台添加新媒体1.点管理 -&gt; 报警媒介类型 -&gt; 创建媒介类型 123456789--AgentID=1000002--CorpID=ww74c********56c --Secret=-c-3Xw*****************j-Zj6cw--Msg=&#123;ALERT.MESSAGE&#125;--UserID=&#123;ALERT.SENDTO&#125; 2.然后再设置上用户：点管理 —&gt; 创建用户（微信报警的用户） 3.再点用户旁边的 报警媒介 进行设置（收件人要填写用户的账号）第一步的第3点获取的账号 到这里就基本都设置完成了，可以设置个触发器和动作来测试脚本。","categories":[{"name":"监控","slug":"监控","permalink":"https://github.com/cyylog/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"https://github.com/cyylog/tags/zabbix/"}]},{"title":"搭建Gitlab","slug":"DevOPs/搭建Gitlab","date":"2019-10-04T17:55:39.000Z","updated":"2020-09-20T15:34:38.937Z","comments":true,"path":"2019/10/05/DevOPs/搭建Gitlab/","link":"","permalink":"https://github.com/cyylog/2019/10/05/DevOPs/%E6%90%AD%E5%BB%BAGitlab/","excerpt":"","text":"Gitlab Server 部署 1、环境准备123456789101112131.系统版本：CentOS7.42.Gitlab版本：gitlab-ee 11.0.13.初始化系统环境4.关闭防火墙[root@localhost ~]# systemctl stop iptables firewalld[root@localhost ~]# systemctl disable iptables firewalld5.开启邮件服务[root@vm1 ~]# systemctl start postfix[root@vm1 ~]# systemctl enable postfix6.关闭SELinux[root@localhost ~]# sed -ri &#39;&#x2F;SELINUX&#x3D;&#x2F;cSELINUX&#x3D;disabled&#39; &#x2F;etc&#x2F;selinux&#x2F;config[root@localhost ~]# setenforce 0 # 临时关闭SELinux[root@localhost ~]# reboot 2、部署Gitlab1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051.安装Gitlab社区版&#x2F;企业版2.安装gitlab依赖包[root@localhost ~]# yum install -y curl openssh-server openssh-clients postfix cronie policycoreutils-python# gitlab-ce 10.x.x以后的版本需要依赖policycoreutils-python3.开启postfix，并设置开机自启[root@localhost ~]# systemctl start postfix;systemctl enable postfix4.选择添加yum源安装gitlab(根据需求配置源)（1）添加阿里源# vim &#x2F;etc&#x2F;yum.repos.d&#x2F;gitlab-ce.repo[gitlab-ce]name&#x3D;gitlab-cebaseurl&#x3D;http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;gitlab-ce&#x2F;yum&#x2F;el7Repo_gpgcheck&#x3D;0Enabled&#x3D;1Gpgkey&#x3D;https:&#x2F;&#x2F;packages.gitlab.com&#x2F;gpg.key（2） 添加清华源# vim gitlab-ce.repo[gitlab-ce]name&#x3D;Gitlab CE Repositorybaseurl&#x3D;https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;gitlab-ce&#x2F;yum&#x2F;el$releasever&#x2F;gpgcheck&#x3D;0enabled&#x3D;1# vim gitlab-ee.repo[gitlab-ee]name&#x3D;Gitlab EE Repositorybaseurl&#x3D;https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;gitlab-ee&#x2F;yum&#x2F;el$releasever&#x2F;gpgcheck&#x3D;0enabled&#x3D;1# vim runner_gitlab-ci-multi-runner.repo[runner_gitlab-ci-multi-runner]name&#x3D;runner_gitlab-ci-multi-runnerbaseurl&#x3D;https:&#x2F;&#x2F;packages.gitlab.com&#x2F;runner&#x2F;gitlab-ci-multi-runner&#x2F;el&#x2F;7&#x2F;$basearchrepo_gpgcheck&#x3D;1gpgcheck&#x3D;0enabled&#x3D;1gpgkey&#x3D;https:&#x2F;&#x2F;packages.gitlab.com&#x2F;runner&#x2F;gitlab-ci-multi-runner&#x2F;gpgkeysslverify&#x3D;1sslcacert&#x3D;&#x2F;etc&#x2F;pki&#x2F;tls&#x2F;certs&#x2F;ca-bundle.crtmetadata_expire&#x3D;300[runner_gitlab-ci-multi-runner-source]name&#x3D;runner_gitlab-ci-multi-runner-sourcebaseurl&#x3D;https:&#x2F;&#x2F;packages.gitlab.com&#x2F;runner&#x2F;gitlab-ci-multi-runner&#x2F;el&#x2F;7&#x2F;SRPMSrepo_gpgcheck&#x3D;1gpgcheck&#x3D;0enabled&#x3D;1gpgkey&#x3D;https:&#x2F;&#x2F;packages.gitlab.com&#x2F;runner&#x2F;gitlab-ci-multi-runner&#x2F;gpgkeysslverify&#x3D;1sslcacert&#x3D;&#x2F;etc&#x2F;pki&#x2F;tls&#x2F;certs&#x2F;ca-bundle.crtmetadata_expire&#x3D;300(3) 添加官方源curl https:&#x2F;&#x2F;packages.gitlab.com&#x2F;install&#x2F;repositories&#x2F;gitlab&#x2F;gitlab-ee&#x2F;script.rpm.sh | sudo bash5.安装包下载https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;gitlab-ce&#x2F;yum&#x2F;el7&#x2F;https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;gitlab-ee&#x2F;yum&#x2F;el7&#x2F;6.根据需要选择ce&#x2F;ee[root@localhost ~]# yum -y install gitlab-ce # 自动安装最新版[root@localhost ~]# yum -y install gitlab-ce-x.x.x # 安装指定版本Gitlab[root@localhost ~]# yum -y install gitlab-ce warning: gitlab-ce-10.7.2-ce.0.el7.x86_64.rpm: Header V4 RSA&#x2F;SHA1 Signature, key ID f27eab47: NOKEYPreparing... ################################# [100%]Updating &#x2F; installing... 1:gitlab-ce-10.7.2-ce.0.el7 ################################# [100%]It looks like GitLab has not been configured yet; skipping the upgrade script. *. *. *** *** ***** ***** .****** ******* ******** ******** ,,,,,,,,,***********,,,,,,,,, ,,,,,,,,,,,*********,,,,,,,,,,, .,,,,,,,,,,,*******,,,,,,,,,,,, ,,,,,,,,,*****,,,,,,,,,. ,,,,,,,****,,,,,, .,,,***,,,, ,*,. _______ __ __ __ &#x2F; ____(_) &#x2F;_&#x2F; &#x2F; ____ _&#x2F; &#x2F;_ &#x2F; &#x2F; __&#x2F; &#x2F; __&#x2F; &#x2F; &#x2F; __ &#96;&#x2F; __ \\ &#x2F; &#x2F;_&#x2F; &#x2F; &#x2F; &#x2F;_&#x2F; &#x2F;___&#x2F; &#x2F;_&#x2F; &#x2F; &#x2F;_&#x2F; &#x2F; \\____&#x2F;_&#x2F;\\__&#x2F;_____&#x2F;\\__,_&#x2F;_.___&#x2F; Thank you for installing GitLab!GitLab was unable to detect a valid hostname for your instance.Please configure a URL for your GitLab instance by setting &#96;external_url&#96;configuration in &#x2F;etc&#x2F;gitlab&#x2F;gitlab.rb file.Then, you can start your GitLab instance by running the following command: sudo gitlab-ctl reconfigureFor a comprehensive list of configuration options please see the Omnibus GitLab readmehttps:&#x2F;&#x2F;gitlab.com&#x2F;gitlab-org&#x2F;omnibus-gitlab&#x2F;blob&#x2F;master&#x2F;README.md ###3、配置 Gitlab 1、查看Gitlab版本12[root@localhost ~]# head -1 &#x2F;opt&#x2F;gitlab&#x2F;version-manifest.txtgitlab-ce 10.1.1 2、Gitlab 配置文登录链接123456789101112#设置登录链接[root@localhost ~]# vim &#x2F;etc&#x2F;gitlab&#x2F;gitlab.rb***## GitLab URL##! URL on which GitLab will be reachable.##! For more details on configuring external_url see:##! https:&#x2F;&#x2F;docs.gitlab.com&#x2F;omnibus&#x2F;settings&#x2F;configuration.html#configuring-the-external-url-for-gitlab# 没有域名，可以设置为本机IP地址external_url &#39;http:&#x2F;&#x2F;172.17.0.61&#39;***[root@localhost ~]# grep &quot;^external_url&quot; &#x2F;etc&#x2F;gitlab&#x2F;gitlab.rbexternal_url &#39;http:&#x2F;&#x2F;172.17.0.61&#39; #绑定监听的域名或IP 3、初始化 Gitlab (第一次使用配置时间较长)12 [root@localhost ~]# gitlab-ctl reconfigure ..... 4、启动 Gitlab 服务1234567891011121314151617181920[root@vm1 ~]# gitlab-ctl startok: run: gitaly: (pid 22896) 2922sok: run: gitlab-monitor: (pid 22914) 2921sok: run: gitlab-workhorse: (pid 22882) 2922sok: run: logrotate: (pid 22517) 2987sok: run: nginx: (pid 22500) 2993sok: run: node-exporter: (pid 22584) 2974sok: run: postgres-exporter: (pid 22946) 2919sok: run: postgresql: (pid 22250) 3047sok: run: prometheus: (pid 22931) 2920sok: run: redis: (pid 22190) 3053sok: run: redis-exporter: (pid 22732) 2962sok: run: sidekiq: (pid 22472) 3005sok: run: unicorn: (pid 22433) 3011s[root@vm1 ~]# [root@vm1 ~]# lsof -i:80COMMAND PID USER FD TYPE DEVICE SIZE&#x2F;OFF NODE NAMEnginx 22500 root 7u IPv4 50923 0t0 TCP *:http (LISTEN)nginx 22501 gitlab-www 7u IPv4 50923 0t0 TCP *:http (LISTEN)[root@vm1 ~]# 5、Gitlab 设置 HTTPS 方式12345如果想要以上的 https 方式正常生效使用，则需要把 letsencrypt 自动生成证书的配置打开，这样在执行重新让配置生效命令 (gitlab-ctl reconfigure) 的时候会自动给域名生成免费的证书并自动在 gitlab 自带的 nginx 中加上相关的跳转配置，都是全自动的，非常方便。letsencrypt[&#39;enable&#39;] &#x3D; true letsencrypt[&#39;contact_emails&#39;] &#x3D; [&#39;caryyu@qq.com&#39;] # 这应该是一组要添加为联系人的电子邮件地址 6、Gitlab 添加smtp邮件功能12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970[root@vm1 ~]# vim &#x2F;etc&#x2F;gitlab&#x2F;gitlab.rbpostfix 并非必须的；根据具体情况配置，以 SMTP 的为例配置邮件服务器来实现通知；参考配置如下： ### Email Settings gitlab_rails[&#39;gitlab_email_enabled&#39;] &#x3D; true gitlab_rails[&#39;gitlab_email_from&#39;] &#x3D; &#39;system.notice@qq.com&#39; gitlab_rails[&#39;gitlab_email_display_name&#39;] &#x3D; &#39;gitlab.notice&#39; gitlab_rails[&#39;gitlab_email_reply_to&#39;] &#x3D; &#39;system.notice@qq.com&#39; gitlab_rails[&#39;gitlab_email_subject_suffix&#39;] &#x3D; &#39;gitlab&#39; ### GitLab email server settings ###! Docs: https:&#x2F;&#x2F;docs.gitlab.com&#x2F;omnibus&#x2F;settings&#x2F;smtp.html ###! **Use smtp instead of sendmail&#x2F;postfix.** gitlab_rails[&#39;smtp_enable&#39;] &#x3D; true gitlab_rails[&#39;smtp_address&#39;] &#x3D; &quot;smtp.qq.com&quot; gitlab_rails[&#39;smtp_port&#39;] &#x3D; 465 gitlab_rails[&#39;smtp_user_name&#39;] &#x3D; &quot;system.notice@qq.com&quot; gitlab_rails[&#39;smtp_password&#39;] &#x3D; &quot;xxxxx&quot; gitlab_rails[&#39;smtp_domain&#39;] &#x3D; &quot;qq.com&quot; gitlab_rails[&#39;smtp_authentication&#39;] &#x3D; &quot;login&quot; gitlab_rails[&#39;smtp_enable_starttls_auto&#39;] &#x3D; true gitlab_rails[&#39;smtp_tls&#39;] &#x3D; true[root@vm1 ~]# grep -P &quot;^[^#].*smtp_|user_email|gitlab_email&quot; &#x2F;etc&#x2F;gitlab&#x2F;gitlab.rbgitlab_rails[&#39;gitlab_email_enabled&#39;] &#x3D; truegitlab_rails[&#39;gitlab_email_from&#39;] &#x3D; &#39;username@domain.cn&#39;gitlab_rails[&#39;gitlab_email_display_name&#39;] &#x3D; &#39;Admin&#39;gitlab_rails[&#39;gitlab_email_reply_to&#39;] &#x3D; &#39;usernamei@domain.cn&#39;gitlab_rails[&#39;gitlab_email_subject_suffix&#39;] &#x3D; &#39;[gitlab]&#39;gitlab_rails[&#39;smtp_enable&#39;] &#x3D; truegitlab_rails[&#39;smtp_address&#39;] &#x3D; &quot;smtp.exmail.qq.com&quot;gitlab_rails[&#39;smtp_port&#39;] &#x3D; 25 gitlab_rails[&#39;smtp_user_name&#39;] &#x3D; &quot;username@domain.cn&quot;gitlab_rails[&#39;smtp_password&#39;] &#x3D; &quot;password&quot;gitlab_rails[&#39;smtp_domain&#39;] &#x3D; &quot;domain.cn&quot;gitlab_rails[&#39;smtp_authentication&#39;] &#x3D; &quot;login&quot;gitlab_rails[&#39;smtp_enable_starttls_auto&#39;] &#x3D; truegitlab_rails[&#39;smtp_tls&#39;] &#x3D; falseuser[&#39;git_user_email&#39;] &#x3D; &quot;username@domain.cn&quot;[root@vm1 ~]# gitlab-ctl reconfigure #修改配置后需要初始化配置......[root@vm1 ~]# gitlab-ctl stopok: down: gitaly: 0s, normally upok: down: gitlab-monitor: 1s, normally upok: down: gitlab-workhorse: 0s, normally upok: down: logrotate: 1s, normally upok: down: nginx: 0s, normally upok: down: node-exporter: 1s, normally upok: down: postgres-exporter: 0s, normally upok: down: postgresql: 0s, normally upok: down: prometheus: 0s, normally upok: down: redis: 0s, normally upok: down: redis-exporter: 1s, normally upok: down: sidekiq: 0s, normally upok: down: unicorn: 1s, normally up[root@vm1 ~]# gitlab-ctl startok: run: gitaly: (pid 37603) 0sok: run: gitlab-monitor: (pid 37613) 0sok: run: gitlab-workhorse: (pid 37625) 0sok: run: logrotate: (pid 37631) 0sok: run: nginx: (pid 37639) 1sok: run: node-exporter: (pid 37644) 0sok: run: postgres-exporter: (pid 37648) 1sok: run: postgresql: (pid 37652) 0sok: run: prometheus: (pid 37660) 1sok: run: redis: (pid 37668) 0sok: run: redis-exporter: (pid 37746) 0sok: run: sidekiq: (pid 37750) 1sok: run: unicorn: (pid 37757) 0s 7、Gitlab 发送邮件测试12345678910111213141516171819202122232425[root@vm1 ~]# gitlab-rails console Loading production environment (Rails 4.2.10)irb(main):001:0&gt; Notify.test_email(&#39;user@destination.com&#39;, &#39;Message Subject&#39;, &#39;Message Body&#39;).deliver_nowNotify#test_email: processed outbound mail in 2219.5msSent mail to user@destination.com (2469.5ms)Date: Fri, 04 May 2018 15:50:10 +0800From: Admin &lt;username@domain.cn&gt;Reply-To: Admin &lt;username@domain.cn&gt;To: user@destination.comMessage-ID: &lt;5aec10b24cfaa_93933fee282db10c162d@vm1.mail&gt;Subject: Message SubjectMime-Version: 1.0Content-Type: text&#x2F;html; charset&#x3D;UTF-8Content-Transfer-Encoding: 7bitAuto-Submitted: auto-generatedX-Auto-Response-Suppress: All&lt;!DOCTYPE html PUBLIC &quot;-&#x2F;&#x2F;W3C&#x2F;&#x2F;DTD HTML 4.0 Transitional&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;www.w3.org&#x2F;TR&#x2F;REC-html40&#x2F;loose.dtd&quot;&gt;&lt;html&gt;&lt;body&gt;&lt;p&gt;Message Body&lt;&#x2F;p&gt;&lt;&#x2F;body&gt;&lt;&#x2F;html&gt;&#x3D;&gt; #&lt;Mail::Message:70291731344240, Multipart: false, Headers: &lt;Date: Fri, 04 May 2018 15:50:10 +0800&gt;, &lt;From: Admin &lt;username@domain.cn&gt;&gt;, &lt;Reply-To: Admin &lt;username@domain.cn&gt;&gt;, &lt;To: user@destination.com&gt;, &lt;Message-ID: &lt;5aec10b24cfaa_93933fee282db10c162d@vm1.mail&gt;&gt;, &lt;Subject: Message Subject&gt;, &lt;Mime-Version: 1.0&gt;, &lt;Content-Type: text&#x2F;html; charset&#x3D;UTF-8&gt;, &lt;Content-Transfer-Encoding: 7bit&gt;, &lt;Auto-Submitted: auto-generated&gt;, &lt;X-Auto-Response-Suppress: All&gt;&gt;irb(main):002:0&gt;quit ###3、gitlab的使用 在浏览器中输入 http://192.168.60.119/ ，然后 change password: ，并使用root用户登录 即可 (后续动作根据提示操作) 1、gitlab 命令行修改密码12345gitlab-rails console productionirb(main):001:0&gt; user &#x3D; User.where(id: 1).first # id为1的是超级管理员irb(main):002:0&gt;user.password &#x3D; &#39;yourpassword&#39; # 密码必须至少8个字符irb(main):003:0&gt;user.save! # 如没有问题 返回trueexit # 退出 2、gitlab服务管理1234567gitlab-ctl start # 启动所有 gitlab 组件；gitlab-ctl stop # 停止所有 gitlab 组件；gitlab-ctl restart # 重启所有 gitlab 组件；gitlab-ctl status # 查看服务状态；gitlab-ctl reconfigure # 启动服务；vim &#x2F;etc&#x2F;gitlab&#x2F;gitlab.rb # 修改默认的配置文件；gitlab-ctl tail # 查看日志； 3、登陆 Gitlab 如果需要手工修改nginx的port ，可以在gitlab.rb中设置 nginx[‘listen_port’] = 8000 ，然后再次 gitlab-ctl reconfigure即可 登录 gitlab 如下所示(首次登陆设置 root 密码)： 创建项目组 group ，组名为plat-sp ,如下所示: 去掉用户的自动注册功能（安全）： admin are -&gt; settings -&gt; Sign-up Restrictions 去掉钩钩，然后拉到最下面保存，重新登录","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://github.com/cyylog/categories/DevOps/"}],"tags":[{"name":"Gitlab","slug":"Gitlab","permalink":"https://github.com/cyylog/tags/Gitlab/"}]},{"title":"linux服务器被黑排查思路","slug":"Linux/服务器被黑排查思路","date":"2019-10-04T17:55:39.000Z","updated":"2020-05-25T13:52:03.920Z","comments":true,"path":"2019/10/05/Linux/服务器被黑排查思路/","link":"","permalink":"https://github.com/cyylog/2019/10/05/Linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A2%AB%E9%BB%91%E6%8E%92%E6%9F%A5%E6%80%9D%E8%B7%AF/","excerpt":"","text":"账户和登录安全账户安全是系统安全的第一道屏障，也是系统安全的核心，保障登录账户的安全，在一定程度上可以提高服务器的安全级别，下面重点介绍下 Linux 系统登录账户的安全设置方法。 ①删除特殊的账户和账户组Linux 提供了各种不同角色的系统账号，在系统安装完成后，默认会安装很多不必要的用户和用户组。 如果不需要某些用户或者组，就要立即删除它，因为账户越多，系统就越不安全，很可能被黑客利用，进而威胁到服务器的安全。 Linux系统中可以删除的默认用户和组大致有如下这些： 可删除的用户，如 adm，lp，sync，shutdown，halt，news，uucp，operator，games，gopher 等。 可删除的组，如 adm，lp，news，uucp，games，dip，pppusers，popusers，slipusers 等。 ②关闭系统不需要的服务Linux 在安装完成后，绑定了很多没用的服务，这些服务默认都是自动启动的。 对于服务器来说，运行的服务越多，系统就越不安全，越少服务在运行，安全性就越好，因此关闭一些不需要的服务，对系统安全有很大的帮助。 具体哪些服务可以关闭，要根据服务器的用途而定，一般情况下，只要系统本身用不到的服务都认为是不必要的服务。 例如：某台 Linux 服务器用于 www 应用，那么除了 httpd 服务和系统运行是必须的服务外，其他服务都可以关闭。 下面这些服务一般情况下是不需要的，可以选择关闭： anacron、auditd、autofs、avahi-daemon、avahi-dnsconfd、bluetooth、cpuspeed、firstboot、gpm、haldaemon、hidd、ip6tables、ipsec、isdn、lpd、mcstrans、messagebus、netfs、nfs、nfslock、nscd、pcscd portmap、readahead_early、restorecond、rpcgssd、rpcidmapd、rstatd、sendmail、setroubleshoot、yppasswdd ypserv ③密码安全策略在 Linux 下，远程登录系统有两种认证方式： 密码认证 密钥认证 密码认证方式是传统的安全策略，对于密码的设置，比较普遍的说法是：至少 6 个字符以上，密码要包含数字、字母、下划线、特殊符号等。 设置一个相对复杂的密码，对系统安全能起到一定的防护作用，但是也面临一些其他问题，例如密码暴力破解、密码泄露、密码丢失等，同时过于复杂的密码对运维工作也会造成一定的负担。 密钥认证是一种新型的认证方式，公用密钥存储在远程服务器上，专用密钥保存在本地，当需要登录系统时，通过本地专用密钥和远程服务器的公用密钥进行配对认证，如果认证成功，就成功登录系统。 这种认证方式避免了被暴力破解的危险，同时只要保存在本地的专用密钥不被黑客盗用，攻击者一般无法通过密钥认证的方式进入系统。 因此，在 Linux 下推荐用密钥认证方式登录系统，这样就可以抛弃密码认证登录系统的弊端。 Linux 服务器一般通过 SecureCRT、Putty、Xshell 之类的工具进行远程维护和管理，密钥认证方式的实现就是借助于 SecureCRT 软件和 Linux 系统中的 SSH 服务实现的。 ④合理使用 su、sudo 命令su 命令：是一个切换用户的工具，经常用于将普通用户切换到超级用户下，当然也可以从超级用户切换到普通用户。 为了保证服务器的安全，几乎所有服务器都禁止了超级用户直接登录系统，而是通过普通用户登录系统，然后再通过 su 命令切换到超级用户下，执行一些需要超级权限的工作。 通过 su 命令能够给系统管理带来一定的方便，但是也存在不安全的因素，例如：系统有 10 个普通用户，每个用户都需要执行一些有超级权限的操作，就必须把超级用户的密码交给这 10 个普通用户。 如果这 10 个用户都有超级权限，通过超级权限可以做任何事，那么会在一定程度上对系统的安全造成了威协。 因此 su 命令在很多人都需要参与的系统管理中，并不是最好的选择，超级用户密码应该掌握在少数人手中，此时 sudo 命令就派上用场了。 sudo 命令：允许系统管理员分配给普通用户一些合理的“权利”，并且不需要普通用户知道超级用户密码，就能让他们执行一些只有超级用户或其他特许用户才能完成的任务。 比如：系统服务重启、编辑系统配置文件等，通过这种方式不但能减少超级用户登录次数和管理时间，也提高了系统安全性。 因此，sudo 命令相对于权限无限制性的 su 来说，还是比较安全的，所以 sudo 也被称为受限制的 su，另外 sudo 也是需要事先进行授权认证的，所以也被称为授权认证的 su。 sudo 执行命令的流程是：将当前用户切换到超级用户下，或切换到指定的用户下，然后以超级用户或其指定切换到的用户身份执行命令。 执行完成后，直接退回到当前用户，而这一切的完成要通过 sudo 的配置文件 /etc/sudoers 来进行授权。 sudo 设计的宗旨是：赋予用户尽可能少的权限但仍允许它们完成自己的工作，这种设计兼顾了安全性和易用性。 因此，强烈推荐通过 sudo 来管理系统账号的安全，只允许普通用户登录系统，如果这些用户需要特殊的权限，就通过配置 /etc/sudoers 来完成，这也是多用户系统下账号安全管理的基本方式。 ⑤删减系统登录欢迎信息系统的一些欢迎信息或版本信息，虽然能给系统管理者带来一定的方便，但是这些信息有时候可能被黑客利用，成为攻击服务器的帮凶。 为了保证系统的安全，可以修改或删除某些系统文件，需要修改或删除的文件有四个，分别是： /etc/issue /etc/issue.net /etc/redhat-release /etc/motd /etc/issue 和 /etc/issue.net 文件都记录了操作系统的名称和版本号，当用户通过本地终端或本地虚拟控制台等登录系统时，/etc/issue 的文件内容就会显示。 当用户通过 ssh 或 telnet 等远程登录系统时，/etc/issue.net 文件内容就会在登录后显示。 在默认情况下 /etc/issue.net 文件的内容是不会在 ssh 登录后显示的，要显示这个信息可以修改 /etc/ssh/sshd_config 文件，在此文件中添加如下内容即可：Banner /etc/issue.net。 其实这些登录提示很明显泄漏了系统信息，为了安全起见，建议将此文件中的内容删除或修改。 /etc/redhat-release 文件也记录了操作系统的名称和版本号，为了安全起见，可以将此文件中的内容删除。 /etc/motd 文件是系统的公告信息。每次用户登录后，/etc/motd 文件的内容就会显示在用户的终端。 通过这个文件系统，管理员可以发布一些软件或硬件的升级、系统维护等通告信息，但是此文件的最大作用就是可以发布一些警告信息，当黑客登录系统后，会发现这些警告信息，进而产生一些震慑作用。 看过国外的一个报道，黑客入侵了一个服务器，而这个服务器却给出了欢迎登录的信息，因此法院不做任何裁决。 远程访问和认证安全①远程登录取消 telnet 而采用 SSH 方式telnet 是一种古老的远程登录认证服务，它在网络上用明文传送口令和数据，因此别有用心的人就会非常容易截获这些口令和数据。 而且，telnet 服务程序的安全验证方式也极其脆弱，攻击者可以轻松将虚假信息传送给服务器。 现在远程登录基本抛弃了 telnet 这种方式，而取而代之的是通过 SSH 服务远程登录服务器。 ②合理使用 Shell 历史命令记录功能在 Linux 下可通过 history 命令查看用户所有的历史操作记录，同时 shell 命令操作记录默认保存在用户目录下的 .bash_history 文件中。 通过这个文件可以查询 shell 命令的执行历史，有助于运维人员进行系统审计和问题排查。 同时，在服务器遭受黑客攻击后，也可以通过这个命令或文件查询黑客登录服务器所执行的历史命令操作。 但是有时候黑客在入侵服务器后为了毁灭痕迹，可能会删除 .bash_history 文件，这就需要合理的保护或备份 .bash_history 文件。 ③启用 Tcp_Wrappers 防火墙Tcp_Wrappers 是一个用来分析 TCP/IP 封包的软件，类似的 IP 封包软件还有 iptables。 Linux 默认都安装了 Tcp_Wrappers。作为一个安全的系统，Linux 本身有两层安全防火墙，通过 IP 过滤机制的 iptables 实现第一层防护。 iptables 防火墙通过直观地监视系统的运行状况，阻挡网络中的一些恶意攻击，保护整个系统正常运行，免遭攻击和破坏。 如果通过了第一层防护，那么下一层防护就是 Tcp_Wrappers 了。通过 Tcp_Wrappers 可以实现对系统中提供的某些服务的开放与关闭、允许和禁止，从而更有效地保证系统安全运行。 文件系统安全①锁定系统重要文件系统运维人员有时候可能会遇到通过 Root 用户都不能修改或者删除某个文件的情况，产生这种情况的大部分原因可能是这个文件被锁定了。 在 Linux 下锁定文件的命令是 Chattr，通过这个命令可以修改 ext2、ext3、ext4 文件系统下文件属性，但是这个命令必须有超级用户 Root 来执行。和这个命令对应的命令是 lsattr，这个命令用来查询文件属性。 对重要的文件进行加锁，虽然能够提高服务器的安全性，但是也会带来一些不便。 例如：在软件的安装、升级时可能需要去掉有关目录和文件的 immutable 属性和 append-only 属性，同时，对日志文件设置了 append-only 属性，可能会使日志轮换（logrotate）无法进行。 因此，在使用 Chattr 命令前，需要结合服务器的应用环境来权衡是否需要设置 immutable 属性和 append-only 属性。 另外，虽然通过 Chattr 命令修改文件属性能够提高文件系统的安全性，但是它并不适合所有的目录。Chattr 命令不能保护 /、/dev、/tmp、/var 等目录。 根目录不能有不可修改属性，因为如果根目录具有不可修改属性，那么系统根本无法工作： /dev 在启动时，syslog 需要删除并重新建立 /dev/log 套接字设备，如果设置了不可修改属性，那么可能出问题。 /tmp 目录会有很多应用程序和系统程序需要在这个目录下建立临时文件，也不能设置不可修改属性。 /var 是系统和程序的日志目录，如果设置为不可修改属性，那么系统写日志将无法进行，所以也不能通过 Chattr 命令保护。 ②文件权限检查和修改不正确的权限设置直接威胁着系统的安全，因此运维人员应该能及时发现这些不正确的权限设置，并立刻修正，防患于未然。下面列举几种查找系统不安全权限的方法。 查找系统中任何用户都有写权限的文件或目录： 12查找文件：find &#x2F; -type f -perm -2 -o -perm -20 |xargs ls -al查找目录：find &#x2F; -type d -perm -2 -o -perm -20 |xargs ls –ld 查找系统中所有含“s”位的程序： 1find &#x2F; -type f -perm -4000 -o -perm -2000 -print | xargs ls –al 含有“s”位权限的程序对系统安全威胁很大，通过查找系统中所有具有“s”位权限的程序，可以把某些不必要的“s”位程序去掉，这样可以防止用户滥用权限或提升权限的可能性。 检查系统中所有 suid 及 sgid 文件： 12find &#x2F; -user root -perm -2000 -print -exec md5sum &#123;&#125; ;find &#x2F; -user root -perm -4000 -print -exec md5sum &#123;&#125; ; 将检查的结果保存到文件中，可在以后的系统检查中作为参考。 检查系统中没有属主的文件： 1find &#x2F; -nouser -o –nogroup 没有属主的孤儿文件比较危险，往往成为黑客利用的工具，因此找到这些文件后，要么删除掉，要么修改文件的属主，使其处于安全状态。 ③/tmp、/var/tmp、/dev/shm 安全设定在 Linux 系统中，主要有两个目录或分区用来存放临时文件，分别是 /tmp 和 /var/tmp。 存储临时文件的目录或分区有个共同点就是所有用户可读写、可执行，这就为系统留下了安全隐患。 攻击者可以将病毒或者木马脚本放到临时文件的目录下进行信息收集或伪装，严重影响服务器的安全。 此时，如果修改临时目录的读写执行权限，还有可能影响系统上应用程序的正常运行，因此，如果要兼顾两者，就需要对这两个目录或分区进行特殊的设置。 /dev/shm 是 Linux 下的一个共享内存设备，在 Linux 启动的时候系统默认会加载 /dev/shm，被加载的 /dev/shm 使用的是 tmpfs 文件系统，而 tmpfs 是一个内存文件系统，存储到 tmpfs 文件系统的数据会完全驻留在 RAM 中。 这样通过 /dev/shm 就可以直接操控系统内存，这将非常危险，因此如何保证 /dev/shm 安全也至关重要。 对于 /tmp 的安全设置，需要看 /tmp 是一个独立磁盘分区，还是一个根分区下的文件夹。 如果 /tmp 是一个独立的磁盘分区，那么设置非常简单，修改 /etc/fstab 文件中 /tmp 分区对应的挂载属性，加上 nosuid、noexec、nodev 三个选项即可。 修改后的 /tmp 分区挂载属性类似如下： 1LABEL&#x3D;&#x2F;tmp &#x2F;tmp ext3 rw,nosuid,noexec,nodev 0 0 其中，nosuid、noexec、nodev 选项，表示不允许任何 suid 程序，并且在这个分区不能执行任何脚本等程序，并且不存在设备文件。 在挂载属性设置完成后，重新挂载 /tmp 分区，保证设置生效。 对于 /var/tmp，如果是独立分区，安装 /tmp 的设置方法是修改 /etc/fstab 文件即可。 如果是 /var 分区下的一个目录，那么可以将 /var/tmp 目录下所有数据移动到 /tmp 分区下，然后在 /var 下做一个指向 /tmp 的软连接即可。 也就是执行如下操作： 12[root@server ~]# mv &#x2F;var&#x2F;tmp&#x2F;* &#x2F;tmp[root@server ~]# ln -s &#x2F;tmp &#x2F;var&#x2F;tmp 如果 /tmp 是根目录下的一个目录，那么设置稍微复杂，可以通过创建一个 loopback 文件系统来利用 Linux 内核的 loopback 特性将文件系统挂载到 /tmp 下，然后在挂载时指定限制加载选项即可。 一个简单的操作示例如下： 1234567[root@server ~]# dd if&#x3D;&#x2F;dev&#x2F;zero of&#x3D;&#x2F;dev&#x2F;tmpfs bs&#x3D;1M count&#x3D;10000[root@server ~]# mke2fs -j &#x2F;dev&#x2F;tmpfs[root@server ~]# cp -av &#x2F;tmp &#x2F;tmp.old[root@server ~]# mount -o loop,noexec,nosuid,rw &#x2F;dev&#x2F;tmpfs &#x2F;tmp[root@server ~]# chmod 1777 &#x2F;tmp[root@server ~]# mv -f &#x2F;tmp.old&#x2F;* &#x2F;tmp&#x2F;[root@server ~]# rm -rf &#x2F;tmp.old 最后，编辑 /etc/fstab，添加如下内容，以便系统在启动时自动加载 loopback 文件系统： 1&#x2F;dev&#x2F;tmpfs &#x2F;tmp ext3 loop,nosuid,noexec,rw 0 0 Linux 后门入侵检测工具Rootkit 是 Linux 平台下最常见的一种木马后门工具，它主要通过替换系统文件来达到入侵和和隐蔽的目的，这种木马比普通木马后门更加危险和隐蔽，普通的检测工具和检查手段很难发现这种木马。 Rootkit 攻击能力极强，对系统的危害很大，它通过一套工具来建立后门和隐藏行迹，从而让攻击者保住权限，以使它在任何时候都可以使用 Root 权限登录到系统。 Rootkit 主要有两种类型：文件级别和内核级别，下面分别进行简单介绍。 文件级别的 Rootkit 一般是通过程序漏洞或者系统漏洞进入系统后，通过修改系统的重要文件来达到隐藏自己的目的。 在系统遭受 Rootkit 攻击后，合法的文件被木马程序替代，变成了外壳程序，而其内部是隐藏着的后门程序。 通常容易被 Rootkit 替换的系统程序有 login、ls、ps、ifconfig、du、find、netstat 等，其中 login 程序是最经常被替换的。 因为当访问 Linux 时，无论是通过本地登录还是远程登录，/bin/login 程序都会运行，系统将通过 /bin/login 来收集并核对用户的账号和密码。 而 Rootkit 就是利用这个程序的特点，使用一个带有根权限后门密码的 /bin/login 来替换系统的 /bin/login，这样攻击者通过输入设定好的密码就能轻松进入系统。 此时，即使系统管理员修改 Root 密码或者清除 Root 密码，攻击者还是一样能通过 Root 用户登录系统。 攻击者通常在进入 Linux 系统后，会进行一系列的攻击动作，最常见的是安装嗅探器收集本机或者网络中其他服务器的重要数据。 在默认情况下，Linux 中也有一些系统文件会监控这些工具动作，例如 ifconfig 命令。 所以，攻击者为了避免被发现，会想方设法替换其他系统文件，常见的就是 ls、ps、ifconfig、du、find、netstat 等。 如果这些文件都被替换，那么在系统层面就很难发现 Rootkit 已经在系统中运行了。 这就是文件级别的 Rootkit，对系统维护很大，目前最有效的防御方法是定期对系统重要文件的完整性进行检查。 如果发现文件被修改或者被替换，那么很可能系统已经遭受了 Rootkit 入侵。 检查文件完整性的工具很多，常见的有 Tripwire、 aide 等，可以通过这些工具定期检查文件系统的完整性，以检测系统是否被 Rootkit 入侵。 内核级 Rootkit 是比文件级 Rootkit 更高级的一种入侵方式，它可以使攻击者获得对系统底层的完全控制权。 此时攻击者可以修改系统内核，进而截获运行程序向内核提交的命令，并将其重定向到入侵者所选择的程序并运行此程序。 也就是说，当用户要运行程序 A 时，被入侵者修改过的内核会假装执行 A 程序，而实际上却执行了程序 B。 内核级 Rootkit 主要依附在内核上，它并不对系统文件做任何修改，因此一般的检测工具很难检测到它的存在，这样一旦系统内核被植入 Rootkit，攻击者就可以对系统为所欲为而不被发现。 目前对于内核级的 Rootkit 还没有很好的防御工具，因此，做好系统安全防范就非常重要，将系统维持在最小权限内工作，只要攻击者不能获取 Root 权限，就无法在内核中植入 Rootkit。 ①Rootkit 后门检测工具 ChkrootkitChkrootkit 是一个 Linux 系统下查找并检测 Rootkit 后门的工具，它的官方地址： 1http:&#x2F;&#x2F;www.chkrootkit.org&#x2F; Chkrootkit 没有包含在官方的 CentOS 源中，因此要采取手动编译的方法来安装，不过这种安装方法也更加安全。 Chkrootkit 的使用比较简单，直接执行 Chkrootkit 命令即可自动开始检测系统。 下面是某个系统的检测结果： 123456789[root@server chkrootkit]# &#x2F;usr&#x2F;local&#x2F;chkrootkit&#x2F;chkrootkitChecking &#96;ifconfig&#39;... INFECTEDChecking &#96;ls&#39;... INFECTEDChecking &#96;login&#39;... INFECTEDChecking &#96;netstat&#39;... INFECTEDChecking &#96;ps&#39;... INFECTEDChecking &#96;top&#39;... INFECTEDChecking &#96;sshd&#39;... not infectedChecking &#96;syslogd&#39;... not tested 从输出可以看出，此系统的 ifconfig、ls、login、netstat、ps 和 top 命令已经被感染。 针对被感染 Rootkit 的系统，最安全而有效的方法就是备份数据重新安装系统。 Chkrootkit 在检查 Rootkit 的过程中使用了部分系统命令，因此，如果服务器被黑客入侵，那么依赖的系统命令可能也已经被入侵者替换，此时 Chkrootkit 的检测结果将变得完全不可信。 为了避免 Chkrootkit 的这个问题，可以在服务器对外开放前，事先将 Chkrootkit 使用的系统命令进行备份，在需要的时候使用备份的原始系统命令让 Chkrootkit 对 Rootkit 进行检测。 ②Rootkit 后门检测工具 RKHunterRKHunter 是一款专业的检测系统是否感染 Rootkit 的工具，它通过执行一系列的脚本来确认服务器是否已经感染 Rootkit。 在官方的资料中，RKHunter 可以做的事情有： 12345678MD5校验测试，检测文件是否有改动，比较系统命令的md5，从而判断系统命令是否被篡改检测rootkit使用的二进制和系统工具文件检测特洛伊木马程序的特征码检测常用程序的文件属性是否异常检测系统相关的测试检测隐藏文件检测可疑的核心模块LKM检测系统已启动的监听端口 在 Linux 终端使用 RKHunter 来检测，最大的好处在于每项的检测结果都有不同的颜色显示，如果是绿色的表示没有问题，如果是红色的，那就要引起关注了。 另外，在执行检测的过程中，在每个部分检测完成后，需要以 Enter 键来继续。 如果要让程序自动运行，可以执行如下命令： 1[root@server ~]# &#x2F;usr&#x2F;local&#x2F;bin&#x2F;rkhunter --check --skip-keypress 同时，如果想让检测程序每天定时运行，那么可以在 /etc/crontab 中加入如下内容： 130 09 * * * root &#x2F;usr&#x2F;local&#x2F;bin&#x2F;rkhunter --check --cronjob 这样，RKHunter 检测程序就会在每天的 9:30 分运行一次。 服务器遭受攻击后的处理过程安全总是相对的，再安全的服务器也有可能遭受到攻击。 作为一个安全运维人员，要把握的原则是：尽量做好系统安全防护，修复所有已知的危险行为，同时，在系统遭受攻击后能够迅速有效地处理攻击行为，最大限度地降低攻击对系统产生的影响。 ①处理服务器遭受攻击的一般思路系统遭受攻击并不可怕，可怕的是面对攻击束手无策，下面就详细介绍下在服务器遭受攻击后的一般处理思路。 切断网络：所有的攻击都来自于网络，因此，在得知系统正遭受黑客的攻击后，首先要做的就是断开服务器的网络连接，这样除了能切断攻击源之外，也能保护服务器所在网络的其他主机。 查找攻击源：可以通过分析系统日志或登录日志文件，查看可疑信息，同时也要查看系统都打开了哪些端口，运行哪些进程，并通过这些进程分析哪些是可疑的程序。 这个过程要根据经验和综合判断能力进行追查和分析。下面会详细介绍这个过程的处理思路。 分析入侵原因和途径：既然系统遭到入侵，那么原因是多方面的，可能是系统漏洞，也可能是程序漏洞。 一定要查清楚是哪个原因导致的，并且还要查清楚遭到攻击的途径，找到攻击源，因为只有知道了遭受攻击的原因和途径，才能删除攻击源同时进行漏洞的修复。 备份用户数据：在服务器遭受攻击后，需要立刻备份服务器上的用户数据，同时也要查看这些数据中是否隐藏着攻击源。 如果攻击源在用户数据中，一定要彻底删除，然后将用户数据备份到一个安全的地方。 重新安装系统：永远不要认为自己能彻底清除攻击源，因为没有人能比黑客更了解攻击程序。 在服务器遭到攻击后，最安全也最简单的方法就是重新安装系统，因为大部分攻击程序都会依附在系统文件或者内核中，所以重新安装系统才能彻底清除攻击源。 修复程序或系统漏洞：在发现系统漏洞或者应用程序漏洞后，首先要做的就是修复系统漏洞或者更改程序 Bug，因为只有将程序的漏洞修复完毕才能正式在服务器上运行。 恢复数据和连接网络：将备份的数据重新复制到新安装的服务器上，然后开启服务，最后将服务器开启网络连接，对外提供服务。 ②检查并锁定可疑用户当发现服务器遭受攻击后，首先要切断网络连接，但是在有些情况下，比如无法马上切断网络连接时，就必须登录系统查看是否有可疑用户。 如果有可疑用户登录了系统，那么需要马上将这个用户锁定，然后中断此用户的远程连接。 ③查看系统日志查看系统日志是查找攻击源最好的方法，可查的系统日志有 /var/log/messages、/var/log/secure 等。 这两个日志文件可以记录软件的运行状态以及远程用户的登录状态，还可以查看每个用户目录下的 .bash_history 文件。 特别是 /root 目录下的 .bash_history 文件，这个文件中记录着用户执行的所有历史命令。 ④检查并关闭系统可疑进程检查可疑进程的命令很多，例如 ps、top 等，但是有时候只知道进程的名称无法得知路径，此时可以通过如下命令查看。 首先通过 pidof 命令可以查找正在运行的进程 PID，例如要查找 sshd 进程的 PID。 执行如下命令： 12[root@server ~]# pidof sshd13276 12942 4284 然后进入内存目录，查看对应 PID 目录下 exe 文件的信息： 12[root@server ~]# ls -al &#x2F;proc&#x2F;13276&#x2F;exe lrwxrwxrwx 1 root root 0 Oct 4 22:09 &#x2F;proc&#x2F;13276&#x2F;exe -&gt; &#x2F;usr&#x2F;sbin&#x2F;sshd 这样就找到了进程对应的完整执行路径。如果还要查看文件的句柄，可以查看如下目录： 1[root@server ~]# ls -al &#x2F;proc&#x2F;13276&#x2F;fd 通过这种方式基本可以找到任何进程的完整执行信息。 ⑤检查文件系统的完好性检查文件属性是否发生变化是验证文件系统完好性最简单、最直接的方法，例如可以检查被入侵服务器上 /bin/ls 文件的大小是否与正常系统上此文件的大小相同，以验证文件是否被替换，但是这种方法比较低级。 此时可以借助于 Linux 下 rpm 这个工具来完成验证，操作如下： 12345678[root@server ~]# rpm -Va....L... c &#x2F;etc&#x2F;pam.d&#x2F;system-authS.5..... c &#x2F;etc&#x2F;security&#x2F;limits.confS.5....T c &#x2F;etc&#x2F;sysctl.confS.5....T &#x2F;etc&#x2F;sgml&#x2F;docbook-simple.catS.5....T c &#x2F;etc&#x2F;login.defsS.5..... c &#x2F;etc&#x2F;openldap&#x2F;ldap.confS.5....T c &#x2F;etc&#x2F;sudoers ⑥重新安装系统恢复数据很多情况下，被攻击过的系统已经不再可信任，因此，最好的方法是将服务器上面数据进行备份，然后重新安装系统，最后再恢复数据即可。 数据恢复完成，马上对系统做上面介绍的安全加固策略，保证系统安全。 原文链接如下： https://www.cnblogs.com/MYSQLZOUQI/p/5317916.html","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/tags/Linux/"}]},{"title":"tmux-初探","slug":"Linux/让你的Linux酷起来--小白也能玩转Tmux","date":"2019-09-04T17:55:39.000Z","updated":"2020-05-25T13:52:55.068Z","comments":true,"path":"2019/09/05/Linux/让你的Linux酷起来--小白也能玩转Tmux/","link":"","permalink":"https://github.com/cyylog/2019/09/05/Linux/%E8%AE%A9%E4%BD%A0%E7%9A%84Linux%E9%85%B7%E8%B5%B7%E6%9D%A5--%E5%B0%8F%E7%99%BD%E4%B9%9F%E8%83%BD%E7%8E%A9%E8%BD%ACTmux/","excerpt":"","text":"Linux终端复用神器-tmux初探1Tmux是一个优秀的终端复用软件，类似GNU Screen，但来自于OpenBSD，采用BSD授权。使用它最直观的好处就是，通过一个终端登录远程主机并运行tmux后，在其中可以开启多个控制台而无需再“浪费”多余的终端来连接这台远程主机。是BSD实现的Screen替代品，相对于Screen，它更加先进：支持屏幕切分，而且具备丰富的命令行参数，使其可以灵活、动态的进行各种布局和操作。 废话不多说来个效果图 Tmux的使用场景12341）可以某个程序在执行时一直是输出状态，需要结合nohup、&amp;来放在后台执行，并且ctrl+c结束。这时可以打开一个Tmux窗口，在该窗口里执行这个程序，用来保证该程序一直在执行中，只要Tmux这个窗口不关闭2）公司需要备份数据库时，数据量巨大，备份两三天弄不完，这时不小心关闭了终端窗口或误操作就前功尽弃了，使用Tmux会话运行命令或任务，就不用担心这些问题。3）下班后，你需要断开ssh或关闭电脑，将运行的命令或任务放置后台运行。4）关闭终端,再次打开时原终端里面的任务进程依然不会中断 Tmux功能：12345678- 提供了强劲的、易于使用的命令行界面。- 可横向和纵向分割窗口。- 窗格可以自由移动和调整大小，或直接利用四个预设布局之一。- 支持 UTF-8 编码及 256 色终端。- 可在多个缓冲区进行复制和粘贴。- 可通过交互式菜单来选择窗口、会话及客户端。- 支持跨窗口搜索。- 支持自动及手动锁定窗口。 Tmux安装1yum -y install tmux Tmux个性化配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859此类配置可以在命令行模式中输入show-options -g查询tmux加上下列参数,实现个性化设置set-option -g base-index 1 # 窗口的初始序号；默认为0，这里设置为1set-option -g display-time 5000 # 提示信息的持续时间；设置足够的时间以避免看不清提示，单位为毫秒set-option -g repeat-time 1000 # 控制台激活后的持续时间；设置合适的时间以避免每次操作都要先激活控制台，单位为毫秒set-option -g status-keys vi # 操作状态栏时的默认键盘布局；可以设置为vi或emacsset-option -g status-utf8 on # 开启状态栏的UTF-8支持---set-option -g status-bg blueset-option -g status-fg &#39;#bbbbbb&#39;set-option -g status-left-fg greenset-option -g status-left-bg blueset-option -g status-right-fg greenset-option -g status-right-bg blueset-option -g status-left-length 10 # 状态栏左方的内容长度；set-option -g status-right-length 15 # 状态栏右方的内容长度；建议把更多的空间留给状态栏左方（用于列出当前窗口）set-option -g status-left &#39;[#(whoami)]&#39; # 状态栏左方的内容set-option -g status-right &#39;[#(date +&quot; %m-%d %H:%M &quot;)]&#39; # 状态栏右方的内容；这里的设置将得到类似23:59的显示set-option -g status-justify &quot;centre&quot; # 窗口列表居中显示set-option -g default-terminal &quot;screen-256color&quot; # 支持256色显示分割窗口边界的颜色set-option -g pane-active-border-fg &#39;#55ff55&#39;set-option -g pane-border-fg &#39;#555555&#39;---此类设置可以在命令行模式中输入show-window-options -g查询set-window-option -g mode-keys vi # 复制模式中的默认键盘布局；可以设置为vi或emacsset-window-option -g utf8 on # 开启窗口的UTF-8支持set-window-option -g mode-mouse on # 窗口切换后让人可以用鼠标上下滑动显示历史输出---窗口切分快捷键(没设置成功)bind \\ split-window -h # 使用 \\ 将窗口竖切bind - split-window -v # 使用 - 将窗口横切bind K confirm-before -p &quot;kill-window #W? (y&#x2F;n)&quot; kill-window # 使用大写 K 来关闭窗口bind &#39;&quot;&#39; choose-window # 双引号选择窗口---Pane之间切换的快捷键bind h select-pane -L # 定位到左边窗口的快捷键bind j select-pane -D # 定位到上边窗口的快捷键bind k select-pane -U # 定位到下方窗口的快捷键bind l select-pane -R # 定位到右边窗口的快捷键---设置window属性setw -g window-status-current-bg redsetw -g window-status-current-fg whitesetw -g window-status-current-attr brightsetw -g window-status-attr brightset-option -g window-status-format &#39;#I #W&#39;set-option -g window-status-current-format &#39; #I #W &#39;setw -g window-status-current-bg bluesetw -g window-status-current-fg green不使用prefix键，使用Ctrl和左右方向键方便切换窗口bind-key -n &quot;C-Left&quot; select-window -t :-bind-key -n &quot;C-Right&quot; select-window -t :+ tmux session 使用介绍1234567891011121314151617181920212223242526272829303132333435363738运行tmux并开启一个新的会话tmux显示所有会话tmux ls新建会话并指定会话名称（建议制定会话名称，以便了解该会话用途）tmux new -s &lt;session-name&gt;新建会话（不指定会话名称）tmux new接入上一个会话tmux a接入指定名称的会话tmux a -t &lt;session-name&gt;断开当前会话（还可以使用快捷键：control+b，再按d）tmux detach关闭指定会话tmux kill-session -t session-name关闭除指定会话外的所有会话tmux kill-session -a -t session-name在会话中切换control+b，再按s 显示会话列表，再进行会话切换销毁所有会话并停止tmuxtmux kill-serverG复制粘贴Ctrl+b [ &#x2F;&#x2F;进入复制模式空格+方向键 &#x2F;&#x2F;选择回车 &#x2F;&#x2F; 确认Ctrl+b [ &#x2F;&#x2F;粘贴 需要注意的几点123456789101112131415161718192021221）进入tmux面板后，一定要先按ctrl+b，然后松开，再按其他的组合键才生效。 2）常用到的几个组合键：ctrl+b ? 显示快捷键帮助ctrl+b 空格键 采用下一个内置布局，这个很有意思，在多屏时，用这个就会将多有屏幕竖着展示ctrl+b ! 把当前窗口变为新窗口ctrl+b &quot; 模向分隔窗口ctrl+b % 纵向分隔窗口ctrl+b q 显示分隔窗口的编号ctrl+b o 跳到下一个分隔窗口。多屏之间的切换ctrl+b 上下键 上一个及下一个分隔窗口ctrl+b C-方向键 调整分隔窗口大小ctrl+b &amp; 确认后退出当前tmuxctrl+b [ 复制模式，即将当前屏幕移到上一个的位置上，其他所有窗口都向前移动一个。ctrl+b c 创建新窗口ctrl+b n 选择下一个窗口ctrl+b l 最后使用的窗口ctrl+b p 选择前一个窗口ctrl+b w 以菜单方式显示及选择窗口ctrl+b s 以菜单方式显示和选择会话。这个常用到，可以选择进入哪个tmuxctrl+b t 显示时钟。然后按enter键后就会恢复到shell终端状态ctrl+b d 脱离当前会话；这样可以暂时返回Shell界面，输入tmux attach能够重新进入之前的会话 tmux的常规运维命令12345678910111）安装命令： [root@---title: tmux-初探date: 2018-12-07 13:59:25tags: - tmux - 骚操作---### Linux终端复用神器-tmux初探​ Tmux是一个优秀的终端复用软件，类似GNU Screen，但来自于OpenBSD，采用BSD授权。使用它最直观的好处就是，通过一个终端登录远程主机并运行tmux后，在其中可以开启多个控制台而无需再“浪费”多余的终端来连接这台远程主机。是BSD实现的Screen替代品，相对于Screen，它更加先进：支持屏幕切分，而且具备丰富的命令行参数，使其可以灵活、动态的进行各种布局和操作。​```废话不多说来个效果图 Tmux的使用场景​1）可以某个程序在执行时一直是输出状态，需要结合nohup、&amp;来放在后台执行，并且ctrl+c结束。这时可以打开一个Tmux窗口，在该窗口里执行这个程序，用来保证该程序一直在执行中，只要Tmux这个窗口不关闭 2）公司需要备份数据库时，数据量巨大，备份两三天弄不完，这时不小心关闭了终端窗口或误操作就前功尽弃了，使用Tmux会话运行命令或任务，就不用担心这些问题。 3）下班后，你需要断开ssh或关闭电脑，将运行的命令或任务放置后台运行。 4）关闭终端,再次打开时原终端里面的任务进程依然不会中断 ​ Tmux功能：​``` 提供了强劲的、易于使用的命令行界面。 可横向和纵向分割窗口。 窗格可以自由移动和调整大小，或直接利用四个预设布局之一。 支持 UTF-8 编码及 256 色终端。 可在多个缓冲区进行复制和粘贴。 可通过交互式菜单来选择窗口、会话及客户端。 支持跨窗口搜索。 支持自动及手动锁定窗口。​```Tmux安装​yum -y install tmux ​ Tmux个性化配置​```此类配置可以在命令行模式中输入show-options -g查询 tmux加上下列参数,实现个性化设置set-option -g base-index 1 # 窗口的初始序号；默认为0，这里设置为1set-option -g display-time 5000 # 提示信息的持续时间；设置足够的时间以避免看不清提示，单位为毫秒set-option -g repeat-time 1000 # 控制台激活后的持续时间；设置合适的时间以避免每次操作都要先激活控制台，单位为毫秒set-option -g status-keys vi # 操作状态栏时的默认键盘布局；可以设置为vi或emacsset-option -g status-utf8 on # 开启状态栏的UTF-8支持 set-option -g status-bg blueset-option -g status-fg ‘#bbbbbb’set-option -g status-left-fg greenset-option -g status-left-bg blueset-option -g status-right-fg greenset-option -g status-right-bg blueset-option -g status-left-length 10 # 状态栏左方的内容长度；set-option -g status-right-length 15 # 状态栏右方的内容长度；建议把更多的空间留给状态栏左方（用于列出当前窗口）set-option -g status-left ‘[#(whoami)]’ # 状态栏左方的内容set-option -g status-right ‘[#(date +” %m-%d %H:%M “)]’ # 状态栏右方的内容；这里的设置将得到类似23:59的显示set-option -g status-justify “centre” # 窗口列表居中显示set-option -g default-terminal “screen-256color” # 支持256色显示分割窗口边界的颜色set-option -g pane-active-border-fg ‘#55ff55’set-option -g pane-border-fg ‘#555555’ 此类设置可以在命令行模式中输入show-window-options -g查询set-window-option -g mode-keys vi # 复制模式中的默认键盘布局；可以设置为vi或emacsset-window-option -g utf8 on # 开启窗口的UTF-8支持set-window-option -g mode-mouse on # 窗口切换后让人可以用鼠标上下滑动显示历史输出 窗口切分快捷键(没设置成功)bind \\ split-window -h # 使用 \\ 将窗口竖切bind - split-window -v # 使用 - 将窗口横切bind K confirm-before -p “kill-window #W? (y/n)” kill-window # 使用大写 K 来关闭窗口bind ‘“‘ choose-window # 双引号选择窗口 Pane之间切换的快捷键bind h select-pane -L # 定位到左边窗口的快捷键bind j select-pane -D # 定位到上边窗口的快捷键bind k select-pane -U # 定位到下方窗口的快捷键bind l select-pane -R # 定位到右边窗口的快捷键 设置window属性setw -g window-status-current-bg redsetw -g window-status-current-fg whitesetw -g window-status-current-attr brightsetw -g window-status-attr brightset-option -g window-status-format ‘#I #W’set-option -g window-status-current-format ‘ #I #W ‘setw -g window-status-current-bg bluesetw -g window-status-current-fg green不使用prefix键，使用Ctrl和左右方向键方便切换窗口bind-key -n “C-Left” select-window -t :-bind-key -n “C-Right” select-window -t :+​``` tmux session 使用介绍​```运行tmux并开启一个新的会话tmux 显示所有会话tmux ls 新建会话并指定会话名称（建议制定会话名称，以便了解该会话用途）tmux new -s 新建会话（不指定会话名称）tmux new 接入上一个会话tmux a 接入指定名称的会话tmux a -t 断开当前会话（还可以使用快捷键：control+b，再按d）tmux detach 关闭指定会话tmux kill-session -t session-name 关闭除指定会话外的所有会话tmux kill-session -a -t session-name 在会话中切换control+b，再按s 显示会话列表，再进行会话切换 销毁所有会话并停止tmuxtmux kill-serverG 复制粘贴Ctrl+b [ //进入复制模式空格+方向键 //选择回车 // 确认Ctrl+b [ //粘贴 ​``` 需要注意的几点​```1）进入tmux面板后，一定要先按ctrl+b，然后松开，再按其他的组合键才生效。 2）常用到的几个组合键：ctrl+b ? 显示快捷键帮助ctrl+b 空格键 采用下一个内置布局，这个很有意思，在多屏时，用这个就会将多有屏幕竖着展示ctrl+b ! 把当前窗口变为新窗口ctrl+b “ 模向分隔窗口ctrl+b % 纵向分隔窗口ctrl+b q 显示分隔窗口的编号ctrl+b o 跳到下一个分隔窗口。多屏之间的切换ctrl+b 上下键 上一个及下一个分隔窗口ctrl+b C-方向键 调整分隔窗口大小ctrl+b &amp; 确认后退出当前tmuxctrl+b [ 复制模式，即将当前屏幕移到上一个的位置上，其他所有窗口都向前移动一个。ctrl+b c 创建新窗口ctrl+b n 选择下一个窗口ctrl+b l 最后使用的窗口ctrl+b p 选择前一个窗口ctrl+b w 以菜单方式显示及选择窗口ctrl+b s 以菜单方式显示和选择会话。这个常用到，可以选择进入哪个tmuxctrl+b t 显示时钟。然后按enter键后就会恢复到shell终端状态ctrl+b d 脱离当前会话；这样可以暂时返回Shell界面，输入tmux attach能够重新进入之前的会话​``` tmux的常规运维命令​```1）安装命令： [root@Centos6 ~]# yum -y install tmux 2）默认创建一个会话，以数字命名。（不推荐）[root@Centos6 ~]# tmux 3）新建会话，比如新创建一个会话以”ccc”命名[root@Centos6 ~]# tmux new -s ccc 加上参数-d，表示在后台新建会话root@bobo:# tmux new -s shibo -droot@bobo:# tmux lsshibo: 1 windows (created Tue Oct 2 19:22:32 2018) [135x35] 4）查看创建得所有会话[root@Centos6 ~]# tmux ls0: 1 windows (created Wed Aug 30 17:58:20 2017) 112x22 #这里的attached表示该会话是当前会话aaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22]ccc: 1 windows (created Wed Aug 30 17:01:05 2017) [112x22] 5）登录一个已知会话。即从终端环境进入会话。第一个参数a也可以写成attach。后面的aaa是会话名称。[root@Centos6 ~]# tmux a -t aaa 6）退出会话不是关闭：登到某一个会话后，依次按键ctrl-b + d，这样就会退化该会话，但不会关闭会话。如果直接ctrl + d，就会在退出会话的通话也关闭了该会话！ 7）关闭会话（销毁会话）[root@Centos6 ~]# tmux lsaaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22]bbb: 1 windows (created Wed Aug 30 19:02:09 2017) [112x22] [root@Centos6 ~]# tmux kill-session -t bbb [root@Centos6 ~]# tmux lsaaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22] 8）重命名会话[root@Centos6 ~]# tmux lswangshibo: 1 windows (created Sun Sep 30 10:17:00 2018) [136x29] (attached) [root@Centos6 ~]# tmux rename -t wangshibo kevin [root@Centos6 ~]# tmux lskevin: 1 windows (created Sun Sep 30 10:17:00 2018) [136x29] (attached) ​```title: tmux-初探date: 2018-12-07 13:59:25tags: tmux 骚操作 Linux终端复用神器-tmux初探​Tmux是一个优秀的终端复用软件，类似GNU Screen，但来自于OpenBSD，采用BSD授权。使用它最直观的好处就是，通过一个终端登录远程主机并运行tmux后，在其中可以开启多个控制台而无需再“浪费”多余的终端来连接这台远程主机。是BSD实现的Screen替代品，相对于Screen，它更加先进：支持屏幕切分，而且具备丰富的命令行参数，使其可以灵活、动态的进行各种布局和操作。 ​废话不多说来个效果图 Tmux的使用场景​1）可以某个程序在执行时一直是输出状态，需要结合nohup、&amp;来放在后台执行，并且ctrl+c结束。这时可以打开一个Tmux窗口，在该窗口里执行这个程序，用来保证该程序一直在执行中，只要Tmux这个窗口不关闭 2）公司需要备份数据库时，数据量巨大，备份两三天弄不完，这时不小心关闭了终端窗口或误操作就前功尽弃了，使用Tmux会话运行命令或任务，就不用担心这些问题。 3）下班后，你需要断开ssh或关闭电脑，将运行的命令或任务放置后台运行。 4）关闭终端,再次打开时原终端里面的任务进程依然不会中断 ​ Tmux功能：​``` 提供了强劲的、易于使用的命令行界面。 可横向和纵向分割窗口。 窗格可以自由移动和调整大小，或直接利用四个预设布局之一。 支持 UTF-8 编码及 256 色终端。 可在多个缓冲区进行复制和粘贴。 可通过交互式菜单来选择窗口、会话及客户端。 支持跨窗口搜索。 支持自动及手动锁定窗口。​```Tmux安装​yum -y install tmux ​ Tmux个性化配置​```此类配置可以在命令行模式中输入show-options -g查询 tmux加上下列参数,实现个性化设置set-option -g base-index 1 # 窗口的初始序号；默认为0，这里设置为1set-option -g display-time 5000 # 提示信息的持续时间；设置足够的时间以避免看不清提示，单位为毫秒set-option -g repeat-time 1000 # 控制台激活后的持续时间；设置合适的时间以避免每次操作都要先激活控制台，单位为毫秒set-option -g status-keys vi # 操作状态栏时的默认键盘布局；可以设置为vi或emacsset-option -g status-utf8 on # 开启状态栏的UTF-8支持 set-option -g status-bg blueset-option -g status-fg ‘#bbbbbb’set-option -g status-left-fg greenset-option -g status-left-bg blueset-option -g status-right-fg greenset-option -g status-right-bg blueset-option -g status-left-length 10 # 状态栏左方的内容长度；set-option -g status-right-length 15 # 状态栏右方的内容长度；建议把更多的空间留给状态栏左方（用于列出当前窗口）set-option -g status-left ‘[#(whoami)]’ # 状态栏左方的内容set-option -g status-right ‘[#(date +” %m-%d %H:%M “)]’ # 状态栏右方的内容；这里的设置将得到类似23:59的显示set-option -g status-justify “centre” # 窗口列表居中显示set-option -g default-terminal “screen-256color” # 支持256色显示分割窗口边界的颜色set-option -g pane-active-border-fg ‘#55ff55’set-option -g pane-border-fg ‘#555555’ 此类设置可以在命令行模式中输入show-window-options -g查询set-window-option -g mode-keys vi # 复制模式中的默认键盘布局；可以设置为vi或emacsset-window-option -g utf8 on # 开启窗口的UTF-8支持set-window-option -g mode-mouse on # 窗口切换后让人可以用鼠标上下滑动显示历史输出 窗口切分快捷键(没设置成功)bind \\ split-window -h # 使用 \\ 将窗口竖切bind - split-window -v # 使用 - 将窗口横切bind K confirm-before -p “kill-window #W? (y/n)” kill-window # 使用大写 K 来关闭窗口bind ‘“‘ choose-window # 双引号选择窗口 Pane之间切换的快捷键bind h select-pane -L # 定位到左边窗口的快捷键bind j select-pane -D # 定位到上边窗口的快捷键bind k select-pane -U # 定位到下方窗口的快捷键bind l select-pane -R # 定位到右边窗口的快捷键 设置window属性setw -g window-status-current-bg redsetw -g window-status-current-fg whitesetw -g window-status-current-attr brightsetw -g window-status-attr brightset-option -g window-status-format ‘#I #W’set-option -g window-status-current-format ‘ #I #W ‘setw -g window-status-current-bg bluesetw -g window-status-current-fg green不使用prefix键，使用Ctrl和左右方向键方便切换窗口bind-key -n “C-Left” select-window -t :-bind-key -n “C-Right” select-window -t :+​``` tmux session 使用介绍​```运行tmux并开启一个新的会话tmux 显示所有会话tmux ls 新建会话并指定会话名称（建议制定会话名称，以便了解该会话用途）tmux new -s 新建会话（不指定会话名称）tmux new 接入上一个会话tmux a 接入指定名称的会话tmux a -t 断开当前会话（还可以使用快捷键：control+b，再按d）tmux detach 关闭指定会话tmux kill-session -t session-name 关闭除指定会话外的所有会话tmux kill-session -a -t session-name 在会话中切换control+b，再按s 显示会话列表，再进行会话切换 销毁所有会话并停止tmuxtmux kill-serverG 复制粘贴Ctrl+b [ //进入复制模式空格+方向键 //选择回车 // 确认Ctrl+b [ //粘贴 ​``` 需要注意的几点​```1）进入tmux面板后，一定要先按ctrl+b，然后松开，再按其他的组合键才生效。 2）常用到的几个组合键：ctrl+b ? 显示快捷键帮助ctrl+b 空格键 采用下一个内置布局，这个很有意思，在多屏时，用这个就会将多有屏幕竖着展示ctrl+b ! 把当前窗口变为新窗口ctrl+b “ 模向分隔窗口ctrl+b % 纵向分隔窗口ctrl+b q 显示分隔窗口的编号ctrl+b o 跳到下一个分隔窗口。多屏之间的切换ctrl+b 上下键 上一个及下一个分隔窗口ctrl+b C-方向键 调整分隔窗口大小ctrl+b &amp; 确认后退出当前tmuxctrl+b [ 复制模式，即将当前屏幕移到上一个的位置上，其他所有窗口都向前移动一个。ctrl+b c 创建新窗口ctrl+b n 选择下一个窗口ctrl+b l 最后使用的窗口ctrl+b p 选择前一个窗口ctrl+b w 以菜单方式显示及选择窗口ctrl+b s 以菜单方式显示和选择会话。这个常用到，可以选择进入哪个tmuxctrl+b t 显示时钟。然后按enter键后就会恢复到shell终端状态ctrl+b d 脱离当前会话；这样可以暂时返回Shell界面，输入tmux attach能够重新进入之前的会话​``` tmux的常规运维命令​```1）安装命令： [root@—title: tmux-初探date: 2018-12-07 13:59:25tags: tmux 骚操作 Linux终端复用神器-tmux初探​Tmux是一个优秀的终端复用软件，类似GNU Screen，但来自于OpenBSD，采用BSD授权。使用它最直观的好处就是，通过一个终端登录远程主机并运行tmux后，在其中可以开启多个控制台而无需再“浪费”多余的终端来连接这台远程主机。是BSD实现的Screen替代品，相对于Screen，它更加先进：支持屏幕切分，而且具备丰富的命令行参数，使其可以灵活、动态的进行各种布局和操作。 ​废话不多说来个效果图 Tmux的使用场景​1）可以某个程序在执行时一直是输出状态，需要结合nohup、&amp;来放在后台执行，并且ctrl+c结束。这时可以打开一个Tmux窗口，在该窗口里执行这个程序，用来保证该程序一直在执行中，只要Tmux这个窗口不关闭 2）公司需要备份数据库时，数据量巨大，备份两三天弄不完，这时不小心关闭了终端窗口或误操作就前功尽弃了，使用Tmux会话运行命令或任务，就不用担心这些问题。 3）下班后，你需要断开ssh或关闭电脑，将运行的命令或任务放置后台运行。 4）关闭终端,再次打开时原终端里面的任务进程依然不会中断 ​ Tmux功能：​``` 提供了强劲的、易于使用的命令行界面。 可横向和纵向分割窗口。 窗格可以自由移动和调整大小，或直接利用四个预设布局之一。 支持 UTF-8 编码及 256 色终端。 可在多个缓冲区进行复制和粘贴。 可通过交互式菜单来选择窗口、会话及客户端。 支持跨窗口搜索。 支持自动及手动锁定窗口。​```Tmux安装​yum -y install tmux ​ Tmux个性化配置​```此类配置可以在命令行模式中输入show-options -g查询 tmux加上下列参数,实现个性化设置set-option -g base-index 1 # 窗口的初始序号；默认为0，这里设置为1set-option -g display-time 5000 # 提示信息的持续时间；设置足够的时间以避免看不清提示，单位为毫秒set-option -g repeat-time 1000 # 控制台激活后的持续时间；设置合适的时间以避免每次操作都要先激活控制台，单位为毫秒set-option -g status-keys vi # 操作状态栏时的默认键盘布局；可以设置为vi或emacsset-option -g status-utf8 on # 开启状态栏的UTF-8支持 set-option -g status-bg blueset-option -g status-fg ‘#bbbbbb’set-option -g status-left-fg greenset-option -g status-left-bg blueset-option -g status-right-fg greenset-option -g status-right-bg blueset-option -g status-left-length 10 # 状态栏左方的内容长度；set-option -g status-right-length 15 # 状态栏右方的内容长度；建议把更多的空间留给状态栏左方（用于列出当前窗口）set-option -g status-left ‘[#(whoami)]’ # 状态栏左方的内容set-option -g status-right ‘[#(date +” %m-%d %H:%M “)]’ # 状态栏右方的内容；这里的设置将得到类似23:59的显示set-option -g status-justify “centre” # 窗口列表居中显示set-option -g default-terminal “screen-256color” # 支持256色显示分割窗口边界的颜色set-option -g pane-active-border-fg ‘#55ff55’set-option -g pane-border-fg ‘#555555’ 此类设置可以在命令行模式中输入show-window-options -g查询set-window-option -g mode-keys vi # 复制模式中的默认键盘布局；可以设置为vi或emacsset-window-option -g utf8 on # 开启窗口的UTF-8支持set-window-option -g mode-mouse on # 窗口切换后让人可以用鼠标上下滑动显示历史输出 窗口切分快捷键(没设置成功)bind \\ split-window -h # 使用 \\ 将窗口竖切bind - split-window -v # 使用 - 将窗口横切bind K confirm-before -p “kill-window #W? (y/n)” kill-window # 使用大写 K 来关闭窗口bind ‘“‘ choose-window # 双引号选择窗口 Pane之间切换的快捷键bind h select-pane -L # 定位到左边窗口的快捷键bind j select-pane -D # 定位到上边窗口的快捷键bind k select-pane -U # 定位到下方窗口的快捷键bind l select-pane -R # 定位到右边窗口的快捷键 设置window属性setw -g window-status-current-bg redsetw -g window-status-current-fg whitesetw -g window-status-current-attr brightsetw -g window-status-attr brightset-option -g window-status-format ‘#I #W’set-option -g window-status-current-format ‘ #I #W ‘setw -g window-status-current-bg bluesetw -g window-status-current-fg green不使用prefix键，使用Ctrl和左右方向键方便切换窗口bind-key -n “C-Left” select-window -t :-bind-key -n “C-Right” select-window -t :+​``` tmux session 使用介绍​```运行tmux并开启一个新的会话tmux 显示所有会话tmux ls 新建会话并指定会话名称（建议制定会话名称，以便了解该会话用途）tmux new -s 新建会话（不指定会话名称）tmux new 接入上一个会话tmux a 接入指定名称的会话tmux a -t 断开当前会话（还可以使用快捷键：control+b，再按d）tmux detach 关闭指定会话tmux kill-session -t session-name 关闭除指定会话外的所有会话tmux kill-session -a -t session-name 在会话中切换control+b，再按s 显示会话列表，再进行会话切换 销毁所有会话并停止tmuxtmux kill-serverG 复制粘贴Ctrl+b [ //进入复制模式空格+方向键 //选择回车 // 确认Ctrl+b [ //粘贴 ​``` 需要注意的几点​```1）进入tmux面板后，一定要先按ctrl+b，然后松开，再按其他的组合键才生效。 2）常用到的几个组合键：ctrl+b ? 显示快捷键帮助ctrl+b 空格键 采用下一个内置布局，这个很有意思，在多屏时，用这个就会将多有屏幕竖着展示ctrl+b ! 把当前窗口变为新窗口ctrl+b “ 模向分隔窗口ctrl+b % 纵向分隔窗口ctrl+b q 显示分隔窗口的编号ctrl+b o 跳到下一个分隔窗口。多屏之间的切换ctrl+b 上下键 上一个及下一个分隔窗口ctrl+b C-方向键 调整分隔窗口大小ctrl+b &amp; 确认后退出当前tmuxctrl+b [ 复制模式，即将当前屏幕移到上一个的位置上，其他所有窗口都向前移动一个。ctrl+b c 创建新窗口ctrl+b n 选择下一个窗口ctrl+b l 最后使用的窗口ctrl+b p 选择前一个窗口ctrl+b w 以菜单方式显示及选择窗口ctrl+b s 以菜单方式显示和选择会话。这个常用到，可以选择进入哪个tmuxctrl+b t 显示时钟。然后按enter键后就会恢复到shell终端状态ctrl+b d 脱离当前会话；这样可以暂时返回Shell界面，输入tmux attach能够重新进入之前的会话​``` tmux的常规运维命令​```1）安装命令： [root@1000phone ~]# yum -y install tmux 2）默认创建一个会话，以数字命名。（不推荐）[root@1000phone ~]# tmux 3）新建会话，比如新创建一个会话以”ccc”命名[root@1000phone ~]# tmux new -s ccc 加上参数-d，表示在后台新建会话root@1000phone:# tmux new -s 1000phone -droot@1000phone:# tmux ls1000phone: 1 windows (created Tue Oct 2 19:22:32 2018) [135x35] 4）查看创建得所有会话[root@1000phone ~]# tmux ls0: 1 windows (created Wed Aug 30 17:58:20 2017) 112x22 #这里的attached表示该会话是当前会话1000phone: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22]ccc: 1 windows (created Wed Aug 30 17:01:05 2017) [112x22] 5）登录一个已知会话。即从终端环境进入会话。第一个参数a也可以写成attach。后面的aaa是会话名称。[root@1000phone ~]# tmux a -t 1000phone 6）退出会话不是关闭：登到某一个会话后，依次按键ctrl-b + d，这样就会退化该会话，但不会关闭会话。如果直接ctrl + d，就会在退出会话的通话也关闭了该会话！ 7）关闭会话（销毁会话）[root@1000phone ~]# tmux ls1000phone: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22]bbb: 1 windows (created Wed Aug 30 19:02:09 2017) [112x22] [root@1000phone ~]# tmux kill-session -t bbb [root@1000phone ~]# tmux ls1000phone: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22] 8）重命名会话[root@1000phone ~]# tmux lstigerfive: 1 windows (created Sun Sep 30 10:17:00 2018) [136x29] (attached) [root@1000phone ~]# tmux rename -t tigerfive 1000phone [root@Centos6 ~]# tmux ls1000phone: 1 windows (created Sun Sep 30 10:17:00 2018) [136x29] (attached) ​``` ~]# yum -y install tmux 2）默认创建一个会话，以数字命名。（不推荐）[root@1000phone ~]# tmux 3）新建会话，比如新创建一个会话以”ccc”命名[root@1000phone ~]# tmux new -s ccc 加上参数-d，表示在后台新建会话root@1000phone:# tmux new -s 1000phone -droot@1000phone:# tmux ls1000phone: 1 windows (created Tue Oct 2 19:22:32 2018) [135x35] 4）查看创建得所有会话[root@1000phone ~]# tmux ls0: 1 windows (created Wed Aug 30 17:58:20 2017) 112x22 #这里的attached表示该会话是当前会话aaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22]ccc: 1 windows (created Wed Aug 30 17:01:05 2017) [112x22] 5）登录一个已知会话。即从终端环境进入会话。第一个参数a也可以写成attach。后面的aaa是会话名称。[root@1000phone ~]# tmux a -t aaa 6）退出会话不是关闭：登到某一个会话后，依次按键ctrl-b + d，这样就会退化该会话，但不会关闭会话。如果直接ctrl + d，就会在退出会话的通话也关闭了该会话！ 7）关闭会话（销毁会话）[root@1000phone ~]# tmux lsaaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22]bbb: 1 windows (created Wed Aug 30 19:02:09 2017) [112x22] [root@1000phone ~]# tmux kill-session -t bbb [root@1000phone ~]# tmux lsaaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22] 8）重命名会话[root@1000phone ~]# tmux lswangshibo: 1 windows (created Sun Sep 30 10:17:00 2018) [136x29] (attached) [root@1000phone ~]# tmux rename -t wangshibo kevin [root@1000phone ~]# tmux lskevin: 1 windows (created Sun Sep 30 10:17:00 2018) [136x29] (attached) ​```","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/categories/Linux/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"https://github.com/cyylog/tags/Tools/"}]},{"title":"Zabbix源码安装","slug":"监控/Zabbix源码安装","date":"2019-08-04T17:55:39.000Z","updated":"2020-05-25T13:59:24.460Z","comments":true,"path":"2019/08/05/监控/Zabbix源码安装/","link":"","permalink":"https://github.com/cyylog/2019/08/05/%E7%9B%91%E6%8E%A7/Zabbix%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85/","excerpt":"","text":"Zabbix源码安装1:前期准备 注意安装zabbix需要lnmp环境可以使用脚本安装lnmp 这里我进行源码安装一步步的操作 建议使用脚本进行 用源码安装比较慢 (1) 关闭防火墙和selinux 建议可以实行放行策略(2)创建安装目录123456mkdir -pv /cyylog/&#123;mysql-5.7,nginx-1.16,php-7.2,zabbix-4.4&#125;mkdir -pv /cyylog/mysql-5.7/dataln -s /cyylog/mysql-5.7 /cyylog/mysqlln -s /cyylog/nginx-1.16 /cyylog/nginxln -s /cyylog/php-7.2 /cyylog/phpln -s /cyylog/zabbix-4.4 /cyylog/zabbix (3)创建用户123useradd -s /sbin/nologin mysqluseradd -s /sbin/nologin nginxuseradd -s /sbin/nologin zabbix 也可执行脚本 2:安装mysql(1)下载mysql源码包12wget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.29.tar.gzwget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-boost-5.7.29.tar.gz (2) 使用yum安装依赖包1yum install -y cmake gcc gcc-c++ openssl-devel ncurses-devel (3) 解压并进入进行安装1234567891011121314151617181920tar xvf mysql-5.7.29.tar.gztar xvf mysql-boost-5.7.29.tar.gz -C /cyylog/配置cmake \\-DCMAKE_INSTALL_PREFIX=/cyylog/mysql-5.7 \\-DMYSQL_DATADIR=/cyylog/mysql-5.7/data \\-DDEFAULT_CHARSET=utf8 \\-DDEFAULT_COLLATION=utf8_unicode_ci \\-DWITH_READLINE=1 \\-DWITH_SSL=system \\-DWITH_EMBEDDED_SERVER=1 \\-DENABLED_LOCAL_INFILE=1 \\-DDEFAULT_COLLATION=utf8_general_ci \\-DWITH_MYISAM_STORAGE_ENGINE=1 \\-DWITH_INNOBASE_STORAGE_ENGINE=1 \\-DWITH_DEBUG=0 \\-DWITH_BOOST=/cyylog/mysql-5.7.29/boost/boost_1_59_0编译且安装 make &amp; make install (4) 创建需要的文件及更改属主和属组1234mkdir -pv /cyylog/mysql/logtouch /cyylog/mysql/log/mariadb.logtouch /cyylog/mysql/log/mariadb.pidchown -R /cyylog/&#123;mysql-5.7,mysql-5.7.29,mysql&#125; (5) 初始化数据12345678910修改配置文件 vim /etc/my.cnf[mysqld]datadir=/cyylog/mysql/data #数据存储的地方socket=/cyylog/mysql/mysql.sock #sock文件的路径skip-grant-tables #跳过登录认证user=mysqlexplicit_defaults_for_timestamp=true[mysqld_safe]log-error=/cyylog/mysql/log/mariadb.log #错误日志存放的地方pid-file=/cyylog/mysql/log/mariadb.pid (6) 添加至环境变量1234567vim /etc/profile 修改末尾添加两行export PATH=$PATH:/cyylog/mysql/support-filesexport PATH=$PATH:/cyylog/mysql/bin保存退出刷新环境变量 source /etc/profile/ (7) 初始化启动mysql123mysqld --initialize --user=mysql --basedir=/cyylog/mysql --datadir=/cyylog/mysql/datamysql.server startln -s /cyylog/mysql/mysql.sock /tmp/ (8) 下载zabbix源码包并进行解压12345678910111213141516171819202122232425wget https://sourceforge.net/projects/zabbix/files/ZABBIX%20Latest%20Stable/4.4.5/zabbix-4.4.5.tar.gztar xvf zabbix-4.4.5.tar.gzcd zabbix-4.4.5/database/mysql登录mysql 命令为 mysql -u root 进入后执行以下命令use mysql;create database zabbix default character set utf8;update mysql.user set authentication_string=password('修改的密码') where user='root';use zabbix;source schema.sql;source images.sql;source data.sql;quit; 最后恢复密码登录mysql 修改文件 vim /etc/my.cnf去掉 skip-grant-tables保存退出重启mysql服务 mysql.sercer restart添加lib文件echo “/cyylog/mysql/lib” &gt; /etc/ld.so.conf.d/mysql.confldconfig -v 3:安装nginx(1) 下载 nginx 并解压12wget http://nginx.org/download/nginx-1.16.1.tar.gztar xvf nginx-1.16.1.tar.gz (2) 编译安装并添加环境变量12345678910111213cd nginx-1.16.1./configure --prefix=/cyylog/nginx-1.16 --user=nginx --group=nginx --without-select_module --without-poll_module --with-http_ssl_module --with-pcre --with-debugmake make install 添加变量vim /etc/profile 追加一行export PATH=$PATH://cyylog/nginx/sbin保存退出刷新变量source /etc/profile (3)更改 nginx 的属主和属组以及修改配置文件12345chown nginx:nginx -R /cyylog/nginx-1.16修改配置文件vim /cyylog/nginx/conf/nginx.conf修改启动用户 user nginx;启动nginx nginx 4:安装php(1) 下载php源码并井进行解压12wget https://www.php.net/distributions/php-7.2.27.tar.gztar xvf php-7.2.27.tar.gz (2) 安装及解决依赖 123456789yum install -y libxml2-devel openssl-devel net-snmp net-snmp-devel libcurl-devel libjpeg-devel libpng-devel libicu-devel openldap-devel bzip2 bzip2-devel freetype-devel gmp-devel readline-devel libxslt-devel fontconfigcd php-7.2.27./configure --prefix=/cyylog/php-7.2 --with-mysqli=/cyylog/mysql/bin/mysql_config --enable-inline-optimization --enable-fpm --enable-soap --enable-pcntl --enable-xml --with-libxml-dir --with-xmlrpc --with-openssl --with-mhash --with-pcre-regex --with-sqlite3 --with-zlib --enable-bcmath --with-iconv --with-bz2 --enable-calendar --with-curl --with-cdb --enable-dom --enable-exif --enable-fileinfo --enable-filter --with-pcre-dir --enable-ftp --with-gd --with-openssl-dir --with-jpeg-dir --with-png-dir --with-freetype-dir --with-gettext --with-gmp --with-mhash --enable-json --enable-mbstring --disable-mbregex --disable-mbregex-backtrack --with-libmbfl --with-onig --enable-pdo --with-pdo-mysql --with-zlib-dir --with-pdo-sqlite --with-readline --enable-session --enable-shmop --enable-simplexml --enable-sockets --enable-sysvmsg --enable-sysvsem --enable-sysvshm --enable-wddx --with-libxml-dir --with-xsl --enable-zip --enable-mysqlnd-compression-support --with-pear --without-pear make make install (3) 拷贝服务和配置文件及属主和属组12345cp /root/php-7.2.27/sapi/fpm/php-fpm.service /usr/lib/systemd/system/php-fpm.servicecp /cyylog/php-7.2/etc/&#123;php-fpm.conf.default,php-fpm.conf&#125;cp /cyylog/php-7.2/etc/php-fpm.d/www.conf&#123;.default,&#125;cp php.ini-production /cyylog/php-7.2/lib/php.inichown nginx:nginx -R /cyylog/php-7.2 (4) 修改配置文件并启动 12345678910111213141516171819202122232425262728293031323334#### 修改php.ini配置文件vim /cyylog/php/lib/php.ini 修改四行post_max_size = 16Mmax_execution_time = 300max_input_time = 300date.timezone = PRC#### 启动php服务systemctl start php-fpm.service &amp;&amp; systemctl enable php-fpm.service#### 修改nginx.conf文件是nginx支持phpvim /cyylog/nginx/conf/nginx.conf 修改如下 location ~ \\.php$ &#123; root /cyylog/nginx/html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /cyylog/nginx/html$fastcgi_script_name; include fastcgi_params; &#125; #### 编写测试php文件 vim /cyylog/nginx/html/index.php &lt;?php phpinfo(); ?&gt; #### 重启nginx服务 nginx -s reload 重启nginx服务 nginx -s reload 5:安装zabbix(1) 安装依赖以及编译安装123456yum localinstall -y libevent-devel-2.0.21-4.el7.x86_64.rpmyum install unixODBC-devel mysql-devel net-snmp-devel libxml2-devel libcurl-devel libevent-devel -y配置cd zabbix-4.4.5./configure --prefix=/cyylog/zabbix-4.4 --enable-server --enable-agent --with-mysql=/cyylog/mysql/bin/mysql_config --enable-ipv6 --with-netsnmp --with-libcurl --with-libxml2make make install (2) 配置环境变量 123456vim /etc/profile 追加一行export PATH=$PATH://cyylog/zabbix/sbin#### 保存退出 刷新 source /etc/profile (3) 修改配置文件 1234567vim /cyylog/zabbix/etc/zabbix_server.conf ##修改如下DBUser=rootDBPassword=beimi123拷贝zabbix至nginx的目录下cp -R frontends/php/* /cyylog/nginx/html/重启nginx服务 nginx -s reload 访问页面ok就行 注意连接数据库那个步骤需要将服务器ip改为127.0.0.1 不能使用localhost 否则会报错 接下会有个配置文件无法安装需手动下载下来传到ngin目录下 最后完成 登录账户为 admin 密码zabbix 登录后界面为","categories":[{"name":"监控","slug":"监控","permalink":"https://github.com/cyylog/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"https://github.com/cyylog/tags/zabbix/"}]},{"title":"Nginx性能优化","slug":"Linux/Nginx/Nginx性能优化","date":"2019-08-04T17:55:39.000Z","updated":"2020-05-25T13:57:06.488Z","comments":true,"path":"2019/08/05/Linux/Nginx/Nginx性能优化/","link":"","permalink":"https://github.com/cyylog/2019/08/05/Linux/Nginx/Nginx%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","excerpt":"","text":"当我需要进行性能优化时，说明我们服务器无法满足日益增长的业务。性能优化是一个比较大的课题，需要从以下几个方面进行探讨 当前系统结构瓶颈 了解业务模式 性能与安全 1、当前系统结构瓶颈首先需要了解的是当前系统瓶颈，用的是什么，跑的是什么业务。里面的服务是什么样子，每个服务最大支持多少并发。比如针对nginx而言，我们处理静态资源效率最高的瓶颈是多大？能支持多少qps访问请求？怎么得出系统当前的结构瓶颈？ 可以通过查看当前cpu负荷，内存使用率，进程使用率来做简单判断。还可以通过操作系统的一些工具来判断当前系统性能瓶颈，如分析对应的日志，查看请求数量。也可以通过nginx http_stub_status_module模块来查看对应的连接数，总握手次数，总请求数。也可以对线上进行压力测试，来了解当前的系统能性能，并发数，做好性能评估。 2、了解业务模式虽然我们是在做性能优化，但还是要熟悉业务，最终目的都是为业务服务的。我们要了解每一个接口业务类型是什么样的业务，比如电子商务抢购模式，这种情况平时流量会很小，但是到了抢购时间，流量一下子就会猛涨。也要了解系统层级结构，每一层在中间层做的是代理还是动静分离，还是后台进行直接服务。需要我们对业务接入层和系统层次要有一个梳理 3、性能与安全性能与安全也是一个需要考虑的因素，往往大家注重性能忽略安全或注重安全又忽略性能。比如说我们在设计防火墙时，如果规则过于全面肯定会对性能方面有影响。如果对性能过于注重在安全方面肯定会留下很大隐患。所以大家要评估好两者的关系，把握好两者的孰重孰轻，以及整体的相关性。权衡好对应的点。 4、系统与nginx性能优化大家对相关的系统瓶颈及现状有了一定的了解之后，就可以根据影响性能方面做一个全体的评估和优化。 网络（网络流量、是否有丢包，网络的稳定性都会影响用户请求） 系统（系统负载、饱和、内存使用率、系统的稳定性、硬件磁盘是否有损坏） 服务（连接优化、内核性能优化、http服务请求优化都可以在nginx中根据业务来进行设置） 程序（接口性能、处理请求速度、每个程序的执行效率） 数据库、底层服务 上面列举出来每一级都会有关联，也会影响整体性能，这里主要关注的是nginx服务这一层。 1、文件句柄在linux/unix操作系统中一切皆文件，我们的设备是文件，文件是文件，文件夹也是文件。当我们用户每发起一次请求，就会产生一个文件句柄。文件句柄可以简单的理解为文件句柄就是一个索引。文件句柄就会随着请求量的增多,进程调用频繁增加，那么产生的文件句柄也就会越多。 系统默认对文件句柄是有限制的，不可能会让一个进程无限制的调用句柄。因为系统资源是有限的，所以我们需要限制每一个服务能够使用多大的文件句柄。操作系统默认使用的文件句柄是1024个句柄。 2、设置方式 系统全局性修改 用户局部性修改 进程局部性修改 3、系统全局性修该和用户局部性修改1[root@server ~]#vim &#x2F;etc&#x2F;security&#x2F;limits.conf 在文件最下面找到 1234567891011121314#* soft core 0#* hard rss 10000#@student hard nproc 20#@faculty soft nproc 20#@faculty hard nproc 50#ftp hard nproc 0#@student - maxlogins 4#root只是针对root这个用户来限制，soft只是发提醒，操作系统不会强制限制,一般的站点设置为一万左右就ok了root soft nofile 65535root hard nofile 65535# *代表通配符 所有的用户* soft nofile 25535* hard nofile 25535 可以看到root和，root代表是root用户，代表的是所有用户，后面的数字就是文件句柄大小。大家可以根据个人业务来进行设置。 4、进程局部性修改123456789101112131415161718192021222324252627282930313233[root@server ~]#vim &#x2F;etc&#x2F;nginx&#x2F;nginx.confuser nginx;worker_processes 1; error_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;error.log warn;pid &#x2F;var&#x2F;run&#x2F;nginx.pid;worker_rlimit_nofile 65535; #进程限制events &#123; worker_connections 1024;&#125;http &#123; include &#x2F;etc&#x2F;nginx&#x2F;mime.types; default_type application&#x2F;octet-stream; log_format main &#39;$http_user_agent&#39; &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &#39; &#39;&quot;$args&quot; &quot;$request_uri&quot;&#39;; access_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;*.conf;&#125; worker_rlimit_nofile 是在进程上面进行限制。 5、cpu的亲和配置cpu的亲和能够使nginx对于不同的work工作进程绑定到不同的cpu上面去。就能够减少在work间不断切换cpu，把进程通常不会在处理器之间频繁迁移，进程迁移的频率小，来减少性能损耗。nginx 亲和配置 查看物理cpu 1[root@server ~]#cat &#x2F;proc&#x2F;cpuinfo|grep &quot;physical id&quot;|sort |uniq|wc -l 查看cpu核心数 1[root@server ~]#cat &#x2F;proc&#x2F;cpuinfo|grep &quot;cpu cores&quot;|uniq 查看cpu使用率 1[root@server ~]#top 回车后按 1 6、配置worker_processes1[root@server ~]#vim &#x2F;etc&#x2F;nginx&#x2F;nginx.conf 将刚才查看到自己cpu * cpu核心就是worker_processes 1worker_processes 2; #根据自己cpu核心数配置 7、cpu亲和配置假如小菜的配置是2cpu，每个cpu是8核。配置如下 12worker_processes 16;worker_cpu_affinity 1010101010101010 0101010101010101; 配置完成后可以通过下面命令查看nginx进程配置在哪个核上 1[root@server ~]#ps -eo pid,args,psr |grep [n]ginx 在nginx 1.9版本之后，就帮我们自动绑定了cpu; 1worker_cpu_affinity auto; 5、nginx通用配置优化1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[root@server ~]#vim &#x2F;etc&#x2F;nginx&#x2F;nginx.conf#将nginx进程设置为普通用户，为了安全考虑user nginx; #当前启动的worker进程，官方建议是与系统核心数一直worker_processes 2;#方式一， 第一个work进程绑定第一个cpu核心，第二个work进程绑定到第二个cpu核心，依次内推 直到弟16个#wokrer_cpu_affinity 0000000000000000 0000000000000001 0000000000000010 0000000000000100 ... 1000000000000000#方式二，当 worker_processes 2 时，表明 第一work进程可以绑定第 2 4 6 8 10 12 14 16 核心，那么第二work进程就绑定 奇数核心#worker_cpu_affinity 1010101010101010 0101010101010101;#方式三，就是自动分配绑定worker_cpu_affinity auto;#日志配置成warnerror_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;error.log warn; pid &#x2F;var&#x2F;run&#x2F;nginx.pid;#针对 nginx 句柄的文件限制worker_rlimit_nofile 35535;#事件模型events &#123; #使用epoll内核模型 user epoll; #每一个进程可以处理多少个连接，如果是多核可以将连接数调高 worker_processes * 1024 worker_connections 10240;&#125;http &#123; include &#x2F;etc&#x2F;nginx&#x2F;mime.types; default_type application&#x2F;octet-stream; charset utf-8; #设置字符集 #设置日志输出格式，根据自己的情况设置 log_format main &#39;$http_user_agent&#39; &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &#39; &#39;&quot;$args&quot; &quot;$request_uri&quot;&#39;; access_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log main; sendfile on; #对静态资源的处理比较有效 #tcp_nopush on; #如果做静态资源服务器可以打开 #tcp_nodeny on; #当nginx做动态的服务时可以选择打开 keepalive_timeout 65; ######## #Gzip module gzip on; #文件压缩默认可以打开 gzip_disable &quot;MSIE [1-6]\\.&quot;; #对于有些浏览器不能识别压缩，需要过滤如ie6 gzip_http_version 1.1; include &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;*.conf;&#125;#查看 核心绑定的nginx work进程[root@server ~]#ps -eo pid,args,psr | grep [n]ginx 6、ab接口压力测试工具ab是Apache超文本传输协议(HTTP)的性能测试工具。其设计意图是描绘当前所安装的Apache的执行性能，主要是显示你安装的Apache每秒可以处理多少个请求。 12345678# 安装工具[root@server ~]#yum install httpd-tools# 使用[root@server ~]#ab -n 2000 -c 2 http:&#x2F;&#x2F;127.0.0.1&#x2F;index.html-n 总的请求数-c 并发数-k 是否开启长连接 1、参数选项1234567891011121314151617181920212223242526-n：即requests，用于指定压力测试总共的执行次数-c：即concurrency，用于指定的并发数-t：即timelimit，等待响应的最大时间(单位：秒)-b：即windowsize，TCP发送&#x2F;接收的缓冲大小(单位：字节)-p：即postfile，发送POST请求时需要上传的文件，此外还必须设置-T参数-u：即putfile，发送PUT请求时需要上传的文件，此外还必须设置-T参数-T：即content-type，用于设置Content-Type请求头信息，例如：application&#x2F;x-www-form-urlencoded，默认值为text&#x2F;plain-v：即verbosity，指定打印帮助信息的冗余级别-w：以HTML表格形式打印结果-i：使用HEAD请求代替GET请求-x：插入字符串作为table标签的属性-y：插入字符串作为tr标签的属性-z：插入字符串作为td标签的属性-C：添加cookie信息，例如：&quot;Apache&#x3D;1234&quot;(可以重复该参数选项以添加多个)-H：添加任意的请求头，例如：&quot;Accept-Encoding: gzip&quot;，请求头将会添加在现有的多个请求头之后(可以重复该参数选项以添加多个)-A：添加一个基本的网络认证信息，用户名和密码之间用英文冒号隔开-P：添加一个基本的代理认证信息，用户名和密码之间用英文冒号隔开-X：指定使用的和端口号，例如:&quot;126.10.10.3:88&quot;-V：打印版本号并退出-k：使用HTTP的KeepAlive特性-d：不显示百分比-S：不显示预估和警告信息-g：输出结果信息到gnuplot格式的文件中-e：输出结果信息到CSV格式的文件中-r：指定接收到错误信息时不退出程序-H：显示用法信息，其实就是ab -help 2、内容解释123456789101112131415161718192021222324252627Server Software: nginx&#x2F;1.10.2 (服务器软件名称及版本信息)Server Hostname: 192.168.1.106(服务器主机名)Server Port: 80 (服务器端口)Document Path: &#x2F;index1.html. (供测试的URL路径)Document Length: 3721 bytes (供测试的URL返回的文档大小)Concurrency Level: 1000 (并发数)Time taken for tests: 2.327 seconds (压力测试消耗的总时间)Complete requests: 5000 (的总次数)Failed requests: 688 (失败的请求数)Write errors: 0 (网络连接写入错误数)Total transferred: 17402975 bytes (传输的总数据量)HTML transferred: 16275725 bytes (HTML文档的总数据量)Requests per second: 2148.98 [#&#x2F;sec] (mean) (平均每秒的请求数) 这个是非常重要的参数数值，服务器的吞吐量 Time per request: 465.338 [ms] (mean) (所有并发用户(这里是1000)都请求一次的平均时间)Time request: 0.247 [ms] (mean, across all concurrent requests) (单个用户请求一次的平均时间)Transfer rate: 7304.41 [Kbytes&#x2F;sec] received 每秒获取的数据长度 (传输速率，单位：KB&#x2F;s)...Percentage of the requests served within a certain time (ms) 50% 347 ## 50%的请求在347ms内返回 66% 401 ## 60%的请求在401ms内返回 75% 431 80% 516 90% 600 95% 846 98% 1571 99% 1593 100% 1619 (longest request) 3、示例演示1[root@server ~]#ab -n 50 -c 20 http:&#x2F;&#x2F;walidream.com&#x2F;sub_module 输出内容 12345678910111213141516171819202122232425262728293031323334353637Server Software: nginx&#x2F;1.14.1Server Hostname: walidream.comServer Port: 80Document Path: &#x2F;sub_moduleDocument Length: 169 bytesConcurrency Level: 20Time taken for tests: 0.005 secondsComplete requests: 50Failed requests: 0Write errors: 0Non-2xx responses: 50Total transferred: 14900 bytesHTML transferred: 8450 bytesRequests per second: 9746.59 [#&#x2F;sec] (mean)Time per request: 2.052 [ms] (mean)Time per request: 0.103 [ms] (mean, across all concurrent requests)Transfer rate: 2836.41 [Kbytes&#x2F;sec] receivedConnection Times (ms) min mean[+&#x2F;-sd] median maxConnect: 0 0 0.1 0 1Processing: 1 1 0.3 1 2Waiting: 0 1 0.2 1 1Total: 1 2 0.3 2 2Percentage of the requests served within a certain time (ms) 50% 2 66% 2 75% 2 80% 2 90% 2 95% 2 98% 2 99% 2 100% 2 (longest request) 5、注意事项● 测试机与被测试机要分开 ● 不要对线上的服务器做压力测试 ● 观察测试工具ab所在机器，以及被测试的前端机的CPU、内存、网络等都不超过最高限度的75% 6、ab性能指标1、吞吐率（Requests per second）服务器并发处理能力的量化描述，单位是reqs/s，指的是在某个并发用户数下单位时间内处理的请求数。某个并发用户数下单位时间内能处理的最大请求数，称之为最大吞吐率。记住：吞吐率是基于并发用户数的。这句话代表了两个含义： 123● 吞吐率和并发用户数相关● 不同的并发用户数下，吞吐率一般是不同的 计算公式：总请求数/处理完成这些请求数所花费的时间，即 1Request per second&#x3D;Complete requests&#x2F;Time taken for tests 必须要说明的是，这个数值表示当前机器的整体性能，值越大越好 2、并发连接数（The number of concurrent connections）并发连接数指的是某个时刻服务器所接受的请求数目，简单的讲，就是一个会话。 3、并发用户数（Concurrency Level）要注意区分这个概念和并发连接数之间的区别，一个用户可能同时会产生多个会话，也即连接数。在HTTP/1.1下，IE7支持两个并发连接，IE8支持6个并发连接，FireFox3支持4个并发连接，所以相应的，我们的并发用户数就得除以这个基数。 4.用户平均请求等待时间（Time per request）计算公式：处理完成所有请求数所花费的时间/（总请求数/并发用户数），即： 1Time per request&#x3D;Time taken for tests&#x2F;（Complete requests&#x2F;Concurrency Level） 5.服务器平均请求等待时间（Time per request:across all concurrent requests）计算公式：处理完成所有请求数所花费的时间/总请求数，即： 1Time taken for&#x2F;testsComplete requests 可以看到，它是吞吐率的倒数。同时，它也等于用户平均请求等待时间/并发用户数，即 1Time per request&#x2F;Concurrency Level","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/categories/Linux/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://github.com/cyylog/tags/Nginx/"}]},{"title":"zabbix邮箱报警设置","slug":"监控/Zabbix邮件报警","date":"2019-07-04T17:55:39.000Z","updated":"2020-05-25T13:59:07.866Z","comments":true,"path":"2019/07/05/监控/Zabbix邮件报警/","link":"","permalink":"https://github.com/cyylog/2019/07/05/%E7%9B%91%E6%8E%A7/Zabbix%E9%82%AE%E4%BB%B6%E6%8A%A5%E8%AD%A6/","excerpt":"","text":"Zabbix 邮件报警前期准备工作：电脑登录网易邮箱配置，把自己的授权码看一下，并写入配置文件 server端安装配置邮件服务器1234[root@master ~]# yum -y install mailx[root@master ~]# mailx -V12.5 7/5/10 配置公网邮箱信息：发邮件：12345678910[root@master ~]# vim /etc/mail.rc #追加以下内容set from=cyylog@163.com #（邮箱地址） set smtp=smtp.163.com #smtp服务器） 发邮件服务器 ---163默认set smtp-auth-user=cyylog@163.com #(用户名) set smtp-auth-password=Password #（邮箱密码）授权之后的密码set smtp-auth=login #默认###### 测试[root@master ~]# echo \"test mail from zabbix.server.com\" |mail -s \"test mail\" cyylog@163.com 然后163邮箱就会收到信息 报警媒体的配置:首先需要配置 Zabbix 的邮件功能。点击 管理-&gt;报警媒介类型-&gt;创建媒体类型 然后在页面中填入你的报警媒介类型信息,例如下图所示:注：脚本名称任意，存放于/usr/lib/zabbix/alertscripts (生产上的测试服放这：s /usr/local/zabbix/share/zabbix/alertscripts） 名称：sendmail //名称任意类型：脚本脚本名称：sendmail.sh脚本参数： //一定要写，否则可能发送不成功{ALERT.SENDTO} //照填，收件人变量{ALERT.SUBJECT} //照填，邮件主题变量，变量值来源于‘动作’中的‘默认接收人’{ALERT.MESSAGE} //照填，邮件正文变量，变量值来源于‘动作’中的‘默认信息’ 配置完成后,不要忘记点击存档,保存你的配置。 修改zabbix服务端配置文件＆编写脚本：123456789101112131415161718192021# 查看指定脚本的存储路径:[root@master ~]# vim /etc/zabbix/zabbix_server.confAlertScriptsPath=/usr/lib/zabbix/alertscripts编写邮件脚本:[root@master alertscripts]# cd /usr/lib/zabbix/alertscripts[root@master alertscripts]# vim sendmail.sh #!/bin/sh #export.UTF-8 -----字符集可以删除掉#send mailmessages=echo $3 | tr '\\r\\n' '\\n'subject=echo $2 | tr '\\r\\n' '\\n'echo \"$&#123;messages&#125;\" | mail -s \"$&#123;subject&#125;\" $1 &gt;&gt;/tmp/mailx.log 2&gt;&amp;1修改权限：[root@master alertscripts]# chmod u+x sendmail.sh &amp;&amp; chown zabbix.zabbix sendmail.sh 创建的脚本名称要和定义的脚本名称一样 修改admin用户的报警媒介：用户默认是没有设置报警媒介的，设置后就可以接收报警消息了。 触发器的配置:接下来,点击配置-&gt;主机 我们给 agent-19 这台主机增加一个触发器。点击 agent-19 这一行中的“触发器”,然后再点击创建触发器。该页各配置项含义如下:名称:填入触发器的名字表达式:用于配置触发器的触发条件,点击添加按钮有条件选项。 —-键值多重事件产生:如果选中,则问题如果持续多重的发生则每次都触发,否则只触发一次点击表达式右侧的添加按钮: 再点击项目右侧的选择,选择我们之前配置过的“web.server.online.monitor”,并设置触发的阀值,如下图所示 Zabbix 会自动生成表达式。接下来根据情况选择事件的严重性。配置完毕后,点击存档保存。 动作的配置:点击:配置-&gt;动作-&gt;事件源下拉菜单中选择触发器-&gt;创建动作可以在内容中使用 Zabbix 内置宏,邮件发出时会自动将宏替换成对应的值。 名称：任意写 默认接收人： 123456789101112故障级别：&#123;TRIGGER.STATUS&#125;。服务器：【&#123;HOSTNAME1&#125; 】 发生：&#123;TRIGGER.NAME&#125; 故障！ 注：默认接收人：相当于邮件的主题默认信息：邮件的主题告警主机：&#123;HOSTNAME1&#125; 告警时间：&#123;EVENT.DATE&#125; &#123;EVENT.TIME&#125;告警等级：&#123;TRIGGER.SEVERITY&#125; 告警信息：&#123;TRIGGER.NAME&#125;告警项目：&#123;TRIGGER.KEY1&#125; 问题详情：&#123;ITEM.NAME&#125;：&#123;ITEM.VALUE&#125;当前状态：&#123;TRIGGER.STATUS&#125;：&#123;ITEM.VALUE1&#125; 事件ID：&#123;EVENT.ID&#125; 恢复邮件：恢复主题： 12服务器：【&#123;HOSTNAME1&#125;】故障已恢复。故障原因：&#123;TRIGGER.NAME&#125; 恢复信息：恢复邮件的正文。当故障恢复正常后也发邮件通知一下。 点击:操作-&gt;编辑： 发送间隔：60秒步骤：发送10次发送到：admin用户仅使用：sendmail方式发送 —-脚本。 方式可以自行设置，根据实际工作要求 需要特别解释一下的是“步骤”部分的配置。所谓步骤是指报警可以有多个步骤,做不同的报警。例如,自从 1 到 3,就是指报警的步骤有三个。步骤持续时间就是一定时间后如果监控人员仍未响应报警就进入下一个报警步骤。例如,发邮件给你报警,如果60 秒后你没响应,那就发 jabber 信息提醒你。如果 60 秒后还没响应,那就发短信给你。要是还没响应,就没有然后了。你可以形象的把它理解为 Zabbix 的一哭二闹三上吊。到此,一个邮件报警功能就配置完毕了。如果你想立即看到结果,可以修改触发器的条件,将条件的阀值设置为 N&gt;0.0003。你马上就会收到 Zabbix 发来的报警邮件了。 补充：邮件美化（修改默认信息） 12345678910111213141516171819202122232425262728293031323334353637383940&lt;table border=\"1\" bordercolor=\"black\" cellspacing=\"0px\" cellpadding=\"4px\"&gt; &lt;tr &gt; &lt;td&gt;告警主机&lt;/td&gt; &lt;td bgcolor=\"#FF3333\"&gt;&#123;HOSTNAME1&#125;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;告警时间&lt;/td&gt; &lt;td&gt;&#123;EVENT.DATE&#125; &#123;EVENT.TIME&#125;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;告警等级&lt;/td&gt; &lt;td&gt;&#123;TRIGGER.SEVERITY&#125;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;告警信息&lt;/td&gt; &lt;td&gt;&#123;TRIGGER.NAME&#125;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;告警项目&lt;/td&gt; &lt;td&gt;&#123;TRIGGER.KEY1&#125;&lt;/td&gt; &lt;/tr&gt; &lt;tr &gt; &lt;td&gt;问题详情&lt;/td&gt; &lt;td bgcolor=\"#FF3333\"&gt;&#123;ITEM.NAME&#125;:&amp;nbsp;&#123;ITEM.VALUE&#125;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;当前状态&lt;/td&gt; &lt;td&gt;&#123;TRIGGER.STATUS&#125;:&amp;nbsp;&#123;ITEM.VALUE1&#125;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;事件ID&lt;/td&gt; &lt;td&gt;&#123;EVENT.ID&#125;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;","categories":[{"name":"监控","slug":"监控","permalink":"https://github.com/cyylog/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"https://github.com/cyylog/tags/zabbix/"}]},{"title":"MySQL部署之源码安装","slug":"SQL/MySQL部署之源码安装","date":"2019-05-27T14:53:26.000Z","updated":"2020-05-25T13:56:34.046Z","comments":true,"path":"2019/05/27/SQL/MySQL部署之源码安装/","link":"","permalink":"https://github.com/cyylog/2019/05/27/SQL/MySQL%E9%83%A8%E7%BD%B2%E4%B9%8B%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85/","excerpt":"","text":"所需要的依赖及安装MySQL的包1234# yum -y update# yum -y groupinstall \"Development Tools\"# yum -y install gcc gcc-c++ ncurses ncurses-devel bison libgcrypt perl make cmake# wget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-boost-5.7.24.tar.gz 在系统中添加运行mysqld进程的用户mysql12[root@mysql_source ~]# groupadd mysql[root@mysql_source ~]# useradd -M -g mysql -s /sbin/nologin mysql 在系统中添加自定义MySQL数据库目录及其他必要目录12[root@mysql_source ~]# mkdir -p /usr/local/mysqld/&#123;data,mysql,log,tmp&#125;[root@mysql_source ~]# chown -R mysql:mysql /usr/local/mysqld/* 将mysql-boost-5.7.24.tar.gz解压到当前目录,并执行部署操作12345678910111213141516171819202122232425262728[root@mysql_source ~]# tar xf mysql-boost-5.7.24.tar.gz[root@mysql_source ~]# cd mysql-5.7.24[root@mysql_source mysql-5.7.24]# $ cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysqld/mysql \\-DMYSQL_DATADIR=/usr/local/mysqld/data \\-DWITH_BOOST=/root/mysql-5.7.24/boost \\-DDEFAULT_CHARSET=utf8......-- Configuring done-- Generating done-- Build files have been written to: /root/mysql-5.7.24[root@mysql_source mysql-5.7.24]# echo $?0[root@mysql_source mysql-5.7.24]# make -j `lscpu | awk 'NR==4&#123; print $2 &#125;'`......[100%] Built target udf_example[root@mysql_source mysql-5.7.24]# echo $?0[root@mysql_source mysql-5.7.24]# make install......-- Installing: /usr/local/mysqld/mysql/support-files/mysql.server[root@mysql_source mysql-5.7.24]# echo $?0[root@mysql_source mysql-5.7.24]#Congratulations Complete! 初始化MySQL安装配置1.提升MySQL命令为系统级别命令12[root@mysql_source ~]# echo \"export PATH=$PATH:/usr/local/mysqld/mysql/bin\" &gt;&gt;/etc/profile[root@mysql_source ~]# source /etc/profile 2.拷贝默认配置文件至/etc/my.cnf中123456789101112131415161718192021[root@mysql_source mysql]# chown -R mysql.mysql /usr/local/mysqld/*[root@mysql_source ~]# cd /usr/local/mysqld/mysql/mysql-test/include[root@mysql_source include]# cp /etc/&#123;my.cnf,my.cnf.bak&#125;[root@mysql_source include]# cp default_mysqld.cnf /etc/my.cnfcp：是否覆盖\"/etc/my.cnf\"？ y[root@mysql_source include]# vim /etc/my.cnf[mysqld]basedir = /usr/local/mysqld/mysqldatadir = /usr/local/mysqld/datatmpdir = /usr/local/mysqld/tmpsocket = /usr/local/mysqld/tmp/mysql.sockpid_file = /usr/local/mysqld/tmp/mysqld.pidlog_error = /usr/local/mysqld/log/mysql_error.logslow_query_log_file = /usr/local/mysqld/log/slow_warn.logserver_id = 11user = mysqlport = 3306bind-address = 0.0.0.0character-set-server = utf8default_storage_engine = InnoDB 3.执行数据库服务初始化操作12[root@mysql_source mysql]# mysqld --defaults-file=/etc/my.cnf --initialize --user='mysql'[root@mysql_source mysql]# 4.启动mysqld服务1234[root@mysql_source mysql]# mysqld_safe --defaults-file=/etc/my.cnf &amp;[1] 257052018-12-28T09:19:35.334751Z mysqld_safe Logging to '/usr/local/mysqld/log/mysql_error.log'.2018-12-28T09:19:35.379829Z mysqld_safe Starting mysqld daemon with databases from /usr/local/mysqld/data 5.设置mysql.socket软链接到mysql命令指定的目录中1[root@mysql_source ～]# ln -s /usr/local/mysqld/tmp/mysql.sock /tmp/mysql.sock 6.配置mysqld服务的管理工具 1234[root@mysql_source support-files]# cd /usr/local/mysqld/mysql/support-files[root@mysql_source support-files]# cp mysql.server /etc/init.d/mysqld[root@mysql_source support-files]# chkconfig --add mysqld[root@mysql_source support-files]# chkconfig mysqld on 登录数据库并进行更改密码123456789101112131415161718192021222324252627282930313233343536[root@mysql_source mysql]# grep \"password\" /usr/local/mysqld/log/mysql_error.log2018-12-28T09:18:34.214401Z 1 [Note] A temporary password is generated for root@localhost: ejhszb2:m3wJ[root@mysql_source tmp]# mysql -uroot -p\"ejhszb2:m3wJ\"mysql: [Warning] Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 2Server version: 5.7.24-logCopyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; alter user 'root'@'localhost' identified by \"(Cyylog..1228)\";平常中常用的MySQL部署参数:&lt;参考使用&gt; -DCMAKE_INSTALL_PREFIX=/usr/local/mysqld/mysql \\ -DMYSQL_DATADIR=/usr/local/mysqld/data \\ -DDOWNLOAD_BOOST=1 \\ -DWITH_BOOST=/root/mysql-5.7.24/boost \\ -DSYSCONFDIR=/etc \\ -DWITH_INNOBASE_STORAGE_ENGINE=1 \\ -DWITH_PARTITION_STORAGE_ENGINE=1 \\ -DWITH_FEDERATED_STORAGE_ENGINE=1 \\ -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \\ -DWITH_MYISAM_STORAGE_ENGINE=1 \\ -DENABLED_LOCAL_INFILE=1 \\ -DENABLE_DTRACE=0 \\ -DDEFAULT_CHARSET=utf8 \\ -DDEFAULT_COLLATION=utf8_general_ci \\ -DWITH_EMBEDDED_SERVER=1 绕过验证密码登录 修改密码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677[root@mysql ~]# vim /etc/my.cnf[mysqld]skip-grant-tables=1[root@mysql ~]# systemctl restart mysqld[root@mysql ~]# mysql -urootWelcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 2Server version: 5.7.24 MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; alter user 'root'@'localhost' identified by \"(Cyylog..1229)\";ERROR 1290 (HY000): The MySQL server is running with the --skip-grant-tables option so it cannot execute this statementmysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+4 rows in set (0.00 sec)mysql&gt; use mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; show tables;..................| user |+---------------------------+31 rows in set (0.00 sec)mysql&gt; select User,Host,authentication_string from user;+---------------+-----------+-------------------------------------------+| User | Host | authentication_string |+---------------+-----------+-------------------------------------------+| root | localhost | *C4571A0C807D96143700250EC4BA41780025A97F || mysql.session | localhost | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE || mysql.sys | localhost | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE |+---------------+-----------+-------------------------------------------+3 rows in set (0.00 sec)mysql&gt; update user set authentication_string=password('(Cyylog@@1229)') where user='root';Query OK, 1 row affected, 1 warning (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 1[root@mysql ~]# vim /etc/my.cnf[mysqld]#skip-grant-tables=1[root@mysql ~]# systemctl restart mysqld[root@mysql ~]# mysql -uroot -p\"(Cyylog@@1229)\"mysql: [Warning] Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 2Server version: 5.7.24 MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt;","categories":[{"name":"SQL","slug":"SQL","permalink":"https://github.com/cyylog/categories/SQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://github.com/cyylog/tags/MySQL/"}]},{"title":"Nginx平滑升级","slug":"Linux/Nginx/Nginx平滑升级","date":"2019-04-27T15:18:34.000Z","updated":"2020-05-25T13:56:54.849Z","comments":true,"path":"2019/04/27/Linux/Nginx/Nginx平滑升级/","link":"","permalink":"https://github.com/cyylog/2019/04/27/Linux/Nginx/Nginx%E5%B9%B3%E6%BB%91%E5%8D%87%E7%BA%A7/","excerpt":"","text":"Nginx 平滑升级1、查看现有的 nginx 编译参数1[root@web ~]#/usr/local/nginx/sbin/nginx -V 按照原来的编译参数安装 nginx 的方法进行安装，只需要到 make，千万不要 make install 2、编译新的 nginx 源码包编译新Nginx源码，安装路径需与旧版一致 (详细过程可参见：Nginx编译安装与配置使用) 12[root@web ~]#./configure --prefix=/usr/local/nginx-1.14.0 --user=www --group=www --with-http_ssl_module --with-openssl=/path/to/openssl_src[root@web ~]#make 3、备份原 nginx 二进制文件备份二进制文件和 nginx 的配置文件（期间nginx不会停止服务） 1[root@web ~]#mv /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx_$(date +%F) 4、复制新的nginx二进制文件，进入新的nginx源码包 1[root@web ~]#cp /usr/local/nginx-1.14.0/objs/nginx /usr/local/nginx/sbin/ 5、测试新版本的nginx是否正常 1[root@web ~]#/usr/local/nginx/sbin/nginx -t 6、给nginx发送平滑迁移信号（若不清楚pid路径，请查看nginx配置文件） 1[root@web ~]#kill -USR2 cat /var/run/nginx.pid 7、查看nginx pid，会出现一个nginx.pid.oldbin 1[root@web ~]#ll /var/run/nginx.pid* 8、从容关闭旧的Nginx进程 1[root@web ~]#kill -WINCH cat /var/run/nginx.pid.oldbin 9、此时不重载配置启动旧的工作进程 1[root@web ~]#kill -HUP cat /var/run/nginx.pid.oldbin 10、结束工作进程，完成此次升级 1[root@web ~]#kill -QUIT cat /var/run/nginx.pid.oldbin 11、验证Nginx是否升级成功 1[root@web ~]#usr/local/nginx/sbin/nginx -V 升级实战1、安装配置1.6版本的 nginx1234567891011[root@web ~]# yum install -y gcc gcc-c++ pcre-devel openssl-devel zlib-devel[root@web ~]# tar zxvf nginx-1.6.0.tar.gz -C /usr/src/[root@web ~]# cd /usr/src/nginx-1.6.0/[root@web nginx-1.6.0]# ./configure --prefix=/usr/local/nginx --user=nginx --group=nginx --with-http_stub_status_module[root@web nginx-1.6.0]# make [root@web nginx-1.6.0]# make install[root@web nginx-1.6.0]# ln -s /usr/local/nginx/sbin/* /usr/sbin/[root@web nginx-1.6.0]# useradd -M -s /sbin/nologin nginx [root@web nginx-1.6.0]# nginx [root@web nginx-1.6.0]# netstat -anput | grep nginx tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 19008/nginx: master 2、查看 nginx 版本12[root@web nginx-1.6.0]# nginx -vnginx version: nginx/1.6.0 3、查看 nginx 现有安装的模块1234[root@web nginx-1.6.0]# nginx -Vnginx version: nginx/1.6.0built by gcc 4.8.5 20150623 (Red Hat 4.8.5-11) (GCC) configure arguments: --prefix=/usr/local/nginx --user=nginx --group=nginx --with-http_stub_status_module 4、访问验证12[root@web nginx-1.6.0]# echo \"nginx1.6.0\" &gt; /usr/local/nginx/html/index.html[root@web nginx-1.6.0]# elinks 192.168.20.167 5、升级 nginx将 nginx 版本进行升级 并在不影响业务的情况下添加 SSL 和 pcre 模块 12345678910111213141516171819202122[root@web ~]# tar zxvf nginx-1.11.2.tar.gz -C /usr/src/[root@web ~]# cd /usr/src/nginx-1.11.2/[root@web nginx-1.11.2]# ./configure --prefix=/usr/local/nginx --user=nginx --group=ngiinx --with-http_stub_status_module --with-http_ssl_module --with-pcre[root@web nginx-1.11.2]# make[root@web nginx-1.11.2]# cd[root@web ~]# mv /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx_old [root@web ~]# cp /usr/src/nginx-1.11.2/objs/nginx /usr/local/nginx/sbin/[root@web ~]# mv /usr/local/nginx/conf/nginx.conf /usr/local/nginx/conf/nginx.conf.old[root@Centos ~]# cp /usr/src/nginx-1.11.2/conf/nginx.conf /usr/local/nginx/conf/nginx.conf[root@web ~]# kill -USR2 `cat /usr/local/nginx/logs/nginx.pid`[root@web ~]# ls /usr/local/nginx/logs/access.log error.log nginx.pid[root@web ~]# ps aux | grep nginx root 19008 0.0 0.0 24324 944 ? Ss 14:07 0:00 nginx: master process nginxnginx 19009 0.0 0.1 26832 1744 ? S 14:07 0:00 nginx: worker processroot 53194 0.0 0.0 112660 976 pts/0 R+ 14:36 0:00 grep --color=auto ngin 6、验证 nginx 是否升级成功","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/categories/Linux/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://github.com/cyylog/tags/Nginx/"}]},{"title":"kafka入门","slug":"SQL/kafka入门","date":"2019-04-25T17:11:26.000Z","updated":"2020-05-25T13:55:36.811Z","comments":true,"path":"2019/04/26/SQL/kafka入门/","link":"","permalink":"https://github.com/cyylog/2019/04/26/SQL/kafka%E5%85%A5%E9%97%A8/","excerpt":"","text":"KAFKA 消息中间件1、认识kafka1.1 kafka简介Kafka 是一个分布式流媒体平台 kafka官网：http://kafka.apache.org/ （1）流媒体平台有三个关键功能： 发布和订阅记录流，类似于消息队列或企业消息传递系统。 以容错的持久方式存储记录流。 记录发生时处理流。 （2）Kafka通常用于两大类应用： 构建可在系统或应用程序之间可靠获取数据的实时流数据管道 构建转换或响应数据流的实时流应用程序 要了解Kafka如何做这些事情，让我们深入探讨Kafka的能力。 （3）首先是几个概念： Kafka作为一个集群运行在一个或多个可跨多个数据中心的服务器上。 Kafka集群以称为 topics主题 的类别存储记录流。 每条记录都包含一个键，一个值和一个时间戳。 （4）Kafka有四个核心API： Producer API（生产者API）允许应用程序发布记录流至一个或多个kafka的topics（主题）。 Consumer API（消费者API）允许应用程序订阅一个或多个topics（主题），并处理所产生的对他们记录的数据流。 Streams API（流API）允许应用程序充当流处理器，从一个或多个topics（主题）消耗的输入流，并产生一个输出流至一个或多个输出的topics（主题），有效地变换所述输入流，以输出流。 Connector API（连接器API）允许构建和运行kafka topics（主题）连接到现有的应用程序或数据系统中重用生产者或消费者。例如，关系数据库的连接器可能捕获对表的每个更改。 在Kafka中，客户端和服务器之间的通信是通过简单，高性能，语言无关的TCP协议完成的。此协议已版本化并保持与旧版本的向后兼容性。Kafka提供Java客户端，但客户端有多种语言版本。 1.2 Topics主题 和 partitions分区我们首先深入了解 Kafka 为记录流提供的核心抽象 - 主题topics 一个Topic可以认为是一类消息，每个topic将被分成多个partition(区),每个partition在存储层面是append log文件 主题是发布记录的类别或订阅源名称。Kafka的主题总是多用户; 也就是说，一个主题可以有零个，一个或多个消费者订阅写入它的数据。 对于每个主题，Kafka群集都维护一个如下所示的分区日志： 每个分区都是一个有序的，不可变的记录序列，不断附加到结构化的提交日志中。分区中的记录每个都分配了一个称为偏移的顺序ID号，它唯一地标识分区中的每个记录。 Kafka集群持久保存所有已发布的记录 - 无论是否已使用 - 使用可配置的保留期。例如，如果保留策略设置为两天，则在发布记录后的两天内，它可供使用，之后将被丢弃以释放空间。Kafka的性能在数据大小方面实际上是恒定的，因此长时间存储数据不是问题。 实际上，基于每个消费者保留的唯一元数据是该消费者在日志中的偏移或位置。这种偏移由消费者控制：通常消费者在读取记录时会线性地提高其偏移量，但事实上，由于该位置由消费者控制，因此它可以按照自己喜欢的任何顺序消费记录。例如，消费者可以重置为较旧的偏移量来重新处理过去的数据，或者跳到最近的记录并从“现在”开始消费。 这些功能组合意味着Kafka 消费者consumers 非常cheap - 他们可以来来往往对集群或其他消费者没有太大影响。例如，您可以使用我们的命令行工具“tail”任何主题的内容，而无需更改任何现有使用者所消耗的内容。 日志中的分区有多种用途。首先，它们允许日志扩展到超出适合单个服务器的大小。每个单独的分区必须适合托管它的服务器，但主题可能有许多分区，因此它可以处理任意数量的数据。其次，它们充当了并行性的单位 - 更多的是它。 1.3 Distribution 分配 一个Topic的多个partitions,被分布在kafka集群中的多个server上;每个server(kafka实例)负责partitions中消息的读写操作;此外kafka还可以配置partitions需要备份的个数(replicas),每个partition将会被备份到多台机器上,以提高可用性. 基于replicated方案,那么就意味着需要对多个备份进行调度;每个partition都有一个server为”leader”;leader负责所有的读写操作,如果leader失效,那么将会有其他follower来接管(成为新的leader);follower只是单调的和leader跟进,同步消息即可..由此可见作为leader的server承载了全部的请求压力,因此从集群的整体考虑,有多少个partitions就意味着有多少个”leader”,kafka会将”leader”均衡的分散在每个实例上,来确保整体的性能稳定。 1.4 Producers生产者 和 Consumers消费者1.4.1 Producers生产者 Producers 将数据发布到指定的topics 主题。同时Producer 也能决定将此消息归属于哪个partition;比如基于”round-robin”方式或者通过其他的一些算法等。 1.4.2 Consumers 本质上kafka只支持Topic.每个consumer属于一个consumer group;反过来说,每个group中可以有多个consumer.发送到Topic的消息,只会被订阅此Topic的每个group中的一个consumer消费。 如果所有使用者实例具有相同的使用者组，则记录将有效地在使用者实例上进行负载平衡。 如果所有消费者实例具有不同的消费者组，则每个记录将广播到所有消费者进程。 分析：两个服务器Kafka群集，托管四个分区（P0-P3），包含两个使用者组。消费者组A有两个消费者实例，B组有四个消费者实例。 在Kafka中实现消费consumption 的方式是通过在消费者实例上划分日志中的分区，以便每个实例在任何时间点都是分配的“公平份额”的独占消费者。维护组中成员资格的过程由Kafka协议动态处理。如果新实例加入该组，他们将从该组的其他成员接管一些分区; 如果实例死亡，其分区将分发给其余实例。 Kafka仅提供分区内记录的总订单，而不是主题中不同分区之间的记录。对于大多数应用程序而言，按分区排序与按键分区数据的能力相结合就足够了。但是，如果您需要对记录进行总订单，则可以使用仅包含一个分区的主题来实现，但这将意味着每个使用者组只有一个使用者进程。 1.5 Consumers kafka确保 发送到partitions中的消息将会按照它接收的顺序追加到日志中。也就是说，如果记录M1由与记录M2相同的生成者发送，并且首先发送M1，则M1将具有比M2更低的偏移并且在日志中更早出现。 消费者实例按照它们存储在日志中的顺序查看记录。对于消费者而言,它们消费消息的顺序和日志中消息顺序一致。 如果Topic的”replicationfactor”为N,那么允许N-1个kafka实例失效，我们将容忍最多N-1个服务器故障，而不会丢失任何提交到日志的记录。 1.6 kafka**作为消息系统**Kafka的流概念与传统的企业邮件系统相比如何？ （1）传统消息系统 消息传统上有两种模型：queuing排队 and publish-subscribe发布 - 订阅。在队列中，消费者池可以从服务器读取并且每个记录转到其中一个; 在发布 - 订阅中，记录被广播给所有消费者。这两种模型中的每一种都有优点和缺点。排队的优势在于它允许您在多个消费者实例上划分数据处理，从而可以扩展您的处理。不幸的是，一旦一个进程读取它已经消失的数据，队列就不是多用户。发布 - 订阅允许您将数据广播到多个进程，但由于每条消息都发送给每个订阅者，因此无法进行扩展处理。 kafka的消费者群体概念概括了这两个概念。与队列一样，使用者组允许您将处理划分为一组进程（使用者组的成员）。与发布 - 订阅一样，Kafka允许您向多个消费者组广播消息。 （2）kafka 的优势 Kafka模型的优势在于每个主题都具有这些属性 - 它可以扩展处理并且也是多用户 - 不需要选择其中一个。 与传统的消息系统相比，Kafka具有更强的订购保证。 传统队列在服务器上按顺序保留记录，如果多个消费者从队列中消耗，则服务器按照存储顺序分发记录。但是，虽然服务器按顺序分发记录，但是记录是异步传递给消费者的，因此它们可能会在不同的消费者处出现故障。这实际上意味着在存在并行消耗的情况下丢失记录的顺序。消息传递系统通常通过具有“独占消费者”概念来解决这个问题，该概念只允许一个进程从队列中消耗，但当然这意味着处理中没有并行性。 kafka做得更好。通过在主题中具有并行性概念 - 分区 - ，Kafka能够在消费者流程池中提供订购保证和负载平衡。这是通过将主题中的分区分配给使用者组中的使用者来实现的，以便每个分区仅由该组中的一个使用者使用。通过这样做，我们确保使用者是该分区的唯一读者并按顺序使用数据。由于有许多分区，这仍然可以平衡许多消费者实例的负载。但请注意，消费者组中的消费者实例不能超过分区。 1.7 kafka作为存储系统 任何允许发布与消费消息分离的消息的消息队列实际上充当了正在进行的消息的存储系统。Kafka的不同之处在于它是一个非常好的存储系统。 写入Kafka的数据将写入磁盘并进行复制以实现容错。Kafka允许生产者等待确认，以便在完全复制之前写入不被认为是完整的，并且即使写入的服务器失败也保证写入仍然存在。 磁盘结构Kafka很好地使用了规模 - 无论服务器上有50 KB还是50 TB的持久数据，Kafka都会执行相同的操作。 由于认真对待存储并允许客户端控制其读取位置，您可以将Kafka视为一种专用于高性能，低延迟提交日志存储，复制和传播的专用分布式文件系统。 有关Kafka的提交日志存储和复制设计的详细信息，请阅读此页面。 1.8 kafka用于流处理 仅仅读取，写入和存储数据流是不够的，目的是实现流的实时处理。 在Kafka中，流处理器是指从输入主题获取连续数据流，对此输入执行某些处理以及生成连续数据流以输出主题的任何内容。 例如，零售应用程序可能会接收销售和发货的输入流，并输出重新排序流和根据此数据计算的价格调整。 可以使用生产者和消费者API直接进行简单处理。但是，对于更复杂的转换，Kafka提供了完全集成的Streams API。这允许构建执行非平凡处理的应用程序，这些应用程序可以计算流的聚合或将流连接在一起。 此工具有助于解决此类应用程序面临的难题：处理无序数据，在代码更改时重新处理输入，执行有状态计算等。 流API构建在Kafka提供的核心原语上：它使用生产者和消费者API进行输入，使用Kafka进行有状态存储，并在流处理器实例之间使用相同的组机制来实现容错。 2、kafka使用场景2.1 消息Messaging Kafka可以替代更传统的消息代理。消息代理的使用有多种原因（将处理与数据生成器分离，缓冲未处理的消息等）。与大多数消息传递系统相比，Kafka具有更好的吞吐量，内置分区，复制和容错功能，这使其成为大规模消息处理应用程序的理想解决方案。 根据经验，消息传递的使用通常相对较低，但可能需要较低的端到端延迟，并且通常取决于Kafka提供的强大的耐用性保证。 在这个领域，Kafka可与传统的消息传递系统（如ActiveMQ或 RabbitMQ）相媲美。 2.2 网站活动跟踪 Kafka的原始用例是能够将用户活动跟踪管道重建为一组实时发布 - 订阅源。这意味着站点活动（页面查看，搜索或用户可能采取的其他操作）将发布到中心主题，每个活动类型包含一个主题。这些源可用于订购一系列用例，包括实时处理，实时监控以及加载到Hadoop或离线数据仓库系统以进行脱机处理和报告。 活动跟踪通常非常高，因为为每个用户页面视图生成了许多活动消息。 2.3 度量Metrics Kafka通常用于运营监控数据。这涉及从分布式应用程序聚合统计信息以生成操作数据的集中式提要。 2.4 日志聚合 许多人使用Kafka作为日志聚合解决方案的替代品。日志聚合通常从服务器收集物理日志文件，并将它们放在中央位置（可能是文件服务器或HDFS）进行处理。Kafka抽象出文件的细节，并将日志或事件数据作为消息流更清晰地抽象出来。这允许更低延迟的处理并更容易支持多个数据源和分布式数据消耗。与Scribe或Flume等以日志为中心的系统相比，Kafka提供了同样出色的性能，由于复制而具有更强的耐用性保证，以及更低的端到端延迟。 2.5 流处理 许多Kafka用户在处理由多个阶段组成的管道时处理数据，其中原始输入数据从Kafka主题中消费，然后聚合，丰富或以其他方式转换为新主题以供进一步消费或后续处理。 例如，用于推荐新闻文章的处理管道可以从RSS订阅源抓取文章内容并将其发布到“文章”主题; 进一步处理可能会对此内容进行规范化或重复数据删除，并将已清理的文章内容发布到新主题; 最终处理阶段可能会尝试向用户推荐此内容。此类处理管道基于各个主题创建实时数据流的图形。从0.10.0.0开始，这是一个轻量级但功能强大的流处理库，名为Kafka Streams 在Apache Kafka中可用于执行如上所述的此类数据处理。除了Kafka Streams之外，其他开源流处理工具包括Apache Storm和 Apache Samza。 2.6 Event Sourcing Event Sourcing是一种应用程序设计风格，其中状态更改记录为按时间排序的记录序列。Kafka对非常大的存储日志数据的支持使其成为以这种风格构建的应用程序的出色后端。 2.7 提交日志 Kafka可以作为分布式系统的一种外部提交日志。该日志有助于在节点之间复制数据，并充当故障节点恢复其数据的重新同步机制。Kafka中的日志压缩功能有助于支持此用法。在这种用法中，Kafka类似于Apache BookKeeper项目。 3、kafka安装3.1 下载安装到官网http://kafka.apache.org/downloads.html下载想要的版本；我这里下载的最新稳定版2.1.0 注：由于Kafka控制台脚本对于基于Unix和Windows的平台是不同的，因此在Windows平台上使用bin\\windows\\ 而不是bin/ 将脚本扩展名更改为.bat。 123[root@along ~]# wget http:&#x2F;&#x2F;mirrors.shu.edu.cn&#x2F;apache&#x2F;kafka&#x2F;2.1.0&#x2F;kafka_2.11-2.1.0.tgz[root@along ~]# tar -C &#x2F;data&#x2F; -xvf kafka_2.11-2.1.0.tgz[root@along ~]# cd &#x2F;data&#x2F;kafka_2.11-2.1.0&#x2F; 3.2 配置启动zookeeper kafka正常运行，必须配置zookeeper，否则无论是kafka集群还是客户端的生存者和消费者都无法正常的工作的；所以需要配置启动zookeeper服务。 （1）zookeeper需要java环境 1[root@along ~]# yum -y install java-1.8.0 （2）这里kafka下载包已经包括zookeeper服务，所以只需修改配置文件，启动即可。 如果需要下载指定zookeeper版本；可以单独去zookeeper官网http://mirrors.shu.edu.cn/apache/zookeeper/下载指定版本。 12345[root@along ~]# cd &#x2F;data&#x2F;kafka_2.11-2.1.0&#x2F;[root@along kafka_2.11-2.1.0]# grep &quot;^[^#]&quot; config&#x2F;zookeeper.properties dataDir&#x3D;&#x2F;tmp&#x2F;zookeeper #数据存储目录clientPort&#x3D;2181 #zookeeper端口maxClientCnxns&#x3D;0 注：可自行添加修改zookeeper配置 3.3 配置kafka（1）修改配置文件 1234567891011121314151617181920[root@along kafka_2.11-2.1.0]# grep &quot;^[^#]&quot; config&#x2F;server.properties broker.id&#x3D;0 listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;localhost:9092num.network.threads&#x3D;3 num.io.threads&#x3D;8socket.send.buffer.bytes&#x3D;102400socket.receive.buffer.bytes&#x3D;102400socket.request.max.bytes&#x3D;104857600log.dirs&#x3D;&#x2F;tmp&#x2F;kafka-logsnum.partitions&#x3D;1num.recovery.threads.per.data.dir&#x3D;1offsets.topic.replication.factor&#x3D;1transaction.state.log.replication.factor&#x3D;1transaction.state.log.min.isr&#x3D;1log.retention.hours&#x3D;168log.segment.bytes&#x3D;1073741824log.retention.check.interval.ms&#x3D;300000zookeeper.connect&#x3D;localhost:2181zookeeper.connection.timeout.ms&#x3D;6000group.initial.rebalance.delay.ms&#x3D;0 注：可根据自己需求修改配置文件 broker.id：唯一标识ID listeners=PLAINTEXT://localhost:9092：kafka服务监听地址和端口 log.dirs：日志存储目录 zookeeper.connect：指定zookeeper服务 （2）配置环境变量 1234[root@along ~]# vim &#x2F;etc&#x2F;profile.d&#x2F;kafka.shexport KAFKA_HOME&#x3D;&quot;&#x2F;data&#x2F;kafka_2.11-2.1.0&quot;export PATH&#x3D;&quot;$&#123;KAFKA_HOME&#125;&#x2F;bin:$PATH&quot;[root@along ~]# source &#x2F;etc&#x2F;profile.d&#x2F;kafka.sh （3）配置服务启动脚本 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364[root@along ~]# vim /etc/init.d/kafka#!/bin/sh## chkconfig: 345 99 01# description: Kafka## File : Kafka## Description: Starts and stops the Kafka server# source /etc/rc.d/init.d/functions KAFKA_HOME=/data/kafka_2.11-2.1.0KAFKA_USER=rootexport LOG_DIR=/tmp/kafka-logs [ -e /etc/sysconfig/kafka ] &amp;&amp; . /etc/sysconfig/kafka # See how we were called.case \"$1\" in start) echo -n \"Starting Kafka:\" /sbin/runuser -s /bin/sh $KAFKA_USER -c \"nohup $KAFKA_HOME/bin/kafka-server-start.sh $KAFKA_HOME/config/server.properties &gt; $LOG_DIR/server.out 2&gt; $LOG_DIR/server.err &amp;\" echo \" done.\" exit 0 ;; stop) echo -n \"Stopping Kafka: \" /sbin/runuser -s /bin/sh $KAFKA_USER -c \"ps -ef | grep kafka.Kafka | grep -v grep | awk '&#123;print \\$2&#125;' | xargs kill\" echo \" done.\" exit 0 ;; hardstop) echo -n \"Stopping (hard) Kafka: \" /sbin/runuser -s /bin/sh $KAFKA_USER -c \"ps -ef | grep kafka.Kafka | grep -v grep | awk '&#123;print \\$2&#125;' | xargs kill -9\" echo \" done.\" exit 0 ;; status) c_pid=`ps -ef | grep kafka.Kafka | grep -v grep | awk '&#123;print $2&#125;'` if [ \"$c_pid\" = \"\" ] ; then echo \"Stopped\" exit 3 else echo \"Running $c_pid\" exit 0 fi ;; restart) stop start ;; *) echo \"Usage: kafka &#123;start|stop|hardstop|status|restart&#125;\" exit 1 ;;esac chmod +x kafka ​ chkconfig –add kafka 添加到服务器中 ​ chkconfig kafka on 设置开机自动启动 3.4 启动kafka服务（1）后台启动zookeeper服务 1[root@along ~]# nohup zookeeper-server-start.sh /data/kafka_2.11-2.1.0/config/zookeeper.properties &amp; （2）启动kafka服务 1234567[root@along ~]# service kafka startStarting kafka (via systemctl): [ OK ][root@along ~]# service kafka statusRunning 86018[root@along ~]# ss -nutlNetid State Recv-Q Send-Q Local Address:Port Peer Address:Port tcp LISTEN 0 50 :::9092 :::* tcp LISTEN 0 50 :::2181 :::* 4、kafka使用简单入门4.1 创建主题topics创建一个名为“along”的主题，它只包含一个分区，只有一个副本： 1[root@along ~]# kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic along Created topic \"along\". 如果我们运行list topic命令，我们现在可以看到该主题： 1[root@along ~]# kafka-topics.sh --list --zookeeper localhost:2181 along 4.2 发送一些消息Kafka附带一个命令行客户端，它将从文件或标准输入中获取输入，并将其作为消息发送到Kafka集群。默认情况下，每行将作为单独的消息发送。 运行生产者，然后在控制台中键入一些消息以发送到服务器。 123[root@along ~]# kafka-console-producer.sh --broker-list localhost:9092 --topic along&gt;This is a message&gt;This is another message 4.3 启动消费者Kafka还有一个命令行使用者，它会将消息转储到标准输出。 123[root@along ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic along --from-beginning This is a message This is another message 所有命令行工具都有其他选项; 运行不带参数的命令将显示更详细地记录它们的使用信息。 5、设置多代理kafka群集 到目前为止，我们一直在与一个broker运行，但这并不好玩。对于Kafka，单个代理只是一个大小为1的集群，因此除了启动一些代理实例之外没有太多变化。但是为了感受它，让我们将我们的集群扩展到三个节点（仍然在我们的本地机器上）。 5.1 准备配置文件1234567891011[root@along kafka_2.11-2.1.0]# cd /data/kafka_2.11-2.1.0/[root@along kafka_2.11-2.1.0]# cp config/server.properties config/server-1.properties[root@along kafka_2.11-2.1.0]# cp config/server.properties config/server-2.properties[root@along kafka_2.11-2.1.0]# vim config/server-1.properties broker.id=1 listeners=PLAINTEXT://:9093log.dirs=/tmp/kafka-logs-1[root@along kafka_2.11-2.1.0]# vim config/server-2.propertiesbroker.id=2listeners=PLAINTEXT://:9094log.dirs=/tmp/kafka-logs-2 注：该broker.id 属性是群集中每个节点的唯一且永久的名称。我们必须覆盖端口和日志目录，因为我们在同一台机器上运行这些，并且我们希望让所有代理尝试在同一端口上注册或覆盖彼此的数据。 5.2 开启集群另2个kafka服务1234567[root@along ~]# nohup kafka-server-start.sh &#x2F;data&#x2F;kafka_2.11-2.1.0&#x2F;config&#x2F;server-1.properties &amp;[root@along ~]# nohup kafka-server-start.sh &#x2F;data&#x2F;kafka_2.11-2.1.0&#x2F;config&#x2F;server-2.properties &amp;[root@along ~]# ss -nutlNetid State Recv-Q Send-Q Local Address:Port Peer Address:Port tcp LISTEN 0 50 ::ffff:127.0.0.1:9092 :::* tcp LISTEN 0 50 ::ffff:127.0.0.1:9093 :::* tcp LISTEN 0 50 ::ffff:127.0.0.1:9094 :::* 5.3 在集群中进行操作（1）现在创建一个复制因子为3的新主题my-replicated-topic 12[root@along ~]# kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic Created topic &quot;my-replicated-topic&quot;. （2）在一个集群中，运行“describe topics”命令查看哪个broker正在做什么 123[root@along ~]# kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic Topic:my-replicated-topic PartitionCount:1 ReplicationFactor:3 Configs:Topic: my-replicated-topic Partition: 0 Leader: 2 Replicas: 2,0,1 Isr: 2,0,1 注释：第一行给出了所有分区的摘要，每个附加行提供有关一个分区的信息。由于我们只有一个分区用于此主题，因此只有一行。 “leader”是负责给定分区的所有读取和写入的节点。每个节点将成为随机选择的分区部分的领导者。 “replicas”是复制此分区日志的节点列表，无论它们是否为领导者，或者即使它们当前处于活动状态。 “isr”是“同步”复制品的集合。这是副本列表的子集，该列表当前处于活跃状态并且已经被领导者捕获。 请注意，Leader: 2，在我的示例中，节点2 是该主题的唯一分区的Leader。 （3）可以在我们创建的原始主题上运行相同的命令，以查看它的位置 123[root@along ~]# kafka-topics.sh --describe --zookeeper localhost:2181 --topic along Topic:along PartitionCount:1 ReplicationFactor:1 Configs: Topic: along Partition: 0 Leader: 0 Replicas: 0 Isr: 0 （4）向我们的新主题发布一些消息： 1234[root@along ~]# kafka-console-producer.sh --broker-list localhost:9092 --topic my-replicated-topic&gt;my test message 1&gt;my test message 2&gt;^C （5）现在让我们使用这些消息： 123[root@along ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic my-replicated-topicmy test message 1my test message 2 5.4 测试集群的容错性（1）现在让我们测试一下容错性。Broker 2 充当leader 所以让我们杀了它： 123456[root@along ~]# ps aux | grep server-2.properties |awk &#39;&#123;print $2&#125;&#39;106737[root@along ~]# kill -9 106737[root@along ~]# ss -nutltcp LISTEN 0 50 ::ffff:127.0.0.1:9092 :::* tcp LISTEN 0 50 ::ffff:127.0.0.1:9093 :::* （2）leader 已切换到其中一个从属节点，节点2不再位于同步副本集中： 1234[root@along ~]# kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic Topic:my-replicated-topic PartitionCount:1 ReplicationFactor:3 Configs: Topic: my-replicated-topic Partition: 0 Leader: 0 Replicas: 2,0,1 Isr: 0,1 （3）即使最初接受写入的leader 已经失败，这些消息仍可供消费： 123[root@along ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic my-replicated-topicmy test message 1my test message 2 6、**使用Kafka Connect导入/导出数据** 从控制台写入数据并将其写回控制台是一个方便的起点，但有时候可能希望使用其他来源的数据或将数据从Kafka导出到其他系统。对于许多系统，您可以使用Kafka Connect导入或导出数据，而不是编写自定义集成代码。 Kafka Connect是Kafka附带的工具，用于向Kafka导入和导出数据。它是一个可扩展的工具，运行连接器，实现与外部系统交互的自定义逻辑。在本快速入门中，我们将了解如何使用简单的连接器运行Kafka Connect，这些连接器将数据从文件导入Kafka主题并将数据从Kafka主题导出到文件。 （1）首先创建一些种子数据进行测试： 1[root@along ~]# echo -e &quot;foo\\nbar&quot; &gt; test.txt 或者在Windows上： 1&gt; echo foo&gt; test.txt&gt; echo bar&gt;&gt; test.txt （2）接下来，启动两个以独立模式运行的连接器，这意味着它们在单个本地专用进程中运行。提供三个配置文件作为参数。 第一个始终是Kafka Connect流程的配置，包含常见配置，例如要连接的Kafka代理和数据的序列化格式。 其余配置文件均指定要创建的连接器。这些文件包括唯一的连接器名称，要实例化的连接器类以及连接器所需的任何其他配置。 12345[root@along ~]# connect-standalone.sh config&#x2F;connect-standalone.properties config&#x2F;connect-file-source.properties config&#x2F;connect-file-sink.properties[2019-01-16 16:16:31,884] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:67)[2019-01-16 16:16:31,903] INFO WorkerInfo values:... ... 注：Kafka附带的这些示例配置文件使用您之前启动的默认本地群集配置并创建两个连接器：第一个是源连接器，它从输入文件读取行并生成每个Kafka主题，第二个是宿连接器从Kafka主题读取消息并将每个消息生成为输出文件中的一行。 （3）验证是否导入成功（另起终端） 在启动过程中，您将看到许多日志消息，包括一些指示正在实例化连接器的日志消息。 ① 一旦Kafka Connect进程启动，源连接器应该开始从test.txt主题读取行并将其生成到主题connect-test，并且接收器连接器应该开始从主题读取消息connect-test 并将它们写入文件test.sink.txt。我们可以通过检查输出文件的内容来验证数据是否已通过整个管道传递： 123[root@along ~]# cat test.sink.txtfoobar ② 请注意，数据存储在Kafka主题中connect-test，因此我们还可以运行控制台使用者来查看主题中的数据（或使用自定义使用者代码来处理它）： 123[root@along ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning&#123;&quot;schema&quot;:&#123;&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false&#125;,&quot;payload&quot;:&quot;foo&quot;&#125;&#123;&quot;schema&quot;:&#123;&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false&#125;,&quot;payload&quot;:&quot;bar&quot;&#125; （4）继续追加数据，验证 123456789[root@along ~]# echo Another line&gt;&gt; test.txt [root@along ~]# cat test.sink.txtfoobarAnother line[root@along ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning&#123;&quot;schema&quot;:&#123;&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false&#125;,&quot;payload&quot;:&quot;foo&quot;&#125;&#123;&quot;schema&quot;:&#123;&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false&#125;,&quot;payload&quot;:&quot;bar&quot;&#125;&#123;&quot;schema&quot;:&#123;&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false&#125;,&quot;payload&quot;:&quot;Another line&quot;&#125;","categories":[{"name":"SQL","slug":"SQL","permalink":"https://github.com/cyylog/categories/SQL/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://github.com/cyylog/tags/kafka/"}]},{"title":"kafka集群搭建","slug":"SQL/kafka集群搭建","date":"2019-04-25T16:09:22.000Z","updated":"2020-05-25T13:55:30.117Z","comments":true,"path":"2019/04/26/SQL/kafka集群搭建/","link":"","permalink":"https://github.com/cyylog/2019/04/26/SQL/kafka%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","excerpt":"","text":"常用Message Queue对比RabbitMQ RabbitMQ是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正因如此，它非常重量级，更适合于企业级的开发。同时实现了Broker构架，这意味着消息在发送给客户端时先在中心队列排队。对路由，负载均衡或者数据持久化都有很好的支持。Redis Redis是一个基于Key-Value对的NoSQL数据库，开发维护很活跃。虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。测试数据分为128Bytes、512Bytes、1K和10K四个不同大小的数据。实验表明：入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。ZeroMQ ZeroMQ号称最快的消息队列系统，尤其针对大吞吐量的需求场景。ZeroMQ能够实现RabbitMQ不擅长的高级/复杂的队列，但是开发人员需要自己组合多种技术框架，技术上的复杂度是对这MQ能够应用成功的挑战。ZeroMQ具有一个独特的非中间件的模式，你不需要安装和运行一个消息服务器或中间件，因为你的应用程序将扮演这个服务器角色。你只需要简单的引用ZeroMQ程序库，可以使用NuGet安装，然后你就可以愉快的在应用程序之间发送消息了。但是ZeroMQ仅提供非持久性的队列，也就是说如果宕机，数据将会丢失。其中，Twitter的Storm 0.9.0以前的版本中默认使用ZeroMQ作为数据流的传输（Storm从0.9版本开始同时支持ZeroMQ和Netty作为传输模块）。ActiveMQ ActiveMQ是Apache下的一个子项目。 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。同时类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景。Kafka/Jafka Kafka是Apache下的一个子项目，是一个高性能跨语言分布式发布/订阅消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行加载机制统一了在线和离线的消息处理。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统相关概念producer： 消息生产者，发布消息到 kafka 集群的终端或服务。broker： kafka 集群中包含的服务器。topic：每条发布到 kafka 集群的消息属于的类别，即 kafka 是面向 topic 的。partition： partition 是物理上的概念，每个 topic 包含一个或多个 partition。kafka 分配的单位是 partition。consumer： 从 kafka 集群中消费消息的终端或服务。Consumer group： high-level consumer API 中，每个 consumer 都属于一个 consumer group，每条消息只能被 consumer group 中的一个 Consumer 消费，但可以被多个 consumer group 消费。replica： partition 的副本，保障 partition 的高可用。leader： replica 中的一个角色， producer 和 consumer 只跟 leader 交互。follower： replica 中的一个角色，从 leader 中复制数据。controller： kafka 集群中的其中一个服务器，用来进行 leader election 以及 各种 failover。zookeeper： kafka 通过 zookeeper 来存储集群的 meta 信息 单实例Kafka前提条件：安装JDK、设置JAVA_HOME、PATH环境变量。 wget http://mirrors.hust.edu.cn/apache/kafka/1.1.0/kafka_2.12-1.1.0.tgz (1) Terminal A12345678910111213141516171819202122232425262728293031323334353637383940414243[root@sdopenswan-jp ~]# lsconfigserver.sh kafka_2.12-0.10.2.1.tgz[root@sdopenswan-jp ~]# tar xfz kafka_2.12-0.10.2.1.tgz[root@sdopenswan-jp ~]# lsconfigserver.sh kafka_2.12-0.10.2.1 kafka_2.12-0.10.2.1.tgz[root@sdopenswan-jp ~]# cd kafka_2.12-0.10.2.1[root@sdopenswan-jp kafka_2.12-0.10.2.1]# vim config/zookeeper.properties[root@sdopenswan-jp kafka_2.12-0.10.2.1]# grep -Pv \"^#\" config/zookeeper.propertiesdataDir=zkdata1clientPort=2181maxClientCnxns=0[root@sdopenswan-jp kafka_2.12-0.10.2.1]# bin/zookeeper-server-start.sh config/zookeeper.properties &amp; #启动zookeeper[root@sdopenswan-jp kafka_2.12-0.10.2.1]# lsbin config libs LICENSE logs NOTICE site-docs zkdata1[root@sdopenswan-jp kafka_2.12-0.10.2.1]# ls zkdata1/version-2[root@sdopenswan-jp kafka_2.12-0.10.2.1]# vim config/server.properties[root@sdopenswan-jp kafka_2.12-0.10.2.1]# grep -Pv \"^($|#)\" config/server.propertiesbroker.id=0listeners=PLAINTEXT://:9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=kfkdata1num.partitions=1num.recovery.threads.per.data.dir=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=localhost:2181zookeeper.connection.timeout.ms=6000[root@sdopenswan-jp kafka_2.12-0.10.2.1]# bin/kafka-server-start.sh config/server.properties[root@sdopenswan-jp kafka_2.12-0.10.2.1]# lsbin config kfkdata1 libs LICENSE logs NOTICE site-docs zkdata1[root@sdopenswan-jp kafka_2.12-0.10.2.1]# ls kfkdata1/cleaner-offset-checkpoint meta.properties recovery-point-offset-checkpoint replication-offset-checkpoint[root@sdopenswan-jp kafka_2.12-0.10.2.1]# jps3538 Jps2964 QuorumPeerMain3214 Kafka[root@sdopenswan-jp kafka_2.12-0.10.2.1]# Kafka 占tcp 9092 端口，而zookeeper占 tcp 2181端口 (2) Terminal B 创建 一个topic12345678910111213[root@sdopenswan-jp kafka_2.12-0.10.2.1]# bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partition 1 --topic myfirst-topicWARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both.Created topic \"myfirst_topic\".[root@sdopenswan-jp kafka_2.12-0.10.2.1]# ls kfkdata1/cleaner-offset-checkpoint meta.properties myfirst_topic-0 recovery-point-offset-checkpoint replication-offset-checkpoint[root@sdopenswan-jp kafka_2.12-0.10.2.1]# ls kfkdata1/myfirst-topic-0/00000000000000000000.index 00000000000000000000.log 00000000000000000000.timeindex[root@sdopenswan-jp kafka_2.12-0.10.2.1]#[root@sdopenswan-jp kafka_2.12-0.10.2.1]# bin/kafka-topics.sh --list --zookeeper localhost:2181myfirst-topic[root@sdopenswan-jp kafka_2.12-0.10.2.1]# bin/kafka-console-producer.sh --topic myfirst-topic --broker-list localhost:9092hello world !hello kafka myfirst_topic (3) Terminal C # consumer端连接到zookeeper 读取信息1234[root@sdopenswan-jp kafka_2.12-0.10.2.1]# bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic myfirst_topic --from-beginningUsing the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper].hello world !hello kafka myfirst_topic 配置文件说明Zookeeper配置1) 在zoo.cfg中追加以下内容： 123456789101112131415server.n=ip:portA:portB#n是服务器标识号（1~255）#ip是服务器ip地址#portA是与leader进行信息交换的端口#portB是在leader宕机后，进行leader选举所用的端口例：server.1=200.31.157.116:20881:30881server.2=200.31.157.116:20882:30882server.3=200.31.157.117:20881:30881tickTime：毫秒级的基本时间单位，其他时间如心跳/超时等都为该单位时间的整数倍。initLimit：tickTime的倍数，表示leader选举结束后，followers与leader同步需要的时间，leader的数据非常多或followers比较多时，该值应适当大一些。syncLimit：tickTime的倍数，表示follower和observer与leader交互时的最大等待时间，是在与leader同步完毕之后，正常请求转发或ping等消息交互时的超时时间。clientPort：监听客户端连接的服务端口，若一台服务器上安装多个ZooKeeper server，则需要设置不同的端口号。dataDir：内存数据库快照地址，事务日志地址（除非由dataLogDir另行指定）。 2) 在$dataDir下新建文件myid，并写入服务器标识号 1234#/tmp/zookeeper为dataDircd /tmp/zookeeper/vim myid#在myid中添加服务器标识号 Kafka配置在配置文件server.properties修改如下内容： 12345678#broker.id是broker的标识，具有唯一性broker.id=0#端口号默认为9092port=9092#host.name位kafka所在机器的iphost.name=10.18.42.251#设置zookeeper，可连接多个zookeeper服务器zookeeper.connect=200.31.157.116:2182,200.31.157.116:2183,200.31.157.117:2182 多实例Kafka(1)配置并启动zookeeper123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[root@sdopenswan-jp kafka_2.12-0.10.2.1]# vim config/zookeeper.properties[root@sdopenswan-jp kafka_2.12-0.10.2.1]# grep -Pv \"^#\" config/zookeeper.propertiesdataDir=zkdata1clientPort=2181maxClientCnxns=0tickTime=2000initLimit=5syncLimit=2server.0=172.16.1.16:2888:3888server.1=172.16.2.59:2888:3888server.2=172.16.0.198:2888:3888[root@sdopenswan-jp kafka_2.12-0.10.2.1]# echo 0 &gt; zkdata1/myid[root@sdredis01-jp kafka_2.12-0.10.2.1]# vim config/zookeeper.properties[root@sdredis01-jp kafka_2.12-0.10.2.1]# grep -Pv \"^#\" config/zookeeper.propertiesdataDir=zkdata1clientPort=2181maxClientCnxns=0tickTime=2000initLimit=5syncLimit=2server.0=172.16.1.16:2888:3888server.1=172.16.2.59:2888:3888server.2=172.16.0.198:2888:3888[root@sdredis01-jp kafka_2.12-0.10.2.1]# lsbin config libs LICENSE NOTICE site-docs[root@sdredis01-jp kafka_2.12-0.10.2.1]# mkdir zkdata1[root@sdredis01-jp kafka_2.12-0.10.2.1]# echo 1 &gt; zkdata1/myid[root@sdredis01-jp kafka_2.12-0.10.2.1]#[root@sdredis02-jp kafka_2.12-0.10.2.1]# vim config/zookeeper.properties[root@sdredis02-jp kafka_2.12-0.10.2.1]# grep -Pv \"^#\" config/zookeeper.propertiesdataDir=zkdata1clientPort=2181maxClientCnxns=0tickTime=2000initLimit=5syncLimit=2server.0=172.16.1.16:2888:3888server.1=172.16.2.59:2888:3888server.2=172.16.0.198:2888:3888[root@sdredis02-jp kafka_2.12-0.10.2.1]# mkdir zkdata1[root@sdredis02-jp kafka_2.12-0.10.2.1]# echo 2 &gt; zkdata1/myid[root@sdredis02-jp kafka_2.12-0.10.2.1]#[root@sdopenswan-jp kafka_2.12-0.10.2.1]# bin/zookeeper-server-start.sh config/zookeeper.properties &amp;[root@sdredis01-jp kafka_2.12-0.10.2.1]# bin/zookeeper-server-start.sh config/zookeeper.properties &amp;[root@sdredis02-jp kafka_2.12-0.10.2.1]# bin/zookeeper-server-start.sh config/zookeeper.properties &amp; (2)配置并启动kafka1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283[root@sdopenswan-jp kafka_2.12-0.10.2.1]# vim config/server.properties[root@sdopenswan-jp kafka_2.12-0.10.2.1]# grep -Pv \"^($|#)\" config/server.propertiesbroker.id=0listeners=PLAINTEXT://:9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=kfklognum.partitions=3num.recovery.threads.per.data.dir=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=172.16.1.16:2181,172.16.2.59:2181,172.16.0.198:2181zookeeper.connection.timeout.ms=6000[root@sdopenswan-jp kafka_2.12-0.10.2.1]# vim config/consumer.properties[root@sdopenswan-jp kafka_2.12-0.10.2.1]# grep -Pv \"^($|#)\" config/consumer.propertieszookeeper.connect=172.16.1.16:2181,172.16.2.59:2181,172.16.0.198:2181zookeeper.connection.timeout.ms=6000group.id=test-consumer-group[root@sdopenswan-jp kafka_2.12-0.10.2.1]# vim config/producer.properties[root@sdopenswan-jp kafka_2.12-0.10.2.1]# grep -Pv \"^($|#)\" config/producer.propertiesbootstrap.servers=172.16.1.16:9092,172.16.2.59:9092,172.16.0.198:9092compression.type=none[root@sdopenswan-jp kafka_2.12-0.10.2.1]#[root@sdredis01-jp kafka_2.12-0.10.2.1]# vim config/server.properties[root@sdredis01-jp kafka_2.12-0.10.2.1]# grep -Pv \"^($|#)\" config/server.propertiesbroker.id=1listeners=PLAINTEXT://:9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=kfklognum.partitions=3num.recovery.threads.per.data.dir=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=172.16.1.16:2181,172.16.2.59:2181,172.16.0.198:2181zookeeper.connection.timeout.ms=6000[root@sdredis01-jp kafka_2.12-0.10.2.1]# vim config/consumer.properties[root@sdredis01-jp kafka_2.12-0.10.2.1]# grep -Pv \"^($|#)\" config/consumer.propertieszookeeper.connect=172.16.1.16:2181,172.16.2.59:2181,172.16.0.198:2181zookeeper.connection.timeout.ms=6000group.id=test-consumer-group[root@sdredis01-jp kafka_2.12-0.10.2.1]# vim config/producer.properties[root@sdredis01-jp kafka_2.12-0.10.2.1]# grep -Pv \"^($|#)\" config/producer.propertiesbootstrap.servers=172.16.1.16:9092,172.16.2.59:9092,172.16.0.198:9092compression.type=none[root@sdredis01-jp kafka_2.12-0.10.2.1]#[root@sdredis02-jp kafka_2.12-0.10.2.1]# vim config/server.properties[root@sdredis02-jp kafka_2.12-0.10.2.1]# grep -Pv \"^($|#)\" config/server.propertiesbroker.id=2listeners=PLAINTEXT://:9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=kfklognum.partitions=3num.recovery.threads.per.data.dir=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=172.16.1.16:2181,172.16.2.59:2181,172.16.0.198:2181zookeeper.connection.timeout.ms=6000[root@sdredis02-jp kafka_2.12-0.10.2.1]# vim config/consumer.properties[root@sdredis02-jp kafka_2.12-0.10.2.1]# grep -Pv \"^($|#)\" config/consumer.propertieszookeeper.connect=172.16.1.16:2181,172.16.2.59:2181,172.16.0.198:2181zookeeper.connection.timeout.ms=6000group.id=test-consumer-group[root@sdredis02-jp kafka_2.12-0.10.2.1]# vim config/producer.properties[root@sdredis02-jp kafka_2.12-0.10.2.1]# grep -Pv \"^($|#)\" config/producer.propertiesbootstrap.servers=172.16.1.16:9092,172.16.2.59:9092,172.16.0.198:9092compression.type=none[root@sdredis02-jp kafka_2.12-0.10.2.1]# 三台机器分别启动 bin/kafka-server-start.sh config/server.properties &amp; (3)测试12345678910111213141516171819[root@sdredis02-jp kafka_2.12-0.10.2.1]# bin/kafka-topics.sh --create --zookeeper 172.16.0.198:2181 --replication-factor 3 --partitions 1 --topic yc01_topicWARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both.Created topic \"yc01_topic\".[root@sdredis02-jp kafka_2.12-0.10.2.1]# bin/kafka-topics.sh --list --zookeeper 172.16.0.198:2181myfirst_topicyc01_topic[root@sdredis02-jp kafka_2.12-0.10.2.1]# bin/kafka-topics.sh --describe --zookeeper 172.16.0.198:2181Topic:myfirst_topic PartitionCount:1 ReplicationFactor:1 Configs: Topic: myfirst_topic Partition: 0 Leader: 0 Replicas: 0 Isr: 0Topic:yc01_topic PartitionCount:1 ReplicationFactor:3 Configs: Topic: yc01_topic Partition: 0 Leader: 1 Replicas: 1,2,0 Isr: 1,2,0[root@sdredis02-jp kafka_2.12-0.10.2.1]#[root@sdredis01-jp kafka_2.12-0.10.2.1]# bin/kafka-console-producer.sh --broker-list 172.16.1.16:9092,172.16.2.59:9092,172.16.0.198:9092 --topic yc01_topichello multi instance kafka[root@sdredis02-jp kafka_2.12-0.10.2.1]# bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic yc01_topic --from-beginningUsing the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper].hello multi instance kafka (4)查看zookeeper状态12345678910111213141516171819202122232425262728293031323334353637383940414243[root@sdopenswan-jp kafka_2.12-0.10.2.1]# echo stat|nc 127.0.0.1 2181Zookeeper version: 3.4.9-1757313, built on 08/23/2016 06:50 GMTClients: /127.0.0.1:46010[0](queued=0,recved=1,sent=0) /172.16.0.198:53940[1](queued=0,recved=875,sent=875)Latency min/avg/max: 0/0/4Received: 890Sent: 889Connections: 2Outstanding: 0Zxid: 0x100000060Mode: leaderNode count: 33[root@sdopenswan-jp kafka_2.12-0.10.2.1]#[root@sdredis01-jp kafka_2.12-0.10.2.1]# echo stat|nc 127.0.0.1 2181Zookeeper version: 3.4.9-1757313, built on 08/23/2016 06:50 GMTClients: /127.0.0.1:53466[0](queued=0,recved=1,sent=0)Latency min/avg/max: 0/0/0Received: 2Sent: 1Connections: 1Outstanding: 0Zxid: 0x10000005dMode: followerNode count: 33[root@sdredis02-jp kafka_2.12-0.10.2.1]# echo stat|nc 127.0.0.1 2181Zookeeper version: 3.4.9-1757313, built on 08/23/2016 06:50 GMTClients: /172.16.2.59:53354[1](queued=0,recved=952,sent=952) /172.16.1.16:53038[1](queued=0,recved=1018,sent=1023) /127.0.0.1:49478[0](queued=0,recved=1,sent=0)Latency min/avg/max: 0/0/15Received: 2566Sent: 2572Connections: 3Outstanding: 0Zxid: 0x100000060Mode: followerNode count: 33[root@sdredis02-jp kafka_2.12-0.10.2.1]# (5)常用命令总结1234567891011bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 2 --partitions 4 --topic testbin/kafka-topics.sh --describe --zookeeper bin/kafka-console-producer.sh --broker-list localhost:9092 --topic testbin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic testbin/kafka-console-producer.sh --broker-list localhost:9092 --topic test --producer.config config/producer.propertiesbin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --new-consumer --from-beginning --consumer.config config/consumer.propertiesbin/kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --listbin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zkconnect localhost:2181 --group testbin/kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --describe --group test-consumer-groupbin/kafka-preferred-replica-election.sh --zookeeper zk_host:port/chrootbin/kafka-producer-perf-test.sh --topic test --num-records 100 --record-size 1 --throughput 100 --producer-props bootstrap.servers=localhost:9092 用户在客户端可以通过 telnet 或 nc 向 ZooKeeper 提交相应的命令 可以通过命令：echo stat|nc 127.0.0.1 2181 来查看哪个节点被选择作为follower或者leader 使用echo ruok|nc 127.0.0.1 2181 测试是否启动了该Server，若回复imok表示已经启动。 echo dump| nc 127.0.0.1 2181 ,列出未经处理的会话和临时节点。 echo kill | nc 127.0.0.1 2181 ,关掉server echo conf | nc 127.0.0.1 2181 ,输出相关服务配置的详细信息。 echo cons | nc 127.0.0.1 2181 ,列出所有连接到服务器的客户端的完全的连接 / 会话的详细信息。 echo envi |nc 127.0.0.1 2181 ,输出关于服务环境的详细信息（区别于 conf 命令）。 echo reqs | nc 127.0.0.1 2181 ,列出未经处理的请求。 echo wchs | nc 127.0.0.1 2181 ,列出服务器 watch 的详细信息。 echo wchc | nc 127.0.0.1 2181 ,通过 session 列出服务器 watch 的详细信息，它的输出是一个与 watch 相关的会话的列表。 echo wchp | nc 127.0.0.1 2181 ,通过路径列出服务器 watch 的详细信息。它输出一个与 session 相关的路径 补充新实验过程(参考)teacher配置如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071[root@teacher ~]# vim /etc/profile[root@teacher ~]# source /etc/profile[root@teacher ~]# echo $JAVA_HOME/usr/java/latest[root@teacher ~]# which java/usr/java/latest/bin/java[root@teacher ~]# java -versionjava version \"1.8.0_162\"Java(TM) SE Runtime Environment (build 1.8.0_162-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.162-b12, mixed mode)[root@teacher ~]#[root@teacher ~]# scp /etc/profile node2:/etc/profile 100% 1859 549.7KB/s 00:00 [root@teacher ~]# scp /etc/profile node3:/etc/profile 100% 1859 448.7KB/s 00:00 [root@teacher ~]#[root@teacher ~]# tar xf kafka_2.12-1.1.0.tgz -C /usr/local/[root@teacher opt]# cd /usr/local/[root@teacher local]# ln -s kafka_2.12-1.1.0/ kafka[root@teacher local]# lsbin etc games include kafka kafka_2.12-1.1.0 lib lib64 libexec logstash php sbin share src zabbix[root@teacher local]# cd kafka[root@teacher kafka]# mkdir zkdata[root@teacher kafka]# mkdir kfklog[root@teacher kafka]# echo 0 &gt; zkdata/myid[root@teacher kafka]# vim config/zookeeper.properties [root@teacher kafka]# grep -Pv \"^(#|$)\" config/zookeeper.propertiesdataDir=zkdataclientPort=2181maxClientCnxns=0tickTime=2000initLimit=5syncLimit=2server.0=192.168.233.102:2888:3888server.1=192.168.233.103:2888:3888server.2=192.168.233.104:2888:3888[root@teacher kafka]# vim config/server.properties [root@teacher kafka]# grep -Pv \"^(#|$)\" config/server.properties broker.id=0listeners=PLAINTEXT://:9092advertised.listeners=PLAINTEXT://192.168.233.102:9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=kfklognum.partitions=3num.recovery.threads.per.data.dir=1offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=192.168.233.102:2181,192.168.233.103:2181,192.168.233.104:2181zookeeper.connection.timeout.ms=6000group.initial.rebalance.delay.ms=0[root@teacher kafka]# vim config/consumer.properties [root@teacher kafka]# grep -Pv \"^(#|$)\" config/consumer.properties bootstrap.servers=192.168.233.102:9092,192.168.233.103:9092,192.168.233.104:9092zookeeper.connect=192.168.233.102:2181,192.168.233.103:2181,192.168.233.104:2181group.id=test-consumer-group[root@teacher kafka]# vim config/producer.properties [root@teacher kafka]# grep -Pv \"^(#|$)\" config/producer.properties bootstrap.servers=192.168.233.102:9092,192.168.233.103:9092,192.168.233.104:9092compression.type=none[root@teacher ~]# cd /usr/local/[root@teacher local]# scp -r kafkakafka/ kafka_2.12-1.1.0/ [root@teacher local]# scp -r kafka_2.12-1.1.0 node2:/usr/local/ node2配置如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[root@node2 ~]# java -version java version \"1.8.0_162\"Java(TM) SE Runtime Environment (build 1.8.0_162-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.162-b12, mixed mode)[root@node2 ~]# source /etc/profile[root@node2 ~]# echo $JAVA_HOME/usr/java/latest[root@node2 ~]# which java/usr/java/latest/bin/java[root@node2 ~]# tail -3 /etc/hosts192.168.233.102 teacher192.168.233.103 node2192.168.233.104 node3[root@node2 ~]# cd /usr/local/[root@node2 local]# ln -s kafka_2.12-1.1.0 kafka[root@node2 local]# cd kafka[root@node2 kafka]# echo 1 &gt; zkdata/myid [root@node2 kafka]# vim config/server.properties [root@node2 kafka]# vim config/consumer.properties [root@node2 kafka]# vim config/producer.properties [root@node2 kafka]# grep -Pv \"^(#|$)\" config/zookeeper.properties dataDir=zkdataclientPort=2181maxClientCnxns=0tickTime=2000initLimit=5syncLimit=2server.0=192.168.233.102:2888:3888server.1=192.168.233.103:2888:3888server.2=192.168.233.104:2888:3888[root@node2 kafka]# grep -Pv \"^(#|$)\" config/server.properties broker.id=1listeners=PLAINTEXT://:9092advertised.listeners=PLAINTEXT://192.168.233.103:9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=kfklognum.partitions=3num.recovery.threads.per.data.dir=1offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=192.168.233.102:2181,192.168.233.103:2181,192.168.233.104:2181zookeeper.connection.timeout.ms=6000group.initial.rebalance.delay.ms=0[root@node2 kafka]# grep -Pv \"^(#|$)\" config/consumer.properties bootstrap.servers=192.168.233.102:9092,192.168.233.103:9092,192.168.233.104:9092zookeeper.connect=192.168.233.102:2181,192.168.233.103:2181,192.168.233.104:2181group.id=test-consumer-group[root@node2 kafka]# grep -Pv \"^(#|$)\" config/producer.properties bootstrap.servers=192.168.233.102:9092,192.168.233.103:9092,192.168.233.104:9092compression.type=none[root@node2 kafka]# node3配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[root@node3 ~]# cd /usr/local/[root@node3 local]# ln -s kafka_2.12-1.1.0 kafka[root@node3 local]# lsbin etc games include kafka kafka_2.12-1.1.0 lib lib64 libexec sbin share src[root@node3 local]# cd kafka[root@node3 kafka]# lsbin config kfklog libs LICENSE NOTICE site-docs zkdata[root@node3 kafka]# echo 2 &gt; zkdata/myid [root@node3 kafka]# vim config/server.properties [root@node3 kafka]# grep -Pv \"^(#|$)\" config/zookeeper.properties dataDir=zkdataclientPort=2181maxClientCnxns=0tickTime=2000initLimit=5syncLimit=2server.0=192.168.233.102:2888:3888server.1=192.168.233.103:2888:3888server.2=192.168.233.104:2888:3888[root@node3 kafka]# grep -Pv \"^(#|$)\" config/server.properties broker.id=2listeners=PLAINTEXT://:9092advertised.listeners=PLAINTEXT://192.168.233.104:9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=kfklognum.partitions=3num.recovery.threads.per.data.dir=1offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=192.168.233.102:2181,192.168.233.103:2181,192.168.233.104:2181zookeeper.connection.timeout.ms=6000group.initial.rebalance.delay.ms=0[root@node3 kafka]# grep -Pv \"^(#|$)\" config/consumer.properties bootstrap.servers=192.168.233.102:9092,192.168.233.103:9092,192.168.233.104:9092zookeeper.connect=192.168.233.102:2181,192.168.233.103:2181,192.168.233.104:2181group.id=test-consumer-group[root@node3 kafka]# grep -Pv \"^(#|$)\" config/producer.properties bootstrap.servers=192.168.233.102:9092,192.168.233.103:9092,192.168.233.104:9092compression.type=none[root@node3 kafka]# 启动zookeeper 123[root@teacher kafka]# bin/zookeeper-server-start.sh config/zookeeper.properties &amp; [root@node2 kafka]# bin/zookeeper-server-start.sh config/zookeeper.properties &amp;[root@node3 kafka]# bin/zookeeper-server-start.sh config/zookeeper.properties &amp; 启动kafka 123[root@teacher kafka]# bin/kafka-server-start.sh config/server.properties &amp;[root@node2 kafka]# bin/kafka-server-start.sh config/server.properties &amp;[root@node3 kafka]# bin/kafka-server-start.sh config/server.properties &amp;","categories":[{"name":"SQL","slug":"SQL","permalink":"https://github.com/cyylog/categories/SQL/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://github.com/cyylog/tags/kafka/"}]},{"title":"ansible","slug":"Linux/ansible","date":"2019-04-16T15:50:14.000Z","updated":"2020-05-25T13:53:31.482Z","comments":true,"path":"2019/04/16/Linux/ansible/","link":"","permalink":"https://github.com/cyylog/2019/04/16/Linux/ansible/","excerpt":"","text":"自动化运维工具—ansible详解一、ansible 简介1、ansible 是什么？ ansible是目前最受运维欢迎的自动化运维工具，基于Python开发，集合了众多运维工具（SaltStack puppet、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能。 ansible是基于 paramiko 开发的,并且基于模块化工作，本身没有批量部署的能力。真正具有批量部署的是ansible所运行的模块，ansible只是提供一种框架。ansible不需要在远程主机上安装client/agents，因为它们是基于ssh来和远程主机通讯的。ansible目前已经已经被红帽官方收购，是自动化运维工具中大家认可度最高的，并且上手容易，学习简单。是每位运维工程师必须掌握的技能之一。 2、ansible 特点 部署简单，只需在主控端部署Ansible环境，被控端无需做任何操作； 默认使用SSH协议对设备进行管理； 有大量常规运维操作模块，可实现日常绝大部分操作； 配置简单、功能强大、扩展性强； 支持API及自定义模块，可通过Python轻松扩展； 通过Playbooks来定制强大的配置、状态管理； 轻量级，无需在客户端安装agent，更新时，只需在操作机上进行一次更新即可； 提供一个功能强大、操作性强的Web管理界面和REST API接口——AWX平台。 3、ansible 架构图 Ansible：Ansible核心程序。HostInventory：记录由Ansible管理的主机信息，包括端口、密码、ip等。Playbooks：“剧本”YAML格式文件，多个任务定义在一个文件中，定义主机需要调用哪些模块来完成的功能。CoreModules：核心模块，主要操作是通过调用核心模块来完成管理任务。CustomModules：自定义模块，完成核心模块无法完成的功能，支持多种语言。ConnectionPlugins：连接插件，Ansible和Host通信使用 二、ansible 任务执行1、ansible 任务执行模式 Ansible 系统由控制主机对被管节点的操作方式可分为两类，即ad-hoc和playbook： ad-hoc模式(点对点模式)使用单个模块，支持批量执行单条命令。ad-hoc 命令是一种可以快速输入的命令，而且不需要保存起来的命令。就相当于bash中的一句话shell。 playbook模式(剧本模式)是Ansible主要管理方式，也是Ansible功能强大的关键所在。playbook通过多个task集合完成一类功能，如Web服务的安装部署、数据库服务器的批量备份等。可以简单地把playbook理解为通过组合多条ad-hoc操作的配置文件。 2、ansible 执行流程 简单理解就是Ansible在运行时， 首先读取ansible.cfg中的配置， 根据规则获取Inventory中的管理主机列表， 并行的在这些主机中执行配置的任务， 最后等待执行返回的结果。 3、ansible 命令执行过程 加载自己的配置文件，默认/etc/ansible/ansible.cfg； 查找对应的主机配置文件，找到要执行的主机或者组； 加载自己对应的模块文件，如 command； 通过ansible将模块或命令生成对应的临时py文件(python脚本)， 并将该文件传输至远程服务器； 对应执行用户的家目录的.ansible/tmp/XXX/XXX.PY文件； 给文件 +x 执行权限； 执行并返回结果； 删除临时py文件，sleep 0退出； 三、ansible 配置详解1、ansible 安装方式 ansible安装常用两种方式，yum 安装 和 pip 程序安装。下面我们来详细介绍一下这两种安装方式。 2、使用 pip（python的包管理模块）安装 首先，我们需要安装一个python-pip包，安装完成以后，则直接使用pip命令来安装我们的包，具体操作过程如下： 12yum install python-pippip install ansible 4、使用 yum 安装 yum 安装是我们很熟悉的安装方式了。我们需要先安装一个epel-release包，然后再安装我们的 ansible 即可。 12yum install epel-release -yyum install ansible –y 5、ansible 程序结构安装目录如下(yum安装)： 配置文件目录：/etc/ansible/ 执行文件目录：/usr/bin/ Lib库依赖目录：/usr/lib/pythonX.X/site-packages/ansible/ Help文档目录：/usr/share/doc/ansible-X.X.X/ Man文档目录：/usr/share/man/man1/ 6、ansible配置文件查找顺序 ansible与我们其他的服务在这一点上有很大不同，这里的配置文件查找是从多个地方找的，顺序如下： 检查环境变量ANSIBLE_CONFIG指向的路径文件(export ANSIBLE_CONFIG=/etc/ansible.cfg)； ~/.ansible.cfg，检查当前目录下的ansible.cfg配置文件； /etc/ansible.cfg检查etc目录的配置文件。 7、ansible配置文件 ansible 的配置文件为/etc/ansible/ansible.cfg，ansible 有许多参数，下面我们列出一些常见的参数： 12345678inventory &#x3D; &#x2F;etc&#x2F;ansible&#x2F;hosts #这个参数表示资源清单inventory文件的位置library &#x3D; &#x2F;usr&#x2F;share&#x2F;ansible #指向存放Ansible模块的目录，支持多个目录方式，只要用冒号（：）隔开就可以forks &#x3D; 5 #并发连接数，默认为5sudo_user &#x3D; root #设置默认执行命令的用户remote_port &#x3D; 22 #指定连接被管节点的管理端口，默认为22端口，建议修改，能够更加安全host_key_checking &#x3D; False #设置是否检查SSH主机的密钥，值为True&#x2F;False。关闭后第一次连接不会提示配置实例timeout &#x3D; 60 #设置SSH连接的超时时间，单位为秒log_path &#x3D; &#x2F;var&#x2F;log&#x2F;ansible.log #指定一个存储ansible日志的文件（默认不记录日志） 8、ansuble主机清单 在配置文件中，我们提到了资源清单，这个清单就是我们的主机清单，里面保存的是一些 ansible 需要连接管理的主机列表。我们可以来看看他的定义方式： 123456789101、 直接指明主机地址或主机名： # green.example.com # blue.example.com # 192.168.100.1 # 192.168.100.102、 定义一个主机组[组名]把地址或主机名加进去 [mysql_test] 192.168.253.159 192.168.253.160 192.168.253.153 需要注意的是，这里的组成员可以使用通配符来匹配，这样对于一些标准化的管理来说就很轻松方便了。 我们可以根据实际情况来配置我们的主机列表，具体操作如下： 1234[root@server ~]# vim &#x2F;etc&#x2F;ansible&#x2F;hosts [web] 192.168.37.122 192.168.37.133 四、ansible 常用命令1、ansible 命令集 /usr/bin/ansible Ansibe AD-Hoc 临时命令执行工具，常用于临时命令的执行/usr/bin/ansible-doc Ansible 模块功能查看工具/usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块 的官网平台，基于网络的/usr/bin/ansible-playbook Ansible 定制自动化的任务集编排工具/usr/bin/ansible-pull Ansible远程执行命令的工具，拉取配置而非推送配置（使用较少，海量机器时使用，对运维的架构能力要求较高）/usr/bin/ansible-vault Ansible 文件加密工具/usr/bin/ansible-console Ansible基于Linux Consoble界面可与用户交互的命令执行工具 其中，我们比较常用的是/usr/bin/ansible和/usr/bin/ansible-playbook。 2、ansible-doc 命令 ansible-doc 命令常用于获取模块信息及其使用帮助，一般用法如下： 12ansible-doc -l #获取全部模块的信息ansible-doc -s MOD_NAME #获取指定模块的使用帮助 我们也可以查看一下ansible-doc的全部用法： 123456789101112[root@server ~]# ansible-docUsage: ansible-doc [options] [module...]Options: -h, --help show this help message and exit # 显示命令参数API文档 -l, --list List available modules #列出可用的模块 -M MODULE_PATH, --module-path&#x3D;MODULE_PATH #指定模块的路径 specify path(s) to module library (default&#x3D;None) -s, --snippet Show playbook snippet for specified module(s) #显示playbook制定模块的用法 -v, --verbose verbose mode (-vvv for more, -vvvv to enable # 显示ansible-doc的版本号查看模块列表： connection debugging) --version show program&#39;s version number and exit 我们可以来看一下，以mysql相关的为例： 123456[root@server ~]# ansible-doc -l |grep mysqlmysql_db Add or remove MySQL databases from a remote...mysql_replication Manage MySQL replication mysql_user Adds or removes a user from a MySQL databas...mysql_variables Manage MySQL global variables [root@server ~]# ansible-doc -s mysql_user 2、ansible 命令详解 命令的具体格式如下： 1ansible &lt;host-pattern&gt; [-f forks] [-m module_name] [-a args] 也可以通过ansible -h来查看帮助，下面我们列出一些比较常用的选项，并解释其含义： -a MODULE_ARGS #模块的参数，如果执行默认COMMAND的模块，即是命令参数，如： “date”，“pwd”等等-k，--ask-pass #ask for SSH password。登录密码，提示输入SSH密码而不是假设基于密钥的验证--ask-su-pass #ask for su password。su切换密码-K，--ask-sudo-pass #ask for sudo password。提示密码使用sudo，sudo表示提权操作--ask-vault-pass #ask for vault password。假设我们设定了加密的密码，则用该选项进行访问-B SECONDS #后台运行超时时间-C #模拟运行环境并进行预运行，可以进行查错测试-c CONNECTION #连接类型使用-f FORKS #并行任务数，默认为5-i INVENTORY #指定主机清单的路径，默认为/etc/ansible/hosts--list-hosts #查看有哪些主机组-m MODULE_NAME #执行模块的名字，默认使用 command 模块，所以如果是只执行单一命令可以不用 -m参数-o #压缩输出，尝试将所有结果在一行输出，一般针对收集工具使用-S #用 su 命令-R SU_USER #指定 su 的用户，默认为 root 用户-s #用 sudo 命令-U SUDO_USER #指定 sudo 到哪个用户，默认为 root 用户-T TIMEOUT #指定 ssh 默认超时时间，默认为10s，也可在配置文件中修改-u REMOTE_USER #远程用户，默认为 root 用户-v #查看详细信息，同时支持-vvv，-vvvv可查看更详细信息 3、ansible 配置公私钥 上面我们已经提到过 ansible 是基于 ssh 协议实现的，所以其配置公私钥的方式与 ssh 协议的方式相同，具体操作步骤如下： 12345#1.生成私钥[root@server ~]# ssh-keygen #2.向主机分发私钥[root@server ~]# ssh-copy-id root@192.168.37.122[root@server ~]# ssh-copy-id root@192.168.37.133 这样的话，就可以实现无密码登录，我们的实验过程也会顺畅很多。 注意，如果出现了一下报错： 1-bash: ssh-copy-id: command not found 那么就证明我们需要安装一个包： 1yum -y install openssh-clientsansible 把包安装上即可。 五、ansible 常用模块1、主机连通性测试 我们使用ansible web -m ping命令来进行主机连通性测试，效果如下： 123456789[root@server ~]# ansible web -m ping192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125; 这样就说明我们的主机是连通状态的。接下来的操作才可以正常进行。 2、command 模块 这个模块可以直接在远程主机上执行命令，并将结果返回本主机。 举例如下： 12345678910111213141516171819202122232425[root@server ~]# ansible web -m command -a &#39;ss -ntl&#39;192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:111 *:* LISTEN 0 5 192.168.122.1:53 *:* LISTEN 0 128 *:22 *:* LISTEN 0 128 127.0.0.1:631 *:* LISTEN 0 128 *:23000 *:* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 128 :::111 :::* LISTEN 0 128 :::22 :::* LISTEN 0 128 ::1:631 :::* LISTEN 0 100 ::1:25 :::* 192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:111 *:* LISTEN 0 128 *:22 *:* LISTEN 0 128 127.0.0.1:631 *:* LISTEN 0 128 *:23000 *:* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 128 :::111 :::* LISTEN 0 128 :::22 :::* LISTEN 0 128 ::1:631 :::* LISTEN 0 100 ::1:25 :::* 命令模块接受命令名称，后面是空格分隔的列表参数。给定的命令将在所有选定的节点上执行。它不会通过shell进行处理，比如$HOME和操作如”&lt;”，”&gt;”，”|”，”;”，”&amp;” 工作（需要使用（shell）模块实现这些功能）。注意，该命令不支持| 管道命令。 下面来看一看该模块下常用的几个命令： chdir # 在执行命令之前，先切换到该目录executable # 切换shell来执行命令，需要使用命令的绝对路径free_form # 要执行的Linux指令，一般使用Ansible的-a参数代替。creates # 一个文件名，当这个文件存在，则该命令不执行,可以用来做判断removes # 一个文件名，这个文件不存在，则该命令不执行 下面我们来看看这些命令的执行效果： 12345678910111213141516171819202122232425262728[root@server ~]# ansible web -m command -a &#39;chdir&#x3D;&#x2F;data&#x2F; ls&#39; #先切换到&#x2F;data&#x2F; 目录，再执行“ls”命令192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;aaa.jpgfastdfsmogdatatmpwebwKgleloeYoCAMLtZAAAWEekAtkc497.jpg192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;aaa.jpgfastdfsmogdatatmpwebwKgleloeYoCAMLtZAAAWEekAtkc497.jpg[root@server ~]# ansible web -m command -a &#39;creates&#x3D;&#x2F;data&#x2F;aaa.jpg ls&#39; #如果&#x2F;data&#x2F;aaa.jpg存在，则不执行“ls”命令192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;skipped, since &#x2F;data&#x2F;aaa.jpg exists192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;skipped, since &#x2F;data&#x2F;aaa.jpg exists[root@server ~]# ansible web -m command -a &#39;removes&#x3D;&#x2F;data&#x2F;aaa.jpg cat &#x2F;data&#x2F;a&#39; #如果&#x2F;data&#x2F;aaa.jpg存在，则执行“cat &#x2F;data&#x2F;a”命令192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;hello192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;hello 3、shell 模块 shell模块可以在远程主机上调用shell解释器运行命令，支持shell的各种功能，例如管道等。 123456[root@server ~]# ansible web -m shell -a &#39;cat &#x2F;etc&#x2F;passwd |grep &quot;keer&quot;&#39;192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;keer:x:10001:1000:keer:&#x2F;home&#x2F;keer:&#x2F;bin&#x2F;sh192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;keer:x:10001:10001::&#x2F;home&#x2F;keer:&#x2F;bin&#x2F;sh 只要是我们的shell命令，都可以通过这个模块在远程主机上运行，这里就不一一举例了。 4、copy 模块 这个模块用于将文件复制到远程主机，同时支持给定内容生成文件和修改权限等。 其相关选项如下： src #被复制到远程主机的本地文件。可以是绝对路径，也可以是相对路径。如果路径是一个目录，则会递归复制，用法类似于”rsync”content #用于替换”src”，可以直接指定文件的值dest #必选项，将源文件复制到的远程主机的绝对路径backup #当文件内容发生改变后，在覆盖之前把源文件备份，备份文件包含时间信息directory_mode #递归设定目录的权限，默认为系统默认权限force #当目标主机包含该文件，但内容不同时，设为”yes”，表示强制覆盖；设为”no”，表示目标主机的目标位置不存在该文件才复制。默认为”yes”others #所有的 file 模块中的选项可以在这里使用 用法举例如下：① 复制文件： 1234567891011121314151617181920212223242526272829[root@server ~]# ansible web -m copy -a &#39;src&#x3D;~&#x2F;hello dest&#x3D;&#x2F;data&#x2F;hello&#39; 192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;checksum&quot;: &quot;22596363b3de40b06f981fb85d82312e8c0ed511&quot;, &quot;dest&quot;: &quot;&#x2F;data&#x2F;hello&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;6f5902ac237024bdd0c176cb93063dc4&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 12, &quot;src&quot;: &quot;&#x2F;root&#x2F;.ansible&#x2F;tmp&#x2F;ansible-tmp-1512437093.55-228281064292921&#x2F;source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;checksum&quot;: &quot;22596363b3de40b06f981fb85d82312e8c0ed511&quot;, &quot;dest&quot;: &quot;&#x2F;data&#x2F;hello&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;6f5902ac237024bdd0c176cb93063dc4&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 12, &quot;src&quot;: &quot;&#x2F;root&#x2F;.ansible&#x2F;tmp&#x2F;ansible-tmp-1512437093.74-44694985235189&#x2F;source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125; ② 给定内容生成文件，并制定权限 1234567891011121314151617181920212223242526272829[root@server ~]# ansible web -m copy -a &#39;content&#x3D;&quot;I am keer\\n&quot; dest&#x3D;&#x2F;data&#x2F;name mode&#x3D;666&#39;192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;checksum&quot;: &quot;0421570938940ea784f9d8598dab87f07685b968&quot;, &quot;dest&quot;: &quot;&#x2F;data&#x2F;name&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;497fa8386590a5fc89090725b07f175c&quot;, &quot;mode&quot;: &quot;0666&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 10, &quot;src&quot;: &quot;&#x2F;root&#x2F;.ansible&#x2F;tmp&#x2F;ansible-tmp-1512437327.37-199512601767687&#x2F;source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;checksum&quot;: &quot;0421570938940ea784f9d8598dab87f07685b968&quot;, &quot;dest&quot;: &quot;&#x2F;data&#x2F;name&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;497fa8386590a5fc89090725b07f175c&quot;, &quot;mode&quot;: &quot;0666&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 10, &quot;src&quot;: &quot;&#x2F;root&#x2F;.ansible&#x2F;tmp&#x2F;ansible-tmp-1512437327.55-218104039503110&#x2F;source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125; 我们现在可以去查看一下我们生成的文件及其权限： 12345678[root@server ~]# ansible web -m shell -a &#39;ls -l &#x2F;data&#x2F;&#39;192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;total 28-rw-rw-rw- 1 root root 12 Dec 6 09:45 name192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;total 40-rw-rw-rw- 1 root root 12 Dec 5 09:45 name 可以看出我们的name文件已经生成，并且权限为666。③ 关于覆盖 我们把文件的内容修改一下，然后选择覆盖备份： 12345678910111213141516171819202122232425262728293031[root@server ~]# ansible web -m copy -a &#39;content&#x3D;&quot;I am keerya\\n&quot; backup&#x3D;yes dest&#x3D;&#x2F;data&#x2F;name mode&#x3D;666&#39;192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;backup_file&quot;: &quot;&#x2F;data&#x2F;name.4394.2017-12-06@09:46:25~&quot;, &quot;changed&quot;: true, &quot;checksum&quot;: &quot;064a68908ab9971ee85dbc08ea038387598e3778&quot;, &quot;dest&quot;: &quot;&#x2F;data&#x2F;name&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;8ca7c11385856155af52e560f608891c&quot;, &quot;mode&quot;: &quot;0666&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 12, &quot;src&quot;: &quot;&#x2F;root&#x2F;.ansible&#x2F;tmp&#x2F;ansible-tmp-1512438383.78-228128616784888&#x2F;source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;backup_file&quot;: &quot;&#x2F;data&#x2F;name.5962.2017-12-05@09:46:24~&quot;, &quot;changed&quot;: true, &quot;checksum&quot;: &quot;064a68908ab9971ee85dbc08ea038387598e3778&quot;, &quot;dest&quot;: &quot;&#x2F;data&#x2F;name&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;8ca7c11385856155af52e560f608891c&quot;, &quot;mode&quot;: &quot;0666&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 12, &quot;src&quot;: &quot;&#x2F;root&#x2F;.ansible&#x2F;tmp&#x2F;ansible-tmp-1512438384.0-170718946740009&#x2F;source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125; 现在我们可以去查看一下： 12345678910[root@server ~]# ansible web -m shell -a &#39;ls -l &#x2F;data&#x2F;&#39;192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;total 28-rw-rw-rw- 1 root root 12 Dec 6 09:46 name-rw-rw-rw- 1 root root 10 Dec 6 09:45 name.4394.2017-12-06@09:46:25~192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;total 40-rw-rw-rw- 1 root root 12 Dec 5 09:46 name-rw-rw-rw- 1 root root 10 Dec 5 09:45 name.5962.2017-12-05@09:46:24~ 可以看出，我们的源文件已经被备份，我们还可以查看一下name文件的内容： 123456[root@server ~]# ansible web -m shell -a &#39;cat &#x2F;data&#x2F;name&#39;192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;I am keerya192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;I am keerya 证明，这正是我们新导入的文件的内容。 5、file 模块 该模块主要用于设置文件的属性，比如创建文件、创建链接文件、删除文件等。 下面是一些常见的命令： force #需要在两种情况下强制创建软链接，一种是源文件不存在，但之后会建立的情况下；另一种是目标软链接已存在，需要先取消之前的软链，然后创建新的软链，有两个选项：yes|nogroup #定义文件/目录的属组。后面可以加上mode：定义文件/目录的权限owner #定义文件/目录的属主。后面必须跟上path：定义文件/目录的路径recurse #递归设置文件的属性，只对目录有效，后面跟上src：被链接的源文件路径，只应用于state=link的情况dest #被链接到的路径，只应用于state=link的情况state #状态，有以下选项： directory：如果目录不存在，就创建目录file：即使文件不存在，也不会被创建link：创建软链接hard：创建硬链接touch：如果文件不存在，则会创建一个新的文件，如果文件或目录已存在，则更新其最后修改时间absent：删除目录、文件或者取消链接文件 用法举例如下：① 创建目录： 1234567891011121314151617181920212223[root@server ~]# ansible web -m file -a &#39;path&#x3D;&#x2F;data&#x2F;app state&#x3D;directory&#39;192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;mode&quot;: &quot;0755&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;path&quot;: &quot;&#x2F;data&#x2F;app&quot;, &quot;size&quot;: 6, &quot;state&quot;: &quot;directory&quot;, &quot;uid&quot;: 0&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;mode&quot;: &quot;0755&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;path&quot;: &quot;&#x2F;data&#x2F;app&quot;, &quot;size&quot;: 4096, &quot;state&quot;: &quot;directory&quot;, &quot;uid&quot;: 0&#125; 我们可以查看一下： 12345678[root@server ~]# ansible web -m shell -a &#39;ls -l &#x2F;data&#39;192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;total 28drwxr-xr-x 2 root root 6 Dec 6 10:21 app192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;total 44drwxr-xr-x 2 root root 4096 Dec 5 10:21 app 可以看出，我们的目录已经创建完成。② 创建链接文件 12345678910111213141516171819202122232425[root@server ~]# ansible web -m file -a &#39;path&#x3D;&#x2F;data&#x2F;bbb.jpg src&#x3D;aaa.jpg state&#x3D;link&#39;192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;dest&quot;: &quot;&#x2F;data&#x2F;bbb.jpg&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;mode&quot;: &quot;0777&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 7, &quot;src&quot;: &quot;aaa.jpg&quot;, &quot;state&quot;: &quot;link&quot;, &quot;uid&quot;: 0&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;dest&quot;: &quot;&#x2F;data&#x2F;bbb.jpg&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;mode&quot;: &quot;0777&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 7, &quot;src&quot;: &quot;aaa.jpg&quot;, &quot;state&quot;: &quot;link&quot;, &quot;uid&quot;: 0&#125; 我们可以去查看一下： 12345678910[root@server ~]# ansible web -m shell -a &#39;ls -l &#x2F;data&#39;192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;total 28-rw-r--r-- 1 root root 5649 Dec 5 13:49 aaa.jpglrwxrwxrwx 1 root root 7 Dec 6 10:25 bbb.jpg -&gt; aaa.jpg192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;total 44-rw-r--r-- 1 root root 5649 Dec 4 14:44 aaa.jpglrwxrwxrwx 1 root root 7 Dec 5 10:25 bbb.jpg -&gt; aaa.jpg 我们的链接文件已经创建成功。③ 删除文件 1234567891011[root@server ~]# ansible web -m file -a &#39;path&#x3D;&#x2F;data&#x2F;a state&#x3D;absent&#39;192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;path&quot;: &quot;&#x2F;data&#x2F;a&quot;, &quot;state&quot;: &quot;absent&quot;&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;path&quot;: &quot;&#x2F;data&#x2F;a&quot;, &quot;state&quot;: &quot;absent&quot;&#125; 我们可以查看一下： 123456[root@server ~]# ansible web -m shell -a &#39;ls &#x2F;data&#x2F;a&#39;192.168.37.122 | FAILED | rc&#x3D;2 &gt;&gt;ls: cannot access &#x2F;data&#x2F;a: No such file or directory192.168.37.133 | FAILED | rc&#x3D;2 &gt;&gt;ls: cannot access &#x2F;data&#x2F;a: No such file or directory 发现已经没有这个文件了。 6、fetch 模块 该模块用于从远程某主机获取（复制）文件到本地。 有两个选项： dest：用来存放文件的目录src：在远程拉取的文件，并且必须是一个file，不能是目录 具体举例如下： 1234567891011121314151617[root@server ~]# ansible web -m fetch -a &#39;src&#x3D;&#x2F;data&#x2F;hello dest&#x3D;&#x2F;data&#39; 192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;checksum&quot;: &quot;22596363b3de40b06f981fb85d82312e8c0ed511&quot;, &quot;dest&quot;: &quot;&#x2F;data&#x2F;192.168.37.122&#x2F;data&#x2F;hello&quot;, &quot;md5sum&quot;: &quot;6f5902ac237024bdd0c176cb93063dc4&quot;, &quot;remote_checksum&quot;: &quot;22596363b3de40b06f981fb85d82312e8c0ed511&quot;, &quot;remote_md5sum&quot;: null&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;checksum&quot;: &quot;22596363b3de40b06f981fb85d82312e8c0ed511&quot;, &quot;dest&quot;: &quot;&#x2F;data&#x2F;192.168.37.133&#x2F;data&#x2F;hello&quot;, &quot;md5sum&quot;: &quot;6f5902ac237024bdd0c176cb93063dc4&quot;, &quot;remote_checksum&quot;: &quot;22596363b3de40b06f981fb85d82312e8c0ed511&quot;, &quot;remote_md5sum&quot;: null&#125; 我们可以在本机上查看一下文件是否复制成功。要注意，文件保存的路径是我们设置的接收目录下的被管制主机ip目录下： 1234567891011[root@server ~]# cd &#x2F;data&#x2F;[root@server data]# ls1 192.168.37.122 192.168.37.133 fastdfs web[root@server data]# cd 192.168.37.122[root@server 192.168.37.122]# lsdata[root@server 192.168.37.122]# cd data&#x2F;[root@server data]# lshello[root@server data]# pwd&#x2F;data&#x2F;192.168.37.122&#x2F;data 7、cron 模块 该模块适用于管理cron计划任务的。 其使用的语法跟我们的crontab文件中的语法一致，同时，可以指定以下选项： day= #日应该运行的工作( 1-31, , /2, )hour= # 小时 ( 0-23, , /2, )minute= #分钟( 0-59, , /2, )month= # 月( 1-12, *, /2, )weekday= # 周 ( 0-6 for Sunday-Saturday,, )job= #指明运行的命令是什么name= #定时任务描述reboot # 任务在重启时运行，不建议使用，建议使用special_timespecial_time #特殊的时间范围，参数：reboot（重启时），annually（每年），monthly（每月），weekly（每周），daily（每天），hourly（每小时）state #指定状态，present表示添加定时任务，也是默认设置，absent表示删除定时任务user # 以哪个用户的身份执行 举例如下：① 添加计划任务 123456789101112131415[root@server ~]# ansible web -m cron -a &#39;name&#x3D;&quot;ntp update every 5 min&quot; minute&#x3D;*&#x2F;5 job&#x3D;&quot;&#x2F;sbin&#x2F;ntpdate 172.17.0.1 &amp;&gt; &#x2F;dev&#x2F;null&quot;&#39;192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;ntp update every 5 min&quot; ]&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;ntp update every 5 min&quot; ]&#125; 我们可以去查看一下： 12345678[root@server ~]# ansible web -m shell -a &#39;crontab -l&#39;192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;#Ansible: ntp update every 5 min*&#x2F;5 * * * * &#x2F;sbin&#x2F;ntpdate 172.17.0.1 &amp;&gt; &#x2F;dev&#x2F;null192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;#Ansible: ntp update every 5 min*&#x2F;5 * * * * &#x2F;sbin&#x2F;ntpdate 172.17.0.1 &amp;&gt; &#x2F;dev&#x2F;null 可以看出，我们的计划任务已经设置成功了。② 删除计划任务 如果我们的计划任务添加错误，想要删除的话，则执行以下操作： 首先我们查看一下现有的计划任务： 123456789101112[root@server ~]# ansible web -m shell -a &#39;crontab -l&#39;192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;#Ansible: ntp update every 5 min*&#x2F;5 * * * * &#x2F;sbin&#x2F;ntpdate 172.17.0.1 &amp;&gt; &#x2F;dev&#x2F;null#Ansible: df everyday* 15 * * * df -lh &gt;&gt; &#x2F;tmp&#x2F;disk_total &amp;&gt; &#x2F;dev&#x2F;null192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;#Ansible: ntp update every 5 min*&#x2F;5 * * * * &#x2F;sbin&#x2F;ntpdate 172.17.0.1 &amp;&gt; &#x2F;dev&#x2F;null#Ansible: df everyday* 15 * * * df -lh &gt;&gt; &#x2F;tmp&#x2F;disk_total &amp;&gt; &#x2F;dev&#x2F;null 然后执行删除操作： 123456789101112131415[root@server ~]# ansible web -m cron -a &#39;name&#x3D;&quot;df everyday&quot; hour&#x3D;15 job&#x3D;&quot;df -lh &gt;&gt; &#x2F;tmp&#x2F;disk_total &amp;&gt; &#x2F;dev&#x2F;null&quot; state&#x3D;absent&#39;192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;ntp update every 5 min&quot; ]&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;ntp update every 5 min&quot; ]&#125; 删除完成后，我们再查看一下现有的计划任务确认一下： 12345678[root@server ~]# ansible web -m shell -a &#39;crontab -l&#39;192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;#Ansible: ntp update every 5 min*&#x2F;5 * * * * &#x2F;sbin&#x2F;ntpdate 172.17.0.1 &amp;&gt; &#x2F;dev&#x2F;null192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;#Ansible: ntp update every 5 min*&#x2F;5 * * * * &#x2F;sbin&#x2F;ntpdate 172.17.0.1 &amp;&gt; &#x2F;dev&#x2F;null 我们的删除操作已经成功。 8、yum 模块 顾名思义，该模块主要用于软件的安装。 其选项如下： name= #所安装的包的名称state= #present—&gt;安装， latest—&gt;安装最新的, absent—&gt; 卸载软件。update_cache #强制更新yum的缓存conf_file #指定远程yum安装时所依赖的配置文件（安装本地已有的包）。disable_pgp_check #是否禁止GPG checking，只用于presentor latest。disablerepo #临时禁止使用yum库。 只用于安装或更新时。enablerepo #临时使用的yum库。只用于安装或更新时。 下面我们就来安装一个包试试看： 1234567891011121314151617[root@server ~]# ansible web -m yum -a &#39;name&#x3D;htop state&#x3D;present&#39;192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;msg&quot;: &quot;&quot;, &quot;rc&quot;: 0, &quot;results&quot;: [ &quot;Loaded plugins: fastestmirror, langpacks\\nLoading mirror speeds from cached hostfile\\nResolving Dependencies\\n--&gt; Running transaction check\\n---&gt; Package htop.x86_64 0:2.0.2-1.el7 will be installed\\n--&gt; Finished Dependency Resolution\\n\\nDependencies Resolved\\n\\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\\n Package Arch Version Repository Size\\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\\nInstalling:\\n htop x86_64 2.0.2-1.el7 epel 98 k\\n\\nTransaction Summary\\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\\nInstall 1 Package\\n\\nTotal download size: 98 k\\nInstalled size: 207 k\\nDownloading packages:\\nRunning transaction check\\nRunning transaction test\\nTransaction test succeeded\\nRunning transaction\\n Installing : htop-2.0.2-1.el7.x86_64 1&#x2F;1 \\n Verifying : htop-2.0.2-1.el7.x86_64 1&#x2F;1 \\n\\nInstalled:\\n htop.x86_64 0:2.0.2-1.el7 \\n\\nComplete!\\n&quot; ]&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;msg&quot;: &quot;Warning: RPMDB altered outside of yum.\\n** Found 3 pre-existing rpmdb problem(s), &#39;yum check&#39; output follows:\\nipa-client-4.4.0-12.el7.centos.x86_64 has installed conflicts freeipa-client: ipa-client-4.4.0-12.el7.centos.x86_64\\nipa-client-common-4.4.0-12.el7.centos.noarch has installed conflicts freeipa-client-common: ipa-client-common-4.4.0-12.el7.centos.noarch\\nipa-common-4.4.0-12.el7.centos.noarch has installed conflicts freeipa-common: ipa-common-4.4.0-12.el7.centos.noarch\\n&quot;, &quot;rc&quot;: 0, &quot;results&quot;: [ &quot;Loaded plugins: fastestmirror, langpacks\\nLoading mirror speeds from cached hostfile\\nResolving Dependencies\\n--&gt; Running transaction check\\n---&gt; Package htop.x86_64 0:2.0.2-1.el7 will be installed\\n--&gt; Finished Dependency Resolution\\n\\nDependencies Resolved\\n\\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\\n Package Arch Version Repository Size\\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\\nInstalling:\\n htop x86_64 2.0.2-1.el7 epel 98 k\\n\\nTransaction Summary\\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\\nInstall 1 Package\\n\\nTotal download size: 98 k\\nInstalled size: 207 k\\nDownloading packages:\\nRunning transaction check\\nRunning transaction test\\nTransaction test succeeded\\nRunning transaction\\n Installing : htop-2.0.2-1.el7.x86_64 1&#x2F;1 \\n Verifying : htop-2.0.2-1.el7.x86_64 1&#x2F;1 \\n\\nInstalled:\\n htop.x86_64 0:2.0.2-1.el7 \\n\\nComplete!\\n&quot; ]&#125; 安装成功。 9、service 模块 该模块用于服务程序的管理。 其主要选项如下： arguments #命令行提供额外的参数enabled #设置开机启动。name= #服务名称runlevel #开机启动的级别，一般不用指定。sleep #在重启服务的过程中，是否等待。如在服务关闭以后等待2秒再启动。(定义在剧本中。)state #有四种状态，分别为：started—&gt;启动服务， stopped—&gt;停止服务， restarted—&gt;重启服务， reloaded—&gt;重载配置 下面是一些例子：① 开启服务并设置自启动 123456789101112131415[root@server ~]# ansible web -m service -a &#39;name&#x3D;nginx state&#x3D;started enabled&#x3D;true&#39; 192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;enabled&quot;: true, &quot;name&quot;: &quot;nginx&quot;, &quot;state&quot;: &quot;started&quot;, ……&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;enabled&quot;: true, &quot;name&quot;: &quot;nginx&quot;, &quot;state&quot;: &quot;started&quot;, ……&#125; 我们可以去查看一下端口是否打开： 12345678[root@server ~]# ansible web -m shell -a &#39;ss -ntl&#39;192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:80 *:* 192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:80 *:* 可以看出我们的80端口已经打开。② 关闭服务 我们也可以通过该模块来关闭我们的服务： 12345678910111213[root@server ~]# ansible web -m service -a &#39;name&#x3D;nginx state&#x3D;stopped&#39;192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;name&quot;: &quot;nginx&quot;, &quot;state&quot;: &quot;stopped&quot;, ……&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;name&quot;: &quot;nginx&quot;, &quot;state&quot;: &quot;stopped&quot;, ……&#125; 一样的，我们来查看一下端口： 1234[root@server ~]# ansible web -m shell -a &#39;ss -ntl | grep 80&#39;192.168.37.122 | FAILED | rc&#x3D;1 &gt;&gt;192.168.37.133 | FAILED | rc&#x3D;1 &gt;&gt; 可以看出，我们已经没有80端口了，说明我们的nginx服务已经关闭了。 10、user 模块 该模块主要是用来管理用户账号。 其主要选项如下： comment # 用户的描述信息createhome # 是否创建家目录force # 在使用state=absent时, 行为与userdel –force一致.group # 指定基本组groups # 指定附加组，如果指定为(groups=)表示删除所有组home # 指定用户家目录move_home # 如果设置为home=时, 试图将用户主目录移动到指定的目录name # 指定用户名non_unique # 该选项允许改变非唯一的用户ID值password # 指定用户密码remove # 在使用state=absent时, 行为是与userdel –remove一致shell # 指定默认shellstate # 设置帐号状态，不指定为创建，指定值为absent表示删除system # 当创建一个用户，设置这个用户是系统用户。这个设置不能更改现有用户uid # 指定用户的uid 举例如下：① 添加一个用户并指定其 uid 123456789101112131415161718192021222324252627[root@server ~]# ansible web -m user -a &#39;name&#x3D;keer uid&#x3D;11111&#39;192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;comment&quot;: &quot;&quot;, &quot;createhome&quot;: true, &quot;group&quot;: 11111, &quot;home&quot;: &quot;&#x2F;home&#x2F;keer&quot;, &quot;name&quot;: &quot;keer&quot;, &quot;shell&quot;: &quot;&#x2F;bin&#x2F;bash&quot;, &quot;state&quot;: &quot;present&quot;, &quot;stderr&quot;: &quot;useradd: warning: the home directory already exists.\\nNot copying any file from skel directory into it.\\nCreating mailbox file: File exists\\n&quot;, &quot;system&quot;: false, &quot;uid&quot;: 11111&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;comment&quot;: &quot;&quot;, &quot;createhome&quot;: true, &quot;group&quot;: 11111, &quot;home&quot;: &quot;&#x2F;home&#x2F;keer&quot;, &quot;name&quot;: &quot;keer&quot;, &quot;shell&quot;: &quot;&#x2F;bin&#x2F;bash&quot;, &quot;state&quot;: &quot;present&quot;, &quot;stderr&quot;: &quot;useradd: warning: the home directory already exists.\\nNot copying any file from skel directory into it.\\nCreating mailbox file: File exists\\n&quot;, &quot;system&quot;: false, &quot;uid&quot;: 11111&#125; 添加完成，我们可以去查看一下： 123456[root@server ~]# ansible web -m shell -a &#39;cat &#x2F;etc&#x2F;passwd |grep keer&#39;192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;keer:x:11111:11111::&#x2F;home&#x2F;keer:&#x2F;bin&#x2F;bash192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;keer:x:11111:11111::&#x2F;home&#x2F;keer:&#x2F;bin&#x2F;bash ② 删除用户 123456789101112131415[root@server ~]# ansible web -m user -a &#39;name&#x3D;keer state&#x3D;absent&#39;192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;force&quot;: false, &quot;name&quot;: &quot;keer&quot;, &quot;remove&quot;: false, &quot;state&quot;: &quot;absent&quot;&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;force&quot;: false, &quot;name&quot;: &quot;keer&quot;, &quot;remove&quot;: false, &quot;state&quot;: &quot;absent&quot;&#125; 一样的，删除之后，我们去看一下： 1234[root@server ~]# ansible web -m shell -a &#39;cat &#x2F;etc&#x2F;passwd |grep keer&#39;192.168.37.122 | FAILED | rc&#x3D;1 &gt;&gt;192.168.37.133 | FAILED | rc&#x3D;1 &gt;&gt; 发现已经没有这个用户了。 11、group 模块 该模块主要用于添加或删除组。 常用的选项如下： gid= #设置组的GID号name= #指定组的名称state= #指定组的状态，默认为创建，设置值为absent为删除system= #设置值为yes，表示创建为系统组 举例如下：① 创建组 123456789101112131415[root@server ~]# ansible web -m group -a &#39;name&#x3D;sanguo gid&#x3D;12222&#39;192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;gid&quot;: 12222, &quot;name&quot;: &quot;sanguo&quot;, &quot;state&quot;: &quot;present&quot;, &quot;system&quot;: false&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;gid&quot;: 12222, &quot;name&quot;: &quot;sanguo&quot;, &quot;state&quot;: &quot;present&quot;, &quot;system&quot;: false&#125; 创建过后，我们来查看一下： 123456[root@server ~]# ansible web -m shell -a &#39;cat &#x2F;etc&#x2F;group | grep 12222&#39; 192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;sanguo:x:12222:192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;sanguo:x:12222: 可以看出，我们的组已经创建成功了。② 删除组 1234567891011[root@server ~]# ansible web -m group -a &#39;name&#x3D;sanguo state&#x3D;absent&#39;192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;name&quot;: &quot;sanguo&quot;, &quot;state&quot;: &quot;absent&quot;&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;name&quot;: &quot;sanguo&quot;, &quot;state&quot;: &quot;absent&quot;&#125; 照例查看一下： 1234[root@server ~]# ansible web -m shell -a &#39;cat &#x2F;etc&#x2F;group | grep 12222&#39; 192.168.37.122 | FAILED | rc&#x3D;1 &gt;&gt;192.168.37.133 | FAILED | rc&#x3D;1 &gt;&gt; 已经没有这个组的相关信息了。 12、script 模块 该模块用于将本机的脚本在被管理端的机器上运行。 该模块直接指定脚本的路径即可，我们通过例子来看一看到底如何使用的： 首先，我们写一个脚本，并给其加上执行权限： 12345[root@server ~]# vim &#x2F;tmp&#x2F;df.sh #!&#x2F;bin&#x2F;bash date &gt;&gt; &#x2F;tmp&#x2F;disk_total.log df -lh &gt;&gt; &#x2F;tmp&#x2F;disk_total.log [root@server ~]# chmod +x &#x2F;tmp&#x2F;df.sh 然后，我们直接运行命令来实现在被管理端执行该脚本： 123456789101112131415[root@server ~]# ansible web -m script -a &#39;&#x2F;tmp&#x2F;df.sh&#39;192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;rc&quot;: 0, &quot;stderr&quot;: &quot;Shared connection to 192.168.37.122 closed.\\r\\n&quot;, &quot;stdout&quot;: &quot;&quot;, &quot;stdout_lines&quot;: []&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;changed&quot;: true, &quot;rc&quot;: 0, &quot;stderr&quot;: &quot;Shared connection to 192.168.37.133 closed.\\r\\n&quot;, &quot;stdout&quot;: &quot;&quot;, &quot;stdout_lines&quot;: []&#125; 照例查看一下文件内容： 1234567891011121314151617181920212223242526[root@server ~]# ansible web -m shell -a &#39;cat &#x2F;tmp&#x2F;disk_total.log&#39;192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;Tue Dec 5 15:58:21 CST 2017Filesystem Size Used Avail Use% Mounted on&#x2F;dev&#x2F;sda2 47G 4.4G 43G 10% &#x2F;devtmpfs 978M 0 978M 0% &#x2F;devtmpfs 993M 84K 993M 1% &#x2F;dev&#x2F;shmtmpfs 993M 9.1M 984M 1% &#x2F;runtmpfs 993M 0 993M 0% &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;dev&#x2F;sda3 47G 33M 47G 1% &#x2F;app&#x2F;dev&#x2F;sda1 950M 153M 798M 17% &#x2F;boottmpfs 199M 16K 199M 1% &#x2F;run&#x2F;user&#x2F;42tmpfs 199M 0 199M 0% &#x2F;run&#x2F;user&#x2F;0192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;Tue Dec 5 15:58:21 CST 2017Filesystem Size Used Avail Use% Mounted on&#x2F;dev&#x2F;sda2 46G 4.1G 40G 10% &#x2F;devtmpfs 898M 0 898M 0% &#x2F;devtmpfs 912M 84K 912M 1% &#x2F;dev&#x2F;shmtmpfs 912M 9.0M 903M 1% &#x2F;runtmpfs 912M 0 912M 0% &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;dev&#x2F;sda3 3.7G 15M 3.4G 1% &#x2F;app&#x2F;dev&#x2F;sda1 1.9G 141M 1.6G 9% &#x2F;boottmpfs 183M 16K 183M 1% &#x2F;run&#x2F;user&#x2F;42tmpfs 183M 0 183M 0% &#x2F;run&#x2F;user&#x2F;0 可以看出已经执行成功了。 13、setup 模块 该模块主要用于收集信息，是通过调用facts组件来实现的。 facts组件是Ansible用于采集被管机器设备信息的一个功能，我们可以使用setup模块查机器的所有facts信息，可以使用filter来查看指定信息。整个facts信息被包装在一个JSON格式的数据结构中，ansible_facts是最上层的值。 facts就是变量，内建变量 。每个主机的各种信息，cpu颗数、内存大小等。会存在facts中的某个变量中。调用后返回很多对应主机的信息，在后面的操作中可以根据不同的信息来做不同的操作。如redhat系列用yum安装，而debian系列用apt来安装软件。① 查看信息 我们可以直接用命令获取到变量的值，具体我们来看看例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[root@server ~]# ansible web -m setup -a &#39;filter&#x3D;&quot;*mem*&quot;&#39; #查看内存192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;ansible_memfree_mb&quot;: 1116, &quot;ansible_memory_mb&quot;: &#123; &quot;nocache&quot;: &#123; &quot;free&quot;: 1397, &quot;used&quot;: 587 &#125;, &quot;real&quot;: &#123; &quot;free&quot;: 1116, &quot;total&quot;: 1984, &quot;used&quot;: 868 &#125;, &quot;swap&quot;: &#123; &quot;cached&quot;: 0, &quot;free&quot;: 3813, &quot;total&quot;: 3813, &quot;used&quot;: 0 &#125; &#125;, &quot;ansible_memtotal_mb&quot;: 1984 &#125;, &quot;changed&quot;: false&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;ansible_memfree_mb&quot;: 1203, &quot;ansible_memory_mb&quot;: &#123; &quot;nocache&quot;: &#123; &quot;free&quot;: 1470, &quot;used&quot;: 353 &#125;, &quot;real&quot;: &#123; &quot;free&quot;: 1203, &quot;total&quot;: 1823, &quot;used&quot;: 620 &#125;, &quot;swap&quot;: &#123; &quot;cached&quot;: 0, &quot;free&quot;: 3813, &quot;total&quot;: 3813, &quot;used&quot;: 0 &#125; &#125;, &quot;ansible_memtotal_mb&quot;: 1823 &#125;, &quot;changed&quot;: false&#125; 我们可以通过命令查看一下内存的大小以确认一下是否一致： 12345678910[root@server ~]# ansible web -m shell -a &#39;free -m&#39;192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt; total used free shared buff&#x2F;cache availableMem: 1984 404 1122 9 457 1346Swap: 3813 0 3813192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt; total used free shared buff&#x2F;cache availableMem: 1823 292 1207 9 323 1351Swap: 3813 0 3813 可以看出信息是一致的。② 保存信息 我们的setup模块还有一个很好用的功能就是可以保存我们所筛选的信息至我们的主机上，同时，文件名为我们被管制的主机的IP，这样方便我们知道是哪台机器出的问题。 我们可以看一看例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[root@server tmp]# ansible web -m setup -a &#39;filter&#x3D;&quot;*mem*&quot;&#39; --tree &#x2F;tmp&#x2F;facts192.168.37.122 | SUCCESS &#x3D;&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;ansible_memfree_mb&quot;: 1115, &quot;ansible_memory_mb&quot;: &#123; &quot;nocache&quot;: &#123; &quot;free&quot;: 1396, &quot;used&quot;: 588 &#125;, &quot;real&quot;: &#123; &quot;free&quot;: 1115, &quot;total&quot;: 1984, &quot;used&quot;: 869 &#125;, &quot;swap&quot;: &#123; &quot;cached&quot;: 0, &quot;free&quot;: 3813, &quot;total&quot;: 3813, &quot;used&quot;: 0 &#125; &#125;, &quot;ansible_memtotal_mb&quot;: 1984 &#125;, &quot;changed&quot;: false&#125;192.168.37.133 | SUCCESS &#x3D;&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;ansible_memfree_mb&quot;: 1199, &quot;ansible_memory_mb&quot;: &#123; &quot;nocache&quot;: &#123; &quot;free&quot;: 1467, &quot;used&quot;: 356 &#125;, &quot;real&quot;: &#123; &quot;free&quot;: 1199, &quot;total&quot;: 1823, &quot;used&quot;: 624 &#125;, &quot;swap&quot;: &#123; &quot;cached&quot;: 0, &quot;free&quot;: 3813, &quot;total&quot;: 3813, &quot;used&quot;: 0 &#125; &#125;, &quot;ansible_memtotal_mb&quot;: 1823 &#125;, &quot;changed&quot;: false&#125; 然后我们可以去查看一下： 12345[root@server ~]# cd &#x2F;tmp&#x2F;facts&#x2F;[root@server facts]# ls192.168.37.122 192.168.37.133[root@server facts]# cat 192.168.37.122 &#123;&quot;ansible_facts&quot;: &#123;&quot;ansible_memfree_mb&quot;: 1115, &quot;ansible_memory_mb&quot;: &#123;&quot;nocache&quot;: &#123;&quot;free&quot;: 1396, &quot;used&quot;: 588&#125;, &quot;real&quot;: &#123;&quot;free&quot;: 1115, &quot;total&quot;: 1984, &quot;used&quot;: 869&#125;, &quot;swap&quot;: &#123;&quot;cached&quot;: 0, &quot;free&quot;: 3813, &quot;total&quot;: 3813, &quot;used&quot;: 0&#125;&#125;, &quot;ansible_memtotal_mb&quot;: 1984&#125;, &quot;changed&quot;: false&#125; 六、Ansible playbook 简介 playbook 是 ansible 用于配置，部署，和管理被控节点的剧本。 通过 playbook 的详细描述，执行其中的一系列 tasks ，可以让远端主机达到预期的状态。playbook 就像 Ansible 控制器给被控节点列出的的一系列 to-do-list ，而被控节点必须要完成。 也可以这么理解，playbook 字面意思，即剧本，现实中由演员按照剧本表演，在Ansible中，这次由计算机进行表演，由计算机安装，部署应用，提供对外服务，以及组织计算机处理各种各样的事情。 七、Ansible playbook使用场景 执行一些简单的任务，使用ad-hoc命令可以方便的解决问题，但是有时一个设施过于复杂，需要大量的操作时候，执行的ad-hoc命令是不适合的，这时最好使用playbook。 就像执行shell命令与写shell脚本一样，也可以理解为批处理任务，不过playbook有自己的语法格式。 使用playbook你可以方便的重用这些代码，可以移植到不同的机器上面，像函数一样，最大化的利用代码。在你使用Ansible的过程中，你也会发现，你所处理的大部分操作都是编写playbook。可以把常见的应用都编写成playbook，之后管理服务器会变得十分简单。 八、Ansible playbook格式1、格式简介 playbook由YMAL语言编写。YAML( /ˈjæməl/ )参考了其他多种语言，包括：XML、C语言、Python、Perl以及电子邮件格式RFC2822，Clark Evans在2001年5月在首次发表了这种语言，另外Ingy döt Net与OrenBen-Kiki也是这语言的共同设计者。 YMAL格式是类似于JSON的文件格式，便于人理解和阅读，同时便于书写。首先学习了解一下YMAL的格式，对我们后面书写playbook很有帮助。以下为playbook常用到的YMAL格式： 1、文件的第一行应该以 “—“ (三个连字符)开始，表明YMAL文件的开始。 2、在同一行中，#之后的内容表示注释，类似于shell，python和ruby。 3、YMAL中的列表元素以”-”开头然后紧跟着一个空格，后面为元素内容。 4、同一个列表中的元素应该保持相同的缩进。否则会被当做错误处理。 5、play中hosts，variables，roles，tasks等对象的表示方法都是键值中间以”:”分隔表示，”:”后面还要增加一个空格。 下面是一个举例： 123456789---#安装与运行mysql服务- hosts: node1 remote_user: root tasks: - name: install mysql-server package yum: name&#x3D;mysql-server state&#x3D;present - name: starting mysqld service service: name&#x3D;mysql state&#x3D;started 我们的文件名称应该以.yml结尾，像我们上面的例子就是mysql.yml。其中，有三个部分组成： host部分：使用 hosts 指示使用哪个主机或主机组来运行下面的 tasks ，每个 playbook 都必须指定 hosts ，hosts也可以使用通配符格式。主机或主机组在 inventory 清单中指定，可以使用系统默认的/etc/ansible/hosts，也可以自己编辑，在运行的时候加上-i选项，指定清单的位置即可。在运行清单文件的时候，–list-hosts选项会显示那些主机将会参与执行 task 的过程中。remote_user：指定远端主机中的哪个用户来登录远端系统，在远端系统执行 task 的用户，可以任意指定，也可以使用 sudo，但是用户必须要有执行相应 task 的权限。tasks：指定远端主机将要执行的一系列动作。tasks 的核心为 ansible 的模块，前面已经提到模块的用法。tasks 包含 name 和要执行的模块，name 是可选的，只是为了便于用户阅读，不过还是建议加上去，模块是必须的，同时也要给予模块相应的参数。 使用ansible-playbook运行playbook文件，得到如下输出信息，输出内容为JSON格式。并且由不同颜色组成，便于识别。一般而言| 绿色代表执行成功，系统保持原样| 黄色代表系统代表系统状态发生改变| 红色代表执行失败，显示错误输出 执行有三个步骤：1、收集facts 2、执行tasks 3、报告结果 2、核心元素 Playbook的核心元素： Hosts：主机组；Tasks：任务列表；Variables：变量，设置方式有四种；Templates：包含了模板语法的文本文件；Handlers：由特定条件触发的任务； 3、基本组件 Playbooks配置文件的基础组件： Hosts：运行指定任务的目标主机remote_user：在远程主机上执行任务的用户；sudo_user：tasks：任务列表 格式： tasks： – name: TASK_NAME module: arguments notify: HANDLER_NAME handlers: – name: HANDLER_NAME module: arguments 模块，模块参数： 格式： (1) action: module arguments (2) module: arguments 注意：shell和command模块后面直接跟命令，而非key=value类的参数列表； handlers：任务，在特定条件下触发；接收到其它任务的通知时被触发； (1) 某任务的状态在运行后为changed时，可通过“notify”通知给相应的handlers； (2) 任务可以通过“tags“打标签，而后可在ansible-playbook命令上使用-t指定进行调用； 举例① 定义playbook 12345678910111213141516171819[root@server ~]# cd &#x2F;etc&#x2F;ansible[root@server ansible]# vim nginx.yml---- hosts: web remote_user: root tasks: - name: install nginx yum: name&#x3D;nginx state&#x3D;present - name: copy nginx.conf copy: src&#x3D;&#x2F;tmp&#x2F;nginx.conf dest&#x3D;&#x2F;etc&#x2F;nginx&#x2F;nginx.conf backup&#x3D;yes notify: reload #当nginx.conf发生改变时，通知给相应的handlers tags: reloadnginx #打标签 - name: start nginx service service: name&#x3D;nginx state&#x3D;started tags: startnginx #打标签 handlers: #注意，前面没有-，是两个空格 - name: reload service: name&#x3D;nginx state&#x3D;restarted #为了在进程中能看出来 ② 测试运行结果 写完了以后，我们就可以运行了： 1[root@server ansible]# ansible-playbook nginx.yml 现在我们可以看看两台机器的端口是否开启： 123456[root@server ansible]# ansible web -m shell -a &#39;ss -nutlp |grep nginx&#39;192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;tcp LISTEN 0 128 *:80 *:* users:((&quot;nginx&quot;,pid&#x3D;8304,fd&#x3D;6),(&quot;nginx&quot;,pid&#x3D;8303,fd&#x3D;6))192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;tcp LISTEN 0 128 *:80 *:* users:((&quot;nginx&quot;,pid&#x3D;9671,fd&#x3D;6),(&quot;nginx&quot;,pid&#x3D;9670,fd&#x3D;6)) ③ 测试标签 我们在里面已经打上了一个标签，所以可以直接引用标签。但是我们需要先把服务关闭，再来运行剧本并引用标签： 12[root@server ansible]# ansible web -m shell -a &#39;systemctl stop nginx&#39;[root@server ansible]# ansible-playbook nginx.yml -t startnginx ④ 测试notify 我们还做了一个notify，来测试一下： 首先，它的触发条件是配置文件被改变，所以我们去把配置文件中的端口改一下： 12[root@server ansible]# vim &#x2F;tmp&#x2F;nginx.conf listen 8080; 然后我们重新加载一下这个剧本： 1[root@server ansible]# ansible-playbook nginx.yml -t reloadnginx 发现我们执行的就是reload段以及我们定义的notify部分。 我们来看一看我们的端口号： 发现我们执行的就是reload段以及我们定义的notify部分。 我们来看一看我们的端口号： 123456[root@server ansible]# ansible web -m shell -a &#39;ss -ntlp | grep nginx&#39;192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;LISTEN 0 128 *:8080 *:* users:((&quot;nginx&quot;,pid&#x3D;2097,fd&#x3D;6),(&quot;nginx&quot;,pid&#x3D;2096,fd&#x3D;6))192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;LISTEN 0 128 *:8080 *:* users:((&quot;nginx&quot;,pid&#x3D;3061,fd&#x3D;6),(&quot;nginx&quot;,pid&#x3D;3060,fd&#x3D;6)) 可以看出，我们的nginx端口已经变成了8080。 4、variables 部分 上文中，我们说到了variables是变量，有四种定义方法，现在我们就来说说这四种定义方法： ① facts ：可直接调用 上一篇中，我们有说到setup这个模块，这个模块就是通过调用facts组件来实现的。我们这里的variables也可以直接调用facts组件。 具体的facters我们可以使用setup模块来获取，然后直接放入我们的剧本中调用即可。 12345678910111213141516171819ansible_all_ipv4_addresses：仅显示ipv4的信息 ---&gt; [u&#39;192.168.95.143&#39;]ansible_eth0[&#39;ipv4&#39;][&#39;address&#39;]：仅显示ipv4的信息 ---&gt; eth0 的ip地址ansible_devices：仅显示磁盘设备信息ansible_distribution：显示是什么系统，例：centos,suse等ansible_distribution_version：仅显示系统版本ansible_machine：显示系统类型，例：32位，还是64位ansible_eth0：仅显示eth0的信息ansible_hostname：仅显示主机名ansible_kernel：仅显示内核版本ansible_lvm：显示lvm相关信息ansible_memtotal_mb：显示系统总内存ansible_memfree_mb：显示可用系统内存ansible_memory_mb：详细显示内存情况ansible_swaptotal_mb：显示总的swap内存ansible_swapfree_mb：显示swap内存的可用内存ansible_mounts：显示系统磁盘挂载情况ansible_processor：显示cpu个数(具体显示每个cpu的型号)ansible_processor_vcpus：显示cpu个数(只显示总的个数)ansible_python_version：显示python版本 例如：批量修改主机 host 文件 1234567891011---- hosts: web vars: IP: \"&#123;&#123; ansible_eth0['ipv4']['address'] &#125;&#125;\" tasks: - name: 将原有的hosts文件备份 shell: mv /etc/hosts /etc/hosts_bak - name: 将ansible端的hosts复制到各自机器上 copy: src=/root/hosts dest=/etc/ owner=root group=root mode=0644 - name: 在新的hosts文件后面追加各自机器内网ip和hostname lineinfile: dest=/etc/hosts line=\"&#123;&#123; IP &#125;&#125; &#123;&#123; ansible_hostname &#125;&#125;\" ② 用户自定义变量 我们也可以直接使用用户自定义变量，想要自定义变量有以下两种方式： 通过命令行传入 ansible-playbook命令的命令行中的-e VARS, --extra-vars=VARS，这样就可以直接把自定义的变量传入。 在playbook中定义变量 我们也可以直接在playbook中定义我们的变量： 123vars: - var1: value1 - var2: value2 举例① 定义剧本 我们就使用全局替换把我们刚刚编辑的文件修改一下： 1[root@server ansible]# vim nginx.yml 这样一来，我们的剧本就定义完成了。② 拷贝配置文件 我们想要在被监管的机器上安装什么服务的话，就直接在我们的server端上把该服务的配置文件拷贝到我们的/tmp/目录下。这样我们的剧本才能正常运行。 我们就以keepalived服务为例： 1[root@server ansible]# cp /etc/keepalived/keepalived.conf /tmp/keepalived.conf ③ 运行剧本，变量由命令行传入 1[root@server ansible]# ansible-playbook nginx.yml -e rpmname&#x3D;keepalived ④ 修改剧本，直接定义变量 同样的，我们可以直接在剧本中把变量定义好，这样就不需要在通过命令行传入了。以后想要安装不同的服务，直接在剧本里把变量修改一下即可。 1[root@server ansible]# vim nginx.yml ![img](E:/学习晋升文件汇总/Linux架构学习入门/4. network_manager/19-20天-企业自动化运维工具Aansible实战/assets/1204916-20171208112356562-1275040347.png)⑤ 运行定义过变量的剧本 我们刚刚已经把变量定义在剧本里面了。现在我们来运行一下试试看： 1[root@server ansible]# ansible-playbook nginx.yml 发现这样也是可以的~ ③ 通过roles传递变量 具体的，我们下文中说到 roles 的时候再详细说明。 ④ Host Inventory 我们也可以直接在主机清单中定义。 定义的方法如下： 向不同的主机传递不同的变量： 1 IP&#x2F;HOSTNAME varaiable&#x3D;value var2&#x3D;value2 向组中的主机传递相同的变量： 12 [groupname:vars] variable&#x3D;value Ansible Inventory 内置参数 ![Ansible Inventory 内置参数](E:/学习晋升文件汇总/Linux架构学习入门/4. network_manager/19-20天-企业自动化运维工具Aansible实战/assets/Ansible Inventory 内置参数.png) 使用内置变量把用户名密码写在Inventory中，也就是/etc/ansible/hosts文件里，缺点就是暴露了账号密码，不安全。如果有多个主机需要使用同样的变量，可以用组变量的形式，书写格式如下： 12345678[web]192.168.100.10192.168.100.11192.168.100.12 [web:vars] #给名为webservers的组定义一个变量，:vars是固定格式ansible_ssh_port=22ansible_ssh_user='root'ansible_ssh_pass='1234.com' 5、模板 templates 模板是一个文本文件，嵌套有脚本（使用模板编程语言编写）。 Jinja2：Jinja2是python的一种模板语言，以Django的模板语言为原本。模板支持： 123456789101112 字符串：使用单引号或双引号； 数字：整数，浮点数； 列表：[item1, item2, ...] 元组：(item1, item2, ...) 字典：&#123;key1:value1, key2:value2, ...&#125; 布尔型：true&#x2F;false 算术运算： +, -, *, &#x2F;, &#x2F;&#x2F;, %, ** 比较操作： &#x3D;&#x3D;, !&#x3D;, &gt;, &gt;&#x3D;, &lt;, &lt;&#x3D; 逻辑运算： and, or, not 通常来说，模板都是通过引用变量来运用的。 举例① 定义模板 我们直接把之前定义的/tmp/nginx.conf改个名，然后编辑一下，就可以定义成我们的模板文件了： 12345[root@server ansible]# cd &#x2F;tmp[root@server tmp]# mv nginx.conf nginx.conf.j2[root@server tmp]# vim nginx.conf.j2 worker_processes &#123;&#123; ansible_processor_vcpus &#125;&#125;; listen &#123;&#123; nginxport &#125;&#125;; ② 修改剧本 我们现在需要去修改剧本来定义变量： 1[root@server ansible]# vim nginx.yml 需要修改的部分如图所示。 copy 也需要修改为 template ③ 运行剧本 上面的准备工作完成后，我们就可以去运行剧本了： 123456789101112131415[root@server ansible]# ansible-playbook nginx.yml -t reloadnginxPLAY [web] *********************************************************************TASK [setup] *******************************************************************ok: [192.168.37.122]ok: [192.168.37.133]TASK [copy nginx.conf] *********************************************************ok: [192.168.37.122]ok: [192.168.37.133]PLAY RECAP *********************************************************************192.168.37.122 : ok&#x3D;2 changed&#x3D;0 unreachable&#x3D;0 failed&#x3D;0 192.168.37.133 : ok&#x3D;2 changed&#x3D;0 unreachable&#x3D;0 failed&#x3D;0 6、条件测试when语句：在task中使用，jinja2的语法格式。举例如下： 1234567tasks:- name: install conf file to centos7 template: src&#x3D;files&#x2F;nginx.conf.c7.j2 when: ansible_distribution_major_version &#x3D;&#x3D; &quot;7&quot;- name: install conf file to centos6 template: src&#x3D;files&#x2F;nginx.conf.c6.j2 when: ansible_distribution_major_version &#x3D;&#x3D; &quot;6&quot; 循环：迭代，需要重复执行的任务； 对迭代项的引用，固定变量名为”item”，而后，要在task中使用with_items给定要迭代的元素列表；举例如下： 1234567tasks:- name: unstall web packages yum: name&#x3D;&#123;&#123; item &#125;&#125; state&#x3D;absent with_items: - httpd - php - php-mysql 7、字典 ansible playbook 还支持字典功能。举例如下： 123456789101112131415161718- name: install some packages yum: name&#x3D;&#123;&#123; item &#125;&#125; state&#x3D;present with_items: - nginx - memcached - php-fpm- name: add some groups group: name&#x3D;&#123;&#123; item &#125;&#125; state&#x3D;present with_items: - group11 - group12 - group13- name: add some users user: name&#x3D;&#123;&#123; item.name &#125;&#125; group&#x3D;&#123;&#123; item.group &#125;&#125; state&#x3D;present with_items: - &#123; name: &#39;user11&#39;, group: &#39;group11&#39; &#125; - &#123; name: &#39;user12&#39;, group: &#39;group12&#39; &#125; - &#123; name: &#39;user13&#39;, group: &#39;group13&#39; &#125; 8、角色订制：roles① 简介 对于以上所有的方式有个弊端就是无法实现复用假设在同时部署Web、db、ha 时或不同服务器组合不同的应用就需要写多个yml文件。很难实现灵活的调用。 roles 用于层次性、结构化地组织playbook。roles 能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需要在playbook中使用include指令即可。简单来讲，roles就是通过分别将变量(vars)、文件(file)、任务(tasks)、模块(modules)及处理器(handlers)放置于单独的目录中，并可以便捷地include它们的一种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程等场景中。 ② 角色集合角色集合：roles/mysql/httpd/nginx/files/：存储由copy或script等模块调用的文件；tasks/：此目录中至少应该有一个名为main.yml的文件，用于定义各task；其它的文件需要由main.yml进行“包含”调用；handlers/：此目录中至少应该有一个名为main.yml的文件，用于定义各handler；其它的文件需要由main.yml进行“包含”调用；vars/：此目录中至少应该有一个名为main.yml的文件，用于定义各variable；其它的文件需要由main.yml进行“包含”调用；templates/：存储由template模块调用的模板文本；meta/：此目录中至少应该有一个名为main.yml的文件，定义当前角色的特殊设定及其依赖关系；其它的文件需要由main.yml进行“包含”调用；default/：此目录中至少应该有一个名为main.yml的文件，用于设定默认变量； ③ 角色定制实例1. 在roles目录下生成对应的目录结构 12345678910111213141516171819202122232425262728293031[root@server ansible]# cd roles&#x2F;[root@server roles]# ls[root@server roles]# mkdir -pv .&#x2F;&#123;nginx,mysql,httpd&#125;&#x2F;&#123;files,templates,vars,tasks,handlers,meta,default&#125;[root@server roles]# tree.├── httpd│ ├── default│ ├── files│ ├── handlers│ ├── meta│ ├── tasks│ ├── templates│ └── vars├── mysql│ ├── default│ ├── files│ ├── handlers│ ├── meta│ ├── tasks│ ├── templates│ └── vars└── nginx ├── default ├── files ├── handlers ├── meta ├── tasks ├── templates └── vars24 directories, 0 files 2. 定义配置文件 我们需要修改的配置文件为/tasks/main.yml，下面，我们就来修改一下： 1234567891011[root@server roles]# vim nginx&#x2F;tasks&#x2F;main.yml- name: cp copy: src&#x3D;nginx-1.10.2-1.el7.ngx.x86_64.rpm dest&#x3D;&#x2F;tmp&#x2F;nginx-1.10.2-1.el7.ngx.x86_64.rpm- name: install yum: name&#x3D;&#x2F;tmp&#x2F;nginx-1.10.2-1.el7.ngx.x86_64.rpm state&#x3D;latest- name: conf template: src&#x3D;nginx.conf.j2 dest&#x3D;&#x2F;etc&#x2F;nginx&#x2F;nginx.conf tags: nginxconf notify: new conf to reload- name: start service service: name&#x3D;nginx state&#x3D;started enabled&#x3D;true 3. 放置我们所需要的文件到指定目录 因为我们定义的角色已经有了新的组成方式，所以我们需要把文件都放到指定的位置，这样，才能让配置文件找到这些并进行加载。 rpm包放在files目录下，模板放在templates目录下： 12345678910111213141516[root@server nginx]# cp &#x2F;tmp&#x2F;nginx-1.10.2-1.el7.ngx.x86_64.rpm .&#x2F;files&#x2F;[root@server nginx]# cp &#x2F;tmp&#x2F;nginx.conf.j2 .&#x2F;templates&#x2F;[root@server nginx]# tree.├── default├── files│ └── nginx-1.10.2-1.el7.ngx.x86_64.rpm├── handlers├── meta├── tasks│ └── main.yml├── templates│ └── nginx.conf.j2└── vars7 directories, 3 files 4. 修改变量文件 我们在模板中定义的变量，也要去配置文件中加上： 12[root@server nginx]# vim vars&#x2F;main.ymlnginxprot: 9999 5. 定义handlers文件 我们在配置文件中定义了notify，所以我么也需要定义handlers，我们来修改配置文件： 123[root@server nginx]# vim handlers&#x2F;main.yml- name: new conf to reload service: name&#x3D;nginx state&#x3D;restarted 6. 定义剧本文件 接下来，我们就来定义剧本文件，由于大部分设置我们都单独配置在了roles里面，所以，接下来剧本就只需要写一点点内容即可： 12345[root@server ansible]# vim roles.yml - hosts: web remote_user: root roles: - nginx 7. 启动服务 剧本定义完成以后，我们就可以来启动服务了： 12345678910111213141516171819202122232425262728293031[root@server ansible]# ansible-playbook roles.ymlPLAY [web] *********************************************************************TASK [setup] *******************************************************************ok: [192.168.37.122]ok: [192.168.37.133]TASK [nginx : cp] **************************************************************ok: [192.168.37.122]ok: [192.168.37.133]TASK [nginx : install] *********************************************************changed: [192.168.37.122]changed: [192.168.37.133]TASK [nginx : conf] ************************************************************changed: [192.168.37.122]changed: [192.168.37.133]TASK [nginx : start service] ***************************************************changed: [192.168.37.122]changed: [192.168.37.133]RUNNING HANDLER [nginx : new conf to reload] ***********************************changed: [192.168.37.122]changed: [192.168.37.133]PLAY RECAP *********************************************************************192.168.37.122 : ok&#x3D;6 changed&#x3D;4 unreachable&#x3D;0 failed&#x3D;0 192.168.37.133 : ok&#x3D;6 changed&#x3D;4 unreachable&#x3D;0 failed&#x3D;0 启动过后照例查看端口号： 123456[root@server ansible]# ansible web -m shell -a &quot;ss -ntulp |grep 9999&quot;192.168.37.122 | SUCCESS | rc&#x3D;0 &gt;&gt;tcp LISTEN 0 128 *:9999 *:* users:((&quot;nginx&quot;,pid&#x3D;7831,fd&#x3D;6),(&quot;nginx&quot;,pid&#x3D;7830,fd&#x3D;6),(&quot;nginx&quot;,pid&#x3D;7829,fd&#x3D;6))192.168.37.133 | SUCCESS | rc&#x3D;0 &gt;&gt;tcp LISTEN 0 128 *:9999 *:* users:((&quot;nginx&quot;,pid&#x3D;9654,fd&#x3D;6),(&quot;nginx&quot;,pid&#x3D;9653,fd&#x3D;6),(&quot;nginx&quot;,pid&#x3D;9652,fd&#x3D;6)) 可以看出我们的剧本已经执行成功。 九、Ansible使用jinja2管理配置文件以及jinja2语法简介1、Jinja2介绍Jinja2是基于python的模板引擎，功能比较类似于PHP的smarty，J2ee的Freemarker和velocity。它能完全支持unicode，并具有集成的沙箱执行环境，应用广泛。jinja2使用BSD授权 Jinja2的语法是由variables(变量)和statement(语句)组成，如下； 1、variables：可以输出数据1my_variables 2、statements: 可以用来创建条件和循环等123456789if语句：&#123;% if my_conditional %&#125; ...&#123;% endif %&#125;for 语句：&#123;% for item in all_items %&#125;`item` ……&#123;% endfor %&#125; 从上面第二个variables的例子中可以看出，jinja2支持使用带过滤器的Unix型管道操作符，有很多的内置过滤器可供使用。我们可以仅仅用一堆简单if和for就可以建立几乎任何的常规配置文件，不过如果你有意更进一步，jinja2 documentation （http://jinja.pocoo.org/docs/dev/）包含了很多有趣的东西可供了解。我们可以看到ansible允许在模板中使用诸如绘制时间此类的一些额外的模板变量 第一个例子：引用变量 1234567891011#cd roles/template/.├── meta│ └── main.yml├── tasks│ ├── template.yml │ └── main.yml├── templates│ ├── order.j2└── vars └── main.yml 总调度yml文件： 1234567#cat templates.yml---- hosts: 10.0.90.27 user: root gather_facts: false roles: - role: template 注意:这里 - role: template 和 - template 是一样的！ 其他yml文件，如下： 12345678910111213141516171819202122232425262728293031323334353637383940#cat tasks/main.yml- include: template.yml#cat tasks/template.yml- name: create &#123;&#123; PROJECT &#125;&#125; directory file: dest=/data/&#123;&#123; PROJECT &#125;&#125; state=directory- name: template transfor java dir template: src=order.j2 dest=/data/&#123;&#123; PROJECT &#125;&#125;/order.conf #cat templates/order.j2project: &#123;&#123; PROJECT &#125;&#125;switch: &#123;&#123; SWITCH &#125;&#125;dbport: &#123;&#123; DBPORT &#125;&#125;#cat vars/main.ymlPROJECT: \"JAVA\"SWITCH: \"ON\"DBPORT: \"8080\"测试：# ansible-playbook templates.yml --syntax-checkplaybook: templates.yml执行：# ansible-playbook templates.yml PLAY [10.0.90.27] **************************************************************TASK [template : include] ***************************************************included: /etc/ansible/roles/template/tasks/template.yml for 10.0.90.27TASK [template : create JAVA directory] *************************************changed: [10.0.90.27]TASK [template : template transfor java dir] ********************************changed: [10.0.90.27]PLAY RECAP *********************************************************************10.0.90.27 : ok=3 changed=2 unreachable=0 failed=0 #到10.0.90.27查看结果#cat /data/JAVA/order.confproject: JAVAswitch: ONdbport: 8080 第二个例子：for 语句 为远程主机生成服务器列表，加入该列表从192.168.13.201 web01.test.com 到192.168.13.211 web11.test.com 结束，如果手动添加就很不科学了，这里需要使用jinja2语法的for循环通过模板批量生成对应的配置文件，如下： ansible目录结构： 1234567891011#cd /etc/ansible/roles/test_hosts.├── meta│ └── main.yml├── tasks│ ├── file1.yml│ └── main.yml├── templates│ └── test1.j2└── vars └── main.yml 各个目录下yml文件内容： 123456789101112131415# cat tasks/file1.yml - name: ansible jinja2 template for hosts config template: src=test1.j2 dest=/etc/httpd/conf/httpd.conf.test # cat tasks/main.yml - include: file1.yml# cat templates/test1.j2 &#123;% for id in range(201,212) %&#125;192.168.13.&#123;&#123; id &#125;&#125; web&#123;&#123; \"%03d\" |format(id-200) &#125;&#125;.test.com&#123;% endfor %&#125;解释：&#123;&#123; id &#125;&#125; 提取for循环中对应的变量id值\"%02d\" 调用的是python内置的字符串格式化输出（%d格式化整数）因为是01,02这种格式，所以是保留2位，故用02然后将结果通过管道符 “|” 传递给format 函数做二次处理。 执行结果： 123456789101112#cat httpd.conf.test192.168.13.201 web01.test.com192.168.13.202 web02.test.com192.168.13.203 web03.test.com192.168.13.204 web04.test.com192.168.13.205 web05.test.com192.168.13.206 web06.test.com192.168.13.207 web07.test.com192.168.13.208 web08.test.com192.168.13.209 web09.test.com192.168.13.210 web10.test.com192.168.13.211 web11.test.com 第三个例子：if语句 说明：如果定义端口号，就绑定定义的端口号，如果不定义端口号，就绑定默认端口号 1234567891011ansible目录结果#cd /etc/ansible/roles/mysql_cnf#tree.├── meta│ └── main.yml├── tasks│ └── main.yml├── templates│ └── test3.j2└── vars 主要的yml文件是templates目录下面的test3.j2 123456# cat templates/test3.j2 &#123;% if PORT %&#125;bind_address=10.0.90.27:&#123;&#123; PORT &#125;&#125;&#123;% else %&#125;bind_address=10.0.90.27:3306&#123;% endif %&#125; playbook主文件 12345678910# cat jinj2_test.yml ---- hosts: 10.0.90.27 user: root gather_facts: false vars: PORT: 3136 tasks: - name: copy file to client template: src=/etc/ansible/roles/mysql_cnf/templates/test3.j2 dest=/root/my.cnf 执行： 123456# ansible-playbook jinj2_test.ymlPLAY [10.0.90.27] **************************************************************TASK [copy file to client] *****************************************************changed: [10.0.90.27]PLAY RECAP *********************************************************************10.0.90.27 : ok=1 changed=1 unreachable=0 failed=0 查看 12# cat my.cnf bind_address=10.0.90.27:3136 如果将vars变量去掉，执行结果： 12345678910# cat jinj2_test.yml ---- hosts: 10.0.90.27 user: root gather_facts: false vars: PORT: false tasks: - name: copy file to client template: src=/etc/ansible/roles/mysql_cnf/templates/test3.j2 dest=/root/my.cnf 查看： 12# cat my.cnf bind_address=10.0.90.27:3306 3、Jinja default()设定精通程序编码的朋友皆知，default()默认值的设定有助于程序的健壮性和简洁性。所幸Jinja也支持该功能，上面的例子中生成Mysql配置文件中的端口定义，如果指定则PORT=3136，否则PORT=3306，我们将该案例改造为使用default()试试 编辑/etc/ansible/roles/mysql_cnf/templates/test3.j2内容如下,这种方法更简介。 bind_address=10.0.90.27:3306 2、ansible使用jiaja2生成apache多主机配置1、创建目录，创建好之后如下：1234567891011121314#cd /etc/ansible/roles/apache_conf# tree ././├── meta│ └── main.yml├── tasks│ ├── file.yml│ └── main.yml├── templates│ └── apache.config.j2└── vars └── main.yml4 directories, 5 files 2、创建tasks调度文件，如下：123456#cat file.yml - name: ansible jinja2 template for apache config template: src=apache.config.j2 dest=/etc/httpd/conf/httpd.conf.template #cat main.yml - include: file.yml 3、创建apache的jinja2模板文件，如下：1234567891011121314151617#cat apache.config.j2 NameVirtualHost *:80&#123;% for vhost in apache_vhost %&#125;&lt;VirtualHost *:80&gt;ServerName &#123;&#123; vhost.servername &#125;&#125;DocumentRoot &#123;&#123; vhost.documentroot &#125;&#125;&#123;% if vhost.serveradmin is defined %&#125;ServerAdmin &#123;&#123; vhost.serveradmin &#125;&#125;&#123;% endif %&#125;&lt;Directory \"&#123;&#123; vhost.documentroot &#125;&#125;\"&gt;AllowOverride AllOptions -Indexes FollowSymLinksOrder allow,denyAllow from all&lt;/Directory&gt;&lt;/VirtualHost&gt;&#123;% endfor %&#125; 4、创建变量，如下：1234#cat vars/main.ymlapache_vhost:- &#123;servername: \"apache.test1.com\", documentroot: \"/data/test1/\"&#125;- &#123;servername: \"apache.test2.com\", documentroot: \"/data/test2/\"&#125; 5、创建总调度yml文件，如下：1234567#cat /etc/ansible/apache_test.yml ---- hosts: 10.0.90.27 user: root gather_facts: no roles: - &#123; role: apache_conf &#125; 6、测试：123#ansible-playbook apache_test.yml --syntax-checkplaybook: apache_test.yml 7、执行测试12345678#ansible-playbook apache_test.yml PLAY [10.0.90.27] **************************************************************TASK [apache_conf : include] ***************************************************included: /etc/ansible/roles/apache_conf/tasks/file.yml for 10.0.90.27TASK [apache_conf : ansible jinja2 template for apache config] *****************changed: [10.0.90.27]PLAY RECAP *********************************************************************10.0.90.27 : ok=2 changed=1 unreachable=0 failed=0 8、到客户端查看12345678910111213141516171819202122#cat httpd.conf.template NameVirtualHost *:80&lt;VirtualHost *:80&gt;ServerName apache.test1.comDocumentRoot /data/test1/&lt;Directory \"/data/test1/\"&gt;AllowOverride AllOptions -Indexes FollowSymLinksOrder allow,denyAllow from all&lt;/Directory&gt;&lt;/VirtualHost&gt;&lt;VirtualHost *:80&gt;ServerName apache.test2.comDocumentRoot /data/test2/&lt;Directory \"/data/test2/\"&gt;AllowOverride AllOptions -Indexes FollowSymLinksOrder allow,denyAllow from all&lt;/Directory&gt;&lt;/VirtualHost&gt; 3、ansible使用jiaja2生成nginx一个模板多种不同配置说明：为2台Nginx Proxy，1台Nginx Web通过一套模板生成对应的配置 1、ansible目录结构：12345678910111213# cd roles/nginx_conf/#tree.├── files├── meta│ └── main.yml├── tasks│ ├── file.yml│ └── main.yml├── templates│ └── nginx.conf.j2└── vars └── main.yml 2、tasks目录下文件内容：123456#cat tasks/file.yml - name: nginx.j2 template transfer example template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf.template #cat tasks/main.yml - include: file.yml 3、nginx模板文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#cat templates/nginx.conf.j2 &#123;% if nginx_use_proxy %&#125;&#123;% for proxy in nginx_proxies %&#125;upstream &#123;&#123; proxy.name &#125;&#125; #server 127.0.0.1:&#123;&#123; proxy.port &#125;&#125;; server &#123;&#123; ansible_eth0.ipv4.address &#125;&#125;:&#123;&#123; proxy.port &#125;&#125;;&#125;&#123;% endfor %&#125;&#123;% endif%&#125;server &#123; listen 80; servername &#123;&#123; nginx_server_name &#125;&#125;; access_log off; error_log /etc/nginx/nginx_error.log; rewrite ^ https://$server_name$request_uri? permanent;&#125;server &#123; listen 443 ssl; server_name &#123;&#123; nginx_server_name &#125;&#125;; ssl_certificate /etc/nginx/ssl/&#123;&#123; nginx_ssl_cert_name &#125;&#125;; ssl_certificate_key /etc/nginx/ssl/&#123;&#123; nginx_ssl_cert_key &#125;&#125;; root &#123;&#123; nginx_web_root &#125;&#125;; index index.html index.html;&#123;% if nginx_use_auth %&#125; auth_basic \"Restricted\"; auth_basic_user_file /etc/nginx/&#123;&#123; project_name &#125;&#125;.htpasswd;&#123;% endif %&#125;&#123;% if nginx_use_proxy %&#125;&#123;% for proxy in nginx_proxies %&#125; location &#123;&#123; proxy.location &#125;&#125; &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto http; proxy_set_header X-Url-Scheme $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header X-NginX-Proxy true; proxy_redirect off; proxy_pass http://&#123;&#123; proxy.name &#125;&#125;; break;&#125;&#123;% endfor %&#125;&#123;% endif %&#125;&#123;% if nginx_server_static %&#125; location / &#123; try_files $url $url/ =404;&#125;&#123;% endif %&#125;&#125; 4、ansible变量文件12345678910cat vars/main.yml nginx_server_name: www.testnginx.comnginx_web_root: /data/html/nginx_proxies:- name: suspicious location: / port: 1234- name: suspicious-api location: /api port: 4567 5、ansible主playbook文件1234567891011121314151617181920212223242526272829#cat nginx_test.yml ##The first roles- name: Nginx Proxy Server's Config Dynamic Create hosts: \"10.0.90.25:10.0.90.26\" remote_user: root vars: nginx_use_proxy: true nginx_ssl_cert_name: ifa.crt nginx_ssl_cert_key: ifa.key nginx_use_auth: true project_name: suspicious nginx_server_static: true gather_facts: true roles: - role: nginx_conf##The second roles- name: Nginx WebServer's Config Dynamic Create hosts: 10.0.90.27 remote_user: root vars: nginx_use_proxy: false nginx_ssl_cert_name: ifa.crt nginx_ssl_cert_key: ifa.crt nginx_use_auth: false project_name: suspicious nginx_server_static: false gather_facts: false roles: - role: nginx_conf 6、测试并执行：123456789101112131415161718192021222324252627282930#ansible-playbook nginx_test.yml --syntax-checkplaybook: nginx_test.yml执行：# ansible-playbook nginx_test.ymlPLAY [Nginx Proxy Server's Config Dynamic Create] ******************************TASK [setup] *******************************************************************ok: [10.0.90.25]ok: [10.0.90.26]TASK [nginx_conf : include] ****************************************************included: /etc/ansible/roles/nginx_conf/tasks/file.yml for 10.0.90.25, 10.0.90.26TASK [nginx_conf : nginx.j2 template transfer example] *************************changed: [10.0.90.26]changed: [10.0.90.25]PLAY [Nginx WebServer's Config Dynamic Create] *********************************TASK [nginx_conf : include] ****************************************************included: /etc/ansible/roles/nginx_conf/tasks/file.yml for 10.0.90.27TASK [nginx_conf : nginx.j2 template transfer example] *************************changed: [10.0.90.27]PLAY RECAP *********************************************************************10.0.90.25 : ok=3 changed=1 unreachable=0 failed=0 10.0.90.26 : ok=3 changed=1 unreachable=0 failed=0 10.0.90.27 : ok=2 changed=1 unreachable=0 failed=0 7、查看检测执行结果到Nginx Proxy 服务器查看配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#cat nginx.conf.template upstream suspicious #server 127.0.0.1:1234; server 10.0.90.26:1234;&#125;upstream suspicious-api #server 127.0.0.1:4567; server 10.0.90.26:4567;&#125;server &#123; listen 80; servername www.testnginx.com; access_log off; error_log /etc/nginx/nginx_error.log; rewrite ^ https://$server_name$request_uri? permanent;&#125;server &#123; listen 443 ssl; server_name www.testnginx.com; ssl_certificate /etc/nginx/ssl/ifa.crt; ssl_certificate_key /etc/nginx/ssl/ifa.key; root /data/html/; index index.html index.html; auth_basic \"Restricted\"; auth_basic_user_file /etc/nginx/suspicious.htpasswd; location / &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto http; proxy_set_header X-Url-Scheme $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header X-NginX-Proxy true; proxy_redirect off; proxy_pass http://suspicious; break;&#125; location /api &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto http; proxy_set_header X-Url-Scheme $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header X-NginX-Proxy true; proxy_redirect off; proxy_pass http://suspicious-api; break;&#125; location / &#123; try_files $url $url/ =404;&#125;&#125; 到Nginx Web 服务器上查看配置文件 12345678910111213141516#cat nginx.conf.template server &#123; listen 80; servername www.testnginx.com; access_log off; error_log /etc/nginx/nginx_error.log; rewrite ^ https://$server_name$request_uri? permanent;&#125;server &#123; listen 443 ssl; server_name www.testnginx.com; ssl_certificate /etc/nginx/ssl/ifa.crt; ssl_certificate_key /etc/nginx/ssl/ifa.crt; root /data/html/; index index.html index.html;&#125; 到这里，就结束了。用同样的模板通过简单的if和变量设置就可以完成不同类型主机的Nginx conf配置，所以一方面在了解Ansible强大的模板功能的同时，也需要看到模板质量的重要性。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/categories/Linux/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"https://github.com/cyylog/tags/Tools/"}]},{"title":"RabbitMQ消息中间件","slug":"SQL/RabbitMQ消息中间件","date":"2019-04-16T15:40:20.000Z","updated":"2020-05-25T13:57:22.799Z","comments":true,"path":"2019/04/16/SQL/RabbitMQ消息中间件/","link":"","permalink":"https://github.com/cyylog/2019/04/16/SQL/RabbitMQ%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/","excerpt":"","text":"RabbitMQ 消息中间件1、消息中间件1、简介消息中间件也可以称消息队列，是指用高效可靠的消息传递机制进行与平台无关的数据交流，并基于数据通信来进行分布式系统的集成。通过提供消息传递和消息队列模型，可以在分布式环境下扩展进程的通信。 当下主流的消息中间件有RabbitMQ、Kafka、ActiveMQ、RocketMQ等。其能在不同平台之间进行通信，常用来屏蔽各种平台协议之间的特性，实现应用程序之间的协同。优点在于能够在客户端和服务器之间进行同步和异步的连接，并且在任何时刻都可以将消息进行传送和转发，是分布式系统中非常重要的组件，主要用来解决应用耦合、异步通信、流量削峰等问题。 2、作用1、消息中间件主要作用 解耦 冗余(存储) 扩展性 削峰 可恢复性 顺序保证 缓冲 异步通信 2、消息中间件的两种模式1、P2P模式P2P模式包含三个角色：消息队列（Queue）、发送者(Sender)、接收者(Receiver)。每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到它们被消费或超时。 P2P的特点： 每个消息只有一个消费者（Consumer），即一旦被消费，消息就不再在消息队列中 发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行它不会影响到消息被发送到队列 接收者在成功接收消息之后需向队列应答成功 如果希望发送的每个消息都会被成功处理的话，那么需要P2P模 2、Pub/Sub模式Pub/Sub模式包含三个角色：主题（Topic）、发布者（Publisher）、订阅者（Subscriber） 。多个发布者将消息发送到Topic，系统将这些消息传递给多个订阅者。 Pub/Sub的特点： 每个消息可以有多个消费者 发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息 为了消费消息，订阅者必须保持运行的状态 如果希望发送的消息可以不被做任何处理、或者只被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用Pub/Sub模型 3、常用中间件介绍与对比1、KafkaKafka是LinkedIn开源的分布式发布-订阅消息系统，目前归属于Apache顶级项目。Kafka主要特点是基于Pull的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输。0.8版本开始支持复制，不支持事务，对消息的重复、丢失、错误没有严格要求，适合产生大量数据的互联网服务的数据收集业务。 2、RabbitMQRabbitMQ是使用Erlang语言开发的开源消息队列系统，基于AMQP协议来实现。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。AMQP协议更多用在企业系统内对数据一致性、稳定性和可靠性要求很高的场景，对性能和吞吐量的要求还在其次。 3、RocketMQRocketMQ是阿里开源的消息中间件，它是纯Java开发，具有高吞吐量、高可用性、适合大规模分布式系统应用的特点。RocketMQ思路起源于Kafka，但并不是Kafka的一个Copy，它对消息的可靠传输及事务性做了优化，目前在阿里集团被广泛应用于交易、充值、流计算、消息推送、日志流式处理、binglog分发等场景。 RabbitMQ比Kafka可靠，Kafka更适合IO高吞吐的处理，一般应用在大数据日志处理或对实时性（少量延迟），可靠性（少量丢数据）要求稍低的场景使用，比如ELK日志收集。 2、RabbitMQ 详解1、RabbitMQ 介绍RabbitMQ是一个在AMQP（Advanced Message Queuing Protocol ）基础上实现的，可复用的企业消息系统。它可以用于大型软件系统各个模块之间的高效通信，支持高并发，支持可扩展。它支持多种客户端如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX，持久化，用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。 RabbitMQ是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正是如此，使的它变的非常重量级，更适合于企业级的开发。它同时实现了一个Broker构架，这意味着消息在发送给客户端时先在中心队列排队，对路由(Routing)、负载均衡(Load balance)或者数据持久化都有很好的支持。 2、RabbitMQ 特点 可靠性 灵活的路由 扩展性 高可用性 多种协议 多语言客户端 管理界面 插件机制 3、AMQP 介绍AMQP，即Advanced Message Queuing Protocol,一个提供统一消息服务的应用层标准高级消息队列协议,是应用层协议的一个开放标准,为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。 4、什么和是消息队列MQ 全称为Message Queue, 消息队列。是一种应用程序对应用程序的通信方法。应用程序通过读写出入队列的消息（针对应用程序的数据）来通信，而无需专用连接来链接它们。 消息传递指的是程序之间通过在消息中发送数据进行通信，而不是通过直接调用彼此来通信。队列的使用除去了接收和发送应用程序同时执行的要求。 在项目中，将一些无需即时返回且耗时的操作提取出来，进行了异步处理，而这种异步处理的方式大大的节省了服务器的请求响应时间，从而提高了系统的吞吐量。 消息队列的使用场景是怎样的？ 5、RabbitMQ 应用场景对于一个大型的软件系统来说，它会有很多的组件或者说模块或者说子系统或者（subsystem or Component or submodule）。那么这些模块的如何通信？这和传统的IPC有很大的区别。传统的IPC很多都是在单一系统上的，模块耦合性很大，不适合扩展（Scalability）；如果使用socket那么不同的模块的确可以部署到不同的机器上，但是还是有很多问题需要解决。比如：1）信息的发送者和接收者如何维持这个连接，如果一方的连接中断，这期间的数据如何防止丢失？2）如何降低发送者和接收者的耦合度？3）如何让Priority高的接收者先接到数据？4）如何做到load balance？有效均衡接收者的负载？5）如何有效的将数据发送到相关的接收者？也就是说将接收者subscribe 不同的数据，如何做有效的filter。6）如何做到可扩展，甚至将这个通信模块发到cluster上？7）如何保证接收者接收到了完整，正确的数据？AMDQ协议解决了以上的问题，而RabbitMQ实现了AMQP。 6、RabbitMQ 概念介绍 Broker：简单来说就是消息队列服务器实体。 Exchange：消息交换机，它指定消息按什么规则，路由到哪个队列。 Queue：消息队列载体，每个消息都会被投入到一个或多个队列。 Binding：绑定，它的作用就是把exchange和queue按照路由规则绑定起来。 Routing Key：路由关键字，exchange根据这个关键字进行消息投递。 vhost：虚拟主机，一个broker里可以开设多个vhost，用作不同用户的权限分离。 producer：消息生产者，就是投递消息的程序。 consumer：消息消费者，就是接受消息的程序。 channel：消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务。 RabbitMQ从整体上来看是一个典型的生产者消费者模型，主要负责接收、存储和转发消息 7、RabbitMQ 使用流程AMQP模型中，消息在producer中产生，发送到MQ的exchange上，exchange根据配置的路由方式发到相应的Queue上，Queue又将消息发送给consumer，消息从queue到consumer有push和pull两种方式。 消息队列的使用过程大概如下： 客户端连接到消息队列服务器，打开一个channel。 客户端声明一个exchange，并设置相关属性。 客户端声明一个queue，并设置相关属性。 客户端使用routing key，在exchange和queue之间建立好绑定关系。 客户端投递消息到exchange。 exchange接收到消息后，就根据消息的key和已经设置的binding，进行消息路由，将消息投递到一个或多个队列里。 exchange也有几个类型，完全根据key进行投递的叫做Direct交换机，例如，绑定时设置了routing key为”abc”，那么客户端提交的消息，只有设置了key为”abc”的才会投递到队列。 3、RabbitMQ 单机安装部署1、下载下载地址：http://www.rabbitmq.com/download.html 2、Windows上安装1、安装安装Erlang下载erlang：http://www.erlang.org/download/otp_win64_17.3.exe 安装： erlang安装完成。 2、安装安装RabbitMQ RabbitMQ安装完成。 启动、停止、重新安装等。 3、启用管理工具第一步：点击打开RabbitMQ的命令窗口。如图： 第二步：输入命令rabbitmq-plugins enable rabbitmq_management 这个命令的意思是安装RabbitMQ的插件。 第三步：测试是否安装成功。 方法：访问地址：http://127.0.0.1:15672/ 默认账号：guest/guest 3、Linux上安装1、安装 erlang添加yum支持 1234567cd &#x2F;usr&#x2F;local&#x2F;src&#x2F;mkdir rabbitmqcd rabbitmqwget http:&#x2F;&#x2F;packages.erlang-solutions.com&#x2F;erlang-solutions-1.0-1.noarch.rpmrpm -ivh erlang-solutions-1.0-1.noarch.rpmrpm --import http:&#x2F;&#x2F;packages.erlang-solutions.com&#x2F;rpm&#x2F;erlang_solutions.ascyum install erlang 2、安装RabbitMQ1、用 yum 安装 RabbitMQ 123rpm --import https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc# this example assumes the CentOS 7 version of the packageyum install rabbitmq-server-3.7.13-1.el7.noarch.rpm 123rpm --import https://www.rabbitmq.com/rabbitmq-release-signing-key.asc# this example assumes the CentOS 7 version of the packageyum install rabbitmq-server-3.7.13-1.el7.noarch.rpm 2、用 rpm 手动安装 下载： 1wget https:&#x2F;&#x2F;github.com&#x2F;rabbitmq&#x2F;rabbitmq-server&#x2F;releases&#x2F;download&#x2F;v3.7.13&#x2F;rabbitmq-server-3.7.13-1.el7.noarch.rpm 上传rabbitmq-server-3.7.13-1.el7.noarch.rpm文件到/usr/local/src/rabbitmq/ 安装： 1rpm -ivh rabbitmq-server-3.7.13-1.el7.noarch.rpm 几个常用命令： 1234service rabbitmq-server startservice rabbitmq-server stopservice rabbitmq-server restart chkconfig rabbitmq-server on &#x2F;&#x2F;设置开机自启 设置配置文件： 123cd &#x2F;etc&#x2F;rabbitmqcp &#x2F;usr&#x2F;share&#x2F;doc&#x2F;rabbitmq-server-3.7.13&#x2F;rabbitmq.config.example &#x2F;etc&#x2F;rabbitmq&#x2F;mv rabbitmq.config.example rabbitmq.config 设置用户远程访问： 1vim &#x2F;etc&#x2F;rabbitmq&#x2F;rabbitmq.config 去掉后面的逗号 开启web界面管理工具 12rabbitmq-plugins enable rabbitmq_managementservice rabbitmq-server restart 防火墙开放15672端口(CentOS7 不用操作) 12&#x2F;sbin&#x2F;iptables -I INPUT -p tcp --dport 15672 -j ACCEPT&#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;iptables save 4、客户端的简单介绍1、界面的介绍 注意设置虚拟主机与添加用户这块。 1234命令行添加用户，设置tagsrabbitmqctl list_usersrabbitmqctl add_user username passwordrabbitmqctl set_user_tags username administrator 关于虚拟主机，Virtual Host，其实是一个虚拟概念，类似于权限控制组，一个Virtual Host里面可以有若干个Exchange和Queue，但是权限控制的最小粒度是Virtual Host 用户角色有下面几种： 超级管理员(administrator) 可登陆管理控制台，可查看所有的信息，并且可以对用户，策略(policy)进行操作。 监控者(monitoring) 可登陆管理控制台，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等) 策略制定者(policymaker) 可登陆管理控制台, 同时可以对policy进行管理。但无法查看节点的相关信息(上图红框标识的部分)。 普通管理者(management) 仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理。 其他 无法登陆管理控制台，通常就是普通的生产者和消费者。 4、Mac 安装教程1、安装在Mac下安装RabbitMQ是非常简单的，一般默认RabbitMQ服务器依赖的Erlang已经安装，只需要用下面两个命令就可以完成RabbitMQ的安装（前提是homebrew已经被安装）： 12brew updatebrew install rabbitmq 耐心等待，安装完成后需要将/usr/local/sbin添加到$PATH，可以将下面这两行加到~/.bash_profile： 12# RabbitMQ Configexport PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;sbin 编辑完后:wq保存退出，使环境变量立即生效。 1source ~&#x2F;.bash_profile 2、启动RabbitMQ服务上面配置完成后，需要关闭终端窗口，重新打开，然后输入下面命令即可启动RabbitMQ服务： 1rabbitmq-server 3、登录Web管理界面浏览器输入localhost：15672,账号密码全输入guest即可登录。 5、RabbitMQ常用的命令1、基本命令启动监控管理器：rabbitmq-plugins enable rabbitmq_management关闭监控管理器：rabbitmq-plugins disable rabbitmq_management启动rabbitmq：rabbitmq-service start关闭rabbitmq：rabbitmq-service stop查看所有的队列：rabbitmqctl list_queues清除所有的队列：rabbitmqctl reset关闭应用：rabbitmqctl stop_app启动应用：rabbitmqctl start_app 2、用户和权限设置添加用户：rabbitmqctl add_user username password分配角色：rabbitmqctl set_user_tags username administrator新增虚拟主机：rabbitmqctl add_vhost vhost_name将新虚拟主机授权给新用户：rabbitmqctl set_permissions -p vhost_name username “.*” “.*” “.*”(后面三个”*”代表用户拥有配置、写、读全部权限) 3、角色说明 超级管理员(administrator)可登陆管理控制台，可查看所有的信息，并且可以对用户，策略(policy)进行操作。 监控者(monitoring)可登陆管理控制台，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等) 策略制定者(policymaker)可登陆管理控制台, 同时可以对policy进行管理。但无法查看节点的相关信息(上图红框标识的部分)。 普通管理者(management)仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理。 其他无法登陆管理控制台，通常就是普通的生产者和消费者。 4、RabbitMQ 集群部署及配置消息中间件RabbitMQ，一般以集群方式部署，主要提供消息的接受和发送，实现各微服务之间的消息异步。以下将介绍RabbitMQ+HA方式进行部署。 1、原理介绍RabbitMQ是依据erlang的分布式特性（RabbitMQ底层是通过Erlang架构来实现的，所以rabbitmqctl会启动Erlang节点，并基于Erlang节点来使用Erlang系统连接RabbitMQ节点，在连接过程中需要正确的Erlang Cookie和节点名称，Erlang节点通过交换Erlang Cookie以获得认证）来实现的，所以部署Rabbitmq分布式集群时要先安装Erlang，并把其中一个服务的cookie复制到另外的节点。 RabbitMQ集群中，各个RabbitMQ为对等节点，即每个节点均提供给客户端连接，进行消息的接收和发送。节点分为内存节点和磁盘节点，一般的，均应建立为磁盘节点，为了防止机器重启后的消息消失； RabbitMQ的Cluster集群模式一般分为两种，普通模式和镜像模式。消息队列通过RabbitMQ HA镜像队列进行消息队列实体复制。 普通模式下，以两个节点（rabbit01、rabbit02）为例来进行说明。对于Queue来说，消息实体只存在于其中一个节点rabbit01（或者rabbit02），rabbit01和rabbit02两个节点仅有相同的元数据，即队列的结构。当消息进入rabbit01节点的Queue后，consumer从rabbit02节点消费时，RabbitMQ会临时在rabbit01、rabbit02间进行消息传输，把A中的消息实体取出并经过B发送给consumer。所以consumer应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理Queue。否则无论consumer连rabbit01或rabbit02，出口总在rabbit01，会产生瓶颈。 镜像模式下，将需要消费的队列变为镜像队列，存在于多个节点，这样就可以实现RabbitMQ的HA高可用性。作用就是消息实体会主动在镜像节点之间实现同步，而不是像普通模式那样，在consumer消费数据时临时读取。缺点就是，集群内部的同步通讯会占用大量的网络带宽。 2、部署 RabbitMQ Cluster多台机器部署RabbitMQ的cluster， 1、环境要求1、所有节点需要再同一个局域网内； 2、所有节点需要有相同的 erlang cookie，否则不能正常通信，为了实现cookie内容一致，采用scp的方式进行。 3、准备三台虚拟机，配置相同 rabbitmq01 192.168.101.11 rabbitmq02 192.168.101.12 rabbitmq03 192.168.101.13 操作系统：centos7.5 2、部署过程1、所有节点配置/etc/hostsnode1 192.168.101.11 node2 192.168.101.12 node3 192.168.101.13 2、所有节点安装 erLang 和 rabbitmq1、安装erlang 安装依赖包 1yum install -y *epel* gcc-c++ unixODBC unixODBC-devel openssl-devel ncurses-devel 编译安装 1234567wget http:&#x2F;&#x2F;erlang.org&#x2F;download&#x2F;otp_src_21.3.tar.gztar -zxvf otp_src_21.3.tar.gzcd otp_src_21.3.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;erlang --without-javacmake &amp;&amp; make installecho &quot;export PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;bin&#x2F;erlang&#x2F;bin:&#x2F;usr&#x2F;local&#x2F;bin&#x2F;rabbitmq_server-3.6.15&#x2F;sbin&quot; &gt;&gt; &#x2F;etc&#x2F;profilesource &#x2F;etc&#x2F;profile 出现 erl 命令则说明安装成功； 2、安装rabbitmq 编译安装 123456wget http:&#x2F;&#x2F;www.rabbitmq.com&#x2F;releases&#x2F;rabbitmq-server&#x2F;v3.6.15&#x2F;rabbitmq-server-generic-unix-3.6.15.tar.xzyum install -y xzxz -d rabbitmq-server-generic-unix-3.6.15.tar.xztar -xvf rabbitmq-server-generic-unix-3.6.15.tar -C &#x2F;usr&#x2F;local&#x2F;bin&#x2F;echo &quot;export PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;bin&#x2F;erlang&#x2F;bin:&#x2F;usr&#x2F;local&#x2F;bin&#x2F;rabbitmq_server-3.6.15&#x2F;sbin&quot; &gt;&gt; &#x2F;etc&#x2F;profilesource &#x2F;etc&#x2F;profile 3、导入 rabbitmq 的管理界面 1rabbitmq-plugins enable rabbitmq_management 4、设置 erlang 找到erlang cookie文件的位置，官方在介绍集群的文档中提到过.erlang.cookie 一般会存在这两个地址：第一个是home/.erlang.cookie；第二个地方就是/var/lib/rabbitmq/.erlang.cookie。如果我们使用解压缩方式安装部署的rabbitmq，那么这个文件会在{home}目录下，也就是$home/.erlang.cookie。如果我们使用rpm等安装包方式进行安装的，那么这个文件会在/var/lib/rabbitmq目录下。 这里将 node1 的该文件复制到 node2、node3，注意这个文件的权限是 400（默认即是400），因此采用scp的方式只拷贝内容即可； 可以通过cat $home/.erlang.cookie来查看三台机器的cookie是否一致，设置erlang的目的是要保证集群内的cookie内容一致。 使用-detached参数运行各节点 123rabbitmqctl stoprabbitmq-server -detached 然后可以通过 rabbitmqctl cluster_status查看节点状态。 注意：要先拷贝cookie到另外两台机器上，保证三台机器上的cookie是一致的，然后再启动服务。 由于guest这个用户,只能在本地访问,所以我们要新增一个用户并赋予权限: 添加用户并设置密码: 1rabbitmqctl add_user admin 123456 添加权限（使admin用户对虚拟主机“/” 具有所有权限）: 1rabbitmqctl set_permissions -p &quot;&#x2F;&quot; admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 修改用户角色（加入administrator用户组） 1rabbitmqctl set_user_tags admin administrator 然后就可以远程访问了，然后可直接配置用户权限等信息。到此,就可以通过http://ip:15672 使用admin 123456 进行登陆了。 到这里的话，每个节点是作为单独的一台RabbitMQ存在的，也可以正常提供服务了 3、组成集群rabbitmq-server 启动时，会一起启动节点和应用，它预先设置RabbitMQ应用为standalone模式。要将一个节点加入到现有的集群中，你需要停止这个应用，并将节点设置为原始状态。如果使用./rabbitmqctl stop，应用和节点都将被关闭。所以使用rabbitmqctl stop_app仅仅关闭应用。 1、将 node2、node3与 node1 组成集群，这里以node2为例 123node2# rabbitmqctl stop_app node2# rabbitmqctl join_cluster rabbit@node1 ####这里集群的名字一定不要写错了node2# rabbitmqctl start_app 2、将node3重复上述操作，也加入node1的集群。 123node3# rabbitmqctl stop_app node3# rabbitmqctl join_cluster rabbit@node1 ####这里集群的名字一定不要写错了node3# rabbitmqctl start_app 则此时 node2 与 node3 也会自动建立连接，集群配置完毕； 12#使用内存节点加入集群node2 # rabbitmqctl join_cluster --ram rabbit@node1 3、在 RabbitMQ 集群任意节点上执行 rabbitmqctl cluster_status来查看是否集群配置成功。 1234567node3# rabbitmqctl cluster_statusCluster status of node rabbit@node3 ...[&#123;nodes,[&#123;disc,[rabbit@node1,rabbit@node2,rabbit@node3]&#125;]&#125;, &#123;running_nodes,[rabbit@node1,rabbit@node2,rabbit@node3]&#125;, &#123;cluster_name,&lt;&quot;rabbit@node1&quot;&gt;&#125;, #集群的名称默认为 rabbit@node1 &#123;partitions,[]&#125;, &#123;alarms,[&#123;rabbit@node1,[]&#125;,&#123;rabbit@node2,[]&#125;,&#123;rabbit@node3,[]&#125;]&#125;] 4、也可通过在web页面上的“Queues”的列表中，查看有如下显示为“同步镜像到node2”，则也表示集群配置成功 5、设置镜像队列策略 在任意一个节点上执行如下操作（这里在node1上执行） 首先，在web界面，登陆后，点击“Admin–Virtual Hosts（页面右侧）”，在打开的页面上的下方的“Add a new virtual host”处增加一个虚拟主机，同时给用户“admin”和“guest”均加上权限（在页面直接设置、点点点即可）； 然后，在linux中执行如下命令 1rabbitmqctl set_policy -p coresystem ha-all &quot;^&quot; &#39;&#123;&quot;ha-mode&quot;:&quot;all&quot;&#125;&#39; “coresystem” vhost名称， “^”匹配所有的队列， ha-all 策略名称为ha-all, ‘{“ha-mode”:”all”}’ 策略模式为 all 即复制到所有节点，包含新增节点。 则此时镜像队列设置成功。（这里的虚拟主机coresystem是代码中需要用到的虚拟主机，虚拟主机的作用是做一个消息的隔离，本质上可认为是一个rabbitmq-server，是否增加虚拟主机，增加几个，这是由开发中的业务决定，即有哪几类服务，哪些服务用哪一个虚拟主机，这是一个规划）。 6、镜像队列策略设置说明 12345678910111213rabbitmqctl set_policy [-p Vhost] Name Pattern Definition [Priority]-p Vhost： 可选参数，针对指定vhost下的queue进行设置Name: policy的名称Pattern: queue的匹配模式(正则表达式)Definition：镜像定义，包括三个部分ha-mode, ha-params, ha-sync-mode ha-mode:指明镜像队列的模式，有效值为 all&#x2F;exactly&#x2F;nodes all：表示在集群中所有的节点上进行镜像 exactly：表示在指定个数的节点上进行镜像，节点的个数由ha-params指定 nodes：表示在指定的节点上进行镜像，节点名称通过ha-params指定 ha-params：ha-mode模式需要用到的参数 ha-sync-mode：进行队列中消息的同步方式，有效值为automatic和manualpriority：可选参数，policy的优先级 将所有队列设置为镜像队列，即队列会被复制到各个节点，各个节点状态保持一直。完成这 6 个步骤后，RabbitMQ 高可用集群搭建完成，最后一个步骤就是搭建均衡器。 7、安装并配置负载均衡器HA 注意：如果使用阿里云，可以使用阿里云的内网slb来实现负载均衡，不用自己搭建HA。 1、在192.168.101.11安装HAProxy 1yum -y install HAProxy 2、修改 /etc/haproxy/haproxy.cfg 12345678910111213141516171819202122232425262728293031vim &#x2F;etc&#x2F;haproxy&#x2F;haproxy.cfgglobal log 127.0.0.1 local2 chroot &#x2F;var&#x2F;lib&#x2F;haproxy pidfile &#x2F;var&#x2F;run&#x2F;haproxy.pid maxconn 4000 user haproxy group haproxy daemon stats socket &#x2F;var&#x2F;lib&#x2F;haproxy&#x2F;stats defaults log global mode tcp option tcplog option dontlognull retries 3 option redispatch maxconn 2000 contimeout 5s clitimeout 120s srvtimeout 120s listen rabbitmq_cluster 192.168.101.11:5670 mode tcp balance roundrobin server rabbit1 192.168.101.11:5672 check inter 5000 rise 2 fall 2 server rabbit2 192.168.101.12:5672 check inter 5000 rise 2 fall 2 3、重启HAProxy 1service haproxy restart 登录浏览器输入地址http://192.168.101.11:8100/rabbitmqstats查看HAProxy的状态 三、常见问题 常见错误： 1、使用 rabbitmq-server -detached命令启动rabbitmq时，出现以下提示Warning: PID file not written; -detached was passed，此时使用rabbitmqctl status提示服务已启动，可知此问题不用解决。 2、由于更改hostname文件，在每次rabbitmqctl stop或者rabbitmqctl cluster_status等，只要是rabbitmq的命令就报错，提示大概如下 1234567891011121314151617181920Cluster status of node rabbit@web2 ...Error: unable to connect to node rabbit@web2: nodedownDIAGNOSTICS&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;attempted to contact: [rabbit@web2]rabbit@web2: * connected to epmd (port 4369) on web2 * epmd reports node &#39;rabbit&#39; running on port 25672 * TCP connection succeeded but Erlang distribution failed * Hostname mismatch: node &quot;rabbit@mq2&quot; believes its host is different. Please ensure that hostnames resolve the same way locally and on &quot;rabbit@mq2&quot;current node details:- node name: &#39;rabbitmq-cli-11@web2&#39;- home dir: &#x2F;root- cookie hash: SGwxMdJ3PjEXG1asIEFpBg&#x3D;&#x3D; 此时先ps aux | grep mq，然后kill -9 该进程，然后再rabbitmq-server -detached即可解决。（即先强杀，再重新启动） 3、使用rabbitmqctl stop，rabbitmq-server -detached重新启动后，原先添加的用户admin、虚拟主机coresystem等均丢失，还需要重新添加。 采用脚本启动，在脚本中写好启动好需要加载的各配置项（创建admin用户并授权，创建虚拟主机并授权，配置镜像队列）。 4、命令 1234rabbitmqctl stop_app #仅关闭应用，不关闭节点rabbitmqctl start_app #开启应用rabbitmq--server -detached #启动节点和应用rabbitmqctl stop #关闭节点和应用 4、常用命令： Rabbitmq服务器的主要通过rabbitmqctl和rabbimq-plugins两个工具来管理，以下是一些常用功能。 1、 服务器启动与关闭 123启动: rabbitmq-server –detached关闭: rabbitmqctl stop若单机有多个实例，则在rabbitmqctl后加 –n 指定名称 2、插件管理 123开启某个插件：rabbitmq-plugins enable xxx关闭某个插件：rabbitmq-plugins disable xxx注意：重启服务器后生效。 3、virtual_host管理 12新建virtual_host:rabbitmqctl add_vhost xxx撤销virtual_host:rabbitmqctl delete_vhost xxx 4、用户管理 123456新建用户：rabbitmqctl add_user xxxpwd删除用户: rabbitmqctl delete_user xxx查看用户：rabbitmqctl list_users改密码: rabbimqctl change_password &#123;username&#125; &#123;newpassword&#125;设置用户角色：rabbitmqctlset_user_tags &#123;username&#125; &#123;tag ...&#125; Tag可以为 administrator,monitoring, management 5、 权限管理 123456权限设置：set_permissions [-pvhostpath] &#123;user&#125; &#123;conf&#125; &#123;write&#125; &#123;read&#125;Vhostpath: Vhost路径user: 用户名Conf: 一个正则表达式match哪些配置资源能够被该用户访问。Write: 一个正则表达式match哪些配置资源能够被该用户读。Read: 一个正则表达式match哪些配置资源能够被该用户访问。 6、获取服务器状态信息 1服务器状态：rabbitmqctl status ##其中可查看rabbitmq的版本信息 7、获取集群状态信息 1rabbitmqctl cluster_status","categories":[{"name":"SQL","slug":"SQL","permalink":"https://github.com/cyylog/categories/SQL/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://github.com/cyylog/tags/RabbitMQ/"}]},{"title":"Nginx编译安装","slug":"Linux/Nginx/Nginx编译安装","date":"2019-03-27T15:14:08.000Z","updated":"2020-05-25T13:56:42.367Z","comments":true,"path":"2019/03/27/Linux/Nginx/Nginx编译安装/","link":"","permalink":"https://github.com/cyylog/2019/03/27/Linux/Nginx/Nginx%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/","excerpt":"","text":"nginx 编译安装与配置使用1、安装编译环境yum -y install gcc gcc-c++ 2、安装pcre软件包（使nginx支持http rewrite模块）yum install -y pcre pcre-devel 3、安装openssl-devel（使nginx支持ssl）yum install -y openssl openssl-devel 4、安装zlibyum install -y zlib zlib-devel 5、创建用户nginxuseradd nginx passwd nginx 6、安装nginx1[root@localhost ～]#wget http://192.168.233.100/nginx.org/download/nginx-1.14.2.tar.gz 1234567891011121314151617181920[root@localhost ～]#tar -vzxf nginx-1.14.2.tar.gz -C /usr/local[root@localhost ～]#cd nginx-1.14.2/ [root@localhost nginx-1.14.2]# ./configure \\ --group=nginx \\ --user=nginx \\ --prefix=/usr/local/nginx \\ --sbin-path=/usr/sbin/nginx \\ --conf-path=/etc/nginx/nginx.conf \\ --error-log-path=/var/log/nginx/error.log \\ --http-log-path=/var/log/nginx/access.log \\ --http-client-body-temp-path=/tmp/nginx/client_body \\ --http-proxy-temp-path=/tmp/nginx/proxy \\ --http-fastcgi-temp-path=/tmp/nginx/fastcgi \\ --pid-path=/var/run/nginx.pid \\ --lock-path=/var/lock/nginx \\ --with-http_stub_status_module \\ --with-http_ssl_module \\ --with-http_gzip_static_module \\ --with-pcre [root@localhost nginx-1.11.3]# make &amp;&amp;make install 7、Nginx 编译参数123456789101112131415161718192021222324252627282930313233343536373839# 查看 nginx 安装的模块[root@tianyun ~]# nginx -V# 模块参数具体功能 --with-cc-opt='-g -O2 -fPIE -fstack-protector //设置额外的参数将被添加到CFLAGS变量。（FreeBSD或者ubuntu使用）--param=ssp-buffer-size=4 -Wformat -Werror=format-security -D_FORTIFY_SOURCE=2' --with-ld-opt='-Wl,-Bsymbolic-functions -fPIE -pie -Wl,-z,relro -Wl,-z,now' --prefix=/usr/share/nginx //指向安装目录--conf-path=/etc/nginx/nginx.conf //指定配置文件--http-log-path=/var/log/nginx/access.log //指定访问日志--error-log-path=/var/log/nginx/error.log //指定错误日志--lock-path=/var/lock/nginx.lock //指定lock文件--pid-path=/run/nginx.pid //指定pid文件--http-client-body-temp-path=/var/lib/nginx/body //设定http客户端请求临时文件路径--http-fastcgi-temp-path=/var/lib/nginx/fastcgi //设定http fastcgi临时文件路径--http-proxy-temp-path=/var/lib/nginx/proxy //设定http代理临时文件路径--http-scgi-temp-path=/var/lib/nginx/scgi //设定http scgi临时文件路径--http-uwsgi-temp-path=/var/lib/nginx/uwsgi //设定http uwsgi临时文件路径--with-debug //启用debug日志--with-pcre-jit //编译PCRE包含“just-in-time compilation”--with-ipv6 //启用ipv6支持--with-http_ssl_module //启用ssl支持--with-http_stub_status_module //获取nginx自上次启动以来的状态--with-http_realip_module //允许从请求标头更改客户端的IP地址值，默认为关--with-http_auth_request_module //实现基于一个子请求的结果的客户端授权。如果该子请求返回的2xx响应代码，所述接入是允许的。如果它返回401或403中，访问被拒绝与相应的错误代码。由子请求返回的任何其他响应代码被认为是一个错误。--with-http_addition_module //作为一个输出过滤器，支持不完全缓冲，分部分响应请求--with-http_dav_module //增加PUT,DELETE,MKCOL：创建集合,COPY和MOVE方法 默认关闭，需编译开启--with-http_geoip_module //使用预编译的MaxMind数据库解析客户端IP地址，得到变量值--with-http_gunzip_module //它为不支持“gzip”编码方法的客户端解压具有“Content-Encoding: gzip”头的响应。--with-http_gzip_static_module //在线实时压缩输出数据流--with-http_image_filter_module //传输JPEG/GIF/PNG 图片的一个过滤器）（默认为不启用。gd库要用到）--with-http_spdy_module //SPDY可以缩短网页的加载时间--with-http_sub_module //允许用一些其他文本替换nginx响应中的一些文本--with-http_xslt_module //过滤转换XML请求--with-mail //启用POP3/IMAP4/SMTP代理模块支持--with-mail_ssl_module //启用ngx_mail_ssl_module支持启用外部模块支持 8、修改配置文件/etc/nginx/nginx.conf12345678910111213141516171819202122232425262728293031323334# 全局参数设置 worker_processes 1; #设置nginx启动进程的数量，一般设置成与逻辑cpu数量相同 error_log logs/error.log; #指定错误日志 worker_rlimit_nofile 102400; #设置一个nginx进程能打开的最大文件数 pid /var/run/nginx.pid; events &#123; worker_connections 1024; #设置一个进程的最大并发连接数 &#125; # http 服务相关设置 http &#123; include mime.types; default_type application/octet-stream; log_format main 'remote_addr - remote_user [time_local] \"request\" ' 'status body_bytes_sent \"$http_referer\" ' '\"http_user_agent\" \"http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; #设置访问日志的位置和格式 sendfile on; #是否调用sendfile函数输出文件，一般设置为on，若nginx是用来进行磁盘IO负载应用时，可以设置为off，降低系统负载 gzip on; #是否开启gzip压缩 keepalive_timeout 65; #设置长连接的超时时间 # 虚拟服务器的相关设置 server &#123; listen 80; #设置监听的端口 server_name localhost; #设置绑定的主机名、域名或ip地址 charset koi8-r; # 设置编码字符 location / &#123; root /var/www/nginx; #设置服务器默认网站的根目录位置 index index.html index.htm; #设置默认打开的文档 &#125; error_page 500 502 503 504 /50x.html; #设置错误信息返回页面 location = /50x.html &#123; root html; #这里的绝对位置是/var/www/nginx/html &#125; &#125; &#125; 9、检测 nginx 配置文件是否正确1[root@localhost ~]#/usr/local/nginx/sbin/nginx -t 10、启动nginx服务1/usr/local/nginx/sbin/nginx 11、通过 nginx 命令控制 nginx 服务1234567nginx -c /path/to/nginx.conf # 以特定目录下的配置文件启动nginx:nginx -s reload # 修改配置后重新加载生效nginx -s reopen # 重新打开日志文件nginx -s stop # 快速停止nginxnginx -s quit # 完整有序的停止nginxnginx -t # 测试当前配置文件是否正确nginx -t -c /path/to/nginx.conf # 测试特定的nginx配置文件是否正确 12、实现nginx开机自启 a、添加启动脚本 vim /etc/init.d/nginx 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126#!/bin/sh # # nginx - this script starts and stops the nginx daemon # # chkconfig: - 85 15 # description: Nginx is an HTTP(S) server, HTTP(S) reverse \\ # proxy and IMAP/POP3 proxy server # processname: nginx # config: /etc/nginx/nginx.conf # config: /etc/sysconfig/nginx # pidfile: /var/run/nginx.pid # Source function library. . /etc/rc.d/init.d/functions # Source networking configuration. . /etc/sysconfig/network # Check that networking is up. [ \"$NETWORKING\" = \"no\" ] &amp;&amp; exit 0 nginx=\"/usr/sbin/nginx\"prog=$(basename $nginx) NGINX_CONF_FILE=\"/etc/nginx/nginx.conf\" [ -f /etc/sysconfig/nginx ] &amp;&amp; . /etc/sysconfig/nginx lockfile=/var/lock/subsys/nginx make_dirs() &#123; # make required directories user=`nginx -V 2&gt;&amp;1 | grep \"configure arguments:\" | sed 's/[^*]*--user=\\([^ ]*\\).*/\\1/g' -` options=`$nginx -V 2&gt;&amp;1 | grep 'configure arguments:'` for opt in $options; do if [ `echo $opt | grep '.*-temp-path'` ]; then value=`echo $opt | cut -d \"=\" -f 2` if [ ! -d \"$value\" ]; then # echo \"creating\" $value mkdir -p $value &amp;&amp; chown -R $user $value fi fi done&#125; start() &#123; [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 make_dirs echo -n $\"Starting $prog: \" daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval &#125; stop() &#123; echo -n $\"Stopping $prog: \" killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval &#125; restart() &#123; configtest || return $? stop sleep 1 start &#125; reload() &#123; configtest || return $? echo -n $\"Reloading $prog: \" killproc $nginx -HUP RETVAL=$? echo&#125; force_reload() &#123; restart &#125; configtest() &#123; $nginx -t -c $NGINX_CONF_FILE &#125; rh_status() &#123; status $prog &#125; rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1 &#125; case \"$1\" in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $\"Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&#125;\" exit 2 esac b、添加权限 1chmod +x /etc/init.d/nginx c、重载系统启动文件 1systemctl daemon-reload d、设置开机自启 1systemctl start nginx 10、nginx 日志文件详解 ​ nginx 日志文件分为 log_format 和 access_log 两部分 ​ log_format 定义记录的格式，其语法格式为 ​ log_format 样式名称 样式详情 ​ 配置文件中默认有 123log_format main &#39;remote_addr - remote_user [time_local] &quot;request&quot; &#39; &#39;status body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;http_user_agent&quot; &quot;http_x_forwarded_for&quot;&#39;; 点击这里 点击这里 变量 说明 $remote_addr和$http_x_forwarded_for 客户端的ip $remote_user 客户端的名称 $time_local 访问时的本地时间 $request 请求的URL和http协议 $status 访问的状态码 $body_bytes_sent 发送给客户端的主体内容大小 $http_referer 记录客户端是从哪个页面链接访问过来的，若没有链接，则访问‘-’ $http_user_agent 记录客户端使用的浏览器的相关信息","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/categories/Linux/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://github.com/cyylog/tags/Nginx/"}]},{"title":"iptables笔记","slug":"Linux/iptables笔记","date":"2019-02-27T16:12:16.000Z","updated":"2020-05-25T13:55:23.570Z","comments":true,"path":"2019/02/28/Linux/iptables笔记/","link":"","permalink":"https://github.com/cyylog/2019/02/28/Linux/iptables%E7%AC%94%E8%AE%B0/","excerpt":"","text":"防火墙之 iptables1.1 安全优化配置原则尽可能不给服务器配置外网ip ,可以通过代理转发或者通过防火墙映射.并发不是特别大情况有外网ip,可以开启防火墙服务. 大并发的情况，不能开iptables,影响性能，利用硬件防火墙提升架构安全 1.1.1 生产中 iptables 的实际应用主要应用方向 1、主机防火墙（filter表的INPUT链）。 2、局域网共享上网(nat 表的 POSTROUTING 链)。半个路由器，NAT功能。 3、端口及IP映射(nat 表的 PREROUTING 链)，硬防的NAT功能。 4、IP一对一映射。 其他说明： ①iptables是基于内核的防火墙，功能非常强大，基于数据包的过滤！特别是可以在一台非常低的硬件配置下跑的非常好。 注：iptables主要工作在OSI七层的2.3.4层。七层的控制可以使用squid代理+iptables。 ②iptabes：生产中根据具体情况，一般，内网关闭，外网打开。大并发的情况不能开iptables，影响性能，iptables是要消耗CPU的，所以大并发的情况下，我们使用硬件防火墙的各方面做的很仔细。selinux：生产中也是关闭的。可以做ids的入侵检测。 ③实际生产中尽可能不给服务器配置外网IP。可以通过代理转发。比如，nagios就不需要外网。 ④并发不是很大的情况下，再外网的IP环境，开防火墙。 ⑤第一次直接默认规则生成配置文件，以后就在配置文件中进行修改（编辑添加删除）。 ⑥封掉IP：根据IP地址和网络连接数进行封杀。（定时任务，定时封掉，判断，存在就不再进行二次封杀） 1.1.2 常用案例功能小结：1）linux主机防火墙，单机作为防火墙（表filter）。 2）局域网共享上网（表nat postrouting）。 3）外部地址映射为内部地址和端口（表nat prerouting） 1.2 iptables 防火墙简介Netfilter/Iptables(以下简称Iptables)是unix/linux自带的一款优秀且开放源代码的完全自由的基于包过滤的防火墙工具，它的功能十分强大，使用非常灵活，可以对流入和流出服务器的数据包进行很精细的控制.特别是它可以在一台非常低的硬件配置服务器上跑的非常好（赛扬500HZ cpu 64M 内存的惲况下部署网关防火墙），提供近400人的上网服务丝毫不逊色专业路由器防火墙。 iptables + zebra + squid (常用网络开源产品）。 iptables是linux2.4及2.6内核中集成的服务，其功能与安全性比其老一蜚ipfwadm，ipchains 强大的多，iptables主要工作在0SI七层的二、三、四层，如果重新编译内核，iptables也可以支持 7 层控制（squid代理+iptables）。 1.2.1 iptables名词和术语不少刚接触到iptables的朋友可能会对iptables防火墙的相关名词搞的很晕，不知道其所云的具体意思，而是就最基本的能让大家容易快速理解和掌握的思路来描述： 容器：包含或者说属于的关系 1.2.2 什么是容器谁不知道啊，容器就是装东西的，如（箱、包、坛）。没错，恭喜你答对了.词典里解释说，容器就是用来包装或装载物品的贮存器（如箱、罐、坛）或者成形或柔软不成形的包覆材料. 在iptables里的呢，就是用来描述这种包含或者说属于的关系。 1.2.3 什么是 Netfilter/iptables ?Netfilter是表（tables）的容器，这样解释大家肯定还是晕。举个例子，如果把Netfilter看成是某个小区的一栋楼。那么表（tables)就是楼里的其中的一套房子。这套房子”表（tables)”属于这栋“Netfilter”。 1.2.4 什么是表（tables）？表（tables）是链的容器，即所有的链（chains）都属于其对应的表（tables）.如上，如果把Netfilter看成是某个小区的一栋楼.那么表（tables）就是楼里的其中的一套房子。 1.2.5 什么是链（chains）？链（chains）是规则（Policys）的容器。接上，如果把表（tables）当作有一套房子，那么链（chains）就可以说是房子里的家具（柜子等）。 1.2.6 什么是规则（Policy）？规则（Policy）就比较容易理解了，就是iptables系列过滤信息的规范和具体方法条款了.可以理解为柜子如何增加并摆放柜子东西等。 基本术语如下表格所示： Netfilter 表（tables**）** 链（chains**）** 规则（Policy**）** 一栋楼 楼里的房子 房子里的柜子 柜子里衣服，摆放规则 1.3 iptables 表和链描述完iptables术语后，相信大家对iptables的表和链有了初步的了解了，默认情况下，iptables根据功能和表的定义划分包含三个表，filter,nat,mangle,其每个表又包含不同的操作链（chains )。 实际iptables包含4张表和五个链,巧主要记住两张表即可filter和nat表即可。 下面表格展示了表和链的对应关系。 四个表： 表（tables**）** 链（chains**）** Filter 1 这是默认表，实现防火墙数据过滤功能。 1-INPUT 对于指定到本地套接字的包，即到达本地防火墙服务器的数据包。 1-FORWARD 路由穿过的数据包，即经过本地防火墙服务器的数据包。 1-OUTPUT 本地创建的数据包 NAT2 当遇到新创建的数据包连接时将参考这个表 2-FREROUTING 一进来就对数据包进行改变 2-OUTPUT 本地创建的数据包在路由前进行改变 2-POSTROUTING 在数据包即将出去时改变数据包信息 Mangle3 这个表专门用于改变数据包 3-INPUT 进入到设备本身的包 3-FORWARD 对路由后的数据包信息进行修改 3-FREROUTING 在路由之前更改传入的包 3-OUTPUT 本地创建的数据包在路由之前改变 3-POSTROUTING 在数据包即将离开时更改数据包信息 raw4 此表用处较少，可以忽略不计。This table is used mainly for configuring exemptions from connection tracking in combination with the NOTRACK target. 4-PREROUTING for packets arriving via any network interface 4-OUTPUT for packets generated by local processes 五个链 表（tables**）** 链（chains**）** INPUT FORWARD OUTPUT PREROUTING POSTROUTING Filter √ √ √ × × NAT × × √ √ √ Managle √ √ √ √ √ raw × × √ √ × 说明：√ 表示有，× 表示无。 图 - iptables中的表与链的结构关系 1.3.1 filter表的详细介绍 filter**表** 主要和主机自身相关，真正负责主机防火墙功能的（过滤流入流出主机的数据包）filter表是iptables默认使用的表，这个表定义了三个链（chains）工作场景:**主机防火墙** INPUT 负责过滤所有目标是本机地址的数据包通俗来说：就是过滤进入主机的数据包 FORWARD 负责转发流经主机的数据包。起到转发的作用，和NAT关系很大。LVS NAT 模式，net.ipv4.ip_forward=0 OUTPUT 处理所有源地址是本机地址的数据包通俗的讲：就是处理从主机发出的数据包 对于filter表的控制是我们实现本机防火墙功能的重要手段，特别是INPUT链的控制。 1.3.2 NAT表信息详细介绍 NAT表 负责网络地址转换的，即来源与目的的IP地址和port的转换。应用：和主机本身无关，一般用于局域网共享上网或者特殊的端口转换相关.工作场景：1、用于路由(zebra)或网关(iptables),共享上网(POSTROUTING)2、做内部外部IP地址一对一映射(dmz),硬件防火墙映射IP到内部服务器，FTP服务(PREROUTING)3、WEB,单个端口的映射，直接映射80端口(PREROUTING)这个表定义了3个链，nat功能相当于网络的acl控制。和网络交换机acl类似。 OUTPUT 和主机放出去的数据包有关，改变主机发出数据包的目的地址。 PREROUTING 在数据包到达防火墙时，进行路由判断之前执行的规则，作用是改变数据包的目的地址、目的端口等就是收信时，根据规则重写收件人的地址例如：把公网IP： xxx.xxx.xxx.xxx 映射到局域网的 x.x.x.x 服务器如果是web服务，可以把80转换为局域网的服务器9000端口上。 POSTROUTING 在数据包离开防火墙时进行路由判断之后执行的规则，作用改变数据包的源地址，源端口等。写好收件人的地址，要让家人回信时能够有地址可回。例如。默认笔记本和虚拟机都是局域网地址，在出网的时候被路由器将源地址改为公网地址。生产应用：局域网共享上网。 1.3.3 Mangle表信息详细介绍 Mangle表 主要负责修改数据包中特殊的路由标记，如TTL,TOS,MARK等，这个表定义了5个链(chains). 由于这个表与特殊标记相关，一般倩况下，我们用不到这个mangle表。 这里就不做详细介绍了。 1.4 iptables工作流程1.4.1 工作流程说明前面介绍已经提到，iptables是采用数据包过滤机制工作的，所以它会对请求的数据包的包头数据进行分析，并根据我们预先设定的规则进行匹配来决定是否可以进入主机。 iptables是采用数据包过滤机制工作的，所以它会对请求的数据包的包头数据进行分析，并根据我们预先设定的规则进行匹配来决定是否可以进入主机。 数据包的流向是从左向右的。 图 - iptables包处理流程图 图 - iptables包处理流程图(简化) 抽象说明：上图可以用北京地铁1,2号线来描述： 1号线：主要是NAT功能 案例： 1)局域网上网共享（路由和网关），使用NAT的POSTROUTING链。 2)外部IP和端口映射为内部IP和端口（DMZ功能），使用NAT的PREROUTING链 2号线：主要是FILTER功能，即防火墙功能FILTER INPUT FORWARD 案例： 主要应用就是主机服务器防火墙，使用FILTER的INPUT链 图 - iptables数据包转发流程图 1.4.2 iptables工作流程小结 1、防火墙是一层层过滤的。实际是按照配置规则的顺序从上到下，从前到后进行过滤的。 2、如果匹配上了规则，即明确表明是阻止还是通过，此时数据包就不在向下匹配新规则了。 3、如果所有规则中没有明确表明是阻止还是通过这个数据包，也就是没有匹配上规则，向下进行匹配，直到匹配默认规则得到明确的阻止还是通过。 4、防火墙的默认规则是对应链的所有的规则执行完以后才会执行的（最后执行的规则）。 1.5 iptables操作系统环境说明 1234[root@clsn ~]# cat &#x2F;etc&#x2F;redhat-release CentOS release 6.9 (Final)[root@clsn ~]# hostname -I10.0.0.188 172.16.1.188 软件版本 12[root@clsn ~]# iptables -Viptables v1.4.7 1.5.1 iptables参数说明 参数 参数说明 显示相关参数 -n/–numeric 以数字的方式显示地址或端口信息 -L/ –list 列出一个链或所有链中的规则信息 –list-rules/-S Print the rules in a chain or all chains –line-number 当列出规则信息时，打印规则行号 -v 显示详细信息，可以叠加 -h 显示帮助信息 初始化相关参数 iptables -F 清除所有规则，不会处理默认的规则 iptables -X 删除用户自定义的链 iptables -Z 链的计数器清零（数据包计数器与数据包字节计数器） 配置常用参数 -t 表名称 指定配置哪个表，指定配置表名称。 –append/-A 链名称 附加或追加上相应规则策略，到指定链(链名称必须大写)，默认将配置的规则插入到最后一条。 –check/-C Check for the existence of a rule –insert/-I 链名称 插入相应规则策略，到指定链上，默认将配置的规则插入到第一条（可以根据规则序号插入到指定位置）–封IP地址使用。 –delete/-D 链名称 删除指定的规则(可以根据规则序号进行删除) –replace/-R Replace rule rulenum (1 = first) in chain -P(**大写)**链名称 改变链上的最终默认规则策略 –new/-N 创建新的用户定义链 -p 协议名称**[!] –proto** 指定规则的协议名称 all tcp udp icmp –dport 指定匹配的目标端口信息 –sport 指定匹配的源端口信息 -j 动作 匹配数据包后的动作 ACCEPT 允许 DROP 丢弃(没有响应) REJECT 拒绝(回应请求者明确的拒绝) MASQUERADE 伪装上网时使用 SNAT 共享地址上网 DNAT 目的地址改写 -i**[!] –in-interface** 在INPUT链配置规则中，指定从哪一个网卡接口进入的流量（只能配置在INPUT链上） -o**[!] –out-interface** 在OUTPUT链配置规则中，指定从哪一个网接口出去的流量（只能配置在OUTPUT链上） -s [!] –source 指定源IP地址或源网段信息 -d**[!] –destination** 指定目标IP地址或目标网段信息 扩展参数 -m 模块 表示增加扩展，匹配功能扩展匹配（可以加载扩展参数） multiport 实现不连续多端口扩展匹配 icmp 使用icmp的扩展 state 状态模块扩展 –icmp-type 只有类型8是真正会影响ping，或者也可以采用any；了解很多icmp类型iptables -p icmp -h –limit n/{second/minute/hour} 指定时间内的请求速率”n”为速率，后面为时间分别为：秒分 时 –limit-burst [n] 在同一时间内允许通过的请求”n”为数字，不指定默认为5 –exact/-x 扩展数字（显示精确数值） !**的使用实例** 1234[root@clsn ~]# iptables ! -VNot 1.4.7 ;-)[root@clsn ~]# iptables -Viptables v1.4.7 注意：在iptables中所有链名必须大写，表明必须小写，动作必须大写，匹配必须小写。 1.5.2 配置前准备在配置防火墙首先要其中防火墙 12[root@clsn ~]# &#x2F;etc&#x2F;init.d&#x2F;iptables start iptables: Applying firewall rules: [ OK ] 清除iptables所有规则 123[root@clsn ~]# iptables -Z[root@clsn ~]# iptables -X[root@clsn ~]# iptables -F 查看iptables的规则 123456789[root@clsn ~]# iptables -nvLChain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 查看其他的表配置（-t 参数） 123456[root@clsn ~]# iptables -nL -t rawChain PREROUTING (policy ACCEPT)target prot opt source destination Chain OUTPUT (policy ACCEPT)target prot opt source destination 查看配置规则的顺序号 12[root@clsn ~]# iptables -nvL -line-number--line-number # 显示规则的序号 1.6 iptables filter表配置实例1.6.1 基础配置配置实例一：配置22/ssh端口访问控制规则 12345iptables -A INPUT -p tcp --dprot 22 -j DROP # 禁止所有人访问22端口iptables -I INPUT -p tcp --dprot 22 -j ACCEPT # 恢复连接方法iptables -I INPUT 2 -p tcp --dprot 22 -j ACCEPT # 通过插入指定行号信息，指定将规则插入到第几行iptables -D INPUT -p tcp --dport 22 -j ACCEPT # 删除指定规则iptables -D INPUT 2 # 根据规则行号，删除相应的规则 只允许10.0.0.1的ip通过ssh连接这台服务器 1iptables -I INPUT -s 10.0.0.1 -p tcp --dport 22 -j ACCEPT 配置实例二：禁止网段连入（禁止172.16.1.0网段访问172.16.1.188） 1iptables -A INPUT -s 172.16.1.0&#x2F;24 -d 172.16.1.188 -j DROP 配置实例三：禁止某个172.16.1.0网段访问服务器主机的22端口 1iptables -A INPUT -s 172.16.1.0&#x2F;24 -d 172.16.1.188 -p tcp --dport 22 -j DROP 方向说明： 1234# 在入方向控制iptables -I INPUT -i eth0 -p tcp --dport 22 -j ACCEPT# 在出方向控制iptables -I OUTPUT -o eth0 -p tcp --sport 22 -j DROP 1.6.2 配置实例四：除10.0.0.0网段可以进行连接服务器主机意外，其余网段都禁止 第一种方式： 1iptables -A INPUT -s 10.0.0.0&#x2F;24 -d 172.16.1.8 -j ACCEPT 修改默认规则，将默认规则改为拒绝 第二种方式： ！ — 表示对规则信息进行取反 12iptables -A INPUT ! -s 10.0.0.0&#x2F;24 -d 172.16.1.8 -j DROP --- centos6用法iptables -A INPUT -s ! 10.0.0.0&#x2F;24 -d 172.16.1.8 -j DROP --- centos5用法 说明：只有iptables帮助手册中指定的参数可以用取反符号（iptables –help） 1.6.3 配置实例五：测试匹配列举端口范围。12iptables -A INPUT -p tcp --dport 22:80 -j DROP # 设置连续多端口控制策略iptables -A INPUT -p tcp -m multiport --dport 22,80 -j DROP # 设置不连续多端口控制策略 -m 参数表示增加扩展匹配功能，multiport 实现不连续多端口扩展匹配 1.6.4 配置实例六：匹配ICMP类型 禁止ping策略原则 iptables服务器是ping命令发起者或是接受者 发起者： input链： 禁止icmp-type 0 0 Echo Reply——回显应答（Ping应答) 1iptables -A INPUT -i eth0 -p icmp --icmp-type 0 -j DROP output链： 禁止icmp-type 8 8 Echo request——回显请求（Ping请求） 1iptables -A OUTPUT -o eth0 -p icmp --icmp-type 8 -j DROP 接受者： input链： 禁止icmp-type 8 8 Echo request——回显请求（Ping请求） 1iptables -A INPUT -i eth0 -p icmp --icmp-type 8 -j DROP output链： 禁止icmp-type 0 0 Echo Reply——回显应答（Ping应答) 1iptables -A OUTPUT -o eth0 -p icmp --icmp-type 0 -j DROP 简化配置： 1iptables -A INPUT -i eth0 -p icmp -m icmp --icmp-type any -j DROP #禁止所有类型的icmp 指定类型禁止icmp 1234iptables -A INPUT -p icmp --icmp-type 8iptables -A INPUT -p icmp --icmp-type 8 -j DROPiptables -A INPUT -p icmp -m icmp --icmp-type any -j ACCEPTiptables -A FORWARD -s 192.168.1.0&#x2F;24 -p icmp -m icmp --icmp-type any -j ACCEPT 说明：只有类型8是真正会影响ping，或者也可以采用any；了解很多icmp类型iptables -p icmp -h ICMP**类型的说明** TYPE CODE Description Query Error 0 0 Echo Reply——回显应答（Ping应答） x 3 0 Network Unreachable——网络不可达 x 3 1 Host Unreachable——主机不可达 x 3 2 Protocol Unreachable——协议不可达 x 3 3 Port Unreachable——端口不可达 x 3 4 Fragmentation needed but no frag. bit set——需要进行分片但设置不分片比特 x 3 5 Source routing failed——源站选路失败 x 3 6 Destination network unknown——目的网络未知 x 3 7 Destination host unknown——目的主机未知 x 3 8 Source host isolated (obsolete)——源主机被隔离（作废不用） x 3 9 Destination network administratively prohibited——目的网络被强制禁止 x 3 10 Destination host administratively prohibited——目的主机被强制禁止 x 3 11 Network unreachable for TOS——由于服务类型TOS，网络不可达 x 3 12 Host unreachable for TOS——由于服务类型TOS，主机不可达 x 3 13 Communication administratively prohibited by filtering——由于过滤，通信被强制禁止 x 3 14 Host precedence violation——主机越权 x 3 15 Precedence cutoff in effect——优先中止生效 x 4 0 Source quench——源端被关闭（基本流控制） 5 0 Redirect for network——对网络重定向 5 1 Redirect for host——对主机重定向 5 2 Redirect for TOS and network——对服务类型和网络重定向 5 3 Redirect for TOS and host——对服务类型和主机重定向 8 0 Echo request——回显请求（Ping请求） x 9 0 Router advertisement——路由器通告 10 0 Route solicitation——路由器请求 11 0 TTL equals 0 during transit——传输期间生存时间为0 x 11 1 TTL equals 0 during reassembly——在数据报组装期间生存时间为0 x 12 0 IP header bad (catchall error)——坏的IP首部（包括各种差错） x 12 1 Required options missing——缺少必需的选项 x 13 0 Timestamp request (obsolete)——时间戳请求（作废不用） x 14 Timestamp reply (obsolete)——时间戳应答（作废不用） x 15 0 Information request (obsolete)——信息请求（作废不用） x 16 0 Information reply (obsolete)——信息应答（作废不用） x 17 0 Address mask request——地址掩码请求 x 18 0 Address mask reply——地址掩码应答 数据来源：http://www.cnitblog.com/yang55xiaoguang/articles/59581.html 1.6.5 防火墙状态机制配置状态集简单说明: 状态集 说明 NEW 表示新建立连接的数据包状态 ESTABLISHED 表示新建立连接数据包发送之后，回复响应的数据包状态 RELATED 表示借助已经建立的链路，发送新的连接数据包 INVALID 无效无法识别的数据包 注意：允许关联的状态包通过（web服务不要使用FTP服务） 防火墙服务配置在FTP服务器上时，需要配置以下策略 12iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPTiptables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT 实现发现sent_syn状态 1iptables -A INPUT -m state --state NEW -j DROP # 防火墙所连接客户端上配置 实现发现sent_rcvd状态 1iptables -I INPUT -i eth0 -s 10.0.0.201 -m state --state ESTABLISHED -j DROP # 防护墙上配置的 1.6.6 使用iptables实现限速功能limit是iptables的一个匹配模块，用它结合iptables的其它命令可以实现限速的功能。 不过首先必须明确，limit本身只是一个“匹配”模块。我们知道，iptables的基本原理是“匹配–处理”，limit在这个工作过程中只能起到匹配的作用，它本身是无法对网络数据包进行任何处理的。我看到网上有些limit的例子里面说只 用一条包含limit匹配规则的iptables语句就可以实现限速，那是错误的。 实际上，利用imit来限速需要包括两个步骤: 1.对符合limit匹配规则包放行 2.丢弃/拒绝未放行的包 示例： 12iptables -I INPUT -s 10.0.0.7 -p icmp --icmp-type 8 -m limit --limit 6&#x2F;min --limit-burst 5 -j ACCEPT iptables -I INPUT -s 10.0.0.7 -p icmp --icmp-type 8 -j DROP 语句含义：当来自10.0.0.7 的ping包超过5个时进行限速，限制为每10s一个。 参数说明： 参数 参数含义 –limit n/{second/minute/hour} 指定时间内的请求速率”n”为速率，后面为时间分别为：秒 分 时 –limit-burst [n] 在同一时间内允许通过的请求”n”为数字，不指定默认为5 limit 模块具体是如何工作的。？ limit的匹配是基于令牌桶 (Token bucket）模型的。 令牌桶是一种网络通讯中常见的缓冲区工作原理，它有两个重要的参数，令牌桶容量n和令牌产生速率s。 我们可以把令牌当成是门票，而令牌桶则是负责制作和发放门票的管理员，它手里最多有n张令牌。一开始，管理员开始手里有n张令牌。每当一个数据包到达后，管理员就看看手里是否还有可用的令牌。如果有，就把令牌发给这个数据包，limit就告诉iptables，这个数据包被匹配了。而当管理员把手上所有的令牌都发完了，再来的数据包就拿不到令牌了。这时，limit模块就告诉iptables，这个数据包不能被匹配。除了发放令牌之外，只要令牌桶中的令牌数量少于n，它就会以速率s来产生新的令牌，直到令牌数量到达n为止。 通过令牌桶机制，即可以有效的控制单位时间内通过（匹配）的数据包数量，又可以容许短时间内突发的大量数据包的通过（只要数据包数量不超过令牌桶n）。 limit模块提供了两个参数–limit和–limit-burst，分别对应于令牌产生速率和令牌桶容量。除了令牌桶模型外，limit匹配的另外一个重要概念是匹配项。在limit中，每个匹配项拥有一个单独的令牌桶，执行独立的匹配计算。 1.6.7防火墙配置清除防火墙规则 123[root@clsn ~]# iptables -F[root@clsn ~]# iptables -X[root@clsn ~]# iptables -Z 修改默认规则为拒绝（修改前先放行22端口，保证自己能够连上主机） 123[root@clsn ~]# iptables -A INPUT -p tcp --dport 22 -j ACCEPT[root@clsn ~]# iptables -P INPUT DROP [root@clsn ~]# iptables -P FORWARD DROP 放行指定的端口 123456[root@clsn ~]# iptables -A INPUT -i lo -j ACCEPT[root@clsn ~]# iptables -A INPUT -p tcp -m multiport --dport 80,443 -j ACCEPT [root@clsn ~]# iptables -A INPUT -s 172.16.1.0&#x2F;24 -j ACCEPT[root@clsn ~]# iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT#multiport多个不连续 21:25,80,443 保存iptables**配置** \\01. 第一种方式 12345678910111213141516[root@clsn ~]# &#x2F;etc&#x2F;init.d&#x2F;iptables saveiptables: Saving firewall rules to &#x2F;etc&#x2F;sysconfig&#x2F;iptables:[ OK ][root@clsn ~]# cat &#x2F;etc&#x2F;sysconfig&#x2F;iptables# Generated by iptables-save v1.4.7 on Tue Apr 4 12:24:43 2017*filter:INPUT DROP [0:0]:FORWARD DROP [0:0]:OUTPUT ACCEPT [159:10664]-A INPUT -s 10.0.0.0&#x2F;24 -j ACCEPT -A INPUT -p tcp -m tcp --dport 22 -j ACCEPT -A INPUT -p tcp -m multiport --dports 80,443 -j ACCEPT -A INPUT -s 172.16.1.0&#x2F;24 -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT COMMIT# Completed on Tue Apr 4 12:24:43 2017 \\02. 第二种方式 1iptables-save &gt;&#x2F;etc&#x2F;sysconfig&#x2F;iptables 1.7 iptables nat表配置实例(理论)(理论掌握) 1.7.1 iptables实现共享上网 图 - SNAT 配置原理图 第一个里程碑：配置内网服务器，设置网关地址 123&#x2F;etc&#x2F;init.d&#x2F;iptables stop # 内网服务器停止防火墙服务ifdown eth0 # 模拟关闭内网服务器外网网卡setup # 修改内网网卡网关和DNS地址信息 也可以使用命令添加默认网关 1route add default gw 172.16.1.188 查看默认的路由信息 123456[root@test ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface172.16.1.0 0.0.0.0 255.255.255.0 U 0 0 0 eth1169.254.0.0 0.0.0.0 255.255.0.0 U 1003 0 0 eth10.0.0.0 172.16.1.188 0.0.0.0 UG 0 0 0 eth1 说明：内网服务器网关地址指定为共享上网服务器内网网卡地址 第二个里程碑：配置共享上网服务器，开启共享上网服务器路由转发功能 12345[root@clsn ~]# vim &#x2F;etc&#x2F;sysctl.conf [root@clsn ~]# sysctl -p~~~net.ipv4.ip_forward &#x3D; 1~~~ 第三个里程碑：配置共享上网服务器，实现内网访问外网的NAT映射 1iptables -t nat -A POSTROUTING -s 172.16.1.0&#x2F;24 -o eth0 -j SNAT --to-source 10.0.0.188 参数详解： 参数 参数说明 -s 172.16.1.0/24 指定将哪些内网网段进行映射转换 -o eth0 指定在共享上网哪个网卡接口上做NAT地址转换 -j SNAT 将源地址进行转换变更 -j DNAT 将目标地址进行转换变更 –to-source ip**地址** 将源地址映射为什么IP地址 –to-destination ip**地址** 将目标地址映射为什么IP地址 当filter表中的forward默认为drop策略时，如何配置forward链？ 图 - forward工作原理 配置示例 1234iptables -A FORWARD -i eth1 -s 172.16.1.0&#x2F;24 -j ACCEPT# iptables -A FORWARD -o eth0 -s 172.16.1.0&#x2F;24 -j ACCEPT # 可以不进行配置iptables -A FORWARD -i eth0 -d 172.16.1.0&#x2F;24 -j ACCEPT# iptables -A FORWARD -o eth1 -d 172.16.1.0&#x2F;24 -j ACCEPT # 可以不进行配置 当外网ip不固定时如何配置？ 1iptables -t nat -A POSTROUTING -s 172.16.1.0&#x2F;24 -o eth0 -j MASQUERADE # 伪装共享上网 说明：在工作中如何没有固定外网IP地址，可以采取以上伪装映射的方式进行共享上网 配置映射方法小结 \\01. 指定哪些网段需要进行映射 -s 172.16.1.0/24 \\02. 指定在哪做映射 -o eth0 \\03. 用什么方法做映射 -j SNAT/DNAT MASQUERADE \\04. 映射成什么地址 –to-source ip地址/–to-destination ip地址 1.7.2 iptables实现外网IP的端口映射到内网IP的端口实际需求：将网关的IP和9000端口映射到内网服务器的22端口 端口映射 10.0.0.188:9000 –&gt;172.16.1.180:22 配置实例： 1iptables -t nat -A PREROUTING -d 10.0.0.188 -p tcp --dport 9000 -i eth0 -j DNAT --to-destination 172.16.1.7:22 参数说明: 参数 参数说明 -d 10.0.0.188 目标地址。 -j DNAT 目的地址改写。 1.7.3 IP一对一映射 图 - DNAT 映射原理 实际需求：将ip 地址172.16.1.180 映射到10.0.0.188 通过辅助IP配置： 123ip addr add 10.0.0.81&#x2F;24 dev eth0 label eth0:0 # 添加辅助IPiptables -t nat -I PREROUTING -d 10.0.0.81 -j DNAT --to-destination 172.16.1.51iptables -t nat -I POSTROUTING -s 172.16.1.51 -o eth0 -j SNAT --to-source 10.0.0.81 适合内网的机器访问NAT外网的IP 1iptables -t nat -I POSTROUTING -s 172.16.1.0&#x2F;255.255.240.0 -d 10.0.0.81 -j SNAT --to-source 172.16.1.8 检查配置： 123ping 10.0.0.81 -ttcpdump|grep -i icmp（两台机器上分别监测）telnet 10.0.0.81 22 1.7.4 映射多个外网IP上网 方法1： 1iptables -t nat -A POSTROUTING -s 10.0.1.0&#x2F;255.255.240.0 -o eth0 -j SNAT --to-source 124.42.60.11-124.42.60.16 ​ 在三层交换机或路由器，划分VLAN。 方法2： 12iptables -t nat -A POSTROUTING -s 10.0.1.0&#x2F;22 -o eth0 -j SNAT --to-source 124.42.60.11iptables -t nat -A POSTROUTING -s 10.0.2.0&#x2F;22 -o eth0 -j SNAT --to-source 124.42.60.12 ​ 扩大子网，会增加广播风暴。 1.7.5 系统防火墙与网络内核优化标准参数有关iptables的内核优化 调整内核参数文件/etc/sysctl.conf 以下是我的生产环境的某个服务器的配置： 解决time-wait**过多**的解决办法： 1234567891011net.ipv4.tcp_fin_timeout &#x3D; 2net.ipv4.tcp_tw_reuse &#x3D; 1net.ipv4.tcp_tw_recycle &#x3D; 1net.ipv4.tcp_syncookies &#x3D; 1net.ipv4.tcp_keepalive_time &#x3D; 600net.ipv4.tcp_max_tw_buckets &#x3D; 36000net.ipv4.ip_local_port_range &#x3D; 4000 65000net.ipv4.tcp_max_syn_backlog &#x3D; 16384net.ipv4.route.gc_timeout &#x3D; 100net.ipv4.tcp_syn_retries &#x3D; 1net.ipv4.tcp_synack_retries &#x3D; 1 在dmesg中显示 ip_conntrack: table full, dropping packet. 的错误提示，什么原因？ 如何解决？ #iptables优化 123456net.nf_conntrack_max &#x3D; 25000000net.netfilter.nf_conntrack_max &#x3D; 25000000net.netfilter.nf_conntrack_tcp_timeout_established &#x3D; 180net.netfilter.nf_conntrack_tcp_timeout_time_wait &#x3D; 120net.netfilter.nf_conntrack_tcp_timeout_close_wait &#x3D; 60net.netfilter.nf_conntrack_tcp_timeout_fin_wait &#x3D; 120 1.8 自定义链的配置(了解) 图 - 自定义链原理 创建自定义链 12#示例：在filter表中创建NOICMP自定义链iptables -t filter -N NOICMP 引用自定义链 12#示例：在INPUT链中引用刚才创建的自定义链iptables -t filter -I INPUT -p icmp -j NOICMP 重命名自定义链 12#示例：将IN_WEB自定义链重命名为WEBiptables -E NOICMP ACCEPTICMP 删除自定义链 删除自定义链需要满足两个条件 1、自定义链没有被引用 2、自定义链中没有任何规则 12# 示例： 删除引用数为0且不包含任何规则的ACCEPTICMP链iptables -X ACCEPTICMP 1.9 附录-防火墙状态机制状态机制是iptables中较为特殊的一部分，这也是iptables和比较老的ipchains的一个比较大的区別之一，运行状态机制（连接跟踪）的防火墙称作带有状态机制的防火墙，以下简称为状态防火墙.状态防火墙比非状态防火墙要安全，因为它允许我们编写更严密的规则。 在iptables上一共有四种状态，分别被称为NEW、ESTABLISHED、INVALID、RELATED,这四种状态对于TCP、UDP、ICMP三种协议均有效。下面，我们来分别阐述四种状态的特性. 🔔 NEW meaning that the packet has started a new connection, or otherwise associated with a connection which has not seen packets in both directions NEW说明这个包是我们看到的第一个包。意思就是，这是conntrack模块看到的某个连接的第一个包，它即格被匹配了。比如，我们看到一个SYN包，是我们所留意的连接的第一个包，就要匹配它。 🔔 ESTABLISHED meaning that the packet is associated with a connection which has seen packets in both directions ESTABLISHED已经注意到两个方向上的数据传输，而且会继续匹配这个连接的包.处于ESTABLISHED状态的连接是非常容易理解的.只要发送并接到应答，连接就是ESTABLISHED的了。一个连接要从NEW变为ESTABLISHED,只需要接到应答包即可，不管这个包是发往防火墙的，还是要由防火墙转发的.ICMP的错误和重定向等信息包也被看作是ESTABLISHED,只要它们是我们所发出的信息的应答。 🔔 RELATED meaning that the packet is starting a new connection, but is associated with an existing connection, such as an FTP data transfer, or an ICMP error. RELATED是个比较麻烦的状态.当一个连接和某个已处于ESTABLISHED状态的连接有关系时，就被认为是RELATED的了，换句话说，一个连接要想是RELATED的，首先要有一个ESTABLISHED的连接。这个ESTABLISHED连接再产生一个主连接之外的连接，这个新的连接就是RELATED的了，当然前提是conntrack模块要能理解RELATED。ftp是个很好的例子，FTP-data连接就是和FTP-control有关联的，如果没有在iptables的策略中配RELATED状态，FTP-data的连接是无法正确建立的，还有其他的例子，比如，通过IRC的DCC连接#有了这个状态，ICMP应答、FTP传输、DCC等才能穿过防火墙正常工作.注意，大部分还有一些UDP协议都依赖这个机制。这些协议是很复杂的，它们把连接信息放在数据包里，并且要求这些信息能被正确理解。 🔔 INVALID meaning that the packet is associated with no known connection INVALID说明数据包不能被识别属于哪个连接或没有任何状态.有几个原因可以产生这种情况，比如，内存溢出，收到不知厲于哪个连接的ICMP错误信息。一般地，我们DROP这个状态的任何东西，因为防火墙认为这是不安全的东西 1.9.1 iptables配置哲学如何防止自己被关在门外？ 01、去机房重启系统或者登陆服努器删除刚才的禁止规则。 02、让机房人员重启服务器或者让机房人员拿用户密码登录进去。 03、通过服务器的远程管理卡管理（推荐）。 04、先写一个定时任务，每5分钟就停止防火墙。 05、测试环境测试好，写成脚本，批置执行 配置禁用22端口策略: 12iptables -I INPUT -p tcp - dport 22 -j DROP# 说明：利用-I参数，实现强行阻止访问22端口，将Jffc规则放在第一位 删除配置的禁止连接22端口的规则 123iptables -t filter -D INPUT -p tcp —dport 22 -j DROPiptables -F&#x2F;etc&#x2F;init.d&#x2F;iptables restart 1.10 参考文献 [1] http://www.aichengxu.com/linux/3122717.htm [2] http://blog.csdn.net/huguohu2006/article/details/6453522 [3] http://blog.csdn.net/lin_credible/article/details/8614907 [4] http://blog.chinaunix.net/uid-27057175-id-5179329.html [5] http://blog.51cto.com/oldboy/974194 [6] http://blog.sina.com.cn/s/blog_773d9b6701018rwo.html [7] http://www.zsythink.net/archives/1625 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# iptables -t 表名 动作(命令) 链名 匹配条件 -j 目标动作 -t 表名 raw mangle nat filter （如果不写-t 默认使用filter表） 链名(各表对应的链)raw(PROROUTING、OUPUT)mangle(PROROUTING、FORWARD、OUTPUT、POSTROUTING)nat(PREROUTING、INPUT、FORWARD、OUTPUT、POSTROUING)filter(INPUT、FORWARD、OUTPUT) 动作(官方叫命令)：-A 添加规则： (append追加) # iptables -t filter -A INPUT -p icmp -j REJECT(拒绝) &#x2F;&#x2F;拒绝所有的icmp，即任何人不能ping同你 # iptables -t filter -A INPUT -p tcp --dport 22 -s 10.18.44.158 -j REJECT 拒绝源地址10.18.44.158的tcp协议的22端口 -I 插入规则 ： # iptables -t filter -I INPUT 2 -p tcp --dport 22 -s 10.18.44.171 -j REJECT &#x2F;&#x2F;INPUT不加数字默认是第一行，数字代表插入到哪一行前边-R 替换规则： # iptables -t filter -R INPUT 1 -p tcp --dport 22 -s 10.18.44.181 -j REJECT &#x2F;&#x2F;替换的时候 INPUT必须跟上行号-D 删除规则 # iptables -t filter -D INPUT -p icmp -j REJECT # iptables -D INPUT 2-P 修改默认策略：只能使用DROP和ACCEPT # iptables -P INPUT DROP # iptables -P INPUT ACCEPT -N 添加自定义链 #iptables -N tiger #iptables -A tiger -p tcp --dport 22 -s 10.18.44.208 -j REJECT 存储规则 自定义链里的规则在没有被调用的情况下不生效 使用自定义链(关联自定义链) #iptables -A INPUT -j tiger 修改自定义链名称 #iptables -E tiger TIGER删掉自定义链： 1.不能被关联 2.必须是空链 #iptables -X 链名-F 清空规则 # iptables -F 链名 &#x2F;&#x2F;指定链的所有规则 #iptables -F &#x2F;&#x2F;所有的规则-Z 计数清零 字节数 数据包个数 #iptables -Z &#x2F;&#x2F;喜爱嗯看到计数用#iptables -L -n -v (v可有号多个) -L 查看规则 -n以数字的形式显示ip和端口协议 --line 显示规则行号 -v流量计数(verbose 数据包的计数) #iptables -L #iptables -L -n #iptables -L -n --line #iptables -L -n -v 匹配条件：基本匹配 在使用协议的时候不必非得写端口，但是使用端口是必须跟协议 协议 &#x2F;etc&#x2F;protocols ---icmp协议簇 &#x2F;etc&#x2F;servers --TCP&#x2F;IP协议簇 -p tcp udp icmp -ptcp 端口 --sport &#x2F;&#x2F;源端口 # iptables -A INPUT -p tcp --sport 22 -s 10.18.44.208 -j REJECT # iptables _A INPUT -p tcp --sport 22:30 -s 10.18.44.208,10.18.44.209,10.18.44.210 -j REJECT --dport &#x2F;&#x2F;目标端口 # iptables -A INPUT -p tcp --dport 22 -s 10.18.44.208 -j REJECT ip -s #iptables -A INPUT -p tcp --dport 20:30 -s 10.18.44.208&#x2F;24 -j REJECT &#x2F;&#x2F; 在iptables中 10.18.44.208&#x2F;24 其实是10.18.44.0&#x2F;24 -d","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/categories/Linux/"}],"tags":[{"name":"iptables","slug":"iptables","permalink":"https://github.com/cyylog/tags/iptables/"}]},{"title":"Redis","slug":"SQL/redis","date":"2018-12-04T17:55:39.000Z","updated":"2020-05-25T13:57:34.458Z","comments":true,"path":"2018/12/05/SQL/redis/","link":"","permalink":"https://github.com/cyylog/2018/12/05/SQL/redis/","excerpt":"","text":"redis redis简介123456789101112131415161718192021什么是redisREmote DIctionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统。Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Hash), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。redis是一个开源的、使用C语言编写的、支持网络交互的、可基于内存也可持久化的Key-Value数据库。redis的官网：redis.io注:域名后缀io属于国家域名，是british Indian Ocean territory，即英属印度洋领地1.Redis是一个key-value存储系统。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set –有序集合)和hash（哈希类型）。这些数据类型都支持push&#x2F;pop、add&#x2F;remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。2.在此基础上，redis支持各种不同方式的排序。与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。 Redis 是一个高性能的key-value数据库。 redis的出现，很大程度补偿了memcached这类key&#x2F;value存储的不足，在部 分场合可以对关系数据库起到很好的补充作用。它提供了Java，C&#x2F;C++，C#，PHP，JavaScript，Perl，Object-C，Python，Ruby，Erlang等客户端，使用很方便。3.Redis支持主从同步。数据可以从主服务器向任意数量的从服务器上同步，从服务器可以是关联其他从服务器的主服务器。这使得Redis可执行单层树复制。存盘可以有意无意的对数据进行写操作。由于完全实现了发布&#x2F;订阅机制，使得从数据库在任何地方同步树时，可订阅一个频道并接收主服务器完整的消息发布记录。同步对读取操作的可扩展性和数据冗余很有帮助。 12345Redis 与其他 key - value 缓存产品有以下三个特点：- Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。- Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。- Redis支持数据的备份，即master-slave模式的数据备份。 redis优势1234- 性能极高 – Redis能读的速度是110000次&#x2F;s,写的速度是81000次&#x2F;s 。- 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。- 原子 – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。- 丰富的特性 – Redis还支持 publish&#x2F;subscribe, 通知, key 过期等等特性。 redis安装123456下载地址http:&#x2F;&#x2F;redis.io&#x2F;download，下载最新稳定版本。$ wget http:&#x2F;&#x2F;download.redis.io&#x2F;releases&#x2F;redis-5.0.4.tar.gz$ tar xzf redis-5.0.4.tar.gz$ cd redis-5.0.4.tar.gz$ yum install -y make gcc$ make redis简单配置1234567891011# cp redis.conf redis.conf.bak# vim redis.conf ---修改如下bind 127.0.0.1 #只监听内网IPdaemonize yes #开启后台模式将on改为yestimeout 300 #连接超时时间port 6379 #端口号databases 0 存储Session的Redis库编号dir .&#x2F; #本地数据库存放目录该目录需要存在pidfile &#x2F;var&#x2F;run&#x2F;redis_6379.pid #定义pid文件logfile &#x2F;var&#x2F;log&#x2F;redis_6379.log #定义log文件requirepass cyy # 设置密码 配置redis为systemctl启动123456789101112131415161718192021222324# cd &#x2F;lib&#x2F;systemd&#x2F;system# vim &#x2F;lib&#x2F;systemd&#x2F;system&#x2F;redis.service[Unit]Description&#x3D;RedisAfter&#x3D;network.target[Service]ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;redis-5.0.4&#x2F;src&#x2F;redis-server &#x2F;usr&#x2F;local&#x2F;redis-5.0.4&#x2F;redis.conf --daemonize noExecStop&#x3D;&#x2F;usr&#x2F;local&#x2F;redis-5.0.4&#x2F;src&#x2F;redis-cli -h 127.0.0.1 -p 6379 shutdown[Install]WantedBy&#x3D;multi-user.target&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;参数详解:• [Unit] 表示这是基础信息 • Description 是描述• After 是在那个服务后面启动，一般是网络服务启动后启动• [Service] 表示这里是服务信息 • ExecStart 是启动服务的命令• ExecStop 是停止服务的指令• [Install] 表示这是是安装相关信息 • WantedBy 是以哪种方式启动：multi-user.target表明当系统以多用户方式（默认的运行级别）启动时，这个服务需要被自动运行。 redis启动123make完后 redis-5.0.4目录下会出现编译后的redis服务程序redis-server,还有用于测试的客户端程序redis-cli,两个程序位于安装目录 src 目录下：下面启动redis服务. 1234567$ src&#x2F;redis-server注意这种方式启动redis 使用的是默认配置。也可以通过启动参数告诉redis使用指定配置文件使用下面命令启动。$ cd src$ .&#x2F;redis-server ..&#x2F;redis.confredis.conf 是一个默认的配置文件。我们可以根据需要使用自己的配置文件。 redis客户端测试1234567$ src&#x2F;redis-cli127.0.0.1:6379&gt; set 2020 GZOK127.0.0.1:6379&gt; get 2020&quot;GZ&quot;127.0.0.1:6379&gt; pingPONG redis配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394redis的配置默认位于redis安装目录下，文件名未redis.confRedis CONFIG 命令格式如下：redis 127.0.0.1:6379&gt; CONFIG GET CONFIG_SETTING_NAME也可以通过命令查看或设置相关配置127.0.0.1:6379&gt; config get loglevel1) &quot;loglevel&quot;2) &quot;notice&quot;通过* 查看所有配置127.0.0.1:6379&gt; config get * 1) &quot;dbfilename&quot; 2) &quot;dump.rdb&quot; 3) &quot;requirepass&quot; 4) &quot;&quot; 5) &quot;masterauth&quot; 6) &quot;&quot; 7) &quot;cluster-announce-ip&quot; 8) &quot;&quot; 9) &quot;unixsocket&quot; 10) &quot;&quot; 11) &quot;logfile&quot; 12) &quot;&quot; 13) &quot;pidfile&quot; 14) &quot;&quot; 15) &quot;slave-announce-ip&quot; 16) &quot;&quot; 17) &quot;replica-announce-ip&quot; 18) &quot;&quot; 19) &quot;maxmemory&quot; 20) &quot;0&quot; 21) &quot;proto-max-bulk-len&quot; 22) &quot;536870912&quot; 23) &quot;client-query-buffer-limit&quot; 24) &quot;1073741824&quot; 25) &quot;maxmemory-samples&quot; 26) &quot;5&quot; 27) &quot;lfu-log-factor&quot; 28) &quot;10&quot; 29) &quot;lfu-decay-time&quot; 30) &quot;1&quot; 31) &quot;timeout&quot; 32) &quot;0&quot; 33) &quot;active-defrag-threshold-lower&quot; 34) &quot;10&quot; 35) &quot;active-defrag-threshold-upper&quot; 36) &quot;100&quot; 37) &quot;active-defrag-ignore-bytes&quot; 38) &quot;104857600&quot; 39) &quot;active-defrag-cycle-min&quot; 40) &quot;5&quot; 41) &quot;active-defrag-cycle-max&quot; 42) &quot;75&quot; 43) &quot;active-defrag-max-scan-fields&quot; 44) &quot;1000&quot; 45) &quot;auto-aof-rewrite-percentage&quot; 46) &quot;100&quot; 47) &quot;auto-aof-rewrite-min-size&quot; 48) &quot;67108864&quot; 49) &quot;hash-max-ziplist-entries&quot; 50) &quot;512&quot; 51) &quot;hash-max-ziplist-value&quot; 52) &quot;64&quot; 53) &quot;stream-node-max-bytes&quot; 54) &quot;4096&quot; 55) &quot;stream-node-max-entries&quot; 56) &quot;100&quot; 57) &quot;list-max-ziplist-size&quot; 58) &quot;-2&quot; 59) &quot;list-compress-depth&quot; 60) &quot;0&quot; 61) &quot;set-max-intset-entries&quot; 62) &quot;512&quot; 63) &quot;zset-max-ziplist-entries&quot; 64) &quot;128&quot; 65) &quot;zset-max-ziplist-value&quot; 66) &quot;64&quot; 67) &quot;hll-sparse-max-bytes&quot; 68) &quot;3000&quot; 69) &quot;lua-time-limit&quot; 70) &quot;5000&quot; 71) &quot;slowlog-log-slower-than&quot; 72) &quot;10000&quot; 73) &quot;latency-monitor-threshold&quot; 74) &quot;0&quot; 75) &quot;slowlog-max-len&quot; 76) &quot;128&quot; 77) &quot;port&quot; 78) &quot;6379&quot; 79) &quot;cluster-announce-port&quot; 80) &quot;0&quot;。。。 编辑配置 可以通过修改redis.conf文件或者使用 CONFIG setm命令修改配置 12345678910CONFIG set 语法如下redis 127.0.0.1:6379&gt; CONFIG SET CONFIG_SETTING_NAME NEW_CONFIG_VALUE示例redis 127.0.0.1:6379&gt; CONFIG SET loglevel &quot;notice&quot;OKredis 127.0.0.1:6379&gt; CONFIG GET loglevel1) &quot;loglevel&quot;2) &quot;notice&quot; 相关配置参数详解 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136 Redis配置文件参数说明:1. Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程daemonize no2. 当Redis以守护进程方式运行时，Redis默认会把pid写入&#x2F;var&#x2F;run&#x2F;redis.pid文件，可以通过pidfile指定pidfile &#x2F;var&#x2F;run&#x2F;redis.pid3. 指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字port 63794. 绑定的主机地址bind 127.0.0.15.当 客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能timeout 3006. 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verboseloglevel verbose7. 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给&#x2F;dev&#x2F;nulllogfile stdout8. 设置数据库的数量，默认数据库为0，可以使用SELECT &lt;dbid&gt;命令在连接上指定数据库iddatabases 169. 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合save &lt;seconds&gt; &lt;changes&gt;Redis默认配置文件中提供了三个条件：save 900 1save 300 10save 60 10000分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。10. 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大rdbcompression yes11. 指定本地数据库文件名，默认值为dump.rdbdbfilename dump.rdb12. 指定本地数据库存放目录dir .&#x2F;13. 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步slaveof &lt;masterip&gt; &lt;masterport&gt;14. 当master服务设置了密码保护时，slav服务连接master的密码masterauth &lt;master-password&gt;15. 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH &lt;password&gt;命令提供密码，默认关闭requirepass foobared16. 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息maxclients 12817. 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区maxmemory &lt;bytes&gt;18. 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为noappendonly no19. 指定更新日志文件名，默认为appendonly.aofappendfilename appendonly.aof20. 指定更新日志条件，共有3个可选值：no：表示等操作系统进行数据缓存同步到磁盘（快）always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）everysec：表示每秒同步一次（折衷，默认值）appendfsync everysec21. 指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析Redis的VM机制）vm-enabled no22. 虚拟内存文件路径，默认值为&#x2F;tmp&#x2F;redis.swap，不可多个Redis实例共享vm-swap-file &#x2F;tmp&#x2F;redis.swap23. 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0vm-max-memory 024. Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值vm-page-size 3225. 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。vm-pages 13421772826. 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4vm-max-threads 427. 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启glueoutputbuf yes28. 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法hash-max-zipmap-entries 64hash-max-zipmap-value 51229. 指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍）activerehashing yes redis数据类型1Redis支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合)。 string12345678910111213string 是 redis 最基本的类型，你可以理解成与 Memcached 一模一样的类型，一个 key 对应一个 value。string 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据。比如jpg图片或者序列化的对象。string 类型是 Redis 最基本的数据类型，string 类型的值最大能存储 512MB127.0.0.1:6379&gt; set name cyylogOK127.0.0.1:6379&gt; get name&quot;cyylog&quot;我们使用了 Redis 的 SET 和 GET 命令。键为 name，对应的值为 cyylog hash123456789101112131415Redis hash 是一个键值(key&#x3D;&gt;value)对集合。Redis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。示例:127.0.0.1:6379&gt; hmset myhash name tiger name2 fiveOK127.0.0.1:6379&gt; hget myhash name&quot;tiger&quot;127.0.0.1:6379&gt; hget myhash name2&quot;five&quot;实例中我们使用了 Redis HMSET, HGET 命令，HMSET 设置了两个 field&#x3D;&gt;value 对, HGET 获取对应 field 对应的 value。每个 hash 可以存储 232 -1 键值对（40多亿）。 List123456789101112131415161718192021222324Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。示例127.0.0.1:6379&gt; lpush mylist redis1(integer) 1127.0.0.1:6379&gt; lpush mylist redis2 redis3 redis4(integer) 4127.0.0.1:6379&gt; lpush mylist tiger 2020(integer) 6127.0.0.1:6379&gt; lrange mylist 0 31) &quot;2020&quot;2) &quot;tiger&quot;3) &quot;redis4&quot;4) &quot;redis3&quot;127.0.0.1:6379&gt; lrange mylist 0 101) &quot;2020&quot;2) &quot;tiger&quot;3) &quot;redis4&quot;4) &quot;redis3&quot;5) &quot;redis2&quot;6) &quot;redis1&quot;上述示例我们通过 lpush 创建list并添加数据，通过lrange获取列表中的数据列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储40多亿)。 set12345678910111213141516171819202122232425262728293031323334Redis的Set是string类型的无序集合。集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。sadd 命令添加一个 string 元素到 key 对应的 set 集合中，成功返回1，如果元素已经在集合中返回 0，如果 key 对应的 set 不存在则返回错误。示例127.0.0.1:6379&gt; sadd myset GZ BJ ZZ BK(integer) 4127.0.0.1:6379&gt; sadd myset TJ(integer) 1127.0.0.1:6379&gt; sadd myset TJ(integer) 0127.0.0.1:6379&gt; smembers myset 1) &quot;BJ&quot;2) &quot;BK&quot;3) &quot;TJ&quot;4) &quot;GZ&quot;5) &quot;ZZ&quot;127.0.0.1:6379&gt; sadd myset SZ(integer) 1127.0.0.1:6379&gt; smembers myset 1) &quot;BJ&quot;2) &quot;BK&quot;3) &quot;TJ&quot;4) &quot;GZ&quot;5) &quot;ZZ&quot;6) &quot;SZ&quot;注意：以上实例中 TJ 添加了两次，但根据集合内元素的唯一性，第二次插入的元素将被忽略。集合中最大的成员数为 232 - 1(4294967295, 每个集合可存储40多亿个成员)。 zset12345678910111213141516171819Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复。zadd 命令添加元素到集合，元素在集合中存在则更新对应score示例127.0.0.1:6379&gt; zadd myzset 0 GZ(integer) 1127.0.0.1:6379&gt; zadd myzset 0 BJ(integer) 1127.0.0.1:6379&gt; zadd myzset 0 ZZ(integer) 1127.0.0.1:6379&gt; zrangebyscore myzset 0 51) &quot;BJ&quot;2) &quot;GZ&quot;3) &quot;ZZ&quot; 1234567891011121314151617181920212223注意：Redis支持多个数据库，并且每个数据库的数据是隔离的不能共享，并且基于单机才有，如果是集群就没有数据库的概念。Redis是一个字典结构的存储服务器，而实际上一个Redis实例提供了多个用来存储数据的字典，客户端可以指定将数据存储在哪个字典中。这与我们熟知的在一个关系数据库实例中可以创建多个数据库类似，所以可以将其中的每个字典都理解成一个独立的数据库。每个数据库对外都是一个从0开始的递增数字命名，Redis默认支持16个数据库（可以通过配置文件支持更多，无上限），可以通过配置databases来修改这一数字。客户端与Redis建立连接后会自动选择0号数据库，不过可以随时使用SELECT命令更换数据库，如要选择1号数据库：示例:127.0.0.1:6379&gt; select 1OK127.0.0.1:6379[1]&gt; get name(nil)127.0.0.1:6379[1]&gt; get myzset(nil)127.0.0.1:6379[1]&gt; select 0OK127.0.0.1:6379&gt; get name&quot;cyylog&quot;127.0.0.1:6379&gt; zrangebyscore myzset 0 21) &quot;BJ&quot;2) &quot;GZ&quot;3) &quot;ZZ&quot;然而这些以数字命名的数据库又与我们理解的数据库有所区别。首先Redis不支持自定义数据库的名字，每个数据库都以编号命名，开发者必须自己记录哪些数据库存储了哪些数据。另外Redis也不支持为每个数据库设置不同的访问密码，所以一个客户端要么可以访问全部数据库，要么连一个数据库也没有权限访问。最重要的一点是多个数据库之间并不是完全隔离的，比如FLUSHALL命令可以清空一个Redis实例中所有数据库中的数据。综上所述，这些数据库更像是一种命名空间，而不适宜存储不同应用程序的数据。比如可以使用0号数据库存储某个应用生产环境中的数据，使用1号数据库存储测试环境中的数据，但不适宜使用0号数据库存储A应用的数据而使用1号数据库B应用的数据，不同的应用应该使用不同的Redis实例存储数据。由于Redis非常轻量级，一个空Redis实例占用的内在只有1M左右，所以不用担心多个Redis实例会额外占用很多内存。 redis命令1234567891011121314Redis 命令用于在 redis 服务上执行操作。要在 redis 服务上执行命令需要一个 redis 客户端。Redis 客户端在我们之前下载的的 redis 的安装包中。语法Redis 客户端的基本语法为：$ redis-cli在远程服务上执行命令如果需要在远程 redis 服务上执行命令，同样我们使用的也是 redis-cli 命令。语法$ redis-cli -h host -p port -a password redis数据备份和恢复12345678910111213141516171819202122Redis SAVE 命令用于创建当前数据库的备份。语法redis Save 命令基本语法如下：127.0.0.1:6379&gt; saveOK该命令会在redis安装目录下创建dump.rdb文件恢复数据如果需要恢复数据，只需将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可。获取 redis 目录可以使用 CONFIG 命令，如下所示：127.0.0.1:6379&gt; config get dir1) &quot;dir&quot;2) &quot;&#x2F;usr&#x2F;local&#x2F;redis&#x2F;src&quot;以上命令 CONFIG GET dir 输出的 redis 安装目录为&#x2F;usr&#x2F;local&#x2F;redis&#x2F;srcBgsave创建 redis 备份文件也可以使用命令 BGSAVE，该命令在后台执行。127.0.0.1:6379&gt; BGSAVEBackground saving started redis安全12345678910111213141516171819202122我们可以通过 redis 的配置文件设置密码参数，这样客户端连接到 redis 服务就需要密码验证，这样可以让你的 redis 服务更安全。127.0.0.1:6379&gt; CONFIG get requirepass1) &quot;requirepass&quot;2) &quot;&quot;默认情况下 requirepass 参数是空的，这就意味着你无需通过密码验证就可以连接到 redis 服务。你可以通过以下命令来修改该参数：127.0.0.1:6379&gt; CONFIG set requirepass &quot;tiger&quot;OK127.0.0.1:6379&gt; CONFIG get requirepass1) &quot;requirepass&quot;2) &quot;tiger&quot;登录redis-cli -h 127.0.0.1 -p 6379 -a tiger或者登陆后认证127.0.0.1:6379&gt; AUTH &quot;tiger&quot;OK127.0.0.1:6379&gt; SET name &quot;Test value&quot;OK127.0.0.1:6379&gt; GET name&quot;Test value&quot; redis持久化123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159redis持久化 – 两种方式开启持久化功能后，重启redis后，数据会自动通过持久化文件恢复！！redis提供了两种持久化的方式，分别是RDB（Redis DataBase）和AOF（Append Only File）。RDB，是在不同的时间点，将redis存储的数据生成快照并存储到磁盘等介质上；AOF，则是换了一个角度来实现持久化，那就是将redis执行过的所有写指令记录下来，在下次redis重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了。RDB和AOF两种方式也可以同时使用，在这种情况下，如果redis重启的话，则会优先采用AOF方式来进行数据恢复，这是因为AOF方式的数据恢复完整度更高。如果你没有数据持久化的需求，也完全可以关闭RDB和AOF方式，这样的话，redis将变成一个纯内存数据库，就像memcache一样。redis持久化 – RDBRDB方式，是将redis某一时刻的数据持久化到磁盘中，是一种快照式的持久化方法。redis在进行数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程都结束了，才会用这个临时文件替换上次持久化好的文件。正是这种特性，让我们可以随时来进行备份，因为快照文件总是完整可用的。 -------------&gt;----------&gt;------------------&gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 -----------&gt; --------&gt; 1 2 3 4 5 1 2 3 4 5 6 7 8 9 10 11 12 13对于RDB方式，redis会单独创建（fork）一个子进程来进行持久化，而主进程是不会进行任何IO操作的，这样就确保了redis极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。虽然RDB有不少优点，但它的缺点也是不容忽视的。如果你对数据的完整性非常敏感，那么RDB方式就不太适合你，因为即使你每5分钟都持久化一次，当redis故障时，仍然会有近5分钟的数据丢失。所以，redis还提供了另一种持久化方式，那就是AOF。redis持久化 – AOFAOF，英文是Append Only File，即只允许追加不允许改写的文件。AOF方式是将执行过的写指令记录下来，在数据恢复时按照从前到后的顺序再将指令都执行一遍，就这么简单。通过配置redis.conf中的appendonly yes就可以打开AOF功能。如果有写操作（如SET等），redis就会被追加到AOF文件的末尾。默认的AOF持久化策略是每秒钟fsync一次（fsync是指把缓存中的写指令记录到磁盘中），因为在这种情况下，redis仍然可以保持很好的处理性能，即使redis故障，也只会丢失最近1秒钟的数据。如果在追加日志时，恰好遇到磁盘空间满、inode满或断电等情况导致日志写入不完整，也没有关系，redis提供了redis-check-aof工具，可以用来进行日志修复。因为采用了追加方式，如果不做任何处理的话，AOF文件会变得越来越大，为此，redis提供了AOF文件重写（rewrite）机制，即当AOF文件的大小超过所设定的阈值时，redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。举个例子或许更形象，假如我们调用了100次INCR指令，在AOF文件中就要存储100条指令，但这明显是很低效的，完全可以把这100条指令合并成一条SET指令，这就是重写机制的原理。在进行AOF重写时，仍然是采用先写临时文件，全部完成后再替换的流程，所以断电、磁盘满等问题都不会影响AOF文件的可用性，这点可以放心。AOF方式的另一个好处，我们通过一个“场景再现”来说明。某同学在操作redis时，不小心执行了FLUSHALL，导致redis内存中的数据全部被清空了，这是很悲剧的事情。不过这也不是世界末日，只要redis配置了AOF持久化方式，且AOF文件还没有被重写（rewrite），我们就可以用最快的速度暂停redis并编辑AOF文件，将最后一行的FLUSHALL命令删除，然后重启redis，就可以恢复redis的所有数据到FLUSHALL之前的状态了。是不是很神奇，这就是AOF持久化方式的好处之一。但是如果AOF文件已经被重写了，那就无法通过这种方法来恢复数据了。虽然优点多多，但AOF方式也同样存在缺陷，比如在同样数据规模的情况下，AOF文件要比RDB文件的体积大。而且，AOF方式的恢复速度也要慢于RDB方式。1 2 3 4 5 6 6zi0如果你直接执行BGREWRITEAOF命令，那么redis会生成一个全新的AOF文件，其中便包括了可以恢复现有数据的最少的命令集。如果运气比较差，AOF文件出现了被写坏的情况，也不必过分担忧，redis并不会贸然加载这个有问题的AOF文件，而是报错退出。这时可以通过以下步骤来修复出错的文件：1.备份被写坏的AOF文件2.运行redis-check-aof –fix进行修复3.用diff -u来看下两个文件的差异，确认问题点4.重启redis，加载修复后的AOF文件redis持久化 – AOF重写AOF重写的内部运行原理，有必要了解一下。在重写即将开始之际，redis会创建（fork）一个“重写子进程”，这个子进程会首先读取现有的AOF文件，并将其包含的指令进行分析压缩并写入到一个临时文件中。与此同时，主工作进程会将新接收到的写指令一边累积到内存缓冲区中，一边继续写入到原有的AOF文件中，这样做是保证原有的AOF文件的可用性，避免在重写过程中出现意外。当“重写子进程”完成重写工作后，它会给父进程发一个信号，父进程收到信号后就会将内存中缓存的写指令追加到新AOF文件中。当追加结束后，redis就会用新AOF文件来代替旧AOF文件，之后再有新的写指令，就都会追加到新的AOF文件中了。redis持久化 – 如何选择RDB和AOF对于我们应该选择RDB还是AOF，官方的建议是两个同时使用。这样可以提供更可靠的持久化方案。写入速度快 AOF写入速度慢 RDBredis的事务处理众所周知，事务是指“一个完整的动作，要么全部执行，要么什么也没有做”。在聊redis事务处理之前，要先和大家介绍四个redis指令，即MULTI、EXEC、DISCARD、WATCH。这四个指令构成了redis事务处理的基础。1.MULTI用来组装一个事务；2.EXEC用来执行一个事务；3.DISCARD用来取消一个事务；4.WATCH用来监视一些key，一旦这些key在事务执行之前被改变，则取消事务的执行。一个MULTI和EXEC的例子：redis&gt; MULTI &#x2F;&#x2F;标记事务开始OKredis&gt; INCR user_id &#x2F;&#x2F;多条命令按顺序入队QUEUEDredis&gt; INCR user_idQUEUEDredis&gt; INCR user_idQUEUEDredis&gt; PINGQUEUEDredis&gt; EXEC &#x2F;&#x2F;执行1) (integer) 12) (integer) 23) (integer) 34) PONG在上面的例子中，看到了QUEUED的字样，这表示我们在用MULTI组装事务时，每一个命令都会进入到内存队列中缓存起来，如果出现QUEUED则表示我们这个命令成功插入了缓存队列，在将来执行EXEC时，这些被QUEUED的命令都会被组装成一个事务来执行。对于事务的执行来说，如果redis开启了AOF持久化的话，那么一旦事务被成功执行，事务中的命令就会通过write命令一次性写到磁盘中去，如果在向磁盘中写的过程中恰好出现断电、硬件故障等问题，那么就可能出现只有部分命令进行了AOF持久化，这时AOF文件就会出现不完整的情况，这时，可以使用redis-check-aof工具来修复这一问题，这个工具会将AOF文件中不完整的信息移除，确保AOF文件完整可用。有关事务，经常会遇到的是两类错误：1.调用EXEC之前的错误2.调用EXEC之后的错误“调用EXEC之前的错误”，有可能是由于语法有误导致的，也可能时由于内存不足导致的。只要出现某个命令无法成功写入缓冲队列的情况，redis都会进行记录，在客户端调用EXEC时，redis会拒绝执行这一事务。（这时2.6.5版本之后的策略。在2.6.5之前的版本中，redis会忽略那些入队失败的命令，只执行那些入队成功的命令）。我们来看一个这样的例子：127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; haha &#x2F;&#x2F;一个明显错误的指令(error) ERR unknown command &#39;haha&#39;127.0.0.1:6379&gt; pingQUEUED127.0.0.1:6379&gt; exec&#x2F;&#x2F;redis无情的拒绝了事务的执行，原因是“之前出现了错误”(error) EXECABORT Transaction discarded because of previous errors.而对于“调用EXEC之后的错误”，redis则采取了完全不同的策略，即redis不会理睬这些错误，而是继续向下执行事务中的其他命令。这是因为，对于应用层面的错误，并不是redis自身需要考虑和处理的问题，所以一个事务中如果某一条命令执行失败，并不会影响接下来的其他命令的执行。我们也来看一个例子：127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set age 23QUEUED&#x2F;&#x2F;age不是集合，所以如下是一条明显错误的指令127.0.0.1:6379&gt; sadd age 15 QUEUED127.0.0.1:6379&gt; set age 29QUEUED127.0.0.1:6379&gt; exec &#x2F;&#x2F;执行事务时，redis不会理睬第2条指令执行错误1) OK2) (error) WRONGTYPE Operation against a key holding the wrong kind of value3) OK127.0.0.1:6379&gt; get age&quot;29&quot; &#x2F;&#x2F;可以看出第3条指令被成功执行了最后一个指令“WATCH”，这是一个很好用的指令，它可以帮我们实现类似于“乐观锁”的效果，即CAS（check and set）。WATCH本身的作用是“监视key是否被改动过”，而且支持同时监视多个key，只要还没真正触发事务，WATCH都会尽职尽责的监视，一旦发现某个key被修改了，在执行EXEC时就会返回nil，表示事务无法触发。127.0.0.1:6379&gt; set age 23OK127.0.0.1:6379&gt; watch age &#x2F;&#x2F;开始监视ageOK127.0.0.1:6379&gt; set age 24 &#x2F;&#x2F;在EXEC之前，age的值被修改了OK127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set age 25QUEUED127.0.0.1:6379&gt; get ageQUEUED127.0.0.1:6379&gt; exec &#x2F;&#x2F;触发EXEC(nil) &#x2F;&#x2F;事务无法被执行 redis主从 + 哨兵主从 - 用法12345像MySQL一样，redis是支持主从同步的，而且也支持一主多从以及多级从结构。主从结构，一是为了纯粹的冗余备份，二是为了提升读性能，比如很消耗性能的SORT就可以由从服务器来承担。redis的主从同步是异步进行的，这意味着主从同步不会影响主逻辑，也不会降低redis的处理性能。主从架构中，可以考虑关闭主服务器的数据持久化功能，只让从服务器进行持久化，这样可以提高主服务器的处理性能。在主从架构中，从服务器通常被设置为只读模式，这样可以避免从服务器的数据被误修改。但是从服务器仍然可以接受CONFIG等指令，所以还是不应该将从服务器直接暴露到不安全的网络环境中。如果必须如此，那可以考虑给重要指令进行重命名，来避免命令被外人误执行。 主从 - 同步原理123456789从服务器会向主服务器发出SYNC指令，当主服务器接到此命令后，就会调用BGSAVE指令来创建一个子进程专门进行数据持久化工作，也就是将主服务器的数据写入RDB文件中。在数据持久化期间，主服务器将执行的写指令都缓存在内存中。在BGSAVE指令执行完成后，主服务器会将持久化好的RDB文件发送给从服务器，从服务器接到此文件后会将其存储到磁盘上，然后再将其读取到内存中。这个动作完成后，主服务器会将这段时间缓存的写指令再以redis协议的格式发送给从服务器。另外，要说的一点是，即使有多个从服务器同时发来SYNC指令，主服务器也只会执行一次BGSAVE，然后把持久化好的RDB文件发给多个下游。在redis2.8版本之前，如果从服务器与主服务器因某些原因断开连接的话，都会进行一次主从之间的全量的数据同步；而在2.8版本之后，redis支持了效率更高的增量同步策略，这大大降低了连接断开的恢复成本。主服务器会在内存中维护一个缓冲区，缓冲区中存储着将要发给从服务器的内容。从服务器在与主服务器出现网络瞬断之后，从服务器会尝试再次与主服务器连接，一旦连接成功，从服务器就会把“希望同步的主服务器ID”和“希望请求的数据的偏移位置（replication offset）”发送出去。主服务器接收到这样的同步请求后，首先会验证主服务器ID是否和自己的ID匹配，其次会检查“请求的偏移位置”是否存在于自己的缓冲区中，如果两者都满足的话，主服务器就会向从服务器发送增量内容。增量同步功能，需要服务器端支持全新的PSYNC指令。这个指令，只有在redis-2.8之后才具有。 sentinel介绍123456789101112131415161718Sentinel(哨兵)是用于监控redis集群中Master状态的工具，其已经被集成在redis2.4+的版本中Sentinel作用： 1)：Master状态检测 2)：如果Master异常，则会进行Master-Slave切换，将其中一个Slave作为Master，将之前的Master作为Slave 3)：Master-Slave切换后，master_redis.conf、slave_redis.conf和sentinel.conf的内容都会发生改变，即master_redis.conf中会多一行slaveof的配置，sentinel.conf的监控目标会随之调换 Sentinel工作方式： 1)：每个Sentinel以每秒钟一次的频率向它所知的Master，Slave以及其他 Sentinel 实例发送一个 PING 命令 2)：如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel 标记为主观下线。 3)：如果一个Master被标记为主观下线，则正在监视这个Master的所有 Sentinel 要以每秒一次的频率确认Master的确进入了主观下线状态。 4)：当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认Master的确进入了主观下线状态， 则Master会被标记为客观下线 5)：在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率向它已知的所有Master，Slave发送 INFO 命令 6)：当Master被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次 7)：若没有足够数量的 Sentinel 同意 Master 已经下线， Master 的客观下线状态就会被移除。 若 Master 重新向 Sentinel 的 PING 命令返回有效回复， Master 的主观下线状态就会被移除。&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;主观下线和客观下线 主观下线：Subjectively Down，简称 SDOWN，指的是当前 Sentinel 实例对某个redis服务器做出的下线判断。 客观下线：Objectively Down， 简称 ODOWN，指的是多个 Sentinel 实例在对Master Server做出 SDOWN 判断，并且通过 SENTINEL is-master-down-by-addr 命令互相交流之后，得出的Master Server下线判断，然后开启failover. 主从同步部署12345678测试环境:centos7.4redis-master:192.168.19.129 vm1redis-slave1:192.168.19.136 vm4redis-slave2:192.168.19.135 vm51.首先三台服务器将redis单机部署完成。编辑master的redis配置文件:[root@redis-master ~]# cd &#x2F;usr&#x2F;local&#x2F;redis-5.0.4[root@redis-master redis]# vim redis.conf 2.修改slave1的配置文件：[root@redis-slave1 ~]# cd /data/application/redis/[root@redis-slave1 redis]# vim redis.conf —修改如下： 3.配置slave2的配置文件:[root@redis-slave2 ~]# cd /data/application/redis/[root@redis-slave2 redis]# vim redis.conf —修改如下 和slave1 相同 4.重启三台redis 5.测试主从 三台均测试无误，主从同步部署完成 配置哨兵模式123456781.每台机器上修改redis主配置文件redis.conf文件设置：bind 0.0.0.0 ---配置主从时已经完成2.每台机器上修改sentinel.conf配置文件：修改如下配置[root@redis-master src]# cd ..[root@redis-master redis]# vim sentinel.conf sentinel monitor mymaster 192.168.233.10 6379 2 (slave上面写的是master的ip，master写自己ip) sentinel down-after-milliseconds mymaster 3000 sentinel failover-timeout mymaster 10000 protected-mode no 12345678关闭加密protected-mode no构成master客观下线的前提，至少有两个sentinel(哨兵)主观认为master已经下线sentinel monitor mymaster 192.168.19.129 6379 2 sentinel每隔一定时间向其已知的master发送ping指令，在设置的这个时间内如果没有收master返回的数据包，就会把master标记为主观下线。单位为毫秒sentinel down-after-milliseconds mymaster 3000在这个时间内如果主从切换没有完成就停止切换。单位毫秒sentinel failover-timeout mymaster 10000 123453.每台机器启动哨兵服务： # .&#x2F;src&#x2F;redis-sentinel sentinel.conf注意:在生产环境下将哨兵模式启动放到后台执行: .&#x2F;src&#x2F;redis-sentinel sentinel.conf &amp;在master上面执行这是启动成功的！ 将master的哨兵模式退出，再将redis服务stop了，在两台slave上面查看其中一台是否切换为master:(没有优先级，为随机切换) master 192.168.19.129 slave 192.168.19.136 ​ 主从+哨兵模式测试部署完成！ ========================================================== 了解 主从+哨兵+lvs 制作redis主从的高科用 redis切片等","categories":[{"name":"SQL","slug":"SQL","permalink":"https://github.com/cyylog/categories/SQL/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://github.com/cyylog/tags/Redis/"}]},{"title":"找出Java中CPU使用率最高的线程，并打印这些线程的堆栈。","slug":"Linux/找出Java中CPU使用率最高的线程，并打印这些线程的堆栈。","date":"2018-09-28T15:54:25.000Z","updated":"2020-05-25T13:53:23.141Z","comments":true,"path":"2018/09/28/Linux/找出Java中CPU使用率最高的线程，并打印这些线程的堆栈。/","link":"","permalink":"https://github.com/cyylog/2018/09/28/Linux/%E6%89%BE%E5%87%BAJava%E4%B8%ADCPU%E4%BD%BF%E7%94%A8%E7%8E%87%E6%9C%80%E9%AB%98%E7%9A%84%E7%BA%BF%E7%A8%8B%EF%BC%8C%E5%B9%B6%E6%89%93%E5%8D%B0%E8%BF%99%E4%BA%9B%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%A0%86%E6%A0%88%E3%80%82/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148#!/bin/bash# @Function# Find out the highest cpu consumed threads of java, and print the stack of these threads.## @Usage# $ ./show-busy-java-threads.sh## @author Jerry Leereadonly PROG=`basename $0`readonly -a COMMAND_LINE=(\"$0\" \"$@\")usage() &#123; cat &lt;&lt;EOFUsage: $&#123;PROG&#125; [OPTION]...Find out the highest cpu consumed threads of java, and print the stack of these threads.Example: $&#123;PROG&#125; -c 10Options: -p, --pid find out the highest cpu consumed threads from the specifed java process, default from all java process. -c, --count set the thread count to show, default is 5 -h, --help display this help and exitEOF exit $1&#125;readonly ARGS=`getopt -n \"$PROG\" -a -o c:p:h -l count:,pid:,help -- \"$@\"`[ $? -ne 0 ] &amp;&amp; usage 1eval set -- \"$&#123;ARGS&#125;\"while true; do case \"$1\" in -c|--count) count=\"$2\" shift 2 ;; -p|--pid) pid=\"$2\" shift 2 ;; -h|--help) usage ;; --) shift break ;; esacdonecount=$&#123;count:-5&#125;redEcho() &#123; [ -c /dev/stdout ] &amp;&amp; &#123; # if stdout is console, turn on color output. echo -ne \"\\033[1;31m\" echo -n \"$@\" echo -e \"\\033[0m\" &#125; || echo \"$@\"&#125;yellowEcho() &#123; [ -c /dev/stdout ] &amp;&amp; &#123; # if stdout is console, turn on color output. echo -ne \"\\033[1;33m\" echo -n \"$@\" echo -e \"\\033[0m\" &#125; || echo \"$@\"&#125;blueEcho() &#123; [ -c /dev/stdout ] &amp;&amp; &#123; # if stdout is console, turn on color output. echo -ne \"\\033[1;36m\" echo -n \"$@\" echo -e \"\\033[0m\" &#125; || echo \"$@\"&#125;# Check the existence of jstack command!if ! which jstack &amp;&gt; /dev/null; then [ -z \"$JAVA_HOME\" ] &amp;&amp; &#123; redEcho \"Error: jstack not found on PATH!\" exit 1 &#125; ! [ -f \"$JAVA_HOME/bin/jstack\" ] &amp;&amp; &#123; redEcho \"Error: jstack not found on PATH and $JAVA_HOME/bin/jstack file does NOT exists!\" exit 1 &#125; ! [ -x \"$JAVA_HOME/bin/jstack\" ] &amp;&amp; &#123; redEcho \"Error: jstack not found on PATH and $JAVA_HOME/bin/jstack is NOT executalbe!\" exit 1 &#125; export PATH=\"$JAVA_HOME/bin:$PATH\"fireadonly uuid=`date +%s`_$&#123;RANDOM&#125;_$$cleanupWhenExit() &#123; rm /tmp/$&#123;uuid&#125;_* &amp;&gt; /dev/null&#125;trap \"cleanupWhenExit\" EXITprintStackOfThread() &#123; local line local count=1 while IFS=\" \" read -a line ; do local pid=$&#123;line[0]&#125; local threadId=$&#123;line[1]&#125; local threadId0x=`printf %x $&#123;threadId&#125;` local user=$&#123;line[2]&#125; local pcpu=$&#123;line[4]&#125; local jstackFile=/tmp/$&#123;uuid&#125;_$&#123;pid&#125; [ ! -f \"$&#123;jstackFile&#125;\" ] &amp;&amp; &#123; &#123; if [ \"$&#123;user&#125;\" == \"$&#123;USER&#125;\" ]; then jstack $&#123;pid&#125; &gt; $&#123;jstackFile&#125; else if [ $UID == 0 ]; then sudo -u $&#123;user&#125; jstack $&#123;pid&#125; &gt; $&#123;jstackFile&#125; else redEcho \"[$((count++))] Fail to jstack Busy($&#123;pcpu&#125;%) thread($&#123;threadId&#125;/0x$&#123;threadId0x&#125;) stack of java process($&#123;pid&#125;) under user($&#123;user&#125;).\" redEcho \"User of java process($user) is not current user($USER), need sudo to run again:\" yellowEcho \" sudo $&#123;COMMAND_LINE[@]&#125;\" echo continue fi fi &#125; || &#123; redEcho \"[$((count++))] Fail to jstack Busy($&#123;pcpu&#125;%) thread($&#123;threadId&#125;/0x$&#123;threadId0x&#125;) stack of java process($&#123;pid&#125;) under user($&#123;user&#125;).\" echo rm $&#123;jstackFile&#125; continue &#125; &#125; blueEcho \"[$((count++))] Busy($&#123;pcpu&#125;%) thread($&#123;threadId&#125;/0x$&#123;threadId0x&#125;) stack of java process($&#123;pid&#125;) under user($&#123;user&#125;):\" sed \"/nid=0x$&#123;threadId0x&#125; /,/^$/p\" -n $&#123;jstackFile&#125; done&#125;ps -Leo pid,lwp,user,comm,pcpu --no-headers | &#123; [ -z \"$&#123;pid&#125;\" ] &amp;&amp; awk '$4==\"java\"&#123;print $0&#125;' || awk -v \"pid=$&#123;pid&#125;\" '$1==pid,$4==\"java\"&#123;print $0&#125;'&#125; | sort -k5 -r -n | head --lines \"$&#123;count&#125;\" | printStackOfThread 原文地址：https://files-cdn.cnblogs.com/files/clsn/show-busy-java-threads.sh","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/tags/Linux/"}]},{"title":"监控体系","slug":"监控/监控体系","date":"2018-06-04T17:55:39.000Z","updated":"2020-05-25T13:52:40.776Z","comments":true,"path":"2018/06/05/监控/监控体系/","link":"","permalink":"https://github.com/cyylog/2018/06/05/%E7%9B%91%E6%8E%A7/%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/","excerpt":"","text":"监控对象： 1. 监控对象的理解：CPU是怎么工作的，原理 2. 监控对象的指标：CPU使用率 CPU负载 CPU个数 上下文切换 3. 确定性能基准线：怎么样才算故障？CPU负载多上才算高监控范围： 1.硬件监控服务器的硬件故障 2.操作系统监控 CPU、内存、硬盘、IO、进程 3.应用服务监控 nginx、MySQL、等服务 4.业务监控 硬件监控： 1.使用IPMI 2.机房巡检远程控制卡： DELL服务器：iDRAC HP服务器：ILO ————-Linux就可以使用IPMI（依赖于BMC控制器） IBM服务器：IMM | Linux是管理IPMI工具 ‘ipmitool’（监控和控制） 1.硬件要支持2.操作系统 ‘Linux IPMI’ipmitool安装: 1234[root@localhost ~]# yum install OpenIPMI ipmitool -y[root@localhost ~]# rpm -qa OpenIPMI ipmitoolipmitool-1.8.13-8.el7_1.x86_64OpenIPMI-2.0.19-11.el7.x86_64 使用IPMI有两种方式1、本地进行调用2、远程调用 （IP地址 用户名和密码） 12[root@localhost ~]# systemctl start ipmi #启动本次以Centos7进行演示 IPMI相关命令 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081[root@localhost ~]# ipmitool --helpipmitool: invalid option -- &#39;-&#39;ipmitool version 1.8.13usage: ipmitool [options...] &lt;command&gt; -h This help -V Show version information -v Verbose (can use multiple times) -c Display output in comma separated format -d N Specify a &#x2F;dev&#x2F;ipmiN device to use (default&#x3D;0) -I intf Interface to use -H hostname Remote host name for LAN interface -p port Remote RMCP port [default&#x3D;623] -U username Remote session username -f file Read remote session password from file -z size Change Size of Communication Channel (OEM) -S sdr Use local file for remote SDR cache -D tty:b[:s] Specify the serial device, baud rate to use and, optionally, specify that interface is the system one -a Prompt for remote password -Y Prompt for the Kg key for IPMIv2 authentication -e char Set SOL escape character -C ciphersuite Cipher suite to be used by lanplus interface -k key Use Kg key for IPMIv2 authentication -y hex_key Use hexadecimal-encoded Kg key for IPMIv2 authentication -L level Remote session privilege level [default&#x3D;ADMINISTRATOR] Append a &#39;+&#39; to use name&#x2F;privilege lookup in RAKP1 -A authtype Force use of auth type NONE, PASSWORD, MD2, MD5 or OEM -P password Remote session password -E Read password from IPMI_PASSWORD environment variable -K Read kgkey from IPMI_KGKEY environment variable -m address Set local IPMB address -b channel Set destination channel for bridged request -t address Bridge request to remote target address -B channel Set transit channel for bridged request (dual bridge) -T address Set transit address for bridge request (dual bridge) -l lun Set destination lun for raw commands -o oemtype Setup for OEM (use &#39;list&#39; to see available OEM types) -O seloem Use file for OEM SEL event descriptions -N seconds Specify timeout for lan [default&#x3D;2] &#x2F; lanplus [default&#x3D;1] interface -R retry Set the number of retries for lan&#x2F;lanplus interface [default&#x3D;4]Interfaces: open Linux OpenIPMI Interface [default] imb Intel IMB Interface lan IPMI v1.5 LAN Interface lanplus IPMI v2.0 RMCP+ LAN Interface serial-terminal Serial Interface, Terminal Mode serial-basic Serial Interface, Basic Mode Commands: raw Send a RAW IPMI request and print response i2c Send an I2C Master Write-Read command and print response spd Print SPD info from remote I2C device lan Configure LAN Channels chassis Get chassis status and set power state power Shortcut to chassis power commands event Send pre-defined events to MC mc Management Controller status and global enables sdr Print Sensor Data Repository entries and readings sensor Print detailed sensor information fru Print built-in FRU and scan SDR for FRU locators gendev Read&#x2F;Write Device associated with Generic Device locators sdr sel Print System Event Log (SEL) pef Configure Platform Event Filtering (PEF) sol Configure and connect IPMIv2.0 Serial-over-LAN tsol Configure and connect with Tyan IPMIv1.5 Serial-over-LAN isol Configure IPMIv1.5 Serial-over-LAN user Configure Management Controller users channel Configure Management Controller channels session Print session information dcmi Data Center Management Interface sunoem OEM Commands for Sun servers kontronoem OEM Commands for Kontron devices picmg Run a PICMG&#x2F;ATCA extended cmd fwum Update IPMC using Kontron OEM Firmware Update Manager firewall Configure Firmware Firewall delloem OEM Commands for Dell systems shell Launch interactive IPMI shell exec Run list of commands from file set Set runtime variable for shell and exec hpm Update HPM components using PICMG HPM.1 file ekanalyzer run FRU-Ekeying analyzer using FRU files ime Update Intel Manageability Engine Firmware IPMI配置网络，有两种方式：ipmi over lan（大体意思是通过网卡来进行连接）独立 （给服务器单独插一个网线） DELL服务器可以在小面板中设置ipmi 云主机我们不需要考虑IPMI 对于路由器和交换机：SNMP对于这些设备，就不做具体描述了，毕竟没有接触过 系统监控做为系统运维来说系统监控是重点 123- CPU- 内存- IO Input&#x2F;Ouput（网络、磁盘） CPU三个重要的概念： 1.上下文切换：CPU调度器实施的进程的切换过程，上下文切换 2.运行队列（负载）：运行队列，排队 可以参考我是一个进程文章 3.使用率监控CPU需要确定服务类型：（1） IO密集型 （数据库）（2） CPU密集型（Web/mail） 确定性能的基准线 运行队列：1-3个线程 1CPU 4核 负载不超过12 CPU使用：65%-70%用户态利用率 30%-35%内核态利用率 0%-5% 空闲 上下文切换： 越少越好所有的监控都要根据业务来考虑 常见的系统监控工具Top、sysstat、mpstat 工具的使用方法TOP参数解释 top的详细可以参考我在51cto的这篇文章 http://blog.51cto.com/12419955/2052642 其实对于Top，现在我更喜欢htop和gtop，gtop虽然色彩和功能更强大，但是因为gtop不在epel源里，导致gtop的使用没有htop用的广泛 当然gtop这么好用，当然要用一下，这是另一片关于gtop的文章 https://tigerfivegit.github.io/2018/12/14/Linux%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7-gtop/ 第一行 分别显示：系统当前时间 系统运行时间 当前用户登陆数 系统负载。 系统负载（load average），这里有三个数值，分别是系统最近1分钟，5分钟，15分钟的平均负载。一般对于单个处理器来说，负载在0 — 1.00 之间是正常的，超过1.00就要引起注意了。在多核处理器中，你的系统均值不应该高于处理器核心的总数。 第二行 分别显示：total进程总数、 running正在运行的进程数、 sleeping睡眠的进程数、stopped停止的进程数、 zombie僵尸进程数。 第三行分别显示：%us用户空间占用CPU百分比、%sy内核空间占用CPU百分比、%ni用户进程空间内改变过优先级的进程占用CPU百分比、%id空闲CPU百分比、%wa等待输入输出（I/O）的CPU时间百分比 、%hi指的是cpu处理硬件中断的时间、%si指的是cpu处理软中断的时间 、%st用于有虚拟cpu的情况，用来指示被虚拟机偷掉的cpu时间。通常id%值可以反映一个系统cpu的闲忙程度。 第四行 MEM ：total 物理内存总量、 used 使用的物理内存总量、free 空闲内存总量、 buffers 用作内核缓存的内存量。 第五行 SWAP：total 交换区总量、 used使用的交换区总量、free 空闲交换区总量、 cached缓冲的交换区总量。buffers和cached的区别需要说明一下，buffers指的是块设备的读写缓冲区，cached指的是文件系统本身的页面缓存。它们都是linux操作系统底层的机制，目的就是为了加速对磁盘的访问。 第六行 PID(进程号)、 USER（运行用户）、PR（优先级）、NI（任务nice值）、VIRT（虚拟内存用量）VIRT=SWAP+RES 、RES（物理内存用量）、SHR（共享内存用量）、S（进程状态）、%CPU（CPU占用比）、%MEM（物理内存占用比）、TIME+（累计CPU占 用时间)、 COMMAND 命令名/命令行。 下面简单介绍top命令的使用方法：top [-] [d] [q] [c] [C] [S] [n]运维必会！参数说明d指定每两次屏幕信息刷新之间的时间间隔。当然用户可以使用s交互命令来改变之。p通过指定监控进程ID来仅仅监控某个进程的状态。q该选项将使top没有任何延迟的进行刷新。如果调用程序有超级用户权限，那么top将以尽可能高的优先级运行。S指定累计模式。s使top命令在安全模式中运行。这将去除交互命令所带来的潜在危险。i使top不显示任何闲置或者僵死进程。c显示整个命令行而不只是显示命令名。下面介绍在top命令执行过程中可以使用的一些交互命令 从使用角度来看，熟练的掌握这些命令比掌握选项还重要一些。 这些命令都是单字母的，如果在命令行选项中使用了s选项，则可能其中一些命令会被屏蔽掉。Ctrl+L 擦除并且重写屏幕。h或者? 显示帮助画面，给出一些简短的命令总结说明。k 终止一个进程。系统将提示用户输入需要终止的进程PID，以及需要发送给该进程什么样的信号。一般的终止进程可以使用15信号；如果不能正常结束那就使用信号9强制结束该进程。默认值是信号15。在安全模式中此命令被屏蔽。i 忽略闲置和僵死进程。这是一个开关式命令。q 退出程序。r 重新安排一个进程的优先级别。系统提示用户输入需要改变的进程PID以及需要设置的进程优先级值。输入一个正值将使优先级降低，反之则可以使该进程拥有更高的优先权。默认值是10。s 改变两次刷新之间的延迟时间。系统将提示用户输入新的时间，单位为s。如果有小数，就换算成m s。输入0值则系统将不断刷新，默认值是5 s。需要注意的是如果设置太小的时间，很可能会引起不断刷新，从而根本来不及看清显示的情况，而且系统负载也会大大增加。f或者F 从当前显示中添加或者删除项目。o或者O 改变显示项目的顺序。l 切换显示平均负载和启动时间信息。m 切换显示内存信息。t 切换显示进程和CPU状态信息。c 切换显示命令名称和完整命令行。M 根据驻留内存大小进行排序。P 根据CPU使用百分比大小进行排序。T 根据时间/累计时间进行排序。W 将当前设置写入~/.toprc文件中。这是写top配置文件的推荐方法。Shift+M 可按内存占用情况进行排序。 sysstat 说明12345678910111213141516yum install sysstat -yvmstat --helpusage: vmstat [-V] [-n] [delay [count]] -V prints version. -n causes the headers not to be reprinted regularly. -a print inactive&#x2F;active page stats. -d prints disk statistics -D prints disk table -p prints disk partition statistics -s prints vm table -m prints slabinfo -t add timestamp to output -S unit size delay is the delay between updates in seconds. unit size k:1000 K:1024 m:1000000 M:1048576 (default is K) count is the number of updates. 例子：每隔1秒获取1次，次数不限 12345678910# vmstat 1procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 547332 177544 535336 0 0 1 6 5 41 1 0 98 0 0 0 0 0 547324 177544 535336 0 0 0 0 210 445 1 0 99 0 0 0 0 0 547324 177544 535336 0 0 0 0 195 435 0 0 100 0 0 0 0 0 547324 177544 535336 0 0 0 0 208 440 1 0 99 0 0 0 0 0 547332 177544 535336 0 0 0 0 209 446 0 0 100 0 0 0 0 0 547332 177544 535336 0 0 0 0 207 442 1 1 98 0 0 0 0 0 547332 177544 535336 0 0 0 0 201 438 0 0 100 0 0 #r表示CPU排队的情况，b代表 进程堵塞，等待io每隔1秒获取1次，次数10次 12345678910111213# vmstat 1 10procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 547340 177544 535344 0 0 1 6 5 41 1 0 98 0 0 0 0 0 547332 177544 535344 0 0 0 28 210 453 1 1 97 1 0 0 0 0 547332 177544 535344 0 0 0 0 200 433 0 0 100 0 0 0 0 0 547332 177544 535344 0 0 0 0 211 445 1 0 99 0 0 0 0 0 547332 177544 535344 0 0 0 0 201 439 0 1 99 0 0 0 0 0 547332 177544 535344 0 0 0 0 197 436 0 0 100 0 0 0 0 0 547332 177544 535344 0 0 0 0 201 442 1 0 99 0 0 0 0 0 547324 177544 535348 0 0 0 0 240 484 2 1 97 0 0 0 0 0 547324 177544 535348 0 0 0 0 203 438 0 0 100 0 0 0 0 0 547324 177544 535348 0 0 0 0 197 430 1 0 99 0 0 mpstat查看所有CPU的平均值 1234567mpstat 1Linux 2.6.32-431.23.3.el6.x86_64 (www) 08&#x2F;30&#x2F;2016 _x86_64_ (1 CPU)05:13:22 PM CPU %usr %nice %sys %iowait %irq %soft %steal %guest %idle05:13:23 PM all 1.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 99.00105:13:24 PM all 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0005:13:25 PM all 2.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 97.0005:13:26 PM all 1.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 99.00 123456mpstat 1 10Linux 2.6.32-431.23.3.el6.x86_64 (www) 08&#x2F;30&#x2F;2016 _x86_64_ (1 CPU)05:13:38 PM CPU %usr %nice %sys %iowait %irq %soft %steal %guest %idle05:13:39 PM all 2.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 98.0005:13:40 PM all 0.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 99.0005:13:41 PM all 1.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 98.99 上述是CPU监控，CPU监控主要靠经验。因为业务不同指标不同，指标越低越好是不变的道理 sar命令也有类似的功能，但是sar命令更能看到历史的信息，对于问题排查有更好的作用当然对于我这种喜欢骚操作的人，sar命令不可能不搞啊，这里放个链接 https://tigerfivegit.github.io/2018/11/21/sar/ 内存硬盘监控：硬盘格式化后分成块（blog）内存默认是页（大小4kb）读取按照页来进行读取内存：free vmstat 12345free -m total used free shared buffers cachedMem: 1875 1338 537 0 173 523-&#x2F;+ buffers&#x2F;cache: 640 1234Swap: 0 0 0 total 总内存used 已使用内存free 空闲内存shared 共享内存（进程间相互通信使用共享内存）buffers 缓冲cached 缓存Centos7 会有一个available，活动内存 #云服务器一般不分配swap分区，物理机能不使用交换分区就不使用交换分区 1234567vmstat 1procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 550628 177684 536324 0 0 1 6 7 46 1 0 98 0 0 0 0 0 550620 177684 536324 0 0 0 40 187 429 0 0 100 0 0 0 0 0 550620 177684 536324 0 0 0 0 183 427 1 0 99 0 0 0 0 0 550620 177684 536324 0 0 0 0 197 436 0 1 99 0 0 swpd交换分区的大小free可用的物理内存大小buff 缓冲区的大小cache 缓存区的大小si 数据从交换分区读取到内存的大小so 数据从内存到交换分区bi 从交换分区读到内存（block）bo 内存写到硬盘的 1内存达到多少报警呢？ 80% 硬盘：IOPS IO’s Per Second iotop df -h iostat 顺序IO（快） 随机IO（慢）查看磁盘剩余空间 1234df -hFilesystem Size Used Avail Use% Mounted on&#x2F;dev&#x2F;xvda1 40G 4.1G 34G 11% &#x2F;tmpfs 938M 0 938M 0% &#x2F;dev&#x2F;shm 监控磁盘IO iotop 1yum install iotop -y 123456789可以使用dd命令生成一个文件夹进行测试 生成命令如下：# dd if&#x3D;&#x2F;dev&#x2F;zero of&#x3D;&#x2F;tmp&#x2F;1.txt bs&#x3D;1M count&#x3D;10001000+0 records in1000+0 records out1048576000 bytes (1.0 GB) copied, 20.509 s, 51.1 MB&#x2F;s[root@www ~]# ls -lh &#x2F;tmp&#x2F;1.txt -rw-r--r-- 1 root root 1000M Aug 30 19:48 &#x2F;tmp&#x2F;1.txt 此时IO写入如下图iostat命令，可以看到那块磁盘，比iotop更加细致 12345678910# iostat 1 2Linux 2.6.32-431.23.3.el6.x86_64 (www) 08&#x2F;30&#x2F;2016 _x86_64_ (1 CPU)avg-cpu: %user %nice %system %iowait %steal %idle 1.10 0.00 0.27 0.16 0.00 98.46Device: tps Blk_read&#x2F;s Blk_wrtn&#x2F;s Blk_read Blk_wrtnxvda 1.51 2.26 17.09 986748 7467560avg-cpu: %user %nice %system %iowait %steal %idle 1.02 0.00 0.00 0.00 0.00 98.98Device: tps Blk_read&#x2F;s Blk_wrtn&#x2F;s Blk_read Blk_wrtnxvda 0.00 0.00 0.00 0 0 tps 设备每秒的传输次数（每秒多少的io请求）Blk_read/s 每秒从设备读取的数据量Blk_wrtn/s 每秒像设备写入的数据量Blk_read 写入数据的总数Blk_wrtn 读取数据的总数 网络监控：iftop12# yum install iftop -y# iftop -n #-n不做域名解析 正常监控只需要监控网卡带宽即可其中网络监控是最复杂的，ping监控网络延迟网络丢包等。但是此类的网络监控只是监控自己到客户端是否丢包，并不能保证客户端到服务器这边不丢包 其中就产生了如：阿里测、奇云测、站长工具等一系列多节点的监控工具 性能测试常用工具：IBM nmon （nmon analyser—生成AIX性能报告的免费工具）http://nmon.sourceforge.net/pmwiki.php #下载地址（需要翻墙工具）所以我们提供了百度云下载链接：http://pan.baidu.com/s/1boXV6R9 密码：sblf只需要下载对应的版本，给执行权限。执行即可 12# chmod +x nmon16e_x86_rhel72 # .&#x2F;nmon16e_x86_rhel72 我们可以直接输入一个c 一个m一个d。这个是实时的一个状态 123456789101112131415161718192021222324.&#x2F;nmon16e_x86_rhel72 --help.&#x2F;nmon16e_x86_rhel72: invalid option -- &#39;-&#39;Hint for nmon16e_x86_rhel72 version 16e Full Help Info : nmon16e_x86_rhel72 -h On-screen Stats: nmon16e_x86_rhel72 Data Collection: nmon16e_x86_rhel72 -f [-s &lt;seconds&gt;] [-c &lt;count&gt;] [-t|-T] Capacity Plan : nmon16e_x86_rhel72 -xInteractive-Mode: Read the Welcome screen &amp; at any time type: &quot;h&quot; for more help Type &quot;q&quot; to exit nmonFor Data-Collect-Mode -f Must be the first option on the line (switches off interactive mode) Saves data to a CSV Spreadsheet format .nmon file in then local directory Note: -f sets a defaults -s300 -c288 which you can then modify Further Data Collection Options: -s &lt;seconds&gt; time between data snapshots -c &lt;count&gt; of snapshots before exiting -t Includes Top Processes stats (-T also collects command arguments) -x Capacity Planning&#x3D;15 min snapshots for 1 day. (nmon -ft -s 900 -c 96)---- End of Hints-c 采集的次数-s 采集的间隔时间-f 生成一个文件-m 指定生成文件位置 采集10次 间隔10秒 123# .&#x2F;nmon16e_x86_rhel72 -c 10 -s 10 -f -m &#x2F;tmp&#x2F;# lslocalhost_160831_0435.nmon nmon16e_x86_rhel72 前面为主机名后面是日期（年月日时分）因为测试可能需要，我们要制作成表格，所以现在将文件上传到桌面上 sz localhost_160831_0435.nmon我们打开下载的工具 解压文件夹，打开nmon analyser v34a.xls 点击Analyse nmon data找到我们刚刚复制出来的文件，就可以看到了。 应用服务监控：举例：Nginx安装nginx 1# yum install -y gcc glibc gcc-c++ prce-devel openssl-devel pcre-devel 提示：nginx可以使用稳定版的最新版，因为安全性会不断的提高。如果是特别老的版本会有一些漏洞和功能 要想监控nginx需要在编译时添加如下参数 1--with-http_stub_status_module 下载Nginx 1wget http:&#x2F;&#x2F;nginx.org&#x2F;download&#x2F;nginx-1.10.1.tar.gz 解压，后面步骤太简单不说了安装 12[root@localhost nginx-1.10.1]# useradd -s &#x2F;sbin&#x2F;nologin www[root@localhost nginx-1.10.1]# .&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx-1.10.1 --user&#x3D;www --group&#x3D;www --with-http_ssl_module --with-http_stub_status_module #configure 是一个shell脚本，执行它的作用是生成MAKEFILE（编译make需要） 12345678910111213141516[root@localhost nginx-1.10.1]# make &amp;&amp; make install[root@localhost nginx-1.10.1]# lltotal 676drwxr-xr-x 6 1001 1001 4096 Aug 31 06:02 auto-rw-r--r-- 1 1001 1001 262898 May 31 09:47 CHANGES-rw-r--r-- 1 1001 1001 400701 May 31 09:47 CHANGES.rudrwxr-xr-x 2 1001 1001 4096 Aug 31 06:02 conf-rwxr-xr-x 1 1001 1001 2481 May 31 09:47 configuredrwxr-xr-x 4 1001 1001 68 Aug 31 06:02 contribdrwxr-xr-x 2 1001 1001 38 Aug 31 06:02 html-rw-r--r-- 1 1001 1001 1397 May 31 09:47 LICENSE-rw-r--r-- 1 root root 404 Aug 31 07:46 Makefiledrwxr-xr-x 2 1001 1001 20 Aug 31 06:02 mandrwxr-xr-x 3 root root 119 Aug 31 07:46 objs-rw-r--r-- 1 1001 1001 49 May 31 09:47 READMEdrwxr-xr-x 9 1001 1001 84 Aug 31 06:02 src #make是生成文件，make install是将生成的文件拷贝到不同的地方make install 完成之后可以直接将当前目录拷贝到其他服务器上，安装相同的依赖就可以进行使用。 123[root@localhost nginx-1.10.1]# ln -s &#x2F;usr&#x2F;local&#x2F;nginx-1.10.1&#x2F; &#x2F;usr&#x2F;local&#x2F;nginx[root@localhost nginx-1.10.1]# netstat -lntp|grep nginxtcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 7058&#x2F;nginx: master 修改nginx.conf配置文件 123456 location &#x2F;status &#123; stub_status on; access_log off; allow 192.168.56.0&#x2F;24; deny all;&#125; 设置只允许56网段访问，并开启日志和状态模块 #这个比较基础，如果不知道怎么添加。可以参考www.nginx.org 状态模块浏览器访问：http://192.168.56.11/status 1234Active connections: 1 server accepts handled requests 3 3 163 Reading: 0 Writing: 1 Waiting: 0 Active connections: 当前活跃的连接数3—-&gt; 一共处理了多少个链接（请求）3—-&gt; 成功创建多少次握手163–&gt; 总共创建了多少个请求Reading:当前读取客户端heardr的数量Writing:当前返回给客户端heardr的数量 #如果这个指标飙升，说明是后面的节点挂掉了，例如数据库等。Waiting:大体意思是已经处理完，等待下次请求的数量提示：我们只需要关注活动链接即可 监控最基础的功能采集 存储 展示 告警 几款监控软件说明：几款监控软件大家都知道应该是zabbix，这个入门和部署比较简单，对于中小企业都是友好的，但是难以细化和深入化。后来因业务需求从zabbix逐渐转用小米的开源监控open-falcon，这个对于新手不太友好，但是后期的添加和细化都是特别友好的，模块化、分支化","categories":[{"name":"监控","slug":"监控","permalink":"https://github.com/cyylog/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/tags/Linux/"}]},{"title":"Linux日志切割工具Logrotate配置详解","slug":"Linux/[Linux日志切割工具Logrotate配置详解]","date":"2018-04-04T17:55:39.000Z","updated":"2020-05-25T13:51:10.623Z","comments":true,"path":"2018/04/05/Linux/[Linux日志切割工具Logrotate配置详解]/","link":"","permalink":"https://github.com/cyylog/2018/04/05/Linux/[Linux%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%E5%B7%A5%E5%85%B7Logrotate%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3]/","excerpt":"","text":"[Linux日志切割工具Logrotate配置详解]文章目录 [TOC] Logrotate 程序是一个日志文件管理工具。用于分割日志文件，压缩转存、删除旧的日志文件，并创建新的日志文件，下面就对logrotate日志轮转的记录： 1. Logrotate配置文件介绍Linux系统默认安装logrotate，默认的配置文件： /etc/logrotate.conf /etc/logrotate.d/ logrotate.conf：为主配置文件 logrotate.d：为配置相关子系统，用于隔离每个应用配置（Nginx、PHP、Tomcat…） Logrotate是基于CRON来运行的，其脚本是/etc/cron.daily/logrotate，日志轮转是系统自动完成的。实际运行时，Logrotate会调用配置文件/etc/logrotate.conf。 Logrotate可以由自动或者手动触发日志轮转： 12logrotate -f /etc/logrotate.d/nginxlogrotate -f /etc/logrotate.d/php 不过正式执行前最好通过Debug选项来验证一下（-d参数）具体logrotate命令格式如下： 1logrotate [OPTION...] &lt;configfile&gt; -d, --debug ：debug模式，测试配置文件是否有错误。 -f, --force ：强制转储文件。 -m, --mail=command ：压缩日志后，发送日志到指定邮箱。 -s, --state=statefile ：使用指定的状态文件。 -v, --verbose ：显示转储过程。 2. Logrotater日志文件切割策略查看logrotate.conf配置： 12345678910111213141516cat /etc/logrotate.confweekly //默认每一周执行一次rotate轮转工作rotate 4 //保留多少个日志文件(轮转几次).默认保留四个.就是指定日志文件删除之前轮转的次数，0 指没有备份create //自动创建新的日志文件，新的日志文件具有和原来的文件相同的权限；因为日志被改名,因此要创建一个新的来继续存储之前的日志dateext //这个参数很重要！就是切割后的日志文件以当前日期为格式结尾，如xxx.log-20131216这样,如果注释掉,切割出来是按数字递增,即前面说的 xxx.log-1这种格式compress //是否通过gzip压缩转储以后的日志文件，如xxx.log-20131216.gz ；如果不需要压缩，注释掉就行include /etc/logrotate.d //导入/etc/logrotate.d/ 目录中的各个应用配置/var/log/wtmp &#123; //仅针对 /var/log/wtmp 所设定的参数monthly //每月一次切割,取代默认的一周minsize 1M //文件大小超过 1M 后才会切割create 0664 root utmp //指定新建的日志文件权限以及所属用户和组rotate 1 //只保留一个日志.&#125;#这个 wtmp 可记录用户登录系统及系统重启的时间#因为有 minsize 的参数，因此不见得每个月一定会执行一次喔.要看文件大小。 Logrotate中其他可配置参数，具体如下： 123456789101112131415161718192021222324252627282930compress //通过gzip 压缩转储以后的日志nocompress //不做gzip压缩处理copytruncate //用于还在打开中的日志文件，把当前日志备份并截断；是先拷贝再清空的方式，拷贝和清空之间有一个时间差，可能会丢失部分日志数据。nocopytruncate //备份日志文件不过不截断create mode owner group //轮转时指定创建新文件的属性，如create 0777 nobody nobodynocreate //不建立新的日志文件delaycompress //和compress 一起使用时，转储的日志文件到下一次转储时才压缩nodelaycompress //覆盖 delaycompress 选项，转储同时压缩。missingok //如果日志丢失，不报错继续滚动下一个日志errors address //专储时的错误信息发送到指定的Email 地址ifempty //即使日志文件为空文件也做轮转，这个是logrotate的缺省选项。notifempty //当日志文件为空时，不进行轮转mail address //把转储的日志文件发送到指定的E-mail 地址nomail //转储时不发送日志文件olddir directory //转储后的日志文件放入指定的目录，必须和当前日志文件在同一个文件系统noolddir //转储后的日志文件和当前日志文件放在同一个目录下sharedscripts //运行postrotate脚本，作用是在所有日志都轮转后统一执行一次脚本。如果没有配置这个，那么每个日志轮转后都会执行一次脚本prerotate //在logrotate转储之前需要执行的指令，例如修改文件的属性等动作；必须独立成行postrotate //在logrotate转储之后需要执行的指令，例如重新启动 (kill -HUP) 某个服务！必须独立成行daily //指定转储周期为每天weekly //指定转储周期为每周monthly //指定转储周期为每月rotate count //指定日志文件删除之前转储的次数，0 指没有备份，5 指保留5 个备份dateext //使用当期日期作为命名格式dateformat .%s //配合dateext使用，紧跟在下一行出现，定义文件切割后的文件名，必须配合dateext使用，只支持 %Y %m %d %s 这四个参数size(或minsize) log-size //当日志文件到达指定的大小时才转储，log-size能指定bytes(缺省)及KB (sizek)或MB(sizem).当日志文件 &gt;= log-size 的时候就转储。 以下为合法格式：（其他格式的单位大小写没有试过）size = 5 或 size 5 （&gt;= 5 个字节就转储）size = 100k 或 size 100ksize = 100M 或 size 100M 3. NGINX日志的配置实例参考:12345678910111213141516vim /etc/logrotate.d/nginx/var/log/weblog/*.log &#123; daily //指定转储周期为每天 compress //通过gzip 压缩转储以后的日志 rotate 7 //保存7天的日志 missingok //如果日志文件丢失，不要显示错误 notifempty //当日志文件为空时，不进行轮转 dateext //使用当期日期作为命名格式，exp: nginx_access.log-20190120 sharedscripts //运行postrotate脚本 postrotate //执行的指令 if [ -f /run/nginx.pid ]; then kill -USR1 `cat /run/nginx.pid` fi endscript //结束指令&#125; 4. PHP-FPM日志的配置实例参考:12345678910111213141516vim /etc/logrotate.d/nginx/usr/local/php/var/log/*.log &#123;dailycompressrotate 7missingoknotifemptydateextsharedscriptspostrotate if [ -f /usr/local/php/var/run/php-fpm.pid ]; then kill -USR2 `cat /usr/local/php/var/run/php-fpm.pid` fiendscript&#125; 5. Logrotater日志切割轮询由于Logrotate是基于CRON运行的，所以这个日志轮转的时间是由CRON控制的，具体可以查询CRON的配置文件/etc/anacrontab，过往的老版本的文件为（/etc/crontab） 查看轮转文件：/etc/anacrontab 12345678910cat /etc/anacrontab SHELL=/bin/sh PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root RANDOM_DELAY=45 START_HOURS_RANGE=3-22 1 5 cron.daily nice run-parts /etc/cron.daily 7 25 cron.weekly nice run-parts /etc/cron.weekly @monthly 45 cron.monthly nice run-parts /etc/cron.monthly 使用anacrontab轮转的配置文件，日志切割的生效时间是在凌晨3点到22点之间，而且随机延迟时间是45分钟，但是这样配置无法满足我们在现实中的应用 现在的需求是将切割时间调整到每天的晚上12点，即每天切割的日志是前一天的0-24点之间的内容，操作如下： 1mv /etc/anacrontab /etc/anacrontab.bak //取消日志自动轮转的设置 使用crontab来作为日志轮转的触发容器来修改Logrotate默认执行时间 123456789101112vi /etc/crontab SHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=rootHOME=/# run-parts01 * * * * root run-parts /etc/cron.hourly59 23 * * * root run-parts /etc/cron.daily22 4 * * 0 root run-parts /etc/cron.weekly42 4 1 * * root run-parts /etc/cron.monthly 6. 解决logrotate无法自动轮询日志的办法现象说明： 使用logrotate轮询nginx日志，配置好之后，发现nginx日志连续两天没被切割，检查后确定配置文件一切正常，这是为什么呢？？ 强行启动记录文件维护操作，纵使logrotate指令认为没有需要，应该有可能是logroate认为nginx日志太小，不进行轮询。故需要强制轮询，即在/etc/cron.daily/logrotate脚本中将 -t 参数替换成 -f 参数 123456789vim /etc/cron.daily/logrotate #!/bin/sh/usr/sbin/logrotate /etc/logrotate.confEXITVALUE=$?if [ $EXITVALUE != 0 ]; then /usr/bin/logger -f logrotate \"ALERT exited abnormally with [$EXITVALUE]\"fiexit 0 最后最后重启下cron服务： 123/etc/init.d/crond restartStopping crond: [ OK ]Starting crond: [ OK ]","categories":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/cyylog/tags/Linux/"}]}]}