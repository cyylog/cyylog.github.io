<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>yaml notes</title>
      <link href="2021/04/19/notes/yaml-bi-ji/"/>
      <url>2021/04/19/notes/yaml-bi-ji/</url>
      
        <content type="html"><![CDATA[<h4 id="Kubernetes"><a href="#Kubernetes" class="headerlink" title="Kubernetes"></a><code>Kubernetes</code></h4><blockquote><p>请看文档：<a href="https://www.kubernetes.org.cn/k8s" target="_blank" rel="noopener">https://www.kubernetes.org.cn/k8s</a></p><p>   <code>Kubernetes</code> (通常称为 <code>K8s</code>) 是开源容器集群管理系统，用于自动部署、扩展和管理容器化 应用程序。 </p></blockquote><h5 id="Rancher-示范"><a href="#Rancher-示范" class="headerlink" title="Rancher 示范"></a><code>Rancher</code> 示范</h5><pre class=" language-shell"><code class="language-shell">sudo docker run -itd --privileged --restart=unless-stopped -p 8080:80 -p 8443:443 -v /home/cyy/rancher:/var/lib/rancher/  -e CATTLE_AGENT_IMAGE="registry.cn-hangzhou.aliyuncs.com/rancher/rancher-agent:v2.4.8" registry.cn-hangzhou.aliyuncs.com/rancher/rancher:v2.4.8</code></pre><h6 id="nginx-and-alpine"><a href="#nginx-and-alpine" class="headerlink" title="nginx and alpine"></a><code>nginx</code> and <code>alpine</code></h6><pre class=" language-shell"><code class="language-shell">nginx:1.18-alpinedocker pull alpine:3.12docker run  -d  --name tt \-v /home/cyylog/myweb:/app \-w /app \-p 8081:80 \alpine:3.12 \./myserver</code></pre><h6 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h6><pre class=" language-shell"><code class="language-shell">第一步:首先创建文件夹[cyy@cyylog1 n1]$ tree /home/cyy/redis/home/cyy/redis├── n1│   ├── conf│   │   └── redis.conf│   ├── data            (用来存放数据目录)│   └── logs            (用来存放日志)└── redis.conf 其中配置文件中daemonize no (不以守护进程启动)port 6379bind 0.0.0.0logfile /logs/redis.log   (日志文件)dir /data   (数据目录)第二步:在Nfs服务器上export 文件夹 sudo vi /etc/exports加入如下一行：在  /home/cyylog/redis    192.168.0.0/24(rw,async,insecure,no_root_squash)然后执行 exportfs -a  或(sudo systemctl restart nfs.service)重新加载配置redis镜像我们还是使用redis:5-alpine为了速度，大家可以提前pull下来docker pull redis:5-alpine映射映射n1/conf:/confn1/data:/datan1/logs:/logs注意：n1 是 子目录  前面不要加 /启动命令redis-server /conf/redis.conf</code></pre><h6 id="registry"><a href="#registry" class="headerlink" title="registry"></a>registry</h6><p>镜像地址：<a href="https://hub.docker.com/_/registry" target="_blank" rel="noopener">https://hub.docker.com/_/registry</a></p><pre class=" language-shell"><code class="language-shell">基本运行docker run  -d --name registry \ -v /home/cyy/registry/config.yml:/etc/docker/registry/config.yml \ -v /home/cyy/registry/data:/var/lib/registry \-p 5000:5000   registry 也可以直接 用k8s 安装一个单机的 容器配置文件version: 0.1log: fields: service: registrystorage: delete:  enabled: true cache:  blobdescriptor: inmemory filesystem:  rootdirectory: /var/lib/registryhttp: addr: :5000 headers:  X-Content-Type-Options: [nosniff]health: storagedriver: enabled: true interval: 10s threshold: 3测试找个已经有的镜像，打个tagdocker tag  redis:5-alpine  192.168.0.129:5000/redis:v1传到我们的私有镜像里 docker push 192.168.0.129:5000/redis:v1sha256:9e0926fe90cef2fc4e435fbcb63c273d34ac9b05de6545cb92d708ccdb7f823f 查看API（https://docs.docker.com/registry/spec/api/#listing-repositories）curl http://192.168.0.129:5000/v2/_catalog   (查看列表)curl http://192.168.0.129:5000/v2/redis/manifests/v1   (查看redis镜像详情)curl http://192.168.0.129:5000/v2/redis/tags/listcurl -X DELETE http://192.168.0.129:5000/v2/redis/manifests/xxx垃圾回收：registry garbage-collect /etc/docker/registry/config.yml 设置安全不出意外会报一个 错误http: server gave HTTP response to HTTPS client那是因为docker为了安全，需要https 。但是我们可以让其不需要  要修改的是/etc/docker/daemon.json{    "insecure-registries":["192.168.0.129:5000"]}然后重载docker 即可systemctl  reload docker下载镜像docker pull 192.168.0.129:5000/redis:v1​~~~##### CI/CD###### 搭建`gitlab`​~~~shelldocker pull gitlab/gitlab-ce创建专属pv sudo vi /etc/exports加入一行 /home/cyy/gitlab    192.168.0.129/24(rw,async,insecure,no_root_squash)然后执行 sudo exportfs -a 重新加载配置[cyy@cyylog1 gitlab]$ pwd   # 的子目录/home/cyy/gitlab[cyy@cyylog1 gitlab]$ tree ..├── config├── data└── logs挂载内容/etc/gitlab       config/var/opt/gitlab data/var/log/gitlab logs配置负载均衡时 别忘了加:nginx.ingress.kubernetes.io/rewrite-target</code></pre><p>使用gitlab</p><pre class=" language-shell"><code class="language-shell">请各位通过百度查询  自行生成生成SSH key并通过如下测试:ssh -T git@git.cyylog.cn -p 30022    (注意 ，这有个端口，22被主机的SSH占用了，你懂的）ssh-keygen -t rsa -C "cyylog@163.com"项目中执行1、git init 2、  git config --global user.name "cyylog"git config --global user.email "cyylog@163.com"先pull下来注意：最终的地址是这样的   ssh://git@git.cyylog.cn:30022/cyylog/mygo.gitgit pull origin master --allow-unrelated-histories</code></pre><h6 id="gitlab-runner"><a href="#gitlab-runner" class="headerlink" title="gitlab-runner"></a>gitlab-runner</h6><pre class=" language-shell"><code class="language-shell">随便找台机器 执行   docker pull gitlab/gitlab-runner 然后创建一个文件夹 /home/cyy/gitlab-runnerdocker run -d --name gitlab-runner   \  -v /home/cyy/gitlab-runner:/etc/gitlab-runner \  -v /var/run/docker.sock:/var/run/docker.sock \  gitlab/gitlab-runner接下来执行 docker exec -it gitlab-runner  gitlab-runner register# vi .gitlab-ci.ymlstages:  - test  - buildjob1:  stage: test  script:    - echo "it is test"job2:  stage: build  script:    - echo "it is build"</code></pre><p>各种参数</p><pre class=" language-shell"><code class="language-shell">script             由Runner执行的Shell脚本。image              使用docker镜像，  image：nameservice            使用docker  services镜像, services：namebefore_script      执行作业前运行的脚本after_script       作业完成后运行的脚本stages             定义管道中的步骤，依次运行stage              定义管道中步骤的作业段only    　　        指定作业限制only:refs，only:kubernetes，only:variables，和only:changestags               指定执行作业的runnerallow_failure      允许job失败when               什么时候开始工作，  on_success       只有当前一个阶段的所有工作都成功时（或者因为它们被标记而被认为是成功的allow_failure）才执行工作 。这是默认值。  on_failure       仅当前一阶段的至少一个作业失败时才执行作业。  always           无论先前阶段的工作状态如何，都可以执行工作。  manual           手动执行作业  delayed          延迟作业。后面跟start_in,start_in 30minutes(延迟30分钟)，不加单位，默认为秒。最长可延迟1小时。environment     作业部署到的环境名称   #暂未搞清 cache    　　key："$CI_JOB_STAGE-$CI_COMMIT_REF_SLUG" #为每分支，每步骤启用缓存artifacts         job成功时附加到作业的文件或目录dependencies      此job依赖其他jobz,主要作用于作业优先级converage         给定作业代码覆盖率设置　　　　　　 retry             在发生故障时，可以自动重试作业的次数。parallel　　      应该并行运行多少个作业实例trigger          定义下游管道触发器include          允许此作业包含外部YAMLextends          此作业将继承的配置项pages            上传作业结果用于gitlab pagesvariables        作业级别定义作业变量</code></pre><h5 id="编译Go程序、打包镜像"><a href="#编译Go程序、打包镜像" class="headerlink" title="编译Go程序、打包镜像"></a>编译Go程序、打包镜像</h5><pre class=" language-shell"><code class="language-shell">把上面的容器删掉   centos7 (阿里云)docker run -d --name gitlab-runner   \  -v /home/cyylog/gitlab-runner:/etc/gitlab-runner \  -v /var/run/docker.sock:/var/run/docker.sock \ -v /usr/bin/docker:/usr/bin/docker \  -v /usr/lib64/libltdl.so.7:/usr/lib/x86_64-linux-gnu/libltdl.so.7  \  gitlab/gitlab-runner并在宿主机上执行 ：chmod 666 /var/run/docker.sockstages:  - testjob1:  stage: test  script:    - docker build -t mygo:v1  .  tags:    - goDocker fileFROM golang:1.14.4-alpine3.12RUN mkdir /src /appADD . ../srcENV GOPROXY="https://goproxy.io"RUN cd /src && ls && go build -o ../app/mygo main.go && cd /app && chmod +x mygo && cd /RUN rm src -frWORKDIR /appENTRYPOINT  ["/app/mygo"]</code></pre><h6 id="打包Go镜像、瘦身镜像"><a href="#打包Go镜像、瘦身镜像" class="headerlink" title="打包Go镜像、瘦身镜像"></a>打包Go镜像、瘦身镜像</h6><pre class=" language-shell"><code class="language-shell">新的 DockerfileFROM golang:1.14.4-alpine3.12RUN mkdir /src /appADD . ../srcENV GOPROXY="https://goproxy.io"RUN cd /src && ls && go build -o ../app/mygo main.go && cd /app && chmod +x mygo && cd /FROM alpine:3.12RUN mkdir /appCOPY --from=0 /app/mygo /appENTRYPOINT ["/app/mygo"]</code></pre><h6 id="打包Go镜像、加入单元测试"><a href="#打包Go镜像、加入单元测试" class="headerlink" title="打包Go镜像、加入单元测试"></a>打包Go镜像、加入单元测试</h6><p>编辑 <code>.gitlab-ci.yml</code></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">stages</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> test  <span class="token punctuation">-</span> build<span class="token key atrule">GoTest</span><span class="token punctuation">:</span>  <span class="token key atrule">stage</span><span class="token punctuation">:</span> test  <span class="token key atrule">script</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> docker build <span class="token punctuation">-</span>f DockerfileTest <span class="token punctuation">-</span>t test<span class="token punctuation">-</span>mygo<span class="token punctuation">:</span>v1 .    <span class="token punctuation">-</span> docker run <span class="token punctuation">-</span><span class="token punctuation">-</span>rm test<span class="token punctuation">-</span>mygo<span class="token punctuation">:</span>v1  <span class="token key atrule">after_script</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> docker rmi test<span class="token punctuation">-</span>mygo<span class="token punctuation">:</span>v1  <span class="token key atrule">tags</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> go<span class="token key atrule">GoBuild</span><span class="token punctuation">:</span>  <span class="token key atrule">stage</span><span class="token punctuation">:</span> build  <span class="token key atrule">script</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> docker build <span class="token punctuation">-</span>t mygo<span class="token punctuation">:</span>v1  .  <span class="token key atrule">after_script</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> docker rmi $(docker images <span class="token punctuation">-</span>af "dangling=true" <span class="token punctuation">-</span>q)  <span class="token key atrule">tags</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> go</code></pre><p><code>Dockerfile</code></p><pre class=" language-dockerfile"><code class="language-dockerfile">FROM golang:1.14.4-alpine3.12RUN mkdir /srcADD . /srcENV GOPROXY="https://goproxy.io"RUN cd /src && ls && go build -o mygo main.go  && chmod +x mygoFROM alpine:3.12RUN mkdir /appCOPY --from=0 /src/mygo /appENTRYPOINT  ["/app/mygo"]</code></pre><p><code>DockerfileTest</code></p><pre class=" language-dockerfile"><code class="language-dockerfile">FROM golang:1.14.4-alpine3.12ADD . /srcWORKDIR /srccmd ["go","test"]</code></pre><h6 id="打包Go镜像、发布到私有镜像库"><a href="#打包Go镜像、发布到私有镜像库" class="headerlink" title="打包Go镜像、发布到私有镜像库"></a>打包Go镜像、发布到私有镜像库</h6><p>编辑 <code>.gitlab-ci.yml</code> 添加<code>deploy</code></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">GoDeploy</span><span class="token punctuation">:</span>  <span class="token key atrule">stage</span><span class="token punctuation">:</span> deploy  <span class="token key atrule">script</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> docker tag  mygo<span class="token punctuation">:</span>v1  192.168.0.129<span class="token punctuation">:</span>5000/mygo<span class="token punctuation">:</span>v1    <span class="token punctuation">-</span> docker push 192.168.0.129<span class="token punctuation">:</span>5000/mygo<span class="token punctuation">:</span>v1  <span class="token key atrule">after_script</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> docker rmi 192.168.0.129<span class="token punctuation">:</span>5000/mygo<span class="token punctuation">:</span>v1    <span class="token punctuation">-</span> docker rmi mygo<span class="token punctuation">:</span>v1  <span class="token key atrule">tags</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> go</code></pre><p><code>Dockerfile</code></p><pre class=" language-dockerfile"><code class="language-dockerfile">FROM golang:1.14.4-alpine3.12RUN mkdir /srcRUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositoriesRUN apk add build-baseADD . /srcRUN cd /src && ls && GOPROXY=https://goproxy.cn go build -o mygo main.go  && chmod +x mygoFROM alpine:3.12RUN mkdir /appCOPY --from=0 /src/mygo /appENTRYPOINT  ["/app/mygo"]</code></pre><p><code>DockerfileTest</code></p><pre class=" language-dockerfile"><code class="language-dockerfile">FROM golang:1.14.4-alpine3.12ADD . /srcWORKDIR /srcENV GOPROXY=https://goproxy.cnRUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositoriesRUN apk add build-basecmd ["go","test"]</code></pre><p>查看仓库</p><pre class=" language-shell"><code class="language-shell">curl http://192.168.0.129:5000/v2/_catalog   (查看列表)curl http://192.168.0.129:5000/v2/镜像名/manifests/v1   (查看redis镜像详情)curl http://192.168.0.129:5000/v2/mygo/tags/list</code></pre><h6 id="打包镜像、自动更新服务"><a href="#打包镜像、自动更新服务" class="headerlink" title="打包镜像、自动更新服务"></a>打包镜像、自动更新服务</h6><p>修改<code>runner</code></p><pre class=" language-shell"><code class="language-shell">docker run -d --name gitlab-runner   \  -v /home/cyy/gitlab-runner:/etc/gitlab-runner \  -v /var/run/docker.sock:/var/run/docker.sock \ -v /usr/bin/docker:/usr/bin/docker \ -v /usr/lib64/libltdl.so.7:/usr/lib/x86_64-linux-gnu/libltdl.so.7  \-v /usr/local/bin/kubectl:/usr/local/bin/kubectl \-v /home/cyy/kubectlconfig/config:/kubeconfig \-e KUBECONFIG=/kubeconfig \  gitlab/gitlab-runner(请自行删除容器后 重新创建)</code></pre><p>熟悉以下命令</p><pre><code>1、kubectl get pod -n myweb| grep mygo2、kubectl get pod -n myweb| grep mygo | awk &#39;{print $1}&#39;3、 kubectl get pod -n myweb| grep mygo | awk &#39;{print $1}&#39;  | xargs kubectl delete pod -n myweb</code></pre><p>加入配置 <code>.gitlab-ci.yml</code></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">GoPub</span><span class="token punctuation">:</span>  <span class="token key atrule">stage</span><span class="token punctuation">:</span> publish  <span class="token key atrule">script</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> kubectl get pod <span class="token punctuation">-</span>n myweb<span class="token punctuation">|</span> grep mygo <span class="token punctuation">|</span> awk '<span class="token punctuation">{</span>print $1<span class="token punctuation">}</span>'  <span class="token punctuation">|</span> xargs kubectl delete pod <span class="token punctuation">-</span>n myweb  <span class="token key atrule">tags</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> go</code></pre><h5 id="灰度发布"><a href="#灰度发布" class="headerlink" title="灰度发布"></a>灰度发布</h5><p>那么现在我们要干的事 是设置 一部分流量</p><p>添加这个标签</p><pre class=" language-shell"><code class="language-shell">nginx.ingress.kubernetes.io/canary-weight</code></pre><p>设置如下标签</p><pre class=" language-shell"><code class="language-shell"> Nginx –Ingress ，支持配置 标签来实现不同场景下的灰度发布和测试。  主要使用如下标签nginx.ingress.kubernetes.io/canary   nginx.ingress.kubernetes.io/canary-by-headernginx.ingress.kubernetes.io/canary-by-header-valuenginx.ingress.kubernetes.io/canary-weightnginx.ingress.kubernetes.io/canary-by-cookie</code></pre><p>3步一键创建services</p><p><code>pub.yml</code></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Deployment<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> mygo  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> myweb<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">selector</span><span class="token punctuation">:</span>    <span class="token key atrule">matchLabels</span><span class="token punctuation">:</span>      <span class="token key atrule">app</span><span class="token punctuation">:</span> mgo  <span class="token key atrule">replicas</span><span class="token punctuation">:</span> <span class="token number">1</span>  <span class="token key atrule">template</span><span class="token punctuation">:</span>    <span class="token key atrule">metadata</span><span class="token punctuation">:</span>      <span class="token key atrule">labels</span><span class="token punctuation">:</span>        <span class="token key atrule">app</span><span class="token punctuation">:</span> mgo    <span class="token key atrule">spec</span><span class="token punctuation">:</span>      <span class="token key atrule">containers</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> mygo          <span class="token key atrule">image</span><span class="token punctuation">:</span> 192.168.0.129<span class="token punctuation">:</span>5000/mygo<span class="token punctuation">:</span>v1          <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> IfNotPresent          <span class="token key atrule">ports</span><span class="token punctuation">:</span>            <span class="token punctuation">-</span> <span class="token key atrule">containerPort</span><span class="token punctuation">:</span> <span class="token number">80</span><span class="token punctuation">---</span><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Service<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> mygo<span class="token punctuation">-</span>service  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> myweb<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">selector</span><span class="token punctuation">:</span>    <span class="token key atrule">app</span><span class="token punctuation">:</span> mgo  <span class="token key atrule">ports</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">protocol</span><span class="token punctuation">:</span> TCP      <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">80</span>      <span class="token key atrule">targetPort</span><span class="token punctuation">:</span> <span class="token number">80</span>  <span class="token key atrule">type</span><span class="token punctuation">:</span> ClusterIP<span class="token punctuation">---</span><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> extensions/v1beta1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Ingress<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> mygolb  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> myweb<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">rules</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">host</span><span class="token punctuation">:</span> api2.cyylog.cn      <span class="token key atrule">http</span><span class="token punctuation">:</span>        <span class="token key atrule">paths</span><span class="token punctuation">:</span>          <span class="token punctuation">-</span> <span class="token key atrule">path</span><span class="token punctuation">:</span> /            <span class="token key atrule">backend</span><span class="token punctuation">:</span>              <span class="token key atrule">serviceName</span><span class="token punctuation">:</span> mygo<span class="token punctuation">-</span>service              <span class="token key atrule">servicePort</span><span class="token punctuation">:</span> <span class="token number">80</span></code></pre><h5 id="ETCD"><a href="#ETCD" class="headerlink" title="ETCD"></a>ETCD</h5><h6 id="单体部署etcd到k8s中"><a href="#单体部署etcd到k8s中" class="headerlink" title="单体部署etcd到k8s中"></a>单体部署etcd到k8s中</h6><p>镜像地址</p><pre class=" language-shell"><code class="language-shell">etcd是一个高可用的键值存储系统,场景主要是1、主要用于共享配置2、服务注册与发现3、分布式锁等etcd是由CoreOS开发并维护的,灵感来自于 ZooKeeper 等。它使用Go语言编写https://quay.io/repository/coreos/etcd?tag=latest&tab=tags</code></pre><p>先pull镜像</p><pre class=" language-shell"><code class="language-shell">Red Hat运营的镜像库docker pull quay.io/coreos/etcd:v3.3.25由于不可描述的原因，一般你是干不下来的。于是可以用中科大的地址:  docker pull  quay.mirrors.ustc.edu.cn/coreos/etcd:v3.3.25（不一定稳定，不能用则自己打包）</code></pre><p>修改tag</p><pre class=" language-shell"><code class="language-shell">1、docker tag quay.mirrors.ustc.edu.cn/coreos/etcd:v3.3.25 etcd:3.3.252、docker rmi quay.mirrors.ustc.edu.cn/coreos/etcd:v3.3.25</code></pre><p>接下来</p><pre class=" language-shell"><code class="language-shell">在我们之前做的nfs-server中 创建文件夹1、首先创建一文件夹 : /home/cyy/etcdconf2、cd进入后，再创建 etcd1目录 目录结构是[cyy@cyylog1 etcdconf]$ pwd/home/cyy/etcdconf[cyy@cyylog1 etcdconf]$ tree ..└── etcd1    ├── conf    └── data配置nfs-serversudo vi /etc/exports加入配置（具体看视频演示）然后执行 sudo exportfs -a 重新加载配置查看 showmount -e 192.168.0.129单机配置文件使用cm配置即可name: etcd1data_dir: /etcd/datalisten-client-urls: http://0.0.0.0:2379启动命令 是  etcd --config-file /etcd/conf/etcd.yaml</code></pre><p>golang测试连接etcd</p><pre class=" language-shell"><code class="language-shell">客户端库  https://github.com/etcd-io/etcd/tree/master/clientv3go get go.etcd.io/etcd/clientv3(如果有版本冲突，可以降低grpc的库replace google.golang.org/grpc => google.golang.org/grpc v1.26.0 )测试连接export ETCDCTL_API=3  切换为API3etcdctl get /service/test </code></pre><p>使用nginx-ingress反代etcd</p><pre class=" language-shell"><code class="language-shell">原理Ingress Controller监听     两个configmap(tcp和udp)，可以设置反代的TCP暴露的端口。当修改并且发生变化后，Ingress controller会去更改Nginx的配置，增加对应的监听格式端口:<namespace/service_name>:<service port>于是我们加入 一个配置：key是  32379对应的值是    myweb/etcd1:2379</code></pre><p>创建etcd集群（3个节点）</p><pre class=" language-shell"><code class="language-shell">之前的配置name: etcd1data_dir: /etcd/datalisten-client-urls: http://0.0.0.0:2379单机的话比较简单基本配置name: etcd1data-dir: /etcd/datalisten-client-urls: http://0.0.0.0:2379advertise-client-urls: http://0.0.0.0:2379listen-peer-urls: http://0.0.0.0:2380initial-advertise-peer-urls: http://etcd1:2380initial-cluster-token: 'etcd-cluster'initial-cluster: etcd1=http://etcd1:2380,etcd2=http://etcd2:2380,etcd3=http://etcd3:2380initial-cluster-state: 'new'基本配置说明listen-client-urls：etcd监听url和端口 advertise-client-urls：etcdctl或curl等客户端工具交互时用的url地址（一般和上面的一样）listen-peer-urls： 节点通信地址，  如：Leader 选举、Message消息传输、快照等。initial-advertise-peer-urls：同上initial-cluster-token：集群唯一标识initial-cluster：集群中所有的initial-advertise-peer-urls的合集。initial-cluster-state：新建集群的标识。创建是别忘了加上环境变量：ETCDCTL_API  =3启动命令 是  etcd --config-file /etcd/conf/etcd.yaml基本情况查询查看节点列表etcdctl -w table member list查看单节点信息 etcdctl -w table  endpoint status查看全部 etcdctl -w table --endpoints=etcd1:2379,etcd2:2379,etcd3:2379  endpoint status</code></pre><h5 id="sidecar"><a href="#sidecar" class="headerlink" title="sidecar"></a>sidecar</h5><blockquote><p>SideCar 是在 Pod 中延伸或增强主容器的    容器。主容器和 Sidecar 共享一个 Pod，可以共享相同的网络空间和存储空间</p></blockquote><pre class=" language-shell"><code class="language-shell">第一步：首先利用   nginx:1.18-alpine  。随随便便创建一个nginx服务 接下来就可以查看日志了    默认目录在 /var/log/nginx下 注意：请不要做任何改变</code></pre><p>接下来</p><pre class=" language-go"><code class="language-go">我做了一个 很随便 很随意的  <span class="token keyword">go</span>程序交叉编译到linux中 。。 然后使用alpine<span class="token punctuation">:</span><span class="token number">3.12</span> 挂载启动    r<span class="token operator">:=</span>gin<span class="token punctuation">.</span><span class="token function">New</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    r<span class="token punctuation">.</span><span class="token function">Use</span><span class="token punctuation">(</span><span class="token keyword">func</span><span class="token punctuation">(</span>context <span class="token operator">*</span>gin<span class="token punctuation">.</span>Context<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">defer</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">if</span> e<span class="token operator">:=</span><span class="token function">recover</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>e<span class="token operator">!=</span><span class="token boolean">nil</span><span class="token punctuation">{</span>                context<span class="token punctuation">.</span><span class="token function">JSON</span><span class="token punctuation">(</span><span class="token number">400</span><span class="token punctuation">,</span>gin<span class="token punctuation">.</span>H<span class="token punctuation">{</span><span class="token string">"error"</span><span class="token punctuation">:</span>e<span class="token punctuation">}</span><span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        context<span class="token punctuation">.</span><span class="token function">Next</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">)</span>    r<span class="token punctuation">.</span><span class="token function">GET</span><span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">,</span> <span class="token keyword">func</span><span class="token punctuation">(</span>context <span class="token operator">*</span>gin<span class="token punctuation">.</span>Context<span class="token punctuation">)</span> <span class="token punctuation">{</span>        context<span class="token punctuation">.</span><span class="token function">JSON</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span>gin<span class="token punctuation">.</span>H<span class="token punctuation">{</span><span class="token string">"message"</span><span class="token punctuation">:</span><span class="token string">"index"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">)</span>    r<span class="token punctuation">.</span><span class="token function">Run</span><span class="token punctuation">(</span><span class="token string">"0.0.0.0:8080"</span><span class="token punctuation">)</span></code></pre><h6 id="emptydir"><a href="#emptydir" class="headerlink" title="emptydir"></a><code>emptydir</code></h6><blockquote><p>文档<br><a href="https://kubernetes.io/zh/docs/concepts/storage/volumes/#emptydir" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/concepts/storage/volumes/#emptydir</a></p></blockquote><p>配置方式</p><pre class=" language-yaml"><code class="language-yaml">   我们需要打开yaml的方式来进行配置 在主容器上写入 （和image 同级）   <span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>            <span class="token punctuation">-</span> <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /var/log/nginx              <span class="token key atrule">name</span><span class="token punctuation">:</span> nginx<span class="token punctuation">-</span>logSideCar中也写入      <span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>            <span class="token punctuation">-</span> <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /app              <span class="token key atrule">name</span><span class="token punctuation">:</span> vol4            <span class="token punctuation">-</span> <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /var/log/nginx              <span class="token key atrule">name</span><span class="token punctuation">:</span> nginx<span class="token punctuation">-</span>log</code></pre><p>最后加入</p><pre class=" language-yaml"><code class="language-yaml"> <span class="token key atrule">volumes</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">emptyDir</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>          <span class="token key atrule">name</span><span class="token punctuation">:</span> nginx<span class="token punctuation">-</span>log        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> vol4          <span class="token key atrule">persistentVolumeClaim</span><span class="token punctuation">:</span>            <span class="token key atrule">claimName</span><span class="token punctuation">:</span> gopvc</code></pre><h5 id="ELK"><a href="#ELK" class="headerlink" title="ELK"></a>ELK</h5><h6 id="filebeat"><a href="#filebeat" class="headerlink" title="filebeat"></a>filebeat</h6><blockquote><p> 用于转发和集中日志数据的轻量级传送工具。Filebeat监视您指定的日志文件或位置，收集日志事件，并将它们转发到Elasticsearch或 数据库中</p><p>  配置文档指引:<br>     <a href="https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-input-log.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-input-log.html</a></p><p> 它属于beats家族成员之一<br>   看github地址<a href="https://github.com/elastic/beats" target="_blank" rel="noopener">https://github.com/elastic/beats</a></p><p> 包含了Packetbeat收集网络流量数据、Metricbeat收集系统、进程的CPU、内存使用情况等数据、Filebeat收集文件数据  等等</p></blockquote><blockquote><p>   安装文档：</p><pre><code>https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-installation-configuration.html</code></pre><p>   我们后面采用docker的方式安装：<br>     <a href="https://www.elastic.co/guide/en/beats/filebeat/current/running-on-docker.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/filebeat/current/running-on-docker.html</a></p></blockquote><pre class=" language-shell"><code class="language-shell">我们先在每个节点上执行  docker pull docker.elastic.co/beats/filebeat:7.10.0这样可以加快点速度基本的配置--input 千万不要背https://www.elastic.co/guide/en/beats/filebeat/current/configuration-filebeat-options.htmlfilebeat.inputs:- type: log  paths:    - /var/log/nginx/access.log放到configmap里面基本的配置--output 千万不要背https://www.elastic.co/guide/en/beats/filebeat/current/console-output.htmloutput.console:  pretty: true放到configmap里面基本的是这样的filebeat.inputs:- type: log  enabled: true  paths:    - /var/log/nginx/access.logoutput.console:  pretty: truesetup.template.enabled: falsescan_frequency: 2s</code></pre><h6 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h6><h6 id="部署单体ElasticSearch"><a href="#部署单体ElasticSearch" class="headerlink" title="部署单体ElasticSearch"></a>部署单体ElasticSearch</h6><blockquote><p>   安装文档：<br>    <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.4/docker.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.4/docker.html</a></p><p>我们先在每个节点上执行  docker pull docker.elastic.co/elasticsearch/elasticsearch:7.4.2</p><p>这样可以加快点速度</p></blockquote><p>接下来的步骤</p><pre class=" language-shell"><code class="language-shell">我们新开一个命名空间 叫做 elkdocker run --rm --name testes -it  docker.elastic.co/elasticsearch/elasticsearch:7.4.2 sh进去后可以看到 ，es的配置文件主要在： /usr/share/elasticsearch/config我们把他们都拷贝下来cd  /usr/share/elasticsearch/config && cat elasticsearch.ymlmkdir myes然后创建一个文件夹叫做 es1  (猜也能猜出 我们后面要创建集群)就拷贝到这个地方docker cp testes:/usr/share/elasticsearch/config .</code></pre><p>基本的配置就能启动</p><pre class=" language-shell"><code class="language-shell">cluster.name: myesnetwork.host: 0.0.0.0http.port: 9200node.name: "es1"cluster.initial_master_nodes: ["es1"]#设置一个集群启动时适合做主节点的列表在各个节点上执行：sudo sysctl -w vm.max_map_count=262144（一个进程可以拥有的VMA(虚拟内存区域)的数量）</code></pre><h6 id="ElasticSearch集群（2节点）"><a href="#ElasticSearch集群（2节点）" class="headerlink" title="ElasticSearch集群（2节点）"></a>ElasticSearch集群（2节点）</h6><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">cluster.name</span><span class="token punctuation">:</span> myes<span class="token key atrule">network.host</span><span class="token punctuation">:</span> 0.0.0.0<span class="token key atrule">http.port</span><span class="token punctuation">:</span> <span class="token number">9200</span><span class="token key atrule">node.name</span><span class="token punctuation">:</span> <span class="token string">"es1"</span><span class="token key atrule">cluster.initial_master_nodes</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"es1"</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#设置一个集群启动时适合做主节点的列表</span>增加一些配置 ：<span class="token key atrule">transport.tcp.port</span><span class="token punctuation">:</span> <span class="token number">9300</span><span class="token key atrule">discovery.zen.ping.unicast.hosts</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"es1"</span><span class="token punctuation">,</span> <span class="token string">"es2"</span><span class="token punctuation">]</span></code></pre><p>我们再来一个</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">cluster.name</span><span class="token punctuation">:</span> myes<span class="token key atrule">network.host</span><span class="token punctuation">:</span> 0.0.0.0<span class="token key atrule">http.port</span><span class="token punctuation">:</span> <span class="token number">9200</span><span class="token key atrule">node.name</span><span class="token punctuation">:</span> <span class="token string">"es2"</span><span class="token key atrule">cluster.initial_master_nodes</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"es1"</span><span class="token punctuation">]</span><span class="token key atrule">transport.tcp.port</span><span class="token punctuation">:</span> <span class="token number">9300</span><span class="token key atrule">discovery.zen.ping.unicast.hosts</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"es1"</span><span class="token punctuation">,</span> <span class="token string">"es2"</span><span class="token punctuation">]</span>使用的镜像依然是：docker.elastic.co/elasticsearch/elasticsearch<span class="token punctuation">:</span>7.4.2挂载文件依然是elasticsearch.yml 挂载到/usr/share/elasticsearch/config/elasticsearch.yml</code></pre><h6 id="部署Kibana"><a href="#部署Kibana" class="headerlink" title="部署Kibana"></a>部署Kibana</h6><blockquote><p>   安装文档：<br>    <a href="https://www.elastic.co/guide/en/kibana/current/docker.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/kibana/current/docker.html</a></p><p>我们先在每个节点上执行  docker pull docker.elastic.co/kibana/kibana:7.4.2</p><p>这样可以加快点速度</p></blockquote><pre class=" language-shell"><code class="language-shell">或者去hub.docker.com 下载 （es也一样）https://hub.docker.com/r/elastic/kibana/tagsdocker pull elastic/kibana:7.4.2注意，此时镜像名称就是elastic/kibana:7.4.2当然 你可以自己改掉</code></pre><p>查看配置文件</p><pre class=" language-shell"><code class="language-shell"> docker run --rm --name testkb -it  elastic/kibana:7.4.2 sh我们发现 kibana的配置 文件在 /usr/share/kibana/config这个目录， 叫做kibana.yml接下来 我们自己创建server.port: 5601   server.host: "0.0.0.0"#ES请求的服务URLelasticsearch.hosts: ["http://es1:9200","http://es2:9200"]#无证书elasticsearch.ssl.verificationMode: nonexpack.security.enabled: false   //不使用安全验证</code></pre><h6 id="Kibana-身份验证"><a href="#Kibana-身份验证" class="headerlink" title="Kibana 身份验证"></a>Kibana 身份验证</h6><p>给Kibana加入Basic Auth身份验证</p><pre class=" language-shell"><code class="language-shell">加入标签nginx.ingress.kubernetes.io/auth-type: basicnginx.ingress.kubernetes.io/auth-secret: kb-auth文档在此：https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#authentication安装工具yum -y install httpd-toolsApache的Web服务器内置的工具,用于创建和更新储存用户名和用户基本认证的密码文件创建一个密码文件  htpasswd -c auth cyylog这时产生了一个 auth文件再添加一个  用户(此时不用-c参数)htpasswd  auth adminkb.cyylog.cn创建secretkubectl -n elk create secret generic kb-auth  --from-file=auth </code></pre><h6 id="IK中文分词插件"><a href="#IK中文分词插件" class="headerlink" title="IK中文分词插件"></a>IK中文分词插件</h6><p>nfsserver</p><pre class=" language-shell"><code class="language-shell">sudo vi /etc/exports加入一行/home/cyy/es 192.168.0.0/24(rw,async,insecure,no_root_squash)（/home/cyy/es  请自行创建,ip请自行修改）修改后 执行exportfs -r 或者 systemctl reload nfs-server确认:  showmount -e 192.168.0.129</code></pre><p>ES 的插件路径</p><pre class=" language-shell"><code class="language-shell">我们使用的 es7.4.2 ，默认容器的插件路径在：/usr/share/elasticsearch/plugins我们把它挂载到刚才创建的目录中https://github.com/medcl/elasticsearch-analysis-ik下载地址：https://github.com/medcl/elasticsearch-analysis-ik/releases/tag/v7.4.2解压后（文件夹名设置成analysis-ik ，然后通通拷贝到plugins里面）个人操作： 先拷贝到 tmp目录下，然后 sudo 拷贝过来  cp ~/tmp/analysis-ik .  -r注意：分词器必须和你的ES版本一致，必须、必须、必须测试下POST  _analyze{  "analyzer": "ik_smart",   "text" : "程序教程java"}创建一个索引试试PUT news{  "mappings": {    "properties": {      "news_title": {        "type":  "text"      },      "news_kind": {        "type":  "keyword"      }    }  }}</code></pre><h6 id="使用SQL查询ES"><a href="#使用SQL查询ES" class="headerlink" title="使用SQL查询ES"></a>使用SQL查询ES</h6><p>创建一个索引试试</p><pre class=" language-json"><code class="language-json"> PUT /books<span class="token punctuation">{</span>  <span class="token property">"mappings"</span><span class="token operator">:</span> <span class="token punctuation">{</span>    <span class="token property">"properties"</span><span class="token operator">:</span> <span class="token punctuation">{</span>      <span class="token property">"BookID"</span><span class="token operator">:</span>    <span class="token punctuation">{</span> <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"integer"</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>      <span class="token property">"BookName"</span><span class="token operator">:</span>    <span class="token punctuation">{</span> <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"text"</span><span class="token punctuation">,</span><span class="token property">"analyzer"</span><span class="token operator">:</span> <span class="token string">"ik_max_word"</span><span class="token punctuation">,</span><span class="token property">"search_analyzer"</span><span class="token operator">:</span> <span class="token string">"ik_smart"</span><span class="token punctuation">,</span><span class="token property">"fields"</span><span class="token operator">:</span><span class="token punctuation">{</span> <span class="token property">"keyword"</span><span class="token operator">:</span><span class="token punctuation">{</span><span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"keyword"</span><span class="token punctuation">,</span><span class="token property">"ignore_above"</span><span class="token operator">:</span><span class="token number">256</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token property">"BookPrice"</span><span class="token operator">:</span>   <span class="token punctuation">{</span> <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"float"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token property">"BookAuthor"</span><span class="token operator">:</span>   <span class="token punctuation">{</span> <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"keyword"</span><span class="token punctuation">}</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>批量插入一些数据</p><pre class=" language-json"><code class="language-json">POST _bulk<span class="token punctuation">{</span> <span class="token property">"index"</span> <span class="token operator">:</span> <span class="token punctuation">{</span> <span class="token property">"_index"</span> <span class="token operator">:</span> <span class="token string">"books"</span><span class="token punctuation">,</span> <span class="token property">"_id"</span> <span class="token operator">:</span> <span class="token string">"101"</span> <span class="token punctuation">}</span> <span class="token punctuation">}</span><span class="token punctuation">{</span><span class="token property">"BookID"</span><span class="token operator">:</span><span class="token number">101</span><span class="token punctuation">,</span><span class="token property">"BookName"</span><span class="token operator">:</span><span class="token string">"C语言程序设计"</span><span class="token punctuation">,</span><span class="token property">"BookPrice"</span><span class="token operator">:</span><span class="token number">19</span><span class="token punctuation">,</span><span class="token property">"BookAuthor"</span><span class="token operator">:</span><span class="token string">"老蒋"</span><span class="token punctuation">}</span><span class="token punctuation">{</span> <span class="token property">"index"</span> <span class="token operator">:</span> <span class="token punctuation">{</span> <span class="token property">"_index"</span> <span class="token operator">:</span> <span class="token string">"books"</span><span class="token punctuation">,</span> <span class="token property">"_id"</span> <span class="token operator">:</span> <span class="token string">"102"</span> <span class="token punctuation">}</span> <span class="token punctuation">}</span> <span class="token punctuation">{</span><span class="token property">"BookID"</span><span class="token operator">:</span><span class="token number">102</span><span class="token punctuation">,</span><span class="token property">"BookName"</span><span class="token operator">:</span><span class="token string">"PHP高级编程"</span><span class="token punctuation">,</span><span class="token property">"BookPrice"</span><span class="token operator">:</span><span class="token number">29</span><span class="token punctuation">,</span><span class="token property">"BookAuthor"</span><span class="token operator">:</span><span class="token string">"老李"</span><span class="token punctuation">}</span><span class="token punctuation">{</span> <span class="token property">"index"</span> <span class="token operator">:</span> <span class="token punctuation">{</span> <span class="token property">"_index"</span> <span class="token operator">:</span> <span class="token string">"books"</span><span class="token punctuation">,</span> <span class="token property">"_id"</span> <span class="token operator">:</span> <span class="token string">"103"</span> <span class="token punctuation">}</span> <span class="token punctuation">}</span> <span class="token punctuation">{</span><span class="token property">"BookID"</span><span class="token operator">:</span><span class="token number">103</span><span class="token punctuation">,</span><span class="token property">"BookName"</span><span class="token operator">:</span><span class="token string">"java编程从入门到精通"</span><span class="token punctuation">,</span><span class="token property">"BookPrice"</span><span class="token operator">:</span><span class="token number">39</span><span class="token punctuation">,</span><span class="token property">"BookAuthor"</span><span class="token operator">:</span><span class="token string">"老王"</span><span class="token punctuation">}</span><span class="token punctuation">{</span> <span class="token property">"index"</span> <span class="token operator">:</span> <span class="token punctuation">{</span> <span class="token property">"_index"</span> <span class="token operator">:</span> <span class="token string">"books"</span><span class="token punctuation">,</span> <span class="token property">"_id"</span> <span class="token operator">:</span> <span class="token string">"104"</span> <span class="token punctuation">}</span> <span class="token punctuation">}</span> <span class="token punctuation">{</span><span class="token property">"BookID"</span><span class="token operator">:</span><span class="token number">104</span><span class="token punctuation">,</span><span class="token property">"BookName"</span><span class="token operator">:</span><span class="token string">"无需流汗和吃苦3天成为java大神"</span><span class="token punctuation">,</span><span class="token property">"BookPrice"</span><span class="token operator">:</span><span class="token number">15.5</span><span class="token punctuation">,</span><span class="token property">"BookAuthor"</span><span class="token operator">:</span><span class="token string">"老张"</span><span class="token punctuation">}</span></code></pre><h6 id="SQL访问"><a href="#SQL访问" class="headerlink" title="SQL访问"></a>SQL访问</h6><blockquote><p>文档<br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/sql-getting-started.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/sql-getting-started.html</a><br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/sql-syntax-select.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/sql-syntax-select.html</a></p><pre class=" language-json"><code class="language-json">POST /_sql<span class="token punctuation">{</span>     <span class="token property">"query"</span><span class="token operator">:</span> <span class="token string">"SELECT * FROM books WHERE BookAuthor = '老王'"</span><span class="token punctuation">}</span>加入?format=txt 参数可以显示 table格式</code></pre></blockquote><p>翻译</p><pre class=" language-json"><code class="language-json">POST /_sql/translate<span class="token punctuation">{</span>     <span class="token property">"query"</span><span class="token operator">:</span> <span class="token string">"SELECT * FROM books WHERE BookAuthor = '老王'"</span><span class="token punctuation">}</span>加入?format=txt 参数可以显示 table格式</code></pre><h6 id="match"><a href="#match" class="headerlink" title="match"></a>match</h6><blockquote><p>文档:<br>  <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/sql-functions-search.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/sql-functions-search.html</a></p></blockquote><pre class=" language-shell"><code class="language-shell"> "query": "SELECT BookName,BookID FROM books WHERE match(BookName,'我从小就喜欢编程')  " "query": "SELECT BookName,BookID FROM books WHERE match('BookName','我从小就喜欢java编程') order by SCORE() desc "</code></pre><h6 id="实操示范"><a href="#实操示范" class="headerlink" title="实操示范"></a>实操示范</h6><blockquote><p>配置负载均衡、Go调用</p></blockquote><p>首先安装客户端库</p><pre class=" language-go"><code class="language-go"><span class="token keyword">go</span> get github<span class="token punctuation">.</span>com<span class="token operator">/</span>olivere<span class="token operator">/</span>elastic<span class="token operator">/</span>v7<span class="token keyword">func</span> <span class="token function">getClient</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span>elastic<span class="token punctuation">.</span>Client  <span class="token punctuation">{</span>    client<span class="token punctuation">,</span> err <span class="token operator">:=</span> elastic<span class="token punctuation">.</span><span class="token function">NewSimpleClient</span><span class="token punctuation">(</span>        elastic<span class="token punctuation">.</span><span class="token function">SetSniff</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        elastic<span class="token punctuation">.</span><span class="token function">SetURL</span><span class="token punctuation">(</span><span class="token string">"http://es.jtthink.com/es1/"</span><span class="token punctuation">,</span><span class="token string">"http://es.jtthink.com/es2/"</span> <span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">)</span>    <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token function">panic</span><span class="token punctuation">(</span>err<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span>  client<span class="token punctuation">}</span>辅助函数<span class="token keyword">type</span> Books <span class="token keyword">struct</span><span class="token punctuation">{</span>    BookID <span class="token builtin">int</span>    BookName <span class="token builtin">string</span>    BookPrice1 <span class="token builtin">float64</span>    BookAuthor <span class="token builtin">string</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token function">MapToBooks</span><span class="token punctuation">(</span>rsp <span class="token operator">*</span>elastic<span class="token punctuation">.</span>SearchResult<span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">*</span>Books  <span class="token punctuation">{</span>    ret<span class="token operator">:=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">*</span>Books<span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token keyword">var</span> t <span class="token operator">*</span>Books    <span class="token keyword">for</span> <span class="token boolean">_</span><span class="token punctuation">,</span>item<span class="token operator">:=</span><span class="token keyword">range</span> rsp<span class="token punctuation">.</span><span class="token function">Each</span><span class="token punctuation">(</span>reflect<span class="token punctuation">.</span><span class="token function">TypeOf</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        ret<span class="token operator">=</span><span class="token function">append</span><span class="token punctuation">(</span>ret<span class="token punctuation">,</span>item<span class="token punctuation">.</span><span class="token punctuation">(</span><span class="token operator">*</span>Books<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> ret<span class="token punctuation">}</span>具体代码matchQuery<span class="token operator">:=</span>elastic<span class="token punctuation">.</span><span class="token function">NewMatchQuery</span><span class="token punctuation">(</span><span class="token string">"BookName"</span><span class="token punctuation">,</span><span class="token string">"编程"</span><span class="token punctuation">)</span>   ret<span class="token punctuation">,</span>err<span class="token operator">:=</span><span class="token function">getClient</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Search</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Index</span><span class="token punctuation">(</span><span class="token string">"books"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Query</span><span class="token punctuation">(</span>matchQuery<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Do</span><span class="token punctuation">(</span>context<span class="token punctuation">.</span><span class="token function">Background</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token keyword">if</span> err<span class="token operator">!=</span><span class="token boolean">nil</span><span class="token punctuation">{</span>         log<span class="token punctuation">.</span><span class="token function">Fatal</span><span class="token punctuation">(</span>err<span class="token punctuation">)</span>   <span class="token punctuation">}</span>   books<span class="token operator">:=</span><span class="token function">MapToBooks</span><span class="token punctuation">(</span>ret<span class="token punctuation">)</span>翻译POST <span class="token operator">/</span>_sql<span class="token operator">/</span>translate<span class="token punctuation">{</span>     <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"SELECT * FROM books WHERE BookAuthor = '老王'"</span><span class="token punctuation">}</span>加入?format<span class="token operator">=</span>txt 参数可以显示 table格式 match文档<span class="token punctuation">:</span>  https<span class="token punctuation">:</span><span class="token operator">/</span><span class="token operator">/</span>www<span class="token punctuation">.</span>elastic<span class="token punctuation">.</span>co<span class="token operator">/</span>guide<span class="token operator">/</span>en<span class="token operator">/</span>elasticsearch<span class="token operator">/</span>reference<span class="token operator">/</span>current<span class="token operator">/</span>sql<span class="token operator">-</span>functions<span class="token operator">-</span>search<span class="token punctuation">.</span>html <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"SELECT BookName,BookID FROM books WHERE match(BookName,'我从小就喜欢编程')  "</span> <span class="token string">"query"</span><span class="token punctuation">:</span> <span class="token string">"SELECT BookName,BookID FROM books WHERE match('BookName','我从小就喜欢java编程') order by SCORE() desc "</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>traefik notes</title>
      <link href="2021/04/10/notes/traefik-kuai-su-shi-zhan-shang-shou-bi-ji/"/>
      <url>2021/04/10/notes/traefik-kuai-su-shi-zhan-shang-shou-bi-ji/</url>
      
        <content type="html"><![CDATA[<h4 id="快速上手traefik速学实战"><a href="#快速上手traefik速学实战" class="headerlink" title="快速上手traefik速学实战"></a>快速上手<code>traefik</code>速学实战</h4><h6 id="traefik是什么"><a href="#traefik是什么" class="headerlink" title="traefik是什么"></a><code>traefik</code>是什么</h6><blockquote><p> <code>Træfɪk</code> 是一个为了让部署微服务更加便捷而诞生的现代HTTP反向代理、负载均衡工具。 它支持多种后台 <code>(Docker, Swarm, Kubernetes, Marathon, Mesos, Consul, Etcd, Zookeeper, BoltDB, Rest API, file…)</code> 来自动化、动态的应用它的配置文件设置</p><p>github地址如下：<br><a href="https://github.com/traefik/traefik" target="_blank" rel="noopener">https://github.com/traefik/traefik</a><br>文档：<a href="https://doc.traefik.io/traefik/providers/kubernetes-crd/" target="_blank" rel="noopener">https://doc.traefik.io/traefik/providers/kubernetes-crd/</a></p></blockquote><h5 id="使用helm部署（helm3）"><a href="#使用helm部署（helm3）" class="headerlink" title="使用helm部署（helm3）"></a>使用<code>helm</code>部署（<code>helm3</code>）</h5><pre class=" language-shell"><code class="language-shell">1、helm repo add traefik https://helm.traefik.io/traefik2、helm repo update3、helm search repo traefik/traefik### 我们fetch下来helm fetch traefik/traefik然后解压tar zxvf traefik-9.11.0.tgz修改几个内容image.tag 改成了 2.3.5websecure.port 改成了 9443  (因为 我8443给占用了)</code></pre><p><strong>install</strong></p><pre class=" language-shell"><code class="language-shell">首先 kubectl create ns tk在你认为需要安装traefik的节点上打标签kubectl label nodes cyylog2 traefik=true   (cyylog2是我喜欢的节点名称)然后 helm install mytk traefik    -n tk更新是：helm upgrade mytk traefik    -n tk卸载则是 helm uninstall mytk -n tk</code></pre><h5 id="使用IngressRoute创建服务反代"><a href="#使用IngressRoute创建服务反代" class="headerlink" title="使用IngressRoute创建服务反代"></a>使用<code>IngressRoute</code>创建服务反代</h5><blockquote><p><code>IngressRoute</code><br>文档在这</p><p>   <a href="https://doc.traefik.io/traefik/routing/providers/kubernetes-crd/" target="_blank" rel="noopener">https://doc.traefik.io/traefik/routing/providers/kubernetes-crd/</a></p><p> <code>traefik2</code>支持 更方便的ingress配置 而创建的一个<code>CRD</code>。</p></blockquote><p><strong>创建</strong><code>ingress</code></p><blockquote><p>文档在这</p><p><a href="https://doc.traefik.io/traefik/providers/kubernetes-ingress/" target="_blank" rel="noopener">https://doc.traefik.io/traefik/providers/kubernetes-ingress/</a></p><p>其他具体看文档说明</p></blockquote><h5 id="http路由"><a href="#http路由" class="headerlink" title="http路由"></a>http路由</h5><h6 id="1-：Path、中间件初步使用"><a href="#1-：Path、中间件初步使用" class="headerlink" title="(1)：Path、中间件初步使用"></a>(1)：Path、中间件初步使用</h6><blockquote><p>文档：</p><p><a href="https://doc.traefik.io/traefik/routing/routers/" target="_blank" rel="noopener">https://doc.traefik.io/traefik/routing/routers/</a> </p></blockquote><blockquote><p><code>Path</code></p><pre><code>match: Host(`tk2.cyylog.cn`) &amp;&amp; Path(`/abc`)当访问 /abc+host时 就会反代到我们的服务https://doc.traefik.io/traefik/routing/routers/</code></pre></blockquote><p><strong>中间件的使用</strong></p><pre class=" language-yaml"><code class="language-yaml">文档https<span class="token punctuation">:</span>//doc.traefik.io/traefik/middlewares/stripprefix/<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> traefik.containo.us/v1alpha1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Middleware<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> ngx<span class="token punctuation">-</span>strip<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">stripPrefix</span><span class="token punctuation">:</span>    <span class="token key atrule">prefixes</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> /abc</code></pre><h6 id="2-：中间件、限流的基本使用"><a href="#2-：中间件、限流的基本使用" class="headerlink" title="(2)：中间件、限流的基本使用"></a>(2)：中间件、限流的基本使用</h6><blockquote><p>文档 地址：</p><p><a href="https://doc.traefik.io/traefik/middlewares/ratelimit/" target="_blank" rel="noopener">https://doc.traefik.io/traefik/middlewares/ratelimit/</a></p></blockquote><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> traefik.containo.us/v1alpha1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Middleware<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> ngx<span class="token punctuation">-</span>ratelimit<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">rateLimit</span><span class="token punctuation">:</span>    <span class="token key atrule">average</span><span class="token punctuation">:</span> <span class="token number">1</span>    <span class="token key atrule">burst</span><span class="token punctuation">:</span> <span class="token number">5</span></code></pre><h6 id="3-：中间件，自定义响应头、跨域头"><a href="#3-：中间件，自定义响应头、跨域头" class="headerlink" title="(3)：中间件，自定义响应头、跨域头"></a>(3)：中间件，自定义响应头、跨域头</h6><blockquote><p>文档</p><p><a href="https://doc.traefik.io/traefik/middlewares/headers/" target="_blank" rel="noopener">https://doc.traefik.io/traefik/middlewares/headers/</a></p><pre class=" language-json"><code class="language-json">加入跨域头：Access-Control-Allow-Origin<span class="token operator">:</span> <span class="token string">"*"</span>Access-Control-Allow-Methods<span class="token operator">:</span> <span class="token string">"POST, GET, OPTIONS, PUT, DELETE, UPDATE"</span>Access-Control-Allow-Headers<span class="token operator">:</span> <span class="token string">"Origin, X-Requested-With, Content-Type, Accept, Authorization"</span>Access-Control-Allow-Credentials<span class="token operator">:</span> <span class="token string">"true"</span>Access-Control-Expose-Headers<span class="token operator">:</span> <span class="token string">"Content-Length, Access-Control-Allow-Origin, Access-Control-Allow-Headers, Cache-Control, Content-Language, Content-Type"</span></code></pre></blockquote><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> traefik.containo.us/v1alpha1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Middleware<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> cross<span class="token punctuation">-</span>header<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">headers</span><span class="token punctuation">:</span>    <span class="token key atrule">customResponseHeaders</span><span class="token punctuation">:</span>      <span class="token key atrule">Myname</span><span class="token punctuation">:</span> <span class="token string">"cyylog"</span>      <span class="token key atrule">Myage</span><span class="token punctuation">:</span> <span class="token string">"14"</span></code></pre><h6 id="设置证书、https访问"><a href="#设置证书、https访问" class="headerlink" title="设置证书、https访问"></a>设置证书、<code>https</code>访问</h6><blockquote><p>首先我有个证书 </p><p> 正规证书</p><p>​    wx.cyylog.cn  </p><p>自签证书也可以，只不过 浏览器会显示不受信任</p></blockquote><p><strong>导入</strong></p><pre class=" language-shell"><code class="language-shell"> kubectl create secret tls mytls --cert=wx.cyylog.cn_chain.crt --key=wx.cyylog.cn_key  -n tk</code></pre><p><strong>配置</strong></p><pre class=" language-yaml"><code class="language-yaml"> <span class="token punctuation">-</span> <span class="token key atrule">match</span><span class="token punctuation">:</span> Host(`wx.cyylog.cn`)      <span class="token key atrule">kind</span><span class="token punctuation">:</span> Rule      <span class="token key atrule">services</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> myngx          <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">80</span>  <span class="token key atrule">tls</span><span class="token punctuation">:</span>    <span class="token key atrule">secretName</span><span class="token punctuation">:</span> mytls</code></pre><h6 id="4-：中间件http跳https、中间件链"><a href="#4-：中间件http跳https、中间件链" class="headerlink" title="(4)：中间件http跳https、中间件链"></a>(4)：中间件http跳https、中间件链</h6><p><strong>基本配置</strong></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> traefik.containo.us/v1alpha1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Middleware<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> redirect<span class="token punctuation">-</span>https<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">redirectScheme</span><span class="token punctuation">:</span>    <span class="token key atrule">scheme</span><span class="token punctuation">:</span> <span class="token string">"https"</span>    <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token string">"9443"</span></code></pre><p><strong>中间件链</strong></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> traefik.containo.us/v1alpha1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Middleware<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> ngx<span class="token punctuation">-</span>secure<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">chain</span><span class="token punctuation">:</span>    <span class="token key atrule">middlewares</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> redirect<span class="token punctuation">-</span>https      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> cross<span class="token punctuation">-</span>header</code></pre><h5 id="带权重的负载均衡、TraefikService使用"><a href="#带权重的负载均衡、TraefikService使用" class="headerlink" title="带权重的负载均衡、TraefikService使用"></a>带权重的负载均衡、TraefikService使用</h5><h6 id="文档地址"><a href="#文档地址" class="headerlink" title="文档地址"></a>文档地址</h6><blockquote><p><a href="https://doc.traefik.io/traefik/routing/providers/kubernetes-crd/#weighted-round-robin" target="_blank" rel="noopener">https://doc.traefik.io/traefik/routing/providers/kubernetes-crd/#weighted-round-robin</a></p></blockquote><p><code>TraefikService</code></p><pre class=" language-shell"><code class="language-shell">apiVersion: traefik.containo.us/v1alpha1kind: TraefikServicemetadata:  name: wrr1spec:  weighted:    services:      - name: ngx1-svc        port: 80        weight: 1        kind: Service      - name: ngx2-svc        port: 80        weight: 2        kind: Service</code></pre><h5 id="创建grpc服务、k8s部署、traefik反代"><a href="#创建grpc服务、k8s部署、traefik反代" class="headerlink" title="创建grpc服务、k8s部署、traefik反代"></a>创建grpc服务、k8s部署、traefik反代</h5><h6 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h6><pre class=" language-shell"><code class="language-shell">docker run --rm -it  \-v /data/tkgrpc:/app \-w /app \-v /data/gopath:/go \-e CGO_ENABLED=0  \-e GOPROXY=https://goproxy.cn \golang:1.14.4-alpine3.12 \go build -o server  server.go</code></pre><p>配置</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> traefik.containo.us/v1alpha1<span class="token key atrule">kind</span><span class="token punctuation">:</span> IngressRoute<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> grpc<span class="token punctuation">-</span>route  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> tk<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">entryPoints</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> web  <span class="token key atrule">routes</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">match</span><span class="token punctuation">:</span> Host(`tk1.cyylog.cn`)      <span class="token key atrule">kind</span><span class="token punctuation">:</span> Rule      <span class="token key atrule">services</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> mygrpc<span class="token punctuation">-</span>svc          <span class="token key atrule">scheme</span><span class="token punctuation">:</span> h2c          <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">8080</span></code></pre><h6 id="traefik反代grpc服务-带证书"><a href="#traefik反代grpc服务-带证书" class="headerlink" title="traefik反代grpc服务(带证书)"></a><code>traefik</code>反代grpc服务(带证书)</h6><p>客户端加入证书</p><pre class=" language-go"><code class="language-go">     creds<span class="token punctuation">,</span> err <span class="token operator">:=</span> credentials<span class="token punctuation">.</span><span class="token function">NewClientTLSFromFile</span><span class="token punctuation">(</span><span class="token string">"mycert/wx.cyylog.cn_chain.crt"</span><span class="token punctuation">,</span> <span class="token string">"wx.cyylog.cn"</span><span class="token punctuation">)</span>  client<span class="token punctuation">,</span>err<span class="token operator">:=</span>grpc<span class="token punctuation">.</span><span class="token function">Dial</span><span class="token punctuation">(</span><span class="token string">"wx.cyylog.cn:9443"</span><span class="token punctuation">,</span>grpc<span class="token punctuation">.</span><span class="token function">WithTransportCredentials</span><span class="token punctuation">(</span>creds<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h5 id="整合grpc-gateway"><a href="#整合grpc-gateway" class="headerlink" title="整合grpc-gateway"></a>整合grpc-gateway</h5><p>客户端加入证书</p><blockquote><p>文档在这<a href="https://github.com/grpc-ecosystem/grpc-gateway" target="_blank" rel="noopener">https://github.com/grpc-ecosystem/grpc-gateway</a></p><p>会在你的gopath 的bin下面 生成一堆文件</p></blockquote><pre class=" language-go"><code class="language-go"><span class="token keyword">go</span> install github<span class="token punctuation">.</span>com<span class="token operator">/</span>grpc<span class="token operator">-</span>ecosystem<span class="token operator">/</span>grpc<span class="token operator">-</span>gateway<span class="token operator">/</span>v2<span class="token operator">/</span>protoc<span class="token operator">-</span>gen<span class="token operator">-</span>grpc<span class="token operator">-</span>gateway  github<span class="token punctuation">.</span>com<span class="token operator">/</span>grpc<span class="token operator">-</span>ecosystem<span class="token operator">/</span>grpc<span class="token operator">-</span>gateway<span class="token operator">/</span>v2<span class="token operator">/</span>protoc<span class="token operator">-</span>gen<span class="token operator">-</span>openapiv2 google<span class="token punctuation">.</span>golang<span class="token punctuation">.</span>org<span class="token operator">/</span>protobuf<span class="token operator">/</span>cmd<span class="token operator">/</span>protoc<span class="token operator">-</span>gen<span class="token operator">-</span><span class="token keyword">go</span> google<span class="token punctuation">.</span>golang<span class="token punctuation">.</span>org<span class="token operator">/</span>grpc<span class="token operator">/</span>cmd<span class="token operator">/</span>protoc<span class="token operator">-</span>gen<span class="token operator">-</span><span class="token keyword">go</span><span class="token operator">-</span>grpc加入Endpoint<span class="token keyword">import</span> <span class="token string">"google/api/annotations.proto"</span><span class="token punctuation">;</span> rpc <span class="token function">GetStock</span><span class="token punctuation">(</span>ProdRequest<span class="token punctuation">)</span> <span class="token function">returns</span> <span class="token punctuation">(</span>ProdStockResponse<span class="token punctuation">)</span><span class="token punctuation">{</span>      <span class="token function">option</span> <span class="token punctuation">(</span>google<span class="token punctuation">.</span>api<span class="token punctuation">.</span>http<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{</span>       get<span class="token punctuation">:</span> <span class="token string">"/v1/prod/stock"</span>     <span class="token punctuation">}</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span>加入生成配置protoc <span class="token operator">--</span>proto_path<span class="token operator">=</span>protos <span class="token operator">--</span>grpc<span class="token operator">-</span>gateway_out<span class="token operator">=</span>logtostderr<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">:</span>pbfiles prod_service<span class="token punctuation">.</span>proto生成</code></pre><p>http代码</p><pre class=" language-go"><code class="language-go">gwmux<span class="token operator">:=</span>runtime<span class="token punctuation">.</span><span class="token function">NewServeMux</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    opt<span class="token operator">:=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>grpc<span class="token punctuation">.</span>DialOption<span class="token punctuation">{</span>grpc<span class="token punctuation">.</span><span class="token function">WithInsecure</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>    err<span class="token operator">:=</span>pbfiles<span class="token punctuation">.</span><span class="token function">RegisterProdServiceHandlerFromEndpoint</span><span class="token punctuation">(</span>context<span class="token punctuation">.</span><span class="token function">Background</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>gwmux<span class="token punctuation">,</span><span class="token string">":8080"</span><span class="token punctuation">,</span>opt<span class="token punctuation">)</span>    <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        log<span class="token punctuation">.</span><span class="token function">Fatal</span><span class="token punctuation">(</span>err<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    httpServer<span class="token operator">:=</span><span class="token operator">&amp;</span>http<span class="token punctuation">.</span>Server<span class="token punctuation">{</span>        Addr<span class="token punctuation">:</span><span class="token string">":8081"</span><span class="token punctuation">,</span>        Handler<span class="token punctuation">:</span>gwmux<span class="token punctuation">,</span>    <span class="token punctuation">}</span>    err<span class="token operator">=</span>httpServer<span class="token punctuation">.</span><span class="token function">ListenAndServe</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> err<span class="token operator">!=</span><span class="token boolean">nil</span><span class="token punctuation">{</span>        log<span class="token punctuation">.</span><span class="token function">Fatal</span><span class="token punctuation">(</span>err<span class="token punctuation">)</span>    <span class="token punctuation">}</span></code></pre><h6 id="编译-grpc服务"><a href="#编译-grpc服务" class="headerlink" title="编译(grpc服务)"></a>编译(grpc服务)</h6><pre class=" language-shell"><code class="language-shell">docker run --rm -it  \-v /data/tkgrpc:/app \-w /app \-v /data/gopath:/go \-e CGO_ENABLED=0  \-e GOPROXY=https://goproxy.cn \golang:1.14.4-alpine3.12 \go build -o server  server.go</code></pre><h6 id="编译-grpc-gateway"><a href="#编译-grpc-gateway" class="headerlink" title="编译(grpc-gateway)"></a>编译(grpc-gateway)</h6><pre class=" language-shell"><code class="language-shell">docker run --rm -it  \-v /data/tkgrpc:/app \-w /app \-v /data/gopath:/go \-e CGO_ENABLED=0  \-e GO111MODULE=on \-e GOPROXY=https://goproxy.io \golang:1.14.4-alpine3.12 \go build -o serverhttp  serverhttp.go </code></pre><p>加入第二个容器</p><pre class=" language-yaml"><code class="language-yaml"> <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> mygrpc<span class="token punctuation">-</span>gateway   <span class="token key atrule">image</span><span class="token punctuation">:</span> alpine<span class="token punctuation">:</span><span class="token number">3.12</span>   <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> IfNotPresent  <span class="token key atrule">command</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"/app/serverhttp"</span><span class="token punctuation">]</span>  <span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>     <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> app       <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /app   <span class="token key atrule">ports</span><span class="token punctuation">:</span>     <span class="token punctuation">-</span> <span class="token key atrule">containerPort</span><span class="token punctuation">:</span> <span class="token number">8081</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
            <tag> traefik </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kubernetes notes</title>
      <link href="2021/03/27/notes/kubeadm-bi-ji/"/>
      <url>2021/03/27/notes/kubeadm-bi-ji/</url>
      
        <content type="html"><![CDATA[<h4 id="安装Helm、nginx-ingress"><a href="#安装Helm、nginx-ingress" class="headerlink" title="安装Helm、nginx-ingress"></a>安装Helm、nginx-ingress</h4><h5 id="Helm"><a href="#Helm" class="headerlink" title="Helm"></a>Helm</h5><blockquote><p>地址：<a href="https://github.com/helm/helm/releases/tag/v3.4.0" target="_blank" rel="noopener">https://github.com/helm/helm/releases/tag/v3.4.0</a></p></blockquote><h5 id="nginx-ingress"><a href="#nginx-ingress" class="headerlink" title="nginx-ingress"></a>nginx-ingress</h5><h6 id="一-、安装报错"><a href="#一-、安装报错" class="headerlink" title="一 、安装报错"></a>一 、安装报错</h6><pre class=" language-shell"><code class="language-shell">1、helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx2、一定要先随便装下     helm install my-nginx ingress-nginx/ingress-nginx    然后肯定会报错，然后 两条命令  1、kubectl logs  pod名称  2、kubectl describe pod 你的pod名称  （这里会看到具体的错误）  像我这里 就是 k8s.gcr.io/ingress-nginx/controller:v0.41.2  这个镜像无法下载Events:  Type     Reason     Age                    From               Message  ----     ------     ----                   ----               -------  Normal   Scheduled  <unknown>              default-scheduler  Successfully assigned default/my-nginx-ingress-nginx-controller-6f59b94645-28qn4 to node2  Normal   Pulling    2m39s (x4 over 4m50s)  kubelet, node2     Pulling image "k8s.gcr.io/ingress-nginx/controller:v0.41.2@sha256:1f4f402b9c14f3ae92b11ada1dfe9893a88f0faeb0b2f4b903e2c67a0c3bf0de"  Warning  Failed     2m24s (x4 over 4m35s)  kubelet, node2     Failed to pull image "k8s.gcr.io/ingress-nginx/controller:v0.41.2@sha256:1f4f402b9c14f3ae92b11ada1dfe9893a88f0faeb0b2f4b903e2c67a0c3bf0de": rpc error: code = Unknown desc = Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)  Warning  Failed     2m24s (x4 over 4m35s)  kubelet, node2     Error: ErrImagePull  Normal   BackOff    118s (x6 over 4m34s)   kubelet, node2     Back-off pulling image "k8s.gcr.io/ingress-nginx/controller:v0.41.2@sha256:1f4f402b9c14f3ae92b11ada1dfe9893a88f0faeb0b2f4b903e2c67a0c3bf0de"  Warning  Failed     103s (x7 over 4m34s)   kubelet, node2     Error: ImagePullBackOff[cyylog@master src]$  helm delete my-nginx </code></pre><h6 id="二-、-解决方法"><a href="#二-、-解决方法" class="headerlink" title="二 、 解决方法"></a>二 、 解决方法</h6><pre class=" language-shell"><code class="language-shell">于是执行：  docker pull giantswarm/ingress-nginx-controller:v0.41.2然后改tag docker tag giantswarm/ingress-nginx-controller:v0.41.2   k8s.gcr.io/ingress-nginx/controller:v0.41.2删之前的tag   docker rmi giantswarm/ingress-nginx-controller:v0.41.2注意：各个节点都要执行然后删掉刚才的安装  helm delete my-nginx ，然后再继续其他内容Digest: sha256:8aa4fda472ec83ae59fe0ce9720684d769ed277ff9bdcbb0169178dc9d1f8e85Status: Downloaded newer image for giantswarm/ingress-nginx-controller:v0.41.2docker.io/giantswarm/ingress-nginx-controller:v0.41.2[cyylog@master src]$ </code></pre><h6 id="三-、再次安装"><a href="#三-、再次安装" class="headerlink" title="三 、再次安装"></a>三 、再次安装</h6><pre class=" language-shell"><code class="language-shell">清除污点，允许 master 调度kubectl taint nodes --all node-role.kubernetes.io/master- 下载chart到本地helm fetch ingress-nginx/ingress-nginx修改部分内容后再次安装helm install my-nginx ingress-nginx    -n my-nginx-ingress更新用的是如下命令（下面用到）helm upgrade my-nginx ingress-nginx    -n my-nginx-ingress</code></pre><p>PS: 修改配置<code>values.yaml</code></p><pre class=" language-shell"><code class="language-shell">$ diff 111111.yaml values.yaml8c8<     digest: sha256:1f4f402b9c14f3ae92b11ada1dfe9893a88f0faeb0b2f4b903e2c67a0c3bf0de--->    # digest: sha256:1f4f402b9c14f3ae92b11ada1dfe9893a88f0faeb0b2f4b903e2c67a0c3bf0de47c47<   hostNetwork: false--->   hostNetwork: true53c53<     enabled: false--->     enabled: true133c133<   kind: Deployment--->   kind: DaemonSet379c379<     type: LoadBalancer--->     type: NodePort388,389c388,389<       http: ""<       https: ""--->       http: "32080">       https: "32443"449c449<     enabled: true--->     enabled: false</code></pre><h4 id="授权和认证机制"><a href="#授权和认证机制" class="headerlink" title="授权和认证机制"></a>授权和认证机制</h4><blockquote><p>认证会的几个要素<br>1、用户/账号。<br>2、登录时认证账号  cyylog<br>3、查看账号权限<br>     这就涉及到角色、权限、用户和角色绑定— RBAC<br>4、根据权限决定是否可以访问</p></blockquote><h5 id="K8S里两种账户类型"><a href="#K8S里两种账户类型" class="headerlink" title="K8S里两种账户类型"></a>K8S里两种账户类型</h5><blockquote><p>UserCount —– 用户账号</p><p>   也就是集群外部访问时使用的用户。最常见的就是kubectl命令就是作为kubernetes-admin用户来执行，k8s本身不记录这些账号.</p><p>   认证的方式:<br>     今天我们先学习默认认证方式：客户端证书   </p></blockquote><h6 id="创建客户端证书"><a href="#创建客户端证书" class="headerlink" title="创建客户端证书"></a>创建客户端证书</h6><pre class=" language-shell"><code class="language-shell">首先假设你装好了openssl (没装执行 sudo yum install openssl  openssl-devel)   1、创建一个文件夹叫做 ua/cyylog   2、cd 到 ua/cyylog 目录下   3、执行  1)openssl genrsa -out client.key 2048    (这一步是生成客户端私钥)  2)openssl req -new -key client.key -out client.csr -subj "/CN=cyylog"  (根据私钥生成csr， /CN指定了用户名cyylog)  3、sudo openssl x509 -req -in client.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out client.crt -days 365(根据k8s的CA证书生成我们用户的客户端证书)</code></pre><h4 id="安装Helm、nginx-ingress-1"><a href="#安装Helm、nginx-ingress-1" class="headerlink" title="安装Helm、nginx-ingress"></a>安装Helm、nginx-ingress</h4><h5 id="Helm-1"><a href="#Helm-1" class="headerlink" title="Helm"></a>Helm</h5><blockquote><p>地址：<a href="https://github.com/helm/helm/releases/tag/v3.4.0" target="_blank" rel="noopener">https://github.com/helm/helm/releases/tag/v3.4.0</a></p></blockquote><h5 id="nginx-ingress-1"><a href="#nginx-ingress-1" class="headerlink" title="nginx-ingress"></a>nginx-ingress</h5><h6 id="一-、安装报错-1"><a href="#一-、安装报错-1" class="headerlink" title="一 、安装报错"></a>一 、安装报错</h6><pre class=" language-shell"><code class="language-shell">1、helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx2、一定要先随便装下     helm install my-nginx ingress-nginx/ingress-nginx    然后肯定会报错，然后 两条命令  1、kubectl logs  pod名称  2、kubectl describe pod 你的pod名称  （这里会看到具体的错误）  像我这里 就是 k8s.gcr.io/ingress-nginx/controller:v0.41.2  这个镜像无法下载Events:  Type     Reason     Age                    From               Message  ----     ------     ----                   ----               -------  Normal   Scheduled  <unknown>              default-scheduler  Successfully assigned default/my-nginx-ingress-nginx-controller-6f59b94645-28qn4 to node2  Normal   Pulling    2m39s (x4 over 4m50s)  kubelet, node2     Pulling image "k8s.gcr.io/ingress-nginx/controller:v0.41.2@sha256:1f4f402b9c14f3ae92b11ada1dfe9893a88f0faeb0b2f4b903e2c67a0c3bf0de"  Warning  Failed     2m24s (x4 over 4m35s)  kubelet, node2     Failed to pull image "k8s.gcr.io/ingress-nginx/controller:v0.41.2@sha256:1f4f402b9c14f3ae92b11ada1dfe9893a88f0faeb0b2f4b903e2c67a0c3bf0de": rpc error: code = Unknown desc = Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)  Warning  Failed     2m24s (x4 over 4m35s)  kubelet, node2     Error: ErrImagePull  Normal   BackOff    118s (x6 over 4m34s)   kubelet, node2     Back-off pulling image "k8s.gcr.io/ingress-nginx/controller:v0.41.2@sha256:1f4f402b9c14f3ae92b11ada1dfe9893a88f0faeb0b2f4b903e2c67a0c3bf0de"  Warning  Failed     103s (x7 over 4m34s)   kubelet, node2     Error: ImagePullBackOff[cyylog@master src]$  helm delete my-nginx </code></pre><h6 id="二-、-解决方法-1"><a href="#二-、-解决方法-1" class="headerlink" title="二 、 解决方法"></a>二 、 解决方法</h6><pre class=" language-shell"><code class="language-shell">于是执行：  docker pull giantswarm/ingress-nginx-controller:v0.41.2然后改tag docker tag giantswarm/ingress-nginx-controller:v0.41.2   k8s.gcr.io/ingress-nginx/controller:v0.41.2删之前的tag   docker rmi giantswarm/ingress-nginx-controller:v0.41.2注意：各个节点都要执行然后删掉刚才的安装  helm delete my-nginx ，然后再继续其他内容Digest: sha256:8aa4fda472ec83ae59fe0ce9720684d769ed277ff9bdcbb0169178dc9d1f8e85Status: Downloaded newer image for giantswarm/ingress-nginx-controller:v0.41.2docker.io/giantswarm/ingress-nginx-controller:v0.41.2[cyylog@master src]$ </code></pre><h6 id="三-、再次安装-1"><a href="#三-、再次安装-1" class="headerlink" title="三 、再次安装"></a>三 、再次安装</h6><pre class=" language-shell"><code class="language-shell">下载chart到本地helm fetch ingress-nginx/ingress-nginx修改部分内容后再次安装helm install my-nginx ingress-nginx    -n my-nginx-ingress更新用的是如下命令（下面用到）helm upgrade my-nginx ingress-nginx    -n my-nginx-ingress</code></pre><p>PS: 修改配置<code>values.yaml</code></p><pre class=" language-shell"><code class="language-shell">$ diff 111111.yaml values.yaml8c8<     digest: sha256:1f4f402b9c14f3ae92b11ada1dfe9893a88f0faeb0b2f4b903e2c67a0c3bf0de--->    # digest: sha256:1f4f402b9c14f3ae92b11ada1dfe9893a88f0faeb0b2f4b903e2c67a0c3bf0de47c47<   hostNetwork: false--->   hostNetwork: true53c53<     enabled: false--->     enabled: true133c133<   kind: Deployment--->   kind: DaemonSet379c379<     type: LoadBalancer--->     type: NodePort388,389c388,389<       http: ""<       https: ""--->       http: "32080">       https: "32443"449c449<     enabled: true--->     enabled: false</code></pre><h4 id="授权和认证机制-1"><a href="#授权和认证机制-1" class="headerlink" title="授权和认证机制"></a>授权和认证机制</h4><blockquote><p>认证会的几个要素<br>1、用户/账号。<br>2、登录时认证账号  cyylog<br>3、查看账号权限<br>     这就涉及到角色、权限、用户和角色绑定— RBAC<br>4、根据权限决定是否可以访问</p></blockquote><h5 id="K8S里两种账户类型-1"><a href="#K8S里两种账户类型-1" class="headerlink" title="K8S里两种账户类型"></a>K8S里两种账户类型</h5><blockquote><p>UserCount —– 用户账号</p><p>   也就是集群外部访问时使用的用户。最常见的就是kubectl命令就是作为kubernetes-admin用户来执行，k8s本身不记录这些账号.</p><p>   认证的方式:<br>     今天我们先学习默认认证方式：客户端证书   </p></blockquote><h6 id="创建客户端证书-1"><a href="#创建客户端证书-1" class="headerlink" title="创建客户端证书"></a>创建客户端证书</h6><pre class=" language-shell"><code class="language-shell">首先假设你装好了openssl (没装执行 sudo yum install openssl  openssl-devel)   1、创建一个文件夹叫做 ua/cyylog   2、cd 到 ua/cyylog 目录下   3、执行  1)openssl genrsa -out client.key 2048    (这一步是生成客户端私钥)  2)openssl req -new -key client.key -out client.csr -subj "/CN=cyylog"  (根据私钥生成csr， /CN指定了用户名cyylog)  3、sudo openssl x509 -req -in client.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out client.crt -days 365(根据k8s的CA证书生成我们用户的客户端证书)</code></pre><h6 id="用户账号"><a href="#用户账号" class="headerlink" title="用户账号"></a>用户账号</h6><blockquote><p>授权和认证机制</p><p> 用户账号 : 使用证书初步请求API、设置上下文</p></blockquote><pre class=" language-shell"><code class="language-shell">     上一步 我们生成一个客户端证书   ：用户名是 cyylog 。    最简单的请求 方式还是：1、kubectl get endpoints  查看下endpoint2、curl --cert ./client.crt --key ./client.key --cacert /etc/kubernetes/pki/ca.crt -s https://192.168.42.140:6443/api 其中 可以用 --insecure 代替 --cacert /etc/kubernetes/pki/ca.crt 从而忽略服务端证书验证证书反解如果你忘了证书设置的CN(Common name)是啥 可以用下面的命令搞定openssl x509 -noout -subject -in client.crt</code></pre><p>接下来我们要干的事</p><pre class=" language-shell"><code class="language-shell"> 把：    client.crt加入到~/.kube/config，执行kubectl命令时切换成我们的用户(虽然现在其实没啥权限)   kubectl config --kubeconfig=/home/cyylog/.kube/config set-credentials cyylog  --client-certificate=/home/cyylog/ua/cyylog/client.crt --client-key=/home/cyylog/ua/cyylog/client.key   这一步把用户设置进去了//创建一个context(上下文)kubectl config --kubeconfig=/home/cyylog/.kube/config set-context user_context --cluster=kubernetes  --user=cyylog指定当前上下文是： kubectl config --kubeconfig=/home/cyylog/.kube/config use-context user_context</code></pre><h5 id="入门Role和RoleBinding"><a href="#入门Role和RoleBinding" class="headerlink" title="入门Role和RoleBinding"></a>入门Role和RoleBinding</h5><blockquote><p>授权和认证机制:  入门Role和RoleBinding、创建一个角色</p><p>Role (角色)<br>    它可以包含一堆权限。用于授予对单个命名空间的资源访问</p><p>RoleBinding<br>   顾名思义，将用户和角色进行绑定</p><p>kubectl get role –all-namespaces</p></blockquote><pre class=" language-shell"><code class="language-shell">上一段：我们把 cyylog 这个用户(usercount)加入到 kubectl config中并且用了 kubectl config  use-context user_context来切换上下文。切回管理员可以这么干： kubectl config  use-context kubernetes-admin@kubernetes</code></pre><p>Next</p><pre class=" language-shell"><code class="language-shell">我们希望让 cyylog 这个用户能查看pod 我们创建一个文件叫做：mypod_role.yamlkind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata:  namespace: default  name: mypodrules:- apiGroups: ["*"]  resources: ["pods"]  verbs: ["get", "watch", "list"]</code></pre><h6 id="关于apiversion"><a href="#关于apiversion" class="headerlink" title="关于apiversion"></a>关于apiversion</h6><blockquote><p>文档地址：（不要网上搜到啥就贴啥）<br><a href="https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#role-v1-rbac-authorization-k8s-io" target="_blank" rel="noopener">https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#role-v1-rbac-authorization-k8s-io</a></p></blockquote><h6 id="关于资源"><a href="#关于资源" class="headerlink" title="关于资源"></a>关于资源</h6><pre class=" language-shell"><code class="language-shell">可以用 这个命令查看：    kubectl api-resources -o wide 譬如role有 对应的操作如下create  delete  deletecollection   get     list        patch        update   watch创建     删除       批量删除          获取  列表    合并变更    更新     监听</code></pre><p>接下来执行</p><pre class=" language-shell"><code class="language-shell">执行下面的内容，则完成角色的创建kubectl apply -f mypod_role.yamlkubectl get role -n default ----查看下kubectl delete role mypod   (不加-n  默认就是default)</code></pre><h6 id="RoleBinding"><a href="#RoleBinding" class="headerlink" title="RoleBinding"></a>RoleBinding</h6><blockquote><p>用户和角色进行绑定</p><p>kubectl get role</p></blockquote><p><strong>第一种方式： 命令行</strong> </p><pre class=" language-shell"><code class="language-shell">   kubectl create rolebinding mypodbinding  -n default  --role mypod --user cyylog 接下来可以 切换1、我们的普通用户是  kubectl config use-context user_context2、管理员是: kubectl config use-context  kubernetes-admin@kubernetes</code></pre><p>第二种方式：</p><pre class=" language-shell"><code class="language-shell">创建一个文件 譬如叫做mypod_rolebinding.yamlapiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata:  creationTimestamp: null  name: mypodrolebindingroleRef:  apiGroup: rbac.authorization.k8s.io  kind: Role  name: mypodsubjects:- apiGroup: rbac.authorization.k8s.io  kind: User  name: cyylog</code></pre><h6 id="CluterRole"><a href="#CluterRole" class="headerlink" title="CluterRole"></a>CluterRole</h6><blockquote><p>ClusterRole和ClusterRoleBinding</p><p>​     可以管理集群中多个 namespace,就需要使用到clusterrole<br>​     绑定既可以使用RoleBinding，也可以使用ClusterRoleBinding  ( 两者效果不同)</p></blockquote><p><strong>之前创建<code>Role</code>的文件</strong></p><pre class=" language-shell"><code class="language-shell">kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata:  namespace: default  name: mypodrules:- apiGroups: ["*"]  resources: ["pods"]  verbs: ["get", "watch", "list"]改一下kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata:  name: mypod-clusterrules:- apiGroups: ["*"]  resources: ["pods"]  verbs: ["get", "watch", "list"]</code></pre><p>然后绑定：</p><pre class=" language-shell"><code class="language-shell">apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata:  name: mypodrolebindingroleRef:  apiGroup: rbac.authorization.k8s.io  kind: Role  name: mypodsubjects:- apiGroup: rbac.authorization.k8s.io  kind: User  name: cyylog改一下：apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata:  name: mypodrolebinding-cluster  namespace: kube-systemroleRef:  apiGroup: rbac.authorization.k8s.io  kind: ClusterRole  name: mypod-clustersubjects:- apiGroup: rbac.authorization.k8s.io  kind: User  name: cyylog</code></pre><h6 id="clusterrole-clusterrolebinding"><a href="#clusterrole-clusterrolebinding" class="headerlink" title="clusterrole+clusterrolebinding"></a>clusterrole+clusterrolebinding</h6><blockquote><p>可以管理集群中多个 namespace,就需要使用到clusterrole<br>     绑定既可以使用RoleBinding，也可以使用ClusterRoleBinding  ( 两者效果不同)</p><p> 1、 上上一段：role+rolebinding<br> 2、 上一段课我们:clusterrole+rolebinding<br> 3、 这节我们学习clusterrole+clusterrolebinding</p><p>首先我们把上一段课的role、rolebinding都删掉</p></blockquote><p><strong>删除命令</strong></p><pre class=" language-shell"><code class="language-shell"> 1、 kubectl delete rolebinding mypodrolebinding-cluster -n kube-system 2、 kubectl delete rolebinding mypodrolebinding 3、 kubectl delete role mypod只保留一个 clusterrole --------mypod-cluster</code></pre><p>改一下文件</p><pre class=" language-shell"><code class="language-shell">apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata:  name: mypod-clusterrolebindingroleRef:  apiGroup: rbac.authorization.k8s.io  kind: ClusterRole  name: mypod-clustersubjects: - apiGroup: rbac.authorization.k8s.io   kind: User   name: cyylog</code></pre><h5 id="UserAccount"><a href="#UserAccount" class="headerlink" title="UserAccount"></a>UserAccount</h5><blockquote><p>使用token的方式请求API</p></blockquote><pre class=" language-shell"><code class="language-shell">1、前面我们学习到了创建UserAccount 。并使用证书的方式请求2、role+rolebinding3、clusterrole+clusterrolebinding那么其实 假设我们要请求API， 还可以使用token的方式</code></pre><h6 id="首先先试一下"><a href="#首先先试一下" class="headerlink" title="首先先试一下"></a><strong>首先先试一下</strong></h6><pre class=" language-shell"><code class="language-shell"> curl https://192.168.42.140:6443   这是不可以访问的接下来我们设置一个 token (现在是我们上面的普通用户cyylog)1、用这个命令生成token    head -c 16 /dev/urandom | od -An -t x | tr -d ' '         (' '之间有个空格)    kubectl config set-credentials cyylog --token=5bd8fce499b79b23bfdef72afb8d7bda</code></pre><h6 id="找个获取pod的API试一试"><a href="#找个获取pod的API试一试" class="headerlink" title="找个获取pod的API试一试"></a><strong>找个获取pod的API试一试</strong></h6><blockquote><p><a href="https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#role-v1-rbac-authorization-k8s-io" target="_blank" rel="noopener">https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#role-v1-rbac-authorization-k8s-io</a></p><p>还是看这个文档</p><p><code>curl -H &quot;Authorization: Bearer 5bd8fce499b79b23bfdef72afb8d7bda&quot; https://192.168.42.140:6443/api/v1/namespaces/default/pods --insecure</code></p><p>对比一下 (默认情况下还是没用的）</p><p><code>curl --cert ./client.crt --key ./client.key --cacert /etc/kubernetes/pki/ca.crt -s https://192.168.42.140:6443/api/v1/namespaces/default/pods</code></p></blockquote><h6 id="修改api-server的启动参数"><a href="#修改api-server的启动参数" class="headerlink" title="修改api-server的启动参数"></a>修改api-server的启动参数</h6><pre class=" language-shell"><code class="language-shell">首先创建 sudo vi /etc/kubernetes/pki/token_auth 塞入如下内容5bd8fce499b79b23bfdef72afb8d7bda,cyylog,1001然后是修改api-server启动参数sudo vi /etc/kubernetes/manifests/kube-apiserver.yaml加入  --token-auth-file=/etc/kubernetes/pki/token_auth</code></pre><h5 id="ServiceAccount"><a href="#ServiceAccount" class="headerlink" title="ServiceAccount"></a>ServiceAccount</h5><h6 id="SA入门-1-创建账号"><a href="#SA入门-1-创建账号" class="headerlink" title="SA入门(1):创建账号"></a>SA入门(1):创建账号</h6><blockquote><p>前面</p><p>1、我们学习到了创建UserAccount 。并使用证书、token的方式请求<br>2、role+rolebinding<br>3、clusterrole+clusterrolebinding</p></blockquote><p><strong>创建一个ServiceAccount</strong></p><pre class=" language-shell"><code class="language-shell">查看 是这样的：   kubectl get sa -n xxxx  (不写-n 就是默认default)用命令创建一个  kubectl  create  serviceaccount   mysa     每个namespace都会有一个默认的 default账号，且sa局限在自己所属的namespace中。而UserAccount是可以跨ns的其他步骤 kubectl describe sa mysa 你还会发现k8s会在secrets 里面保存一个token通过kubectl describe secret mysa-token-sk67q （改成你自己的）</code></pre><p><strong>第二种方式:</strong></p><pre class=" language-shell"><code class="language-shell">kubectl  create  serviceaccount  mysa  -o  yaml  --dry-run=client进阶一下，可以这样kubectl  create  serviceaccount  mysa  -o  yaml  --dry-run=client > mysa.yaml</code></pre><h6 id="SA入门-2-赋予权限"><a href="#SA入门-2-赋予权限" class="headerlink" title="SA入门(2):赋予权限"></a>SA入门(2):赋予权限</h6><blockquote><p>前面：</p><p>我们创建了一个sa账号，叫做mysa。现在尝试用sa账号访问 api</p><p>装个工具叫做jq<br>   是一个轻量级的json处理命令。可以对json数据进行分片、过滤、映射和转换 jq . 对json数据进行格式化输出</p><pre class=" language-shell"><code class="language-shell">sudo yum install jq -y</code></pre></blockquote><p><strong>绑定角色</strong></p><blockquote><p>在此之前，我们创建一个 clusterrole叫做 mypod-cluster</p><p>此权限 可以查看 pods列表</p><pre class=" language-shell"><code class="language-shell">kubectl create clusterrolebinding mysa-crb --clusterrole=mypod-cluster --serviceaccount=default:mysa</code></pre></blockquote><p><strong>分解命令</strong></p><pre class=" language-shell"><code class="language-shell">分解命令1、kubectl get sa  mysa2、 kubectl get sa  mysa -o json3、kubectl get sa  mysa -o json | jq  '.secrets[0].name'4、kubectl get sa  mysa -o json | jq -Mr '.secrets[0].name'假设得到的值是 mysa-token-x6ct65、kubectl get secret  mysa-token-x6ct66、kubectl get secret  mysa-token-x6ct6 -o json | jq -Mr '.data.token'7、 kubectl get secret  mysa-token-x6ct6 -o json | jq -Mr '.data.token' | base64 -d</code></pre><p><strong>连起来</strong></p><pre class=" language-shell"><code class="language-shell">kubectl get secret  $(kubectl get sa  mysa -o json | jq -Mr '.secrets[0].name') -o json | jq -Mr '.data.token' | base64 -d设置成一个变量mysatoken=$(kubectl get secret  $(kubectl get sa  mysa -o json | jq -Mr '.secrets[0].name') -o json | jq -Mr '.data.token' | base64 -d)请求:curl -H "Authorization: Bearer $mysatoken" --insecure  https://192.168.42.140:6443/api/v1/namespaces/default/pods </code></pre><h6 id="SA入门-3-访问方式一"><a href="#SA入门-3-访问方式一" class="headerlink" title="SA入门(3):访问方式一"></a>SA入门(3):访问方式一</h6><blockquote><p>在POD里访问k8s API(token的方式)</p></blockquote><p><strong>为了简单</strong></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Deployment<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> myngx<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">selector</span><span class="token punctuation">:</span>    <span class="token key atrule">matchLabels</span><span class="token punctuation">:</span>      <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx  <span class="token key atrule">replicas</span><span class="token punctuation">:</span> <span class="token number">1</span>  <span class="token key atrule">template</span><span class="token punctuation">:</span>    <span class="token key atrule">metadata</span><span class="token punctuation">:</span>      <span class="token key atrule">labels</span><span class="token punctuation">:</span>        <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx    <span class="token key atrule">spec</span><span class="token punctuation">:</span>      <span class="token key atrule">containers</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> nginxtest          <span class="token key atrule">image</span><span class="token punctuation">:</span> nginx<span class="token punctuation">:</span>1.18<span class="token punctuation">-</span>alpine          <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> IfNotPresent          <span class="token key atrule">ports</span><span class="token punctuation">:</span>            <span class="token punctuation">-</span> <span class="token key atrule">containerPort</span><span class="token punctuation">:</span> <span class="token number">80</span></code></pre><p><strong>接下来执行</strong></p><pre class=" language-shell"><code class="language-shell">kubectl get pod 可以看到pod列表 ，然后我们 进入 该容器kubectl exec -it  myngx-58bddf9b8d-qmdq7 -- sh</code></pre><p><strong>记录几个知识点</strong></p><pre class=" language-shell"><code class="language-shell">echo $KUBERNETES_SERVICE_HOST   echo $KUBERNETES_PORT_443_TCP_PORT于是   echo $KUBERNETES_SERVICE_HOST:$KUBERNETES_PORT_443_TCP_PORT保存到环境变量中： 1、TOKEN=`cat /var/run/secrets/kubernetes.io/serviceaccount/token`2、APISERVER="https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_PORT_443_TCP_PORT"</code></pre><p><strong>请求试一试</strong></p><pre class=" language-shell"><code class="language-shell"> curl --header "Authorization: Bearer $TOKEN" --insecure -s $APISERVER/api我们可以看到 上面是可以的，但下面不可以，因为default账号没有列出pods的权限curl --header "Authorization: Bearer $TOKEN" --insecure -s $APISERVER/api/v1/namespaces/default/pods </code></pre><p><strong>修改我们<code>deployment</code></strong></p><pre class=" language-yaml"><code class="language-yaml"> <span class="token key atrule">spec</span><span class="token punctuation">:</span>      <span class="token key atrule">serviceAccountName</span><span class="token punctuation">:</span> mysa      <span class="token key atrule">containers</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> nginxtest          <span class="token key atrule">image</span><span class="token punctuation">:</span> nginx<span class="token punctuation">:</span>1.18<span class="token punctuation">-</span>alpine          <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> IfNotPresent          <span class="token key atrule">ports</span><span class="token punctuation">:</span></code></pre><h6 id="SA入门-3-访问方式二"><a href="#SA入门-3-访问方式二" class="headerlink" title="SA入门(3):访问方式二"></a>SA入门(3):访问方式二</h6><blockquote><p>在POD里访问k8s API(token+证书的方式)</p></blockquote><p><strong>更常用的方式是直接用证书</strong></p><pre class=" language-shell"><code class="language-shell">证书的位置在:/var/run/secrets/kubernetes.io/serviceaccount/ca.crt上面讲的token的位置在cat /var/run/secrets/kubernetes.io/serviceaccount/token前面curl --header "Authorization: Bearer $TOKEN"  -s $APISERVER/api/v1/namespaces/default/pods 现在curl --header "Authorization: Bearer $TOKEN" --cacert  /var/run/secrets/kubernetes.io/serviceaccount/ca.crt   $APISERVER/api/v1/namespaces/default/pods </code></pre><h4 id="Pod-和-Deployment"><a href="#Pod-和-Deployment" class="headerlink" title="Pod 和 Deployment"></a>Pod 和 Deployment</h4><blockquote><p>本章节：Pod入门、看文档的方式、创建Pod</p><p>文档地址：<a href="https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#pod-v1-core" target="_blank" rel="noopener">https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#pod-v1-core</a></p></blockquote><h5 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h5><blockquote><p>最小调度单位（pod）好处：<br>1、 方便部署、扩展和收缩、方便调度等，反正各种方便</p><p>2、Pod中的容器共享数据和网络空间，统一的资源管理与分配（想想第二章我们讲的ServiceCount）</p></blockquote><blockquote><p>pause容器作用</p><p>1、扮演Pid=1的，回收僵尸进程</p><p>2、基于Linux的namespace的共享</p></blockquote><p><a href="https://imgchr.com/i/rPuUIA" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/09/rPuUIA.png" alt="rPuUIA.png"></a></p><h6 id="Pod基本操作"><a href="#Pod基本操作" class="headerlink" title="Pod基本操作"></a>Pod基本操作</h6><blockquote><p>Pod基本操作、创建一个多容器的Pod(上)</p></blockquote><p><strong>创建第一个Pod</strong></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Pod<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> myngx<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">containers</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> ngx    <span class="token key atrule">image</span><span class="token punctuation">:</span> <span class="token string">"nginx:1.18-alpine"</span></code></pre><p><strong>顺手学习几个命令</strong></p><pre class=" language-shell"><code class="language-shell">kubectl describe pod xxxx  查看pod详细kubectl logs   xxx 查看日志kubectl exec -it xxx  -- sh  //进入pod</code></pre><p><strong>多容器</strong></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Pod<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> myngx<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">containers</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> ngx    <span class="token key atrule">image</span><span class="token punctuation">:</span> <span class="token string">"nginx:1.18-alpine"</span>  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> alpine    <span class="token key atrule">image</span><span class="token punctuation">:</span> <span class="token string">"alpine:3.12"</span></code></pre><p>发现，<code>alpine</code> 容器没有启动，未启动<code>command</code> </p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Pod<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> myngx<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">containers</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> ngx    <span class="token key atrule">image</span><span class="token punctuation">:</span> <span class="token string">"nginx:1.18-alpine"</span>  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> alpine    <span class="token key atrule">command</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"sh"</span><span class="token punctuation">,</span><span class="token string">"-c"</span><span class="token punctuation">,</span><span class="token string">"echo this is second &amp;&amp; sleep 3600"</span><span class="token punctuation">]</span>    <span class="token key atrule">image</span><span class="token punctuation">:</span> <span class="token string">"alpine:3.12"</span></code></pre><h5 id="Volumes-配置数据卷"><a href="#Volumes-配置数据卷" class="headerlink" title="Volumes 配置数据卷"></a>Volumes 配置数据卷</h5><blockquote><p>配置数据卷:挂载主机目录、排坑方式</p><p>文档<br><a href="https://kubernetes.io/zh/docs/concepts/storage/volumes/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/concepts/storage/volumes/</a></p></blockquote><h6 id="基本格式"><a href="#基本格式" class="headerlink" title="基本格式"></a><strong>基本格式</strong></h6><pre class=" language-yaml"><code class="language-yaml"><span class="token punctuation">...</span><span class="token punctuation">...</span><span class="token punctuation">...</span>. (略)<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">containers</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> ngx    <span class="token key atrule">image</span><span class="token punctuation">:</span> <span class="token string">"nginx:1.18-alpine"</span>    <span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> mydata      <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /data  <span class="token key atrule">volumes</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> mydata      <span class="token key atrule">hostPath</span><span class="token punctuation">:</span>        <span class="token key atrule">path</span><span class="token punctuation">:</span> /data        <span class="token key atrule">type</span><span class="token punctuation">:</span> Directory</code></pre><h6 id="基本写法"><a href="#基本写法" class="headerlink" title="基本写法"></a><strong>基本写法</strong></h6><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Pod<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> myngx<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">containers</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> ngx    <span class="token key atrule">image</span><span class="token punctuation">:</span> <span class="token string">"nginx:1.18-alpine"</span>    <span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> mydata      <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /data  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> alpine    <span class="token key atrule">command</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"sh"</span><span class="token punctuation">,</span><span class="token string">"-c"</span><span class="token punctuation">,</span><span class="token string">"echo this is second &amp;&amp; sleep 3600"</span><span class="token punctuation">]</span>    <span class="token key atrule">image</span><span class="token punctuation">:</span> <span class="token string">"alpine:3.12"</span>  <span class="token key atrule">volumes</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> mydata    <span class="token key atrule">hostPath</span><span class="token punctuation">:</span>      <span class="token key atrule">path</span><span class="token punctuation">:</span> /data/cyylog/data      <span class="token key atrule">type</span><span class="token punctuation">:</span> Directory</code></pre><h5 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h5><blockquote><p>本小节讲述 Pod和Deployment基本区别、创建deployment</p></blockquote><pre class=" language-shell"><code class="language-shell">Pods：  1、运行一组容器 、适合一次性开发  2、很少直接用于生产Deployment1、运行一组相同的Pod（副本水平扩展）、滚动更新2、适合生产总结为：Deployment通过副本集管理和创建POD。</code></pre><p><code>myngx.yaml</code>文件</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Deployment<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> myngx<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">selector</span><span class="token punctuation">:</span>    <span class="token key atrule">matchLabels</span><span class="token punctuation">:</span>      <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx  <span class="token key atrule">replicas</span><span class="token punctuation">:</span> <span class="token number">1</span>  <span class="token key atrule">template</span><span class="token punctuation">:</span>    <span class="token key atrule">metadata</span><span class="token punctuation">:</span>      <span class="token key atrule">labels</span><span class="token punctuation">:</span>        <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx    <span class="token key atrule">spec</span><span class="token punctuation">:</span>      <span class="token key atrule">containers</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> ngx          <span class="token key atrule">image</span><span class="token punctuation">:</span> nginx<span class="token punctuation">:</span>1.18<span class="token punctuation">-</span>alpine          <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> IfNotPresent</code></pre><h5 id="两个容器共享文件夹"><a href="#两个容器共享文件夹" class="headerlink" title="两个容器共享文件夹"></a>两个容器共享文件夹</h5><blockquote><p>文档<br><a href="https://kubernetes.io/zh/docs/concepts/storage/volumes/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/concepts/storage/volumes/</a></p></blockquote><pre class=" language-shell"><code class="language-shell">两个节点分别写入挂载点volumeMounts:    - name: sharedata      mountPath: /data</code></pre><p><strong>关键点</strong></p><pre class=" language-shell"><code class="language-shell"> volumes:  - name:  sharedata    emptyDir: {}    同一个pod内的容器都能读写EmptyDir中 文件。常用于临时空间、多容器共享，如日志或者tmp文件需要的临时目录</code></pre><p><code>myngx.yaml</code></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Deployment<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> myngx<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">selector</span><span class="token punctuation">:</span>    <span class="token key atrule">matchLabels</span><span class="token punctuation">:</span>      <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx  <span class="token key atrule">replicas</span><span class="token punctuation">:</span> <span class="token number">1</span>  <span class="token key atrule">template</span><span class="token punctuation">:</span>    <span class="token key atrule">metadata</span><span class="token punctuation">:</span>      <span class="token key atrule">labels</span><span class="token punctuation">:</span>        <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx    <span class="token key atrule">spec</span><span class="token punctuation">:</span>      <span class="token key atrule">containers</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> ngx          <span class="token key atrule">image</span><span class="token punctuation">:</span> nginx<span class="token punctuation">:</span>1.18<span class="token punctuation">-</span>alpine          <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> IfNotPresent          <span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> sharedata              <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /data        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> alpine          <span class="token key atrule">image</span><span class="token punctuation">:</span> alpine<span class="token punctuation">:</span><span class="token number">3.12</span>          <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> IfNotPresent          <span class="token key atrule">command</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"sh"</span><span class="token punctuation">,</span><span class="token string">"-c"</span><span class="token punctuation">,</span><span class="token string">"echo this is alpine &amp;&amp; sleep 36000"</span><span class="token punctuation">]</span>          <span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> sharedata              <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /data      <span class="token key atrule">volumes</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span>  sharedata          <span class="token key atrule">emptyDir</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token punctuation">}</span></code></pre><h5 id="init容器"><a href="#init容器" class="headerlink" title="init容器"></a>init容器</h5><blockquote><p>​    Init 容器是一种特殊容器，在 Pod 内的应用容器启动之前运行。Init 容器可以包括一些应用镜像中不存在的实用工具和安装脚本</p><p>  Init 容器与普通的容器非常像，除了如下两点：<br>     它们总是运行到完成。<br>    每个都必须在下一个启动之前成功完成。</p><p>​     如果 Pod 的 Init 容器失败，kubelet 会不断地重启该 Init 容器直到该容器成功为止。 然而，如果 Pod 对应的 restartPolicy 值为 “Never”，Kubernetes 不会重新启动 Pod。<br>文档地址:<br><a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/init-containers/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/concepts/workloads/pods/init-containers/</a></p></blockquote><h6 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h6><pre class=" language-shell"><code class="language-shell"> initContainers:  - name: init-mydb    image: alpine:3.12    command: ['sh', '-c', 'echo wait for db && sleep 35 && echo done']具体场景以后我们再演示:1、譬如 ping db2、譬如控制服务启动顺序</code></pre><p><code>myngx.yaml</code>案例文件</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Deployment<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> myngx<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">selector</span><span class="token punctuation">:</span>    <span class="token key atrule">matchLabels</span><span class="token punctuation">:</span>      <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx  <span class="token key atrule">replicas</span><span class="token punctuation">:</span> <span class="token number">1</span>  <span class="token key atrule">template</span><span class="token punctuation">:</span>    <span class="token key atrule">metadata</span><span class="token punctuation">:</span>      <span class="token key atrule">labels</span><span class="token punctuation">:</span>        <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx    <span class="token key atrule">spec</span><span class="token punctuation">:</span>      <span class="token key atrule">initContainers</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> init<span class="token punctuation">-</span>mydb          <span class="token key atrule">image</span><span class="token punctuation">:</span> alpine<span class="token punctuation">:</span><span class="token number">3.12</span>          <span class="token key atrule">command</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'sh'</span><span class="token punctuation">,</span> <span class="token string">'-c'</span><span class="token punctuation">,</span> <span class="token string">'echo wait for db &amp;&amp; sleep 35 &amp;&amp; echo done'</span><span class="token punctuation">]</span>      <span class="token key atrule">containers</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> ngx          <span class="token key atrule">image</span><span class="token punctuation">:</span> nginx<span class="token punctuation">:</span>1.18<span class="token punctuation">-</span>alpine          <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> IfNotPresent          <span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> sharedata              <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /data        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> alpine          <span class="token key atrule">image</span><span class="token punctuation">:</span> alpine<span class="token punctuation">:</span><span class="token number">3.12</span>          <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> IfNotPresent          <span class="token key atrule">command</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"sh"</span><span class="token punctuation">,</span><span class="token string">"-c"</span><span class="token punctuation">,</span><span class="token string">"echo this is alpine &amp;&amp; sleep 36000"</span><span class="token punctuation">]</span>          <span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> sharedata              <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /data      <span class="token key atrule">volumes</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span>  sharedata          <span class="token key atrule">emptyDir</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token punctuation">}</span></code></pre><h4 id="Deployment和ConfigMap"><a href="#Deployment和ConfigMap" class="headerlink" title="Deployment和ConfigMap"></a><code>Deployment</code>和<code>ConfigMap</code></h4><blockquote><p>本章节讲述 <code>ConfigMap</code> 基本创建、环境变量引用</p></blockquote><h5 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h5><blockquote><p>​     ConfigMap 是一种 API 对象，用来将非机密性的数据保存到健值对中。使用时可以用作环境变量、命令行参数或者存储卷中的配置文件。</p><p>​     ConfigMap 将您的环境配置信息和 容器镜像 解耦，便于应用配置的修改。当您需要储存机密信息时可以使用 Secret 对象。</p></blockquote><h6 id="使用的场景"><a href="#使用的场景" class="headerlink" title="使用的场景"></a>使用的场景</h6><pre class=" language-shell"><code class="language-shell">    1、 容器 entrypoint 的命令行参数    2、 容器的环境变量    3、 映射成文件    4、 编写代码在 Pod 中运行，使用 Kubernetes API 来读取 ConfigMap</code></pre><h6 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h6><pre class=" language-shell"><code class="language-shell">获取列表  kubectl get cm 创建一个cm apiVersion: v1kind: ConfigMapmetadata:  name: mycmdata:  # 每一个键对应一个简单的值,以字符串的形式体现  username: "cyylog"  userage: "19"也可以这样 。。。。。data:  username: "cyylog"  userage: "19“  user.info: |    name=cyylog    age=19</code></pre><p><strong>接下来</strong></p><pre class=" language-yaml"><code class="language-yaml">删掉之前的deployment (myngx)写入  （和image同级）   <span class="token key atrule">env</span><span class="token punctuation">:</span>           <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> USER_NAME             <span class="token key atrule">valueFrom</span><span class="token punctuation">:</span>                <span class="token key atrule">configMapKeyRef</span><span class="token punctuation">:</span>                  <span class="token key atrule">name</span><span class="token punctuation">:</span> mycm           <span class="token comment" spellcheck="true">#  ConfigMap的名称</span>                  <span class="token key atrule">key</span><span class="token punctuation">:</span> username <span class="token comment" spellcheck="true"># 需要取值的键</span></code></pre><p><code>mycm.yaml</code></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> ConfigMap<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> mycm<span class="token key atrule">data</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 每一个键对应一个简单的值,以字符串的形式体现</span>  <span class="token key atrule">username</span><span class="token punctuation">:</span> <span class="token string">"cyylog"</span>  <span class="token key atrule">userage</span><span class="token punctuation">:</span> <span class="token string">"19"</span>  <span class="token key atrule">user.info</span><span class="token punctuation">:</span> <span class="token punctuation">|</span><span class="token scalar string">    name=cyylog    age=19</span></code></pre><p><code>myngx.yaml</code></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Deployment<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> myngx<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">selector</span><span class="token punctuation">:</span>    <span class="token key atrule">matchLabels</span><span class="token punctuation">:</span>      <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx  <span class="token key atrule">replicas</span><span class="token punctuation">:</span> <span class="token number">1</span>  <span class="token key atrule">template</span><span class="token punctuation">:</span>    <span class="token key atrule">metadata</span><span class="token punctuation">:</span>      <span class="token key atrule">labels</span><span class="token punctuation">:</span>        <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx    <span class="token key atrule">spec</span><span class="token punctuation">:</span>      <span class="token key atrule">containers</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> ngx          <span class="token key atrule">image</span><span class="token punctuation">:</span> nginx<span class="token punctuation">:</span>1.18<span class="token punctuation">-</span>alpine          <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> IfNotPresent          <span class="token key atrule">env</span><span class="token punctuation">:</span>            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> TEST              <span class="token key atrule">value</span><span class="token punctuation">:</span> testvalue            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> USERNAME              <span class="token key atrule">valueFrom</span><span class="token punctuation">:</span>                <span class="token key atrule">configMapKeyRef</span><span class="token punctuation">:</span>                  <span class="token key atrule">name</span><span class="token punctuation">:</span> mycm           <span class="token comment" spellcheck="true">#  ConfigMap的名称</span>                  <span class="token key atrule">key</span><span class="token punctuation">:</span> username <span class="token comment" spellcheck="true"># 需要取值的键</span></code></pre><h6 id="映射成文件"><a href="#映射成文件" class="headerlink" title="映射成文件"></a>映射成文件</h6><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> cmdata              <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /data然后写卷 https<span class="token punctuation">:</span>//kubernetes.io/zh/docs/concepts/storage/volumes <span class="token key atrule">volumes</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> cmdata          <span class="token key atrule">configMap</span><span class="token punctuation">:</span>            <span class="token key atrule">name</span><span class="token punctuation">:</span> mycm            <span class="token key atrule">items</span><span class="token punctuation">:</span>              <span class="token punctuation">-</span> <span class="token key atrule">key</span><span class="token punctuation">:</span> user.info                <span class="token key atrule">path</span><span class="token punctuation">:</span> user.txt</code></pre><p><code>myngx.yaml</code></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Deployment<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> myngx<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">selector</span><span class="token punctuation">:</span>    <span class="token key atrule">matchLabels</span><span class="token punctuation">:</span>      <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx  <span class="token key atrule">replicas</span><span class="token punctuation">:</span> <span class="token number">1</span>  <span class="token key atrule">template</span><span class="token punctuation">:</span>    <span class="token key atrule">metadata</span><span class="token punctuation">:</span>      <span class="token key atrule">labels</span><span class="token punctuation">:</span>        <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx    <span class="token key atrule">spec</span><span class="token punctuation">:</span>      <span class="token key atrule">containers</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> ngx          <span class="token key atrule">image</span><span class="token punctuation">:</span> nginx<span class="token punctuation">:</span>1.18<span class="token punctuation">-</span>alpine          <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> IfNotPresent          <span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> cmdata              <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /data          <span class="token key atrule">env</span><span class="token punctuation">:</span>            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> TEST              <span class="token key atrule">value</span><span class="token punctuation">:</span> testvalue            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> USERNAME              <span class="token key atrule">valueFrom</span><span class="token punctuation">:</span>                <span class="token key atrule">configMapKeyRef</span><span class="token punctuation">:</span>                  <span class="token key atrule">name</span><span class="token punctuation">:</span> mycm           <span class="token comment" spellcheck="true">#  ConfigMap的名称</span>                  <span class="token key atrule">key</span><span class="token punctuation">:</span> username <span class="token comment" spellcheck="true"># 需要取值的键</span>      <span class="token key atrule">volumes</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> cmdata          <span class="token key atrule">configMap</span><span class="token punctuation">:</span>            <span class="token key atrule">name</span><span class="token punctuation">:</span> mycm            <span class="token key atrule">items</span><span class="token punctuation">:</span>              <span class="token punctuation">-</span> <span class="token key atrule">key</span><span class="token punctuation">:</span> user.info                <span class="token key atrule">path</span><span class="token punctuation">:</span> user.txt</code></pre><h6 id="subpath"><a href="#subpath" class="headerlink" title="subpath"></a><code>subpath</code></h6><p>上一个节</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> cmdata              <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /data然后写卷 https<span class="token punctuation">:</span>//kubernetes.io/zh/docs/concepts/storage/volumes <span class="token key atrule">volumes</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> cmdata          <span class="token key atrule">configMap</span><span class="token punctuation">:</span>            <span class="token key atrule">name</span><span class="token punctuation">:</span> mycm            <span class="token key atrule">items</span><span class="token punctuation">:</span>              <span class="token punctuation">-</span> <span class="token key atrule">key</span><span class="token punctuation">:</span> user.info                <span class="token key atrule">path</span><span class="token punctuation">:</span> user.txt</code></pre><p>如果我们不指定具体的key</p><pre class=" language-yaml"><code class="language-yaml">  <span class="token key atrule">volumes</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> cmdata          <span class="token key atrule">configMap</span><span class="token punctuation">:</span>            <span class="token key atrule">name</span><span class="token punctuation">:</span> mycm这时你会发现，所有文件都被 映射进去了，文件名就是key名</code></pre><blockquote><p>如果我希望：<br>     不指定key 。也想挂载其中一个配置</p><p>文档:<br><a href="https://kubernetes.io/zh/docs/concepts/storage/volumes/#using-path" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/concepts/storage/volumes/#using-path</a></p><p>用于指定所引用的卷（volumes）内的子路径，而不是其根路径</p></blockquote><p><strong>修改点</strong></p><pre class=" language-yaml"><code class="language-yaml"> <span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /data/user.txt          <span class="token key atrule">name</span><span class="token punctuation">:</span> cmdata          <span class="token key atrule">subPath</span><span class="token punctuation">:</span> user.info这个不变 <span class="token key atrule">volumes</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> cmdata          <span class="token key atrule">configMap</span><span class="token punctuation">:</span>            <span class="token key atrule">name</span><span class="token punctuation">:</span> mycm</code></pre><p><code>myngx.yaml</code></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Deployment<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> myngx<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">selector</span><span class="token punctuation">:</span>    <span class="token key atrule">matchLabels</span><span class="token punctuation">:</span>      <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx  <span class="token key atrule">replicas</span><span class="token punctuation">:</span> <span class="token number">1</span>  <span class="token key atrule">template</span><span class="token punctuation">:</span>    <span class="token key atrule">metadata</span><span class="token punctuation">:</span>      <span class="token key atrule">labels</span><span class="token punctuation">:</span>        <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx    <span class="token key atrule">spec</span><span class="token punctuation">:</span>      <span class="token key atrule">containers</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> ngx          <span class="token key atrule">image</span><span class="token punctuation">:</span> nginx<span class="token punctuation">:</span>1.18<span class="token punctuation">-</span>alpine          <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> IfNotPresent          <span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> cmdata              <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /data/user.txt              <span class="token key atrule">subPath</span><span class="token punctuation">:</span> user.info          <span class="token key atrule">env</span><span class="token punctuation">:</span>            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> TEST              <span class="token key atrule">value</span><span class="token punctuation">:</span> testvalue            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> USERNAME              <span class="token key atrule">valueFrom</span><span class="token punctuation">:</span>                <span class="token key atrule">configMapKeyRef</span><span class="token punctuation">:</span>                  <span class="token key atrule">name</span><span class="token punctuation">:</span> mycm           <span class="token comment" spellcheck="true">#  ConfigMap的名称</span>                  <span class="token key atrule">key</span><span class="token punctuation">:</span> username <span class="token comment" spellcheck="true"># 需要取值的键</span>      <span class="token key atrule">volumes</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> cmdata          <span class="token key atrule">configMap</span><span class="token punctuation">:</span>            <span class="token key atrule">defaultMode</span><span class="token punctuation">:</span> <span class="token number">0655</span>            <span class="token key atrule">name</span><span class="token punctuation">:</span> mycm        <span class="token comment" spellcheck="true">#            items:</span><span class="token comment" spellcheck="true">#              - key: user.info</span><span class="token comment" spellcheck="true">#                path: user.txt</span></code></pre><h4 id="Deployment和Secret"><a href="#Deployment和Secret" class="headerlink" title="Deployment和Secret"></a>Deployment和Secret</h4><h5 id="入门和无脑创建（Opaque）"><a href="#入门和无脑创建（Opaque）" class="headerlink" title="入门和无脑创建（Opaque）"></a>入门和无脑创建（Opaque）</h5><p>根据官方定义</p><blockquote><p>​    Secret 对象类型用来保存敏感信息，例如密码、OAuth 令牌和 SSH 密钥。 将这些信息放在 secret 中比放在 Pod 的定义或者 容器镜像 中来说更加安全和灵活。 参阅 Secret 设计文档 获取更多详细信息。</p><p>​     Secret 是一种包含少量敏感信息例如密码、令牌或密钥的对象。 这样的信息可能会被放在 Pod 规约中或者镜像中。 用户可以创建 Secret，同时系统也创建了一些 Secret。</p><p>关键词<br>1、敏感、少量<br>2、安全和灵活</p></blockquote><p>类型</p><p><a href="https://imgtu.com/i/65K9jx" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/03/21/65K9jx.png" alt="65K9jx.png"></a></p><p>先来一把配置</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Secret<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> mysecret<span class="token key atrule">type</span><span class="token punctuation">:</span> Opaque<span class="token key atrule">data</span><span class="token punctuation">:</span>  <span class="token key atrule">user</span><span class="token punctuation">:</span> <span class="token string">"cyylog"</span>  <span class="token key atrule">pass</span><span class="token punctuation">:</span> <span class="token string">"123"</span>试一下 对还是不对？</code></pre><p>根据提示</p><blockquote><p>我们需要 先base64编码</p><p>最简单的方式  使用命令直接搞定</p><p>echo cyylog | base64 &amp;&amp; echo 123 | base64 </p><p>把得到的值替换即可</p></blockquote><h5 id="命令获取secret内容、挂载文件"><a href="#命令获取secret内容、挂载文件" class="headerlink" title="命令获取secret内容、挂载文件"></a>命令获取secret内容、挂载文件</h5><h6 id="查看命令"><a href="#查看命令" class="headerlink" title="查看命令"></a>查看命令</h6><pre class=" language-shell"><code class="language-shell"> 上一步用到了    kubectl get secret mysecret -o yaml其实 还可以kubectl get secret mysecret -o json</code></pre><h5 id="secret进行basic-auth认证"><a href="#secret进行basic-auth认证" class="headerlink" title="secret进行basic-auth认证"></a>secret进行basic-auth认证</h5><h6 id="1-手工配置"><a href="#1-手工配置" class="headerlink" title="(1):手工配置"></a>(1):手工配置</h6><p>类型</p><p><a href="https://imgtu.com/i/6OVou9" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/03/25/6OVou9.png" alt="6OVou9.png"></a></p><p><strong>nginx 认证</strong></p><pre class=" language-shell"><code class="language-shell">location / {  auth_basic      "xxxxooooo";  auth_basic_user_file conf/htpasswd;}其中密码 我们常用的是     通过apache的工具htpasswd或者openssl passwd命令生成htpasswd提供了一个变种的MD5加密算法(apr1),这里不深究</code></pre><p><strong>安装工具</strong></p><pre class=" language-shell"><code class="language-shell">sudo yum -y install httpd-toolsApache的Web服务器内置的工具,用于创建和更新储存用户名和用户基本认证的密码文件创建一个密码文件  htpasswd -c auth cyylog这时产生了一个 auth文件再添加一个  用户(此时不用-c参数)htpasswd  auth lisi</code></pre><p>我们做成一个<strong>ConfigMap</strong></p><pre class=" language-shell"><code class="language-shell">名称叫做bauth然后把刚才的内容 拷贝进去注意点：我们课程使用的镜像是 nginx:1.18-alpine它的 默认配置文件在/etc/nginx/nginx.conf其中 主配置文件引用了 /etc/nginx/conf.d/default.conf 文件 </code></pre><p>拷贝并修改</p><pre class=" language-shell"><code class="language-shell">server {    listen       80;    server_name  localhost;    location / {       auth_basic      "test auth";       auth_basic_user_file /etc/nginx/basicauth;        root   /usr/share/nginx/html;        index  index.html index.htm;    }    error_page   500 502 503 504  /50x.html;    location = /50x.html {        root   /usr/share/nginx/html;    }}</code></pre><p><strong>挂载</strong></p><pre class=" language-yaml"><code class="language-yaml"> <span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> nginxconf              <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /etc/nginx/conf.d/default.conf              <span class="token key atrule">subPath</span><span class="token punctuation">:</span> ngx            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> basicauth              <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /etc/nginx/basicauth              <span class="token key atrule">subPath</span><span class="token punctuation">:</span> auth</code></pre><p><strong>卷</strong></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">volumes</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> nginxconf          <span class="token key atrule">configMap</span><span class="token punctuation">:</span>            <span class="token key atrule">defaultMode</span><span class="token punctuation">:</span> <span class="token number">0655</span>            <span class="token key atrule">name</span><span class="token punctuation">:</span> nginxconfig        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> basicauth          <span class="token key atrule">configMap</span><span class="token punctuation">:</span>              <span class="token key atrule">defaultMode</span><span class="token punctuation">:</span> <span class="token number">0655</span>              <span class="token key atrule">name</span><span class="token punctuation">:</span> bauth</code></pre><blockquote><p>访问测试</p><pre class=" language-shell"><code class="language-shell">curl --basic -u cyylog:123456  http://10.42.2.52</code></pre></blockquote><h6 id="2-使用secret挂载"><a href="#2-使用secret挂载" class="headerlink" title="(2):使用secret挂载"></a>(2):使用secret挂载</h6><p><strong>前面</strong>：</p><pre class=" language-shell"><code class="language-shell">location / {  auth_basic      "xxxxooooo";  auth_basic_user_file conf/htpasswd;}    其中我们映射了 一个configMap来 实现 。</code></pre><p><strong>用文件的方式导入</strong></p><pre class=" language-shell"><code class="language-shell">kubectl  create secret generic secret-basic-auth  --from-file=auth</code></pre><p><strong>访问测试</strong></p><pre class=" language-shell"><code class="language-shell">curl --basic -u cyylog:123456  http://10.42.2.52</code></pre><h6 id="拉取私有镜像、创建Docker-Secret"><a href="#拉取私有镜像、创建Docker-Secret" class="headerlink" title="拉取私有镜像、创建Docker Secret"></a>拉取私有镜像、创建Docker Secret</h6><blockquote><p><strong>首先去</strong><br><a href="https://hub.docker.com/signup" target="_blank" rel="noopener">https://hub.docker.com/signup</a></p><p>注册 并且登录  。 这个过程自行搞定</p><p>然后 随便</p><pre class=" language-shell"><code class="language-shell">1、docker pull alpine:3.12 2、docker login --username=cyylog  (输入密码)3、docker tag alpine:3.12 cyylog/myalpine:3.12</code></pre></blockquote><p><strong>创建私有镜像库</strong></p><p><a href="https://hub.docker.com/repository/create" target="_blank" rel="noopener">https://hub.docker.com/repository/create</a></p><p><a href="https://imgtu.com/i/6OqYU1" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/03/25/6OqYU1.png" alt="6OqYU1.png"></a></p><p><strong>发布</strong></p><pre class=" language-shell"><code class="language-shell">docker push cyylog/myalpine:3.12 稍等片刻 后 我们一个 简单的私有镜像就好了 接下来 把我们刚才打标签的tag给删掉 docker rmi cyylog/myalpine:3.12</code></pre><p><strong>写个<code>deployment</code></strong></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Deployment<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> myalpine<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">selector</span><span class="token punctuation">:</span>    <span class="token key atrule">matchLabels</span><span class="token punctuation">:</span>      <span class="token key atrule">app</span><span class="token punctuation">:</span> myalpine  <span class="token key atrule">replicas</span><span class="token punctuation">:</span> <span class="token number">1</span>  <span class="token key atrule">template</span><span class="token punctuation">:</span>    <span class="token key atrule">metadata</span><span class="token punctuation">:</span>      <span class="token key atrule">labels</span><span class="token punctuation">:</span>        <span class="token key atrule">app</span><span class="token punctuation">:</span> myalpine    <span class="token key atrule">spec</span><span class="token punctuation">:</span>      <span class="token key atrule">containers</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> alpine          <span class="token key atrule">image</span><span class="token punctuation">:</span> cyylog/myalpine<span class="token punctuation">:</span><span class="token number">3.12</span>          <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> IfNotPresent          <span class="token key atrule">command</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"sh"</span><span class="token punctuation">,</span><span class="token string">"-c"</span><span class="token punctuation">,</span><span class="token string">"echo this is alpine &amp;&amp; sleep 36000"</span><span class="token punctuation">]</span></code></pre><p><strong>接下来就要创建<code>secret</code>了</strong></p><pre class=" language-shell"><code class="language-shell">kubectl create secret docker-registry dockerreg \  --docker-server=https://index.docker.io/v1/\  --docker-username=cyylog \  --docker-password=pass123 \  --docker-email=cyylog@test.com</code></pre><p><strong>内容解码后</strong></p><p><a href="https://imgtu.com/i/6XSVh9" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/03/25/6XSVh9.png" alt="6XSVh9.png"></a></p><pre class=" language-shell"><code class="language-shell">kubectl get secret  dockerreg -o jsonpath={.data.*} | base64 -d</code></pre><p><strong>加入配置</strong> </p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">imagePullSecrets</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> dockerreg</code></pre><h4 id="Deployment和Service"><a href="#Deployment和Service" class="headerlink" title="Deployment和Service"></a>Deployment和Service</h4><h5 id="创建一个最基本的Service、ClusterIP"><a href="#创建一个最基本的Service、ClusterIP" class="headerlink" title="创建一个最基本的Service、ClusterIP"></a>创建一个最基本的Service、ClusterIP</h5><h6 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h6><blockquote><p>作用：<br>     一句话：提供负载均衡和服务自动发现</p></blockquote><p><strong>我们先弄个一个</strong><code>ConfigMap</code></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">data</span><span class="token punctuation">:</span>  <span class="token key atrule">h1</span><span class="token punctuation">:</span> this is h1  <span class="token key atrule">h2</span><span class="token punctuation">:</span> this is h2<span class="token key atrule">kind</span><span class="token punctuation">:</span> ConfigMap<span class="token key atrule">metadata</span><span class="token punctuation">:</span>    <span class="token key atrule">name</span><span class="token punctuation">:</span> html</code></pre><p><strong>写个**</strong><code>deployment</code>**</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Service<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> nginx<span class="token punctuation">-</span>svc<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">type</span><span class="token punctuation">:</span> ClusterIP  <span class="token key atrule">ports</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">80</span>      <span class="token key atrule">targetPort</span><span class="token punctuation">:</span> <span class="token number">80</span>  <span class="token key atrule">selector</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true">#service通过selector和pod建立关联</span>    <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx</code></pre><p>**服务类型—<code>ClusterIP</code></p><blockquote><p>ClusterIP：通过集群的内部 IP 暴露服务，选择该值时服务只能够在集群内部  访问。 这也是默认的 ServiceType。</p></blockquote><h6 id="宿主机访问k8s的Service的基本方法"><a href="#宿主机访问k8s的Service的基本方法" class="headerlink" title="宿主机访问k8s的Service的基本方法"></a>宿主机访问k8s的Service的基本方法</h6><p><strong>安装一个工具</strong></p><pre class=" language-shell"><code class="language-shell">sudo yum install  bind-utils  -y记下来我们执行nslookup nginx-svc</code></pre><p><strong>处理办法</strong> </p><pre class=" language-shell"><code class="language-shell"># kubectl get svc -n kube-system10.43.0.10 # sudo vi /etc/resolv.confnameserver 10.43.0.10search default.svc.cluster.local svc.cluster.local</code></pre><blockquote><p><code>/etc/resolv.conf</code></p><p>用于设置DNS服务器IP地址、DNS域名和设置主机的域名搜索顺序</p><p>我们加一个进去</p><p>然后执行 nslookup nginx-svc.default.svc.cluster.local</p></blockquote><h6 id="无头Service初步入门"><a href="#无头Service初步入门" class="headerlink" title="无头Service初步入门"></a>无头Service初步入门</h6><p><strong>无头服务</strong></p><blockquote><p>所谓的无头服务<br>   通过指定 ClusterIP的值为“None”来创建 Headless Service</p></blockquote><p><strong>具体配置</strong></p><pre class=" language-yaml"><code class="language-yaml">先删掉  nginx<span class="token punctuation">-</span>svc 这个service<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Service<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> nginx<span class="token punctuation">-</span>svc<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">clusterIP</span><span class="token punctuation">:</span> <span class="token string">"None"</span>  <span class="token key atrule">ports</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">80</span>      <span class="token key atrule">targetPort</span><span class="token punctuation">:</span> <span class="token number">80</span>  <span class="token key atrule">selector</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true">#service通过selector和pod建立关联</span>    <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx</code></pre><blockquote><p><strong>作用</strong></p><p>有些程序 需要自己来决定到底 使用哪个IP<br>  譬如golang  可以使用  net.LookupIP(“服务名”)，来获取 IP ,然后自己来决定到底使用哪个</p><p> StatefulSet 状态下。POD互相访问#### PV和PVC</p></blockquote><h5 id="创建PV、Local方式、基本设置"><a href="#创建PV、Local方式、基本设置" class="headerlink" title="创建PV、Local方式、基本设置"></a>创建PV、Local方式、基本设置</h5><h6 id="PV"><a href="#PV" class="headerlink" title="PV"></a>PV</h6><blockquote><p>全称是：PersistentVolume（持久化卷），是对底层的共享存储的一种抽象，  由管理员进行创建和配置。</p><p>然后由 卷插件  如local、NFS 等具体的底层技术来实现</p><p>官网地址：<a href="https://kubernetes.io/zh/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes</a></p></blockquote><p><strong>创建一个</strong></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> PersistentVolume<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> local<span class="token punctuation">-</span>pv<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">capacity</span><span class="token punctuation">:</span>    <span class="token key atrule">storage</span><span class="token punctuation">:</span> 1Gi  <span class="token key atrule">volumeMode</span><span class="token punctuation">:</span> Filesystem  <span class="token key atrule">accessModes</span><span class="token punctuation">:</span>     <span class="token punctuation">-</span> ReadWriteOnce  <span class="token key atrule">persistentVolumeReclaimPolicy</span><span class="token punctuation">:</span> Delete  <span class="token key atrule">storageClassName</span><span class="token punctuation">:</span> local<span class="token punctuation">-</span>storage  <span class="token key atrule">local</span><span class="token punctuation">:</span>    <span class="token key atrule">path</span><span class="token punctuation">:</span> /mnt/disks/ssd1</code></pre><p><strong><code>capacity</code></strong></p><pre class=" language-shell"><code class="language-shell">它的单位有:     P,T,G,M,K或 Pi,Ti,Gi,Mi,Ki 区别   加i的是以1024为换算单位 如 (1Mi)1M=1024K=1024×1024byte1M 则是1000*1000</code></pre><p> <strong><code>accessModes</code></strong></p><pre class=" language-shell"><code class="language-shell">访问模式有：ReadWriteOnce -- 卷可以被一个节点以读写方式挂载；ReadOnlyMany -- 卷可以被多个节点以只读方式挂载；ReadWriteMany -- 卷可以被多个节点以读写方式挂载。</code></pre><p><strong><code>PersistentVolume</code> 对象的回收策略</strong></p><blockquote><p> Retained（保留）、Recycled（回收）或 Deleted（删除）</p></blockquote><p><strong>节点亲和性</strong></p><blockquote><p>   之前我们调度节点时用过nodeSelector  ，设定标签进行匹配。这种方式过于”粗暴简单”。使用NodeAffinity来进行控制颗粒度更小（对于local模式 ，我们必须要设置）<br>   软策略 (有最好，没有也无所谓)<br>  如果没有满足调度要求的节点的话，就会忽略按正常调度<br>  preferredDuringSchedulingIgnoredDuringExecution<br>  preferredDuringSchedulingRequiredDuringExecution (一旦后面标签改了，有满足条件的节点了，就会重新调度到该节点上)</p></blockquote><p><strong>硬策略</strong> </p><blockquote><p>硬策略<br>    如果没有满足条件的节点的话，就不断重试直到满足条件为止 </p><p>requiredDuringSchedulingIgnoredDuringExecution  （如果一开始满足的，后面node标签发生变化了，也无妨，继续运行）</p><p>requiredDuringSchedulingRequiredDuringExecution（一旦变了，不符合条件了。则重新选择）</p></blockquote><p><strong>查看标签</strong> </p><pre class=" language-shell"><code class="language-shell">kubectl get node --show-labels=true打标签语法：kubectl label nodes <node-name> <label-key>=<label-value>kubectl label nodes cyylog2 pv=local删除语法kubectl label nodes <node-name> <label-key>-kubectl label nodes cyylog2 pv-</code></pre><p><strong><code>matchExpressions</code></strong></p><pre class=" language-shell"><code class="language-shell">In: label的值在某个列表中NotIn：label的值不在某个列表中Exists：某个label存在DoesNotExist：某个label不存在Gt：label的值大于某个值（字符串比较）Lt：label的值小于某个值（字符串比较） </code></pre><h5 id="创建PVC、初步绑定PV-、POD挂载"><a href="#创建PVC、初步绑定PV-、POD挂载" class="headerlink" title="创建PVC、初步绑定PV 、POD挂载"></a>创建PVC、初步绑定PV 、POD挂载</h5><p><strong>复习</strong><code>PV</code>：</p><blockquote><p>全称是：PersistentVolume（持久化卷），是对底层的共享存储的一种抽象，  由管理员进行创建和配置。</p><p>然后由 卷插件  如local、NFS 等具体的底层技术来实现 </p><p>(运维 或管理员  )   PVC</p></blockquote><h6 id="PVC-Persistent-Volume-Claim"><a href="#PVC-Persistent-Volume-Claim" class="headerlink" title="PVC(Persistent Volume Claim)"></a><strong><code>PVC</code>(Persistent Volume Claim)</strong></h6><blockquote><p>Persistent Volume提供存储资源(并实现)<br>Persistent Volume Claim 描述需要的存储标准，然后从现有PV中匹配或者动态建立新的资源，最后将两者进行绑定。</p><p>好比<br>   PV是提供者，提供存储方式和容量  ( 销售费用1万)</p><p>   PVC是消费者，消费容量  （它不需要关注用什么技术实现，绑定即可）</p></blockquote><p><strong>绑定方式</strong></p><blockquote><p>PV和PVC中<br>   spec关键字段要匹配 。<br>   storageClassName字段必须一致  </p></blockquote><p><strong><code>PersistentVolume</code> 对象的回收策略</strong></p><pre class=" language-shell"><code class="language-shell"> Retained（保留）、Recycled（回收）或 Deleted（删除）</code></pre><h5 id="StorageClass简单入门和创建"><a href="#StorageClass简单入门和创建" class="headerlink" title="StorageClass简单入门和创建"></a><code>StorageClass</code>简单入门和创建</h5><h6 id="StorageClass"><a href="#StorageClass" class="headerlink" title="StorageClass"></a><code>StorageClass</code></h6><blockquote><p>理解为创建PV的模板   </p><p>文档</p><p><a href="https://kubernetes.io/zh/docs/concepts/storage/storage-classes/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/concepts/storage/storage-classes/</a></p></blockquote><p><strong>例子</strong></p><pre class=" language-shell"><code class="language-shell">provisioner:指的是卷插件  (如NFS，local)reclaimPolicy:  回收策略。 volumeBindingMode ：绑定模式    Immediate :一旦创建PVC 就绑定    WaitForFirstConsumer：就是延迟绑定，直到使用该 PVC 的 Pod 被创建parameters：参数（不同的存储方式有N多个不同参数，这里不讲了。大家自行看文档）</code></pre><h4 id="POD自动伸缩（HPA）"><a href="#POD自动伸缩（HPA）" class="headerlink" title="POD自动伸缩（HPA）"></a><code>POD</code>自动伸缩（<code>HPA</code>）</h4><h5 id="HPA入门、部署metrics-server"><a href="#HPA入门、部署metrics-server" class="headerlink" title="HPA入门、部署metrics-server"></a><code>HPA</code>入门、部署<code>metrics-server</code></h5><h6 id="HPA"><a href="#HPA" class="headerlink" title="HPA"></a>HPA</h6><blockquote><p><code>Pod</code> 水平自动扩缩（<code>Horizontal Pod Autoscaler</code>） 可以</p><p>1、基于 <code>CPU</code> 利用率自动扩缩 <code>ReplicationController</code>、<code>Deployment</code>、<code>ReplicaSet</code> 和 <code>StatefulSet</code> 中的 Pod 数量。</p><p>2、 除了 <code>CPU</code> 利用率，也可以基于其他应程序提供的自定义度量指标 来执行自动扩缩。</p><p>3、 <code>Pod</code> 自动扩缩不适用于无法扩缩的对象，比如 <code>DaemonSet</code>。</p></blockquote><h6 id="metrics-server"><a href="#metrics-server" class="headerlink" title="metrics-server"></a><code>metrics-server</code></h6><blockquote><p>   k8s里。可以通过<code>Metrics-Server</code>服务采集节点和Pod的内存、磁盘、CPU和网络的使用率等</p><p>注意：<br>    <code>Metrics API</code> 只可以查询当前的度量数据，并不保存历史数据<br>    <code>Metrics API URI</code> 为 <code>/apis/metrics.k8s.io/</code><br>    必须部署 <code>metrics-server</code> 才能使用该 API，<code>metrics-server</code> 通过调用 <code>Kubelet Summary API</code> 获取数据</p></blockquote><h6 id="部署方式"><a href="#部署方式" class="headerlink" title="部署方式"></a>部署方式</h6><blockquote><p>官方告诉我们<br>kubectl apply -f <a href="https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml" target="_blank" rel="noopener">https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml</a></p><p>这里面有个镜像干不下来,一些配置也需要修改。 </p><p>具体附件</p></blockquote><pre class=" language-shell"><code class="language-shell">### 查看kubectl top pod    (还可以写node)### 创建一个最简单是 使用命令直接创建kubectl autoscale deployment ngx1 --min=2 --max=5 --cpu-percent=20</code></pre><h5 id="限制POD资源、创建HPA"><a href="#限制POD资源、创建HPA" class="headerlink" title="限制POD资源、创建HPA"></a>限制<code>POD</code>资源、创建<code>HPA</code></h5><blockquote><p>看一段配置</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">resources</span><span class="token punctuation">:</span>        <span class="token key atrule">requests</span><span class="token punctuation">:</span>            <span class="token key atrule">cpu</span><span class="token punctuation">:</span> <span class="token string">"200m"</span>            <span class="token key atrule">memory</span><span class="token punctuation">:</span> <span class="token string">"256Mi"</span>        <span class="token key atrule">limits</span><span class="token punctuation">:</span>           <span class="token key atrule">cpu</span><span class="token punctuation">:</span> <span class="token string">"400m"</span>            <span class="token key atrule">memory</span><span class="token punctuation">:</span> "512Mi“ requests来设置各容器需要的最小资源 limits用于限制运行时容器占用的资源 1物理核=1000个微核(millicores)      1000m=1CPU</code></pre></blockquote><p><strong>装个工具</strong></p><pre class=" language-shell"><code class="language-shell">sudo yum -y install httpd-tools里面包含了一个 apache ab 工具  做简单压测ab -n 10000 -c 10  http://web1/</code></pre><p>创建一个</p><pre class=" language-shell"><code class="language-shell">最简单是 使用命令直接创建kubectl autoscale deployment web1 --min=1 --max=5 --cpu-percent=20</code></pre><h5 id="yaml的方式创建HPA"><a href="#yaml的方式创建HPA" class="headerlink" title="yaml的方式创建HPA"></a><code>yaml</code>的方式创建<code>HPA</code></h5><h6 id="几个API版本"><a href="#几个API版本" class="headerlink" title="几个API版本"></a>几个API版本</h6><blockquote><p><code>kubectl api-versions | grep autoscaling</code></p><p><code>autoscaling/v1</code>         #只支持通过cpu伸缩<br><code>autoscaling/v2beta1</code>    #支持通过cpu、内存 和自定义数据来进行伸缩。<br><code>autoscaling/v2beta2</code>     #beta1的进一步 （一般用它）</p></blockquote><h6 id="yaml配置方式"><a href="#yaml配置方式" class="headerlink" title="yaml配置方式"></a><code>yaml</code>配置方式</h6><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> autoscaling/v2beta2<span class="token key atrule">kind</span><span class="token punctuation">:</span> HorizontalPodAutoscaler<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> web1hpa  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> default<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">minReplicas</span><span class="token punctuation">:</span> <span class="token number">1</span>  <span class="token key atrule">maxReplicas</span><span class="token punctuation">:</span> <span class="token number">5</span>  <span class="token key atrule">scaleTargetRef</span><span class="token punctuation">:</span>    <span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1    <span class="token key atrule">kind</span><span class="token punctuation">:</span> Deployment    <span class="token key atrule">name</span><span class="token punctuation">:</span> web1  <span class="token key atrule">metrics</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">type</span><span class="token punctuation">:</span> Resource      <span class="token key atrule">resource</span><span class="token punctuation">:</span>        <span class="token key atrule">name</span><span class="token punctuation">:</span> cpu        <span class="token key atrule">target</span><span class="token punctuation">:</span>          <span class="token key atrule">type</span><span class="token punctuation">:</span> Utilization          <span class="token key atrule">averageUtilization</span><span class="token punctuation">:</span> <span class="token number">50   </span><span class="token comment" spellcheck="true">#使用率</span>    <span class="token punctuation">-</span> <span class="token key atrule">type</span><span class="token punctuation">:</span> Resource      <span class="token key atrule">resource</span><span class="token punctuation">:</span>        <span class="token key atrule">name</span><span class="token punctuation">:</span> memory        <span class="token key atrule">target</span><span class="token punctuation">:</span>          <span class="token key atrule">type</span><span class="token punctuation">:</span> Utilization          <span class="token key atrule">averageUtilization</span><span class="token punctuation">:</span> <span class="token number">50   </span><span class="token comment" spellcheck="true">#使用率</span></code></pre><p><strong>使用量</strong></p><pre class=" language-yaml"><code class="language-yaml"> <span class="token key atrule">metrics</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">type</span><span class="token punctuation">:</span> Resource      <span class="token key atrule">resource</span><span class="token punctuation">:</span>        <span class="token key atrule">name</span><span class="token punctuation">:</span> cpu        <span class="token key atrule">target</span><span class="token punctuation">:</span>          <span class="token key atrule">type</span><span class="token punctuation">:</span> AverageValue          <span class="token key atrule">averageValue</span><span class="token punctuation">:</span> 230m   <span class="token comment" spellcheck="true">#使用量</span>    <span class="token punctuation">-</span> <span class="token key atrule">type</span><span class="token punctuation">:</span> Resource      <span class="token key atrule">resource</span><span class="token punctuation">:</span>        <span class="token key atrule">name</span><span class="token punctuation">:</span> memory        <span class="token key atrule">target</span><span class="token punctuation">:</span>          <span class="token key atrule">type</span><span class="token punctuation">:</span> AverageValue          <span class="token key atrule">averageValue</span><span class="token punctuation">:</span> 400m   <span class="token comment" spellcheck="true">#使用量</span></code></pre><h6 id="关于自定义指标"><a href="#关于自定义指标" class="headerlink" title="关于自定义指标"></a>关于自定义指标</h6><blockquote><p>自定义指标 比较主流的方式是使用<code>prometheus</code></p><p>大概有几项需要安装:<br><code>node-exporter</code>：<code>prometheus</code>的<code>export</code>，收集Node级别的监控数据<br><code>prometheus</code>：监控服务端，从<code>node-exporter</code>拉数据并存储为时序数据。<br><code>kube-state-metrics</code>：将<code>prometheus</code>中可以用<code>PromQL</code>查询到的指标数据转换成<code>k8s</code>对应的数据<br><code>k8s-prometheus-adpater</code>：聚合进<code>apiserver</code>，即<code>custom-metrics-apiserver</code>实现(也可以用自定义<code>CRD</code>来实现)#### <code>CRD</code>和<code>Controller</code></p></blockquote><h6 id="什么是CRD"><a href="#什么是CRD" class="headerlink" title="什么是CRD"></a>什么是CRD</h6><blockquote><p>​    CRD  是 Kubernetes 的一种资源(CustomResourceDefinition )，允许我们基于它自定义新的资源类型.</p><p>  值得注意的是：k8s所有的东西都叫做资源（Resource）</p><p>  CRD就是 我们对自定义资源的定义</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
            <tag> notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kubectl 命令自动补全</title>
      <link href="2021/01/01/container/kubectl-ming-ling-zi-dong-bu-quan/"/>
      <url>2021/01/01/container/kubectl-ming-ling-zi-dong-bu-quan/</url>
      
        <content type="html"><![CDATA[<p><strong>kubectl 命令自动补全</strong></p><h5 id="一-简介"><a href="#一-简介" class="headerlink" title="一.简介"></a>一.简介</h5><p>在k8s 1.3版本之前，设置kubectl命令自动补全是通过以下的方式：<br><code>source ./contrib/completions/bash/kubectl</code></p><p>但是在k8s 1.3版本，源码contrib目录中已经没有了completions目录，无法再使用以上方式添加自动补全功能。</p><p>查看 linux架构图 的作用</p><p>1.3版本中，kubectl添加了一个completions的命令， 该命令可用于自动补全<br><code>source &lt;(kubectl completion bash)</code></p><h5 id="二-设置补全"><a href="#二-设置补全" class="headerlink" title="二.设置补全"></a>二.设置补全</h5><h6 id="linux上"><a href="#linux上" class="headerlink" title="linux上"></a>linux上</h6><pre class=" language-shell"><code class="language-shell">k8s 命令自动补全yum install -y bash-completionsource /usr/share/bash-completion/bash_completionsource <(kubectl completion bash)echo "source <(kubectl completion bash)" >> ~/.bashrc</code></pre><h6 id="在mac上"><a href="#在mac上" class="headerlink" title="在mac上"></a>在mac上</h6><pre class=" language-shell"><code class="language-shell">brew install bash-completionsource $(brew --prefix)/etc/bash_completionsource <(kubectl completion bash)</code></pre>]]></content>
      
      
      <categories>
          
          <category> container </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决keepalived脑裂问题</title>
      <link href="2020/12/27/linux/jie-jue-keepalived-nao-lie-wen-ti/"/>
      <url>2020/12/27/linux/jie-jue-keepalived-nao-lie-wen-ti/</url>
      
        <content type="html"><![CDATA[<h2 id="一-介绍"><a href="#一-介绍" class="headerlink" title="一.介绍"></a>一.介绍</h2><p>脑裂（split-brain）：指在一个高可用（HA）系统中，当联系着的两个节点断开联系时，本来为一个整体的系统，分裂为两个独立节点，这时两个节点开始争抢共享资源，例如都去用同一个ip提供网页服务，结果会导致系统混乱，数据损坏。</p><p>对于无状态服务的HA，无所谓脑裂不脑裂；但对有状态服务(比如MySQL)的HA，必须要严格防止脑裂。</p><h2 id="二-产生的原因"><a href="#二-产生的原因" class="headerlink" title="二.产生的原因"></a>二.产生的原因</h2><ul><li>高可用服务器对之间心跳线链路发生故障，导致无法正常通信。</li><li>因心跳线坏了（包括断了，老化）。</li><li>因网卡及相关驱动坏了，ip配置及冲突问题（网卡直连）。</li><li>因心跳线间连接的设备故障（网卡及交换机）。</li><li>因仲裁的机器出问题（采用仲裁的方案）。</li><li>高可用服务器上开启了 iptables防火墙阻挡了心跳消息传输。</li><li>高可用服务器上心跳网卡地址等信息配置不正确，导致发送心跳失败。</li><li>其他服务配置不当等原因，如心跳方式不同，心跳广插冲突、软件Bug等。</li></ul><p>提示： Keepalived配置里同一 VRRP实例如果 virtual_router_id两端参数配置不一致也会导致裂脑问题发生。</p><h2 id="三-解决方案"><a href="#三-解决方案" class="headerlink" title="三.解决方案"></a>三.解决方案</h2><h3 id="检测网关"><a href="#检测网关" class="headerlink" title="检测网关"></a>检测网关</h3><p>由于keepalived体系中主备两台机器所处的状态与对方有关。如果主备机器之间的通信出了网题，那就ping网关，如果失败则证明网络有问题，将当前节点关闭，如果成功再开启。</p><p>问题是，当内部mysql所在机器出现网络问题，但是他是给内网提供服务的，这会导致2台mysql都关闭虚拟ip。</p><p>所以可以改改，将两台机器互相ping，防止网络问题。</p><p><code>vim check_keepalived.sh</code></p><pre class=" language-shell"><code class="language-shell">#!/bin/bash#检测keepalived脑裂脚本#ping网关失败2次则关闭keepalived服务，成功2次则启动#[使用设置]#网关地址或者对方keepalived节点地址，互pinggetway_ip=192.168.1.1#[自带变量]check_ok=0check_no=0while [ 1 ]do    ping -c 1 $getway_ip    if [[ $? -eq 0 ]];then        let check_ok++    else        let check_ok++    fi    if [[ $check_ok -eq 2 ]];then        systemctl start keepalived        check_ok=0    elif [[ $check_no -eq 2 ]];then        systemctl stop keepalived        check_no=0    fi    sleep 1done</code></pre><h3 id="更改为单播"><a href="#更改为单播" class="headerlink" title="更改为单播"></a>更改为单播</h3><p>将方式改为单播，这样检测更加完善</p><pre class=" language-shell"><code class="language-shell">vrrp_instance VI_1 {    state MASTER    interface enp0s8    virtual_router_id 51    priority 100    advert_int 1    authentication {        auth_type PASS        auth_pass 1111    }#增加部分unicast_src_ip 192.168.2.41 #本机ipunicast_peer {        192.168.2.150 #其他机器ip，可多个}    virtual_ipaddress {        192.168.2.99    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> keepalived </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nil in Go</title>
      <link href="2020/12/16/devops/go-nil-in-go/"/>
      <url>2020/12/16/devops/go-nil-in-go/</url>
      
        <content type="html"><![CDATA[<h4 id="Nil-in-Go"><a href="#Nil-in-Go" class="headerlink" title="Nil in Go"></a>Nil in Go</h4><h4 id="Go中-的-nil-是什么"><a href="#Go中-的-nil-是什么" class="headerlink" title="Go中 的 nil 是什么"></a>Go中 的 <code>nil</code> 是什么</h4><blockquote><p>Go中的nil具有以下含义：</p><ul><li>它代表Go中的“ <code>null</code>”。这意味着两件事：1.它没有类型。 2.其值为“ null”。</li><li>它是Go中预先声明的标识符，这意味着您可以使用它而不必声明它。</li><li>它表示Go中某些类型的零值（和默认值），包括 interface types, pointer types, slice types, map types, channel types, function types 。</li></ul></blockquote><h4 id="使用nil-作为零值"><a href="#使用nil-作为零值" class="headerlink" title="使用nil 作为零值"></a>使用<code>nil</code> 作为零值</h4><p><code>nil</code>表示Go中某些类型的零值（和默认值）。</p><p>例如:</p><pre class=" language-go"><code class="language-go"><span class="token keyword">package</span> main<span class="token keyword">func</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// Use `nil` as zero values</span>    <span class="token boolean">_</span> <span class="token operator">=</span> <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span>    <span class="token boolean">_</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token operator">*</span><span class="token keyword">struct</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// () around *struct{} is necessary, otherwise Go will not be able to know where `*` points to.</span>    <span class="token boolean">_</span> <span class="token operator">=</span> <span class="token builtin">string</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span>    <span class="token boolean">_</span> <span class="token operator">=</span> <span class="token keyword">map</span><span class="token punctuation">[</span><span class="token builtin">string</span><span class="token punctuation">]</span><span class="token function">int</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span>    <span class="token boolean">_</span> <span class="token operator">=</span> <span class="token keyword">chan</span> <span class="token function">string</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span>    <span class="token boolean">_</span> <span class="token operator">=</span><span class="token punctuation">(</span><span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">// () around func() is necessary</span>    <span class="token comment" spellcheck="true">// This lines are equivalent to the above lines</span>    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span> <span class="token operator">=</span> <span class="token boolean">nil</span>    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token operator">*</span><span class="token keyword">struct</span><span class="token punctuation">{</span><span class="token punctuation">}</span> <span class="token operator">=</span> <span class="token boolean">nil</span>    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token builtin">string</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">nil</span>    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token keyword">map</span><span class="token punctuation">[</span><span class="token builtin">string</span><span class="token punctuation">]</span><span class="token builtin">int</span> <span class="token operator">=</span> <span class="token boolean">nil</span>    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token keyword">chan</span> <span class="token builtin">string</span> <span class="token operator">=</span> <span class="token boolean">nil</span>    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token boolean">nil</span>    <span class="token comment" spellcheck="true">// This lines are equivalent to the above lines, as `nil` is default values of these types</span>    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token operator">*</span><span class="token keyword">struct</span><span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token builtin">string</span><span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token keyword">map</span><span class="token punctuation">[</span><span class="token builtin">string</span><span class="token punctuation">]</span><span class="token builtin">int</span>    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token keyword">chan</span> <span class="token builtin">string</span>    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><h4 id="对比-nil"><a href="#对比-nil" class="headerlink" title="对比 nil"></a>对比 <code>nil</code></h4><h5 id="两种不同类型的两个nil值是不可比较的"><a href="#两种不同类型的两个nil值是不可比较的" class="headerlink" title="两种不同类型的两个nil值是不可比较的"></a>两种不同类型的两个<code>nil</code>值是不可比较的</h5><p> 例如：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">package</span> main<span class="token keyword">func</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">bool</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">string</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">// compiler error: mismatched types.</span>    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token operator">=</span> <span class="token keyword">chan</span> <span class="token function">int</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">chan</span> <span class="token function">bool</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">// compiler error: mismatched types.</span><span class="token punctuation">}</span></code></pre><blockquote><p>当他们试图比较两种不同类型的<code>nil</code>值时，这段代码将无法编译。</p></blockquote><h5 id="两个相同类型的nil值可能无法比较"><a href="#两个相同类型的nil值可能无法比较" class="headerlink" title="两个相同类型的nil值可能无法比较"></a>两个相同类型的<code>nil</code>值可能无法比较</h5><p>例如:</p><pre class=" language-go"><code class="language-go"><span class="token keyword">package</span> main<span class="token keyword">func</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">string</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">string</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span>                  <span class="token comment" spellcheck="true">// compiler error: invalid operation.</span>    <span class="token keyword">var</span> sb <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">map</span><span class="token punctuation">[</span><span class="token builtin">string</span><span class="token punctuation">]</span><span class="token builtin">bool</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span><span class="token keyword">map</span><span class="token punctuation">[</span><span class="token builtin">string</span><span class="token punctuation">]</span><span class="token builtin">bool</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">// compiler error: invalid operation.</span>    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span><span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span>                      <span class="token comment" spellcheck="true">// compiler error: invalid operation.</span><span class="token punctuation">}</span></code></pre><blockquote><p>以 <code>var sb = (map[string]bool)(nil) == (map[string]bool)(nil)</code> 为例，同一类型 ( <code>map[string]bool</code>) 的两个nil值不可比较的原因是Go不支持切片、映射和函数类型的比较。 <strong>在本例中，我们正在比较一个不可比较类型的两个值，从而导致失败。</strong></p></blockquote><p>但以下代码有效，结果是<code>true</code>：</p><pre class=" language-go"><code class="language-go">    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">string</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token boolean">nil</span>              <span class="token comment" spellcheck="true">// true</span>    <span class="token keyword">var</span> sb <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">map</span><span class="token punctuation">[</span><span class="token builtin">string</span><span class="token punctuation">]</span><span class="token builtin">bool</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token boolean">nil</span>      <span class="token comment" spellcheck="true">// true</span>    <span class="token keyword">var</span> <span class="token boolean">_</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token boolean">nil</span>                <span class="token comment" spellcheck="true">// true</span></code></pre><blockquote><p>以 <code>var sb = (map[string]bool)(nil) == nil</code> 为例, <code>(map[string]bool)(nil)</code> 声明一个临时变量 <code>map[string]bool</code> 其值为 <code>nil</code> ，<code>(map[string]bool)(nil) == nil</code> 检测变量的值是否为 <code>nil</code> 然后将结果分配给 <code>sb</code>. <strong>可以看到，在本例中，我们将不可比较类型的值与其零值（nil）进行比较。这就是它起作用的原因</strong></p></blockquote><h5 id="只有当该类型支持比较时，同一类型的两个nil值才能进行比较"><a href="#只有当该类型支持比较时，同一类型的两个nil值才能进行比较" class="headerlink" title="只有当该类型支持比较时，同一类型的两个nil值才能进行比较"></a>只有当该类型支持比较时，同一类型的两个<code>nil</code>值才能进行比较</h5><p> 例如：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">package</span> main<span class="token keyword">import</span> <span class="token string">"fmt"</span><span class="token keyword">func</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    fmt<span class="token punctuation">.</span><span class="token function">Println</span><span class="token punctuation">(</span> <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token punctuation">)</span> <span class="token comment" spellcheck="true">// true</span>    fmt<span class="token punctuation">.</span><span class="token function">Println</span><span class="token punctuation">(</span> <span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token punctuation">)</span>           <span class="token comment" spellcheck="true">// true</span>    fmt<span class="token punctuation">.</span><span class="token function">Println</span><span class="token punctuation">(</span> <span class="token keyword">chan</span> <span class="token function">string</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">chan</span> <span class="token function">string</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token punctuation">)</span> <span class="token comment" spellcheck="true">// true</span><span class="token punctuation">}</span></code></pre><h5 id="当涉及Interface-时，在-nil比较中要小心"><a href="#当涉及Interface-时，在-nil比较中要小心" class="headerlink" title="当涉及Interface 时，在 nil比较中要小心"></a>当涉及<code>Interface</code> 时，在 <code>nil</code>比较中要小心</h5><p><strong>下面的代码不会导致任何编译器报错，但结果是<code>false</code>而不是<code>true</code>。</strong></p><pre class=" language-go"><code class="language-go"><span class="token keyword">package</span> main<span class="token keyword">import</span> <span class="token string">"fmt"</span><span class="token keyword">func</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    fmt<span class="token punctuation">.</span><span class="token function">Println</span><span class="token punctuation">(</span> <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token boolean">nil</span><span class="token punctuation">)</span> <span class="token punctuation">)</span>      <span class="token comment" spellcheck="true">// false</span><span class="token punctuation">}</span></code></pre><p>Explanation:</p><blockquote><ul><li><p>接口值由动态类型和动态值组成。  <code>interface{}(nil)</code> 使用 <code>{type: nil, value: nil}</code>声明一个接口值。</p></li><li><p>在与接口值进行比较之前，将非接口值转换为接口值的类型。在此示例中，<code>(*int)(nil)</code>使用 <code>{type: *int, value: nil}</code>转换为接口值。</p></li><li><p>两个<code>nil</code>接口值只有在携带相同类型时才是等价的。在本例中，转换后的接口值 <code>{type: *int, value: nil}</code> 具有具体的动态类型，但另一个接口值没有。这就是为什么比较结果是<code>false</code>的。</p></li></ul></blockquote><p>一个更有意思的例子：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">package</span> main<span class="token keyword">import</span> <span class="token string">"io"</span><span class="token keyword">import</span> <span class="token string">"bytes"</span><span class="token keyword">import</span> <span class="token string">"fmt"</span><span class="token keyword">func</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">var</span> w io<span class="token punctuation">.</span>Writer    fmt<span class="token punctuation">.</span><span class="token function">Println</span><span class="token punctuation">(</span>w <span class="token operator">==</span> <span class="token boolean">nil</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">// True</span>    <span class="token keyword">var</span> b <span class="token operator">*</span>bytes<span class="token punctuation">.</span>Buffer    w <span class="token operator">=</span> b    fmt<span class="token punctuation">.</span><span class="token function">Println</span><span class="token punctuation">(</span>w <span class="token operator">==</span> <span class="token boolean">nil</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">// false</span>    <span class="token function">write</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true">// panic: runtime error: invalid memory address or nil pointer dereference</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// If out is non-nil, output will be written to it.</span><span class="token comment" spellcheck="true">//</span><span class="token keyword">func</span> <span class="token function">write</span><span class="token punctuation">(</span>out io<span class="token punctuation">.</span>Writer<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// ...do something...</span>    <span class="token keyword">if</span> out <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>                     <span class="token comment" spellcheck="true">// This guard is not secure enough</span>        out<span class="token punctuation">.</span><span class="token function">Write</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token function">byte</span><span class="token punctuation">(</span><span class="token string">"done!\n"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>Explanation:</p><blockquote><ul><li>接口值仅在其类型和值均为 <code>**nil**</code>时才等于 <code>**nil**</code>。在此示例中， <code>w</code> 是  <code>io.Writer</code>的 interface value ，在<code>w = b</code>赋值后带有 <code>{type: *bytes.Buffer, value: nil}</code>。因此， <code>w==nil</code>为 <code>false</code>，因为它携带 <code>*byte.Buffer</code> 而不是<code>nil</code>作为它得具体动态类型。</li></ul></blockquote><h4 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h4><blockquote><ul><li><code>nil</code>是一个预先声明的标识符，可用于表示Go中某些类型的零值。</li><li>在比较时使用<code>nil</code>时要特别小心，尤其是在涉及 <code>interface values</code>时。需要了解所比较的内容：<code>types, or values</code>，或两者。</li><li><code>(a thing)(nil)</code> may not equal to <code>nil</code>, depends on what that thing is (a pointer or an interface). This means <code>nil</code> is strong-typed even though <code>nil</code>does not have a default type (<strong>sarcasm</strong>).</li><li><code>(a thing)(nil)</code>可能不等于<code>nil</code>，取决于事物是什么（指针或接口）。这意味着nil是强类型的，即使nil没有默认类型（<strong>sarcasm</strong>）。</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> Golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes on CRI-O (CentOS)</title>
      <link href="2020/12/15/container/kubernetes-on-cri-o-centos/"/>
      <url>2020/12/15/container/kubernetes-on-cri-o-centos/</url>
      
        <content type="html"><![CDATA[<h3 id="Kubernetes-on-CRI-O-CentOS"><a href="#Kubernetes-on-CRI-O-CentOS" class="headerlink" title="Kubernetes on CRI-O (CentOS)"></a>Kubernetes on CRI-O (CentOS)</h3><h4 id="Docker-现在在-Kubernetes-中已弃用-。"><a href="#Docker-现在在-Kubernetes-中已弃用-。" class="headerlink" title="Docker 现在在 Kubernetes 中已弃用 。"></a>Docker 现在在 Kubernetes 中已弃用 。</h4><p>kubelet 中的 Docker 支持现已弃用，并将在以后的版本中删除。Kubelet 使用一个名为 <code>dockershim</code>的模块，该模块实现了对 Docker 的 CRI 支持，并且在 Kubernetes 社区中看到了维护问题。</p><p>So，现在 Kubernetes 推荐使用不同的 Container Runtime Interface 而不是 docker。</p><h4 id="为什么选择-CRI-O"><a href="#为什么选择-CRI-O" class="headerlink" title="为什么选择 CRI-O ?"></a>为什么选择 CRI-O ?</h4><p>CRI-O是 Kubernetes CRI（ Container Runtime Interface ）的实现，以启用使用OCI（ Open Container Initiative ）兼容的运行时。</p><p>它是将Docker，Moby 或 rkt 用作 Kubernetes 的运行时的轻量级替代方案。</p><p>CRI-O是主要由Red Hat员工开发的CRI运行时。实际上，该运行时现在已在 Red Hat OpenShift 中使用。并且，他们不再依赖 Docker。</p><p>有趣的是，RHEL 7 也不正式支持 Docker。相反，它们为容器环境提供 Podman，Buildah 和 CRI-O。</p><h4 id="Let’s-get-started"><a href="#Let’s-get-started" class="headerlink" title="Let’s get started"></a>Let’s get started</h4><ul><li>one master node</li><li>two worker nodes</li></ul><h5 id="Installing-CRI-O"><a href="#Installing-CRI-O" class="headerlink" title="Installing CRI-O"></a>Installing CRI-O</h5><blockquote><p> (在所有节点上完成)</p></blockquote><ul><li>为OS创建一个环境变量。</li></ul><pre><code>$ export OS=CentOS_7</code></pre><blockquote><p>注意：如果您使用的是CentOS 8，则将变量名称命名为CentOS_8</p></blockquote><ul><li>为crio的VERSION创建另一个环境变量。</li></ul><pre><code>$ export VERSION=1.17</code></pre><blockquote><p>注意：如果您使用的是CentOS 8，则还可以安装crio版本1.18</p></blockquote><ul><li>为cri-o配置REPO。</li></ul><pre><code>$ sudo curl -L -o /etc/yum.repos.d/devel:kubic:libcontainers:stable.repo https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/$OS/devel:kubic:libcontainers:stable.repo</code></pre><pre><code>$ sudo curl -L -o /etc/yum.repos.d/devel:kubic:libcontainers:stable:cri-o:$VERSION.repo https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable:cri-o:$VERSION/$OS/devel:kubic:libcontainers:stable:cri-o:$VERSION.repo</code></pre><ul><li>Install cri-o.</li></ul><pre><code>$ sudo yum install cri-o -y</code></pre><ul><li>启动并启用cri-o服务。</li></ul><pre><code>$ sudo systemctl start cri-o </code></pre><ul><li>如果启动cri-o有任何问题，请参阅故障排除部分！</li></ul><pre><code>$ sudo systemctl enable cri-o</code></pre><h5 id="故障排除"><a href="#故障排除" class="headerlink" title="故障排除"></a>故障排除</h5><h6 id="无法启动cri-o服务："><a href="#无法启动cri-o服务：" class="headerlink" title="无法启动cri-o服务："></a>无法启动cri-o服务：</h6><pre><code>$ sudo systemctl status cri-ocrio.service - Container Runtime Interface for OCI (CRI-O)   Loaded: loaded (/usr/lib/systemd/system/crio.service; disabled; vendor preset: disabled)   Active: failed (Result: exit-code) since Fri 2020-12-11 01:42:49 EST; 29s ago     Docs: https://github.com/cri-o/cri-o  Process: 1259 ExecStart=/usr/bin/crio $CRIO_CONFIG_OPTIONS $CRIO_RUNTIME_OPTIONS $CRIO_STORAGE_OPTIONS $CRIO_NETWORK_OPTIONS $CRIO_METRICS_OPTIONS (code=exited, status=1/FAILURE) Main PID: 1259 (code=exited, status=1/FAILURE)Dec 11 01:42:49 ip-172-31-89-94.ec2.internal systemd[1]: Starting Container Runtime Interface for OCI (CRI-O)...Dec 11 01:42:49 ip-172-31-89-94.ec2.internal crio[1259]: time=&quot;2020-12-11 01:42:49.409813214-01:00&quot; level=fatal msg=&quot;Validating root config: failed to get store to set defaults: kernel does not support overlay fs: overlay: the backing xfs filesystem is formatted without d_type support, which leads to incorrect behavior. Reformat the filesystem with ftype=1 to enable d_type support. Running without d_type is not supported.: driver not supported&quot;Dec 11 01:42:49 ip-172-31-89-94.ec2.internal systemd[1]: crio.service: main process exited, code=exited, status=1/FAILUREDec 11 01:42:49 ip-172-31-89-94.ec2.internal systemd[1]: Failed to start Container Runtime Interface for OCI (CRI-O).Dec 11 01:42:49 ip-172-31-89-94.ec2.internal systemd[1]: Unit crio.service entered failed state.Dec 11 01:42:49 ip-172-31-89-94.ec2.internal systemd[1]: crio.service failed.</code></pre><h6 id="根本原因："><a href="#根本原因：" class="headerlink" title="根本原因："></a>根本原因：</h6><p>默认容器存储即  <code>/var/lib/containers/storage</code> 是以 <code>ftype=0</code>, 挂载的，因此<code>d_type</code>被禁用（<code>d_type</code>启用文件名到其<code>inode</code>的映射）。修改后，<code>ftype=1</code>！</p><pre><code>$ sudo xfs_info /var/lib/containers/storage | grep ftypenaming   =version 2              bsize=4096   ascii-ci=0 ftype=0</code></pre><h6 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法:"></a>解决方法:</h6><ul><li>创建一个逻辑卷（LV）。</li></ul><pre><code>$ sudo fdisk &lt;disk_name&gt;</code></pre><pre><code>$ sudo partprobe &lt;disk_name&gt;</code></pre><pre><code>$ sudo vgcreate vgname &lt;partition&gt;</code></pre><pre><code>$ sudo lvcreate -l 100%FREE -n lvname vgname</code></pre><pre><code>$ sudo lvsLV     VG     Attr       LSize   Pool Origin Data%  Meta%  Move Log Cpy%Sync Convertroot   centos -wi-ao----  &lt;6.67gswap   centos -wi-ao---- 820.00mlvname vgname -wi-a-----  &lt;5.00g</code></pre><ul><li>使用XFS文件系统格式化LV</li></ul><pre><code>$ sudo mkfs.xfs /dev/mapper/vgname-lvnamemeta-data=/dev/mapper/vgname-lvname isize=512    agcount=4, agsize=327424 blks         =                       sectsz=512   attr=2, projid32bit=1         =                       crc=1        finobt=0, sparse=0data     =                       bsize=4096   blocks=1309696, imaxpct=25         =                       sunit=0      swidth=0 blksnaming   =version 2              bsize=4096   ascii-ci=0 ftype=1log      =internal log           bsize=4096   blocks=2560, version=2         =                       sectsz=512   sunit=0 blks, lazy-count=1realtime =none                   extsz=4096   blocks=0, rtextents=0</code></pre><ul><li>现在ftype设置为1。</li><li>Mount LV on /var/lib/containers/storage permanently.</li><li>将 LV 永久挂载在/var/lib/containers/storage上。</li></ul><pre><code>$ sudo cat /etc/fstab | grep /var/lib/containers/storage/dev/mapper/vgname-lvname /var/lib/containers/storage xfs defaults 0 0</code></pre><pre><code>$ sudo mount -a</code></pre><pre><code>$ sudo df -hT | grep /var/lib/containers/storage/dev/mapper/vgname-lvname xfs       5.0G   33M  5.0G   1% /var/lib/containers/storage</code></pre><ul><li>更改runroot路径，并取消哈希 runroot 和 root 在 /etc/crio/crio.conf 中。</li></ul><pre><code>$ sudo cat /etc/crio/crio.conf | grep /var/lib/containers/storageroot = &quot;/var/lib/containers/storage&quot;runroot = &quot;/var/lib/containers/storage&quot;</code></pre><ul><li>然后启动并启用cri-o服务。</li></ul><pre><code>$ sudo systemctl start cri-o</code></pre><pre><code>$ sudo systemctl enable cri-o</code></pre><h5 id="前期准备："><a href="#前期准备：" class="headerlink" title="前期准备："></a>前期准备：</h5><blockquote><p>（应该在所有节点上完成）</p></blockquote><ul><li>加载 overlay 模块</li></ul><pre><code>$ sudo modprobe overlay</code></pre><ul><li>加载 br_netfilter 模块.</li></ul><pre><code>$ sudo modprobe br_netfilter</code></pre><p>启用此模块，以便 iptables，ip6tables 和 arptables 可以过滤桥接的 IPv4/IPv6/ARP 数据包并使防火墙 transparent 。</p><ul><li>Set up required sysctl params, these persist across reboots.</li><li>设置所需的 sysctl 参数，这些参数将在重新启动后还生效。</li></ul><pre><code>$ cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.confnet.bridge.bridge-nf-call-iptables  = 1net.ipv4.ip_forward                 = 1net.bridge.bridge-nf-call-ip6tables = 1EOF</code></pre><ul><li>重新加载 sysctl 。</li></ul><pre><code>$ sudo sysctl --system</code></pre><ul><li>禁用防火墙。</li></ul><pre><code>$ sudo systemctl stop firewalld &amp;&amp; sudo systemctl disable firewalld</code></pre><ul><li>禁用 SELinux </li></ul><pre><code>$ sudo setenforce 0</code></pre><pre><code>$ sudo sed -i -e s/SELINUX=enforcing/SELINUX=permissive/g /etc/sysconfig/selinux</code></pre><ul><li>关闭 swap .</li></ul><pre><code>$ sudo swapoff -a</code></pre><ul><li>禁用 swap 在 /etc/fstab 处修改</li></ul><pre><code>$ sudo cat /etc/fstab | grep swap#/dev/mapper/centos-swap                                swap                    swap    defaults        0 0</code></pre><ul><li>在  /etc/crio/crio.conf  更改 crio 的 cgroup_manager .</li></ul><pre><code>$ sudo cat /etc/crio/crio.conf | grep cgroup_managercgroup_manager = &quot;cgroupfs&quot;</code></pre><ul><li>配置 Kubernetes repo.</li></ul><pre><code>$ sudo cat /etc/yum.repos.d/kube.repo[kubernetes]name=Kubernetesbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</code></pre><h5 id="部署-Kubernetes-集群"><a href="#部署-Kubernetes-集群" class="headerlink" title="部署 Kubernetes 集群"></a>部署 Kubernetes 集群</h5><h6 id="COMMANDS-ON-MASTER"><a href="#COMMANDS-ON-MASTER" class="headerlink" title="COMMANDS ON MASTER"></a>COMMANDS ON MASTER</h6><ul><li>Install kubeadm package.</li></ul><pre><code>$ sudo yum install kubeadm -y</code></pre><ul><li>Start and enable kubelet.</li></ul><pre><code>$ sudo systemctl start kubelet &amp;&amp; sudo systemctl enable kubelet</code></pre><ul><li>初始化 Kubernetes </li></ul><pre><code>$ sudo kubeadm init</code></pre><blockquote><p>Note: If giving error of iptables does not exist, just load br_netfilter module again and run the command.</p><p>注意：如果有<code>iptables does not exist</code> 错误信息，只需再次加载 br_netfilter 模块并运行命令。</p></blockquote><ul><li>Output</li></ul><pre><code>Your Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user:  mkdir -p $HOME/.kube  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config  sudo chown $(id -u):$(id -g) $HOME/.kube/configAlternatively, if you are the root user, you can run:  export KUBECONFIG=/etc/kubernetes/admin.confYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:  https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.46.157:6443 --token 7xlnp0.9uv4z0qr4wvzhtqn \    --discovery-token-ca-cert-hash sha256:4a1a412d2e682556df0bf10dc380c744a98eb99e8c927fa58eb025d5ff7dc694</code></pre><ul><li>使用普通用户运行 kunectl ,请运行以下命令</li></ul><pre><code>$ mkdir -p $HOME/.kube</code></pre><pre><code>$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</code></pre><pre><code>$ sudo chown $(id -u):$(id -g) $HOME/.kube/config</code></pre><ul><li>这些命令将您的 Kubernetes 配置文件存储在主目录中。</li><li>记录 kubeadm init 输出的kubeadm join命令。需要使用此命令将节点加入集群。</li><li>安装CNI插件使 CoreDNS Pod 正常运行。</li></ul><pre><code>$ kubectl apply -f &quot;https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d &#39;\n&#39;)&quot;</code></pre><ul><li>Weave Net creates a virtual network that connects Docker containers across multiple hosts and enables their automatic discovery.</li><li>Weave Net创建了一个虚拟网络，该网络可以使 Docker 容器跨主机通信。</li></ul><pre><code>$ kubectl get nodesNAME     STATUS   ROLES                  AGE   VERSIONmaster   Ready    control-plane,master   14m   v1.20.0</code></pre><ul><li>Now we need to add worker nodes to the cluster.</li><li>现在我们需要将nodes 添加到集群中。</li></ul><h6 id="Worker-nodes-命令："><a href="#Worker-nodes-命令：" class="headerlink" title="Worker nodes 命令："></a>Worker nodes 命令：</h6><ul><li>Install kubeadm package.</li></ul><pre><code>$ sudo yum install kubeadm -y</code></pre><ul><li>运行 kubeadm join命令。 （在 kubeadm init 输出中的命令）</li></ul><pre><code>$ sudo kubeadm join 192.168.46.157:6443 --token 7xlnp0.9uv4z0qr4wvzhtqn \    --discovery-token-ca-cert-hash sha256:4a1a412d2e682556df0bf10dc380c744a98eb99e8c927fa58eb025d5ff7dc694</code></pre><ul><li>Output</li></ul><pre><code>This node has joined the cluster:* Certificate signing request was sent to apiserver and a response was received.* The Kubelet was informed of the new secure connection details.Run &#39;kubectl get nodes&#39; on the control-plane to see this node join the cluster.</code></pre><ul><li>现在我们的工作节点已加入集群！</li></ul><h6 id="Master-命令"><a href="#Master-命令" class="headerlink" title="Master 命令"></a>Master 命令</h6><ul><li>检查节点是否准备就绪。</li></ul><pre><code>$ kubectl get nodesNAME      STATUS   ROLES                  AGE     VERSIONmaster    Ready    control-plane,master   15m     v1.20.0worker1   Ready    &lt;none&gt;                 4m44s   v1.20.0worker2   Ready    &lt;none&gt;                 4m18s   v1.20.0</code></pre>]]></content>
      
      
      <categories>
          
          <category> container </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> CRI-O </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>了解 Sync.Pool</title>
      <link href="2020/12/09/devops/go-liao-jie-sync.pool/"/>
      <url>2020/12/09/devops/go-liao-jie-sync.pool/</url>
      
        <content type="html"><![CDATA[<h4 id="Go-了解-Sync-Pool"><a href="#Go-了解-Sync-Pool" class="headerlink" title="Go: 了解 Sync.Pool"></a>Go: 了解 Sync.Pool</h4><blockquote><p>在项目中的“垃圾回收”中经常会遇到这么一个问题。大量对象被重复分配，导致<code>GC</code>的工作量很大。使用<code>sync.Pool</code>，可以减少分配和<code>GC</code>工作量。</p></blockquote><h5 id="什么是-sync-Pool"><a href="#什么是-sync-Pool" class="headerlink" title="什么是 sync.Pool?"></a>什么是 <code>sync.Pool</code>?</h5><blockquote><p>Go 1.3 版本的亮点之一是 <code>sync Pool</code>。它是<code>sync</code>包下的一个组件，用于创建自我管理的临时检索对象池。</p></blockquote><h5 id="为什么要使用-sync-Pool"><a href="#为什么要使用-sync-Pool" class="headerlink" title="为什么要使用 sync.Pool?"></a>为什么要使用 <code>sync.Pool</code>?</h5><blockquote><p>我们希望尽可能减少GC的开销。 频繁分配和回收内存将给GC造成沉重负担。 <code>sync.Pool</code>可以缓存暂时不使用的对象，并在下次需要它们时直接使用它们（无需重新分配）。 这样可以潜在地减少GC工作量并提高性能。</p></blockquote><h5 id="如何使用-sync-Pool"><a href="#如何使用-sync-Pool" class="headerlink" title="如何使用 sync.Pool?"></a>如何使用 <code>sync.Pool</code>?</h5><blockquote><p>首先，您需要设一个 新的 <code>function</code>.。 当池中没有缓存的对象时，将使用此功能。 之后，您只需要使用Get和Put方法来检索和返回对象。 另外，<code>Pool</code>在首次使用后不得复制。</p><p>由于新函数类型为 <code>func（）interface {}</code>，因此给方法将返回 <code>interface{}</code> 。因此，需要执行类型断言以获取具体对象。</p></blockquote><pre class=" language-go"><code class="language-go"><span class="token comment" spellcheck="true">// A dummy struct</span><span class="token keyword">type</span> Person <span class="token keyword">struct</span> <span class="token punctuation">{</span>    Name <span class="token builtin">string</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// Initializing pool</span><span class="token keyword">var</span> personPool <span class="token operator">=</span> sync<span class="token punctuation">.</span>Pool<span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// New optionally specifies a function to generate</span>    <span class="token comment" spellcheck="true">// a value when Get would otherwise return nil.</span>    New<span class="token punctuation">:</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span> <span class="token punctuation">{</span> <span class="token keyword">return</span> <span class="token function">new</span><span class="token punctuation">(</span>Person<span class="token punctuation">)</span> <span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// Main function</span><span class="token keyword">func</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// Get hold of an instance</span>    newPerson <span class="token operator">:=</span> personPool<span class="token punctuation">.</span><span class="token function">Get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token punctuation">(</span><span class="token operator">*</span>Person<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// Defer release function</span>    <span class="token comment" spellcheck="true">// After that the same instance is </span>    <span class="token comment" spellcheck="true">// reusable by another routine</span>    <span class="token keyword">defer</span> personPool<span class="token punctuation">.</span><span class="token function">Put</span><span class="token punctuation">(</span>newPerson<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// Using the instance</span>    newPerson<span class="token punctuation">.</span>Name <span class="token operator">=</span> <span class="token string">"Jack"</span><span class="token punctuation">}</span></code></pre><h6 id="Benchmark"><a href="#Benchmark" class="headerlink" title="Benchmark"></a>Benchmark</h6><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> Person <span class="token keyword">struct</span> <span class="token punctuation">{</span>    Age <span class="token builtin">int</span><span class="token punctuation">}</span><span class="token keyword">var</span> personPool <span class="token operator">=</span> sync<span class="token punctuation">.</span>Pool<span class="token punctuation">{</span>    New<span class="token punctuation">:</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span> <span class="token punctuation">{</span> <span class="token keyword">return</span> <span class="token function">new</span><span class="token punctuation">(</span>Person<span class="token punctuation">)</span> <span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token function">BenchmarkWithoutPool</span><span class="token punctuation">(</span>b <span class="token operator">*</span>testing<span class="token punctuation">.</span>B<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">var</span> p <span class="token operator">*</span>Person    b<span class="token punctuation">.</span><span class="token function">ReportAllocs</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    b<span class="token punctuation">.</span><span class="token function">ResetTimer</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token operator">:=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> b<span class="token punctuation">.</span>N<span class="token punctuation">;</span> i<span class="token operator">++</span> <span class="token punctuation">{</span>        <span class="token keyword">for</span> j <span class="token operator">:=</span> <span class="token number">0</span><span class="token punctuation">;</span> j <span class="token operator">&lt;</span> <span class="token number">10000</span><span class="token punctuation">;</span> j<span class="token operator">++</span> <span class="token punctuation">{</span>            p <span class="token operator">=</span> <span class="token function">new</span><span class="token punctuation">(</span>Person<span class="token punctuation">)</span>            p<span class="token punctuation">.</span>Age <span class="token operator">=</span> <span class="token number">23</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token function">BenchmarkWithPool</span><span class="token punctuation">(</span>b <span class="token operator">*</span>testing<span class="token punctuation">.</span>B<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">var</span> p <span class="token operator">*</span>Person    b<span class="token punctuation">.</span><span class="token function">ReportAllocs</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    b<span class="token punctuation">.</span><span class="token function">ResetTimer</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token operator">:=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> b<span class="token punctuation">.</span>N<span class="token punctuation">;</span> i<span class="token operator">++</span> <span class="token punctuation">{</span>        <span class="token keyword">for</span> j <span class="token operator">:=</span> <span class="token number">0</span><span class="token punctuation">;</span> j <span class="token operator">&lt;</span> <span class="token number">10000</span><span class="token punctuation">;</span> j<span class="token operator">++</span> <span class="token punctuation">{</span>            p <span class="token operator">=</span> personPool<span class="token punctuation">.</span><span class="token function">Get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token punctuation">(</span><span class="token operator">*</span>Person<span class="token punctuation">)</span>            p<span class="token punctuation">.</span>Age <span class="token operator">=</span> <span class="token number">23</span>            personPool<span class="token punctuation">.</span><span class="token function">Put</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>Benchmark result:</p><pre><code>BenchmarkWithoutPoolBenchmarkWithoutPool-8   160698 ns/op   80001 B/op   10000 allocs/opBenchmarkWithPoolBenchmarkWithPool-8      191163 ns/op       0 B/op       0 allocs/op</code></pre><h6 id="Trade-off"><a href="#Trade-off" class="headerlink" title="Trade-off"></a>Trade-off</h6><p>Everything* <em>in</em> <em>life</em> <em>is a</em> <em>trade</em>-<em>off</em>.</p><p>池也有其性能成本。使用<code>sync.Pool</code>比简单的初始化要慢得多。</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">BenchmarkPool</span><span class="token punctuation">(</span>b <span class="token operator">*</span>testing<span class="token punctuation">.</span>B<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">var</span> p sync<span class="token punctuation">.</span>Pool    b<span class="token punctuation">.</span><span class="token function">RunParallel</span><span class="token punctuation">(</span><span class="token keyword">func</span><span class="token punctuation">(</span>pb <span class="token operator">*</span>testing<span class="token punctuation">.</span>PB<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">for</span> pb<span class="token punctuation">.</span><span class="token function">Next</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            p<span class="token punctuation">.</span><span class="token function">Put</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>            p<span class="token punctuation">.</span><span class="token function">Get</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token function">BenchmarkAllocation</span><span class="token punctuation">(</span>b <span class="token operator">*</span>testing<span class="token punctuation">.</span>B<span class="token punctuation">)</span> <span class="token punctuation">{</span>    b<span class="token punctuation">.</span><span class="token function">RunParallel</span><span class="token punctuation">(</span><span class="token keyword">func</span><span class="token punctuation">(</span>pb <span class="token operator">*</span>testing<span class="token punctuation">.</span>PB<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">for</span> pb<span class="token punctuation">.</span><span class="token function">Next</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            i <span class="token operator">:=</span> <span class="token number">0</span>            i <span class="token operator">=</span> i        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><p>Benchmark result:</p><pre><code>BenchmarkPoolBenchmarkPool-8           283395016          4.40 ns/opBenchmarkAllocationBenchmarkAllocation-8    1000000000         0.344 ns/op</code></pre><h5 id="sync-Pool如何工作？"><a href="#sync-Pool如何工作？" class="headerlink" title="sync.Pool如何工作？"></a><code>sync.Pool</code>如何工作？</h5><blockquote><p><code>sync.Pool</code> has two containers for objects: local pool (active) and victim cache (archived).</p><p>根据 <code>sync/pool.go</code> , package <code>init</code> function <a href="https://golang.org/src/sync/pool.go?s=8003:8060#L271" target="_blank" rel="noopener">registers to the runtime as a method</a> 去清理 <code>pools</code>. 此方法将由GC触发。</p></blockquote><pre><code>func init() {   runtime_registerPoolCleanup(poolCleanup)}</code></pre><blockquote><p>When the GC is triggered, objects inside the victim cache will be collected and then objects inside the local pool will be moved to the victim cache.</p></blockquote><pre><code>func poolCleanup() {   // Drop victim caches from all pools.   for _, p := range oldPools {      p.victim = nil      p.victimSize = 0   }   // Move primary cache to victim cache.   for _, p := range allPools {      p.victim = p.local      p.victimSize = p.localSize      p.local = nil      p.localSize = 0   }   oldPools, allPools = allPools, nil}</code></pre><blockquote><p>New objects are put in the local pool. Calling <code>Put</code> method will put the object into the local pool as well. Calling <code>Get</code> method will take an object from the victim cache in the first place and if the victim cache was empty the object will be taken from the local pool.</p></blockquote><p>[<img src="https://s3.ax1x.com/2020/12/09/r9F2VK.gif" alt="r9F2VK.gif"></p><blockquote><p>sync.Pool localPool and victimCache</p><p>For your information, the Go 1.12 sync.Pool implementation uses a <code>mutex</code> based locking for thread-safe operations from multiple Goroutines. Go 1.13 <a href="https://github.com/golang/go/commit/d5fd2dd6a17a816b7dfd99d4df70a85f1bf0de31#diff-491b0013c82345bf6cfa937bd78b690d" target="_blank" rel="noopener">introduces a doubly-linked list</a> as a shared pool which removes the <code>mutex</code> lock and improves the shared access.</p></blockquote><h5 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h5><blockquote><p>When there is an expensive object you have to create it frequently, it can be very beneficial to use <code>sync.Pool</code>.</p></blockquote><h5 id="PS："><a href="#PS：" class="headerlink" title="PS："></a>PS：</h5><blockquote><p>个人英语水平有限，大部分内容觉得原文跟容易理解，翻译之后就变得怪怪的，因此部分内容保留原文。不懂英语不是不想学的借口。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CPU占用过高排查</title>
      <link href="2020/12/08/linux/cpu-zhan-yong-guo-gao-pai-cha/"/>
      <url>2020/12/08/linux/cpu-zhan-yong-guo-gao-pai-cha/</url>
      
        <content type="html"><![CDATA[<h1 id="CPU占用过高排查"><a href="#CPU占用过高排查" class="headerlink" title="CPU占用过高排查"></a>CPU占用过高排查</h1><h2 id="一-简介"><a href="#一-简介" class="headerlink" title="一.简介"></a>一.简介</h2><p>最近一段时间 某台服务器上的一个应用总是隔一段时间就自己挂掉 用top看了看 从重新部署应用开始没有多长时间CPU占用上升得很快</p><p>排查步骤</p><p>1.使用top 定位到占用CPU高的进程PID<br><code>top</code></p><p>2.通过ps aux | grep PID命令<br>获取线程信息，并找到占用CPU高的线程<br><code>ps -mp pid -o THREAD,tid,time | sort -rn</code></p><p>3.将需要的线程ID转换为16进制格式<br><code>printf &quot;%x\n&quot; tid</code></p><p>4.打印线程的堆栈信息 到了这一步具体看堆栈的日志来定位问题了<br><code>jstack pid |grep tid -A 30</code></p><h2 id="二-例子"><a href="#二-例子" class="headerlink" title="二.例子"></a>二.例子</h2><p>1.<code>top</code> 可以看出PID 733进程 的占用CPU 172%<br><img src="http://52wiki.oss-cn-beijing.aliyuncs.com/doc/fb92bdc5bdb24e8bf80970c0df7f6ac426af6da6.png" alt="null"></p><p>2.查找进程733下的线程 可以看到TID 线程775占用了96%且持有了很长时间 其实到这一步基本上能猜测到应该是 肯定是那段代码发生了死循环<br><code>ps -mp 733 -o THREAD,tid,time | sort -rn</code><br><img src="http://52wiki.oss-cn-beijing.aliyuncs.com/doc/439824ac6acd7ff070d40c6ec493d4a46dd3df7b.png" alt="null"></p><p>3.线程ID转换为16进制格式<br><code>printf &quot;%x\n&quot; 775</code><br><img src="http://52wiki.oss-cn-beijing.aliyuncs.com/doc/216d653218dd336e2ec0e087c5bdb456c6a1c687.png" alt="null"></p><p>4.查看java 的堆栈信息<br><code>jstack 733 |grep 307 -A 30</code><br><img src="http://52wiki.oss-cn-beijing.aliyuncs.com/doc/052b92c367c00603377f840323e1c4034ba48cfc.png" alt="null"></p><p><img src="http://52wiki.oss-cn-beijing.aliyuncs.com/doc/3a40734e205741f6cf12628fef50a8921d8f23d5.png" alt="null"></p><p>显然是 SmsQueueServiceImpl 中的produceMissSms 和 consumeMissSms 方法有问题<br>一下为精简的部分代码</p><pre><code>/** * Created by dongxc on 2015/7/7. 通知消息队列 */@Service(&quot;smsQueueService&quot;)public class SmsQueueServiceImpl {    // 生产异常队列方法    public void produceMissSms(SmsLogDo smsLogDo) {        /*         * try{ String key = EnumRedisPrefix.SMS_QUEUE_MISS_DEAL.getValue(); boolean result = redisService.lpush(key,         * smsLogDo, 0); if(result==false){ logger.error(&quot;通知消息异常队列生产消息返回失败！&quot;+smsLogDo.getId()); } }catch(Exception e){         * logger.error(&quot;通知消息异常队列生产消息失败！&quot;, e); }         */    }    // 消费异常队列方法    public SmsLogDo consumeMissSms() {        try {            String destKey = EnumRedisPrefix.SMS_QUEUE_MISS_DEAL.getValue();            SmsLogDo smsLogDo = new SmsLogDo();            Object obj = null;            if (obj == null) {                return null;            } else {                smsLogDo = (SmsLogDo) obj;            }            return smsLogDo;        } catch (Exception e) {            logger.error(&quot;通知消息队列消费方法失败！&quot;, e);            return null;        }    }}</code></pre><p>在应用一启动的时候 spring初始化的就会执行这一段处理丢失消息的代码 然后这段死循环代码 没有任何作用</p><p>解决方法 即 注释掉whlie(true)这一段代码</p><p>重新部署后 cpu占用就很正常了<br><img src="http://52wiki.oss-cn-beijing.aliyuncs.com/doc/f11fcd96a69755f4f94f901114488b546515dab6.png" alt="null"></p><hr>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql解决主从慢同步问题</title>
      <link href="2020/11/27/sql/mysql-jie-jue-zhu-cong-man-tong-bu-wen-ti/"/>
      <url>2020/11/27/sql/mysql-jie-jue-zhu-cong-man-tong-bu-wen-ti/</url>
      
        <content type="html"><![CDATA[<h2 id="一-简介"><a href="#一-简介" class="headerlink" title="一.简介"></a>一.简介</h2><p>一般主从复制，有三个线程参与，都是单线程：Binlog Dump（主） —–&gt;IO Thread （从） —–&gt; SQL Thread（从）。复制出现延迟一般出在两个地方</p><p>1）SQL线程忙不过来（可能需要应用数据量较大，可能和从库本身的一些操作有锁和资源的冲突；主库可以并发写，SQL线程不可以；一个大的sql语句导致执行很慢；）</p><p>2）网络抖动导致IO线程复制延迟（次要原因）。</p><p>SQL thread在执行IO thread dump下来的relay log的时间差。大家都知道relay log中event记录的时间戳是主库上的时间戳，而SQL thread的时间戳是从库上的，也就是说，如果主库和从库的时间是一致的，那么这个SBM代表的确实是从库延后主库的一个时间差。但是如果主库和从库的时间不是一致的，那么这个SBM的意义就基本不存在了。将主库时间调快1小时，那从库默认慢一小时。</p><h3 id="为何有延迟"><a href="#为何有延迟" class="headerlink" title="为何有延迟"></a>为何有延迟</h3><p>1.网络延迟<br>若主从之间网络延迟到，会造成sql线程无法实时将主的binlog日志复制过来。</p><p>2.机器性能差<br>若主用的固态硬盘，从用的机械硬盘，那读取速度自然不一样，会造成主写入很快，从在慢慢读取，这样就不适合读写分离了。</p><p>3.高负载<br>若从机器还安装了别的服务，用<code>top</code>可以看出是否有其它进程在占用资源，导致从性能下降。</p><p>4.磁盘负载<br>用<code>iotop</code>可以看到当前磁盘的负载，若正在复制某些东西，会导致将主的binlog复制过来了，但写入到从mysql中会很慢，数据不一致。</p><p>5.是否经常会有大事务？<br>这个可能DBA们会遇到比较多，比如在RBR模式下，执行带有大量的Delete操作，或者在MBR模式下删除时添加了不确定语句（类似limit）或一个表的Alter操作等，都会导致延迟情况的发生。</p><p>这种可通过查看Processlist相关信息，以及使用mysqlbinlog查看binlog中的SQL就能快速进行确认。这个设想也被排除。</p><p>6.死锁<br>锁冲突问题也可能导致从机的SQL线程执行慢，比如从机上有一些select …. for update的SQL，或者使用了MyISAM引擎等。此类问题，可以通过抓去Processlist以及查看information_schema下面和锁以及事务相关的表来查看。</p><h2 id="二-观察"><a href="#二-观察" class="headerlink" title="二.观察"></a>二.观察</h2><p>在主上用<code>SHOW MASTER STATUS;</code>查看最新的binlog日志，在从上用<code>show slave status\G;</code>查看<strong>Master_Log_File</strong>，如果是一样的，说明sql线程将主的binlog日志都复制过来了，这是没延迟的。如果<strong>Seconds_Behind_Master</strong>是0则IO线程将同步过来的binlog日志都加载了，那延迟为0。</p><p><strong>seconds_behind_master</strong>如果一直为0，突然就很高，那是因为主库在执行一个大的事件，当事件执行完成后从才开始复制，sbm会突然很高。</p><h2 id="三-解决办法"><a href="#三-解决办法" class="headerlink" title="三.解决办法"></a>三.解决办法</h2><h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><p>关闭binlog日志可以减轻从库的负载</p><p>配置文件添加如下，将不缓冲直接写入，从而加速性能</p><pre class=" language-shell"><code class="language-shell">sync_binlog=0innodb_flushloginnodb_flush_log_at_trx_commi=0</code></pre><h3 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h3><p>5.6开始MySQL正式支持多线程复制，如下命令查看有多少个线程在同步。<br><code>show variables like &#39;%slave_parallel%&#39;</code><br><img src="http://linkdevops.oss-cn-beijing.aliyuncs.com/wp-content/uploads/2020/04/image-1588056883161.png" alt="file"></p><p>slave_parallel_type<br>为DATABASE时，基于数据库的并发，也就是每一个数据库都有一个线程去同步，如果只有一个数据库，那其它线程不工作。不同库下的表并发提交时的数据不会相互影响，即slave节点可以用对relay log中不同的库各分配一个类似SQL功能的线程，来重放relay log中主库已经提交的事务，保持数据与主库一致。</p><p>为LOGICAL_CLOCK时，则可以一个数据库一个多线程同步。一个组提交的事务都是可以并行回放（配合binary log group commit）。</p><p>slave_parallel_workers<br>代表启动多少个线程用于同步，0就是默认1个。</p><p>静态设置：</p><pre class=" language-shell"><code class="language-shell">slave_parallel_type='LOGICAL_CLOCK'slave_parallel_workers=8</code></pre><p>动态设置：<br><code>SET GLOBAL slave_parallel_type=&#39;LOGICAL_CLOCK&#39;;</code><br><code>SET GLOBAL slave_parallel_workers=8;</code></p><h3 id="组提交"><a href="#组提交" class="headerlink" title="组提交"></a>组提交</h3><p>在5.7中，多线程复制的功能有很很大的改善，支持LOGICAL_CLOCK的方式，在这种方式下，并发执行的多个事务只要能在同一时刻commit，就说明线程之间没有锁冲突，那么Master就可以将这一组的事务标记并在slave机器上安全的进行并发执行。</p><p>因此，可以尽可能地使所有线程能在同一时刻提交，这样就能很大程度上提升从机的执行的并行度，从而减少从机的延迟。</p><p>有了这个猜想后，很自然想到了人为控制尽可能多地使所有线程在同一时刻提交，其实官方已经给我们提供了类似的参数，参数如下：<br>binlog_group_commit_sync_delay</p><p>备注：这个参数会对延迟SQL的响应，对延迟非常敏感的环境需要特别注意，单位是微秒。</p><p>由于是监控的DB，主要是load数据，然后进行展示，1秒左右的导入延迟对业务没什么影响，因此将两个参数调整为：<br><code>SET GLOBAL binlog_group_commit_sync_delay = 1000000;</code><br><code>SET GLOBAL binlog_group_commit_sync_no_delay_count = 20;</code></p><p>备注：这两个参数请根据业务特性进行调整，以免造成线上故障。</p><p>为了防止导入SQL堆积，设置SET GLOBAL binlog_group_commit_sync_no_delay_count为20，在达到20个事务时不管是否达到了1秒都进行提交，来减少对业务的影响。</p>]]></content>
      
      
      <categories>
          
          <category> SQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Interview </tag>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>keepalived配置nfs高可用</title>
      <link href="2020/11/24/linux/keepalived-pei-zhi-nfs-gao-ke-yong/"/>
      <url>2020/11/24/linux/keepalived-pei-zhi-nfs-gao-ke-yong/</url>
      
        <content type="html"><![CDATA[<h5 id="一-简介"><a href="#一-简介" class="headerlink" title="一.简介"></a>一.简介</h5><p>NFS是单点的，如果一个节点出现问题，那使用它挂载服务的都将出现问题。所以需要高可用，挂掉一台不影响。<br>采用keepalived+rsync+inotify-tools</p><p>环境：ubuntu16.4<br>nfs1 192.168.1.1 /mnt/server<br>nfs2 192.168.1.2 /mnt/server</p><p>虚拟地址 192.168.1.3</p><h5 id="二-操作"><a href="#二-操作" class="headerlink" title="二.操作"></a>二.操作</h5><h6 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h6><p>1.机器之间添加信任关系免密码登录，安装nfs</p><p>2.有三项输出,则表示默认支持inotify,可以安装inotify-tools工具.<br><code>ll /proc/sys/fs/inotify</code></p><blockquote><p>-rw-r–r– 1 root root 0 Oct 18 12:18 max_queued_events<br>-rw-r–r– 1 root root 0 Oct 18 12:18 max_user_instances<br>-rw-r–r– 1 root root 0 Oct 18 12:18 max_user_watches</p></blockquote><h6 id="同步配置（2台服务器均操作）"><a href="#同步配置（2台服务器均操作）" class="headerlink" title="同步配置（2台服务器均操作）"></a>同步配置（2台服务器均操作）</h6><p>1.编写脚本<br><code>vim sync_nfs.sh</code></p><pre class=" language-shell"><code class="language-shell">#!/bin/bash#监控本地目录，有变动则输出一下inotifywait -mrq --timefmt '%d/%m/%y %H:%M' --format '%T %w%f%e' -e close_write,delete,create,attrib /mnt/server/ |  while read filedo    #将本地同步到远程目录，这里要根据实际情况修改    rsync -avz --delete  /mnt/server/ root@192.168.1.1:/mnt/server/    echo "  ${file} was rsynced" >>/tmp/rsync.log 2>&1done</code></pre><p>2.添加权限并运行<br><code>chmod +x sync_nfs.sh</code><br><code>nohup inotify_bak.sh &amp;</code></p><p>3.查看日志<br><code>tail -f /tmp/rsync.log</code></p><p>4.提示<br>如果是主备模式，则一个脚本直接同步即可，如果是双方做备份，则要写2个脚本进行互相同步</p><h6 id="主备切换（均操作）"><a href="#主备切换（均操作）" class="headerlink" title="主备切换（均操作）"></a>主备切换（均操作）</h6><p>1.安装keepalived<br><code>apt-get install keepalived -y</code></p><p>2.编写文件，默认可能没有配置文件，直接新建即可<br><code>vim /etc/keepalived/keepalived.conf</code></p><pre class=" language-shell"><code class="language-shell">! Configuration File for keepalivedglobal_defs { #全局配置   router_id lb01 #路由id号，不能重复}vrrp_script nfs  #vrrp脚本命名{    script "/etc/keepalived/check_nfs.sh" #要执行的脚本    interval 2 #脚本指定间隔    weight -40   #优先级（如果脚本执行结果为0，并且weight配置的值大于0，则优先级相应的增加，如果脚本执行结果非0，并且weight配置的值小于0，则优先级相应的减少）}vrrp_instance VI_1 { #定义一个实例    state MASTER #态参数 master/backup 只是说明，具体根据优先级    interface eth0 #虚IP地址放置的网卡位置    virtual_router_id 51 #同一个集群id一致    priority 100 #优先级决定是主还是备    越大越优先    advert_int 1 #主备通讯时间间隔    authentication {        auth_type PASS        auth_pass 1111 #认证号，集群中要一致    }    virtual_ipaddress {        192.168.1.3 #使用的虚拟ip，要和网段内ip不冲突    }}</code></pre><p>备份nfs配置文件，这是不一样的</p><pre class=" language-shell"><code class="language-shell">! Configuration File for keepalivedglobal_defs { #全局配置   router_id lb02 #路由id号，不能重复}vrrp_script nfs  #vrrp脚本命名{    script "/etc/keepalived/check_nfs.sh" #要执行的脚本    interval 2 #脚本指定间隔    weight -40   #优先级（如果脚本执行结果为0，并且weight配置的值大于0，则优先级相应的增加，如果脚本执行结果非0，并且weight配置的值小于0，则优先级相应的减少）}vrrp_instance VI_1 { #定义一个实例    state BACKUP #态参数 master/backup 只是说明，具体根据优先级    interface eth0 #虚IP地址放置的网卡位置    virtual_router_id 51 #同一个集群id一致    priority 80 #优先级决定是主还是备    越大越优先    advert_int 1 #主备通讯时间间隔    authentication {        auth_type PASS        auth_pass 1111 #认证号，集群中要一致    }    virtual_ipaddress {        192.168.1.3 #使用的虚拟ip，要和网段内ip不冲突    }}</code></pre><p>3.编写检查脚本<br><code>vim /etc/keepalived/check_nfs.sh</code></p><pre class=" language-shell"><code class="language-shell">#!/bin/bash#nfs服务检测脚本，服务不存在则返回1A=`ps -aux | grep '\[nfsd\]' | wc -l`if [ $A -eq 0 ];then    exit 1 #测试的时候可以加一个echo 1fi</code></pre><p>添加权限<br><code>chmod +x /etc/keepalived/check_nfs.sh</code></p><p>4.测试<br>systemctl start keepalived</p><p>查看是否有配置的虚拟ip，ping一下试试，只会在主上面出现<br><code>ip addr</code></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> keepalived </tag>
            
            <tag> NFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mongodb单点部署</title>
      <link href="2020/11/22/sql/mongodb-dan-dian-bu-shu/"/>
      <url>2020/11/22/sql/mongodb-dan-dian-bu-shu/</url>
      
        <content type="html"><![CDATA[<h5 id="一-依赖和环境"><a href="#一-依赖和环境" class="headerlink" title="一.依赖和环境"></a>一.依赖和环境</h5><p>centos7.2，4核cpu, 8G内存 100G硬盘<br>版本：3.4.7社区版本<br>端口：27017<br>数据目录：/usr/local/mongodb/data/mongodb<br>配置文件：/usr/local/mongodb/data/mongodb.conf</p><h5 id="二-部署"><a href="#二-部署" class="headerlink" title="二.部署"></a>二.部署</h5><p>1.下载3.4.7版本<br><code>wget http://downloads.mongodb.org/linux/mongodb-linux-x86_64-rhel70-3.4.7.tgz?_ga=2.27332668.129100306.1533718841-1981701661.1533718841</code></p><p>2.改名并移动<br><code>mv mongodb-* mongodb.tgz</code><br><code>tar -xf mongodb.tgz</code><br><code>mv mongodb-linux-x86_64-rhel70-3.4.7 /usr/lcoal/mongodb</code><br><code>chmod +x /usr/local/mongodb/bin/*</code></p><p>3.添加环境变量<br><code>vim /etc/profile</code></p><pre class=" language-shell"><code class="language-shell">export PATH=/usr/local/mongodb/bin:$PATHsource/etc/profile</code></pre><p>4.创建数据目录和日志目录<br><code>cd /usr/local/mongodb/</code><br><code>mkdir -p data/mongodb</code><br><code>mkdir -p data/logs</code></p><p>5.编写配置文件<br><code>vim data/mongodb.conf</code></p><pre class=" language-shell"><code class="language-shell">bind_ip = 192.168.146.38port = 27017#后台运行fork = true## 数据目录dbpath=/usr/local/mongodb/data/mongodb## 日志路径logpath=/usr/local/mongodb/data/logs/mongod.log## is log Rotate mongoDB 3.0logappend = true#logRotate = true## 开启日志journal = true## 使用小文件进行开发smallfiles = true</code></pre><h5 id="三-启动和测试"><a href="#三-启动和测试" class="headerlink" title="三.启动和测试"></a>三.启动和测试</h5><p>1.启动<br><code>mongod --config /usr/local/mongodb/data/mongodb.conf</code></p><p>2.显示如下正确</p><pre class=" language-shell"><code class="language-shell">about to fork child process, waiting until server is ready for connections.forked process: 17802child process started successfully, parent exiting</code></pre><p>3.查看进程<br><code>netstat -unltp | grep mongo</code></p>]]></content>
      
      
      <categories>
          
          <category> SQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mongodb </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes-network</title>
      <link href="2020/11/21/container/kubernetes-network/"/>
      <url>2020/11/21/container/kubernetes-network/</url>
      
        <content type="html"><![CDATA[<h4 id="Kubernetes-network"><a href="#Kubernetes-network" class="headerlink" title="Kubernetes-network"></a>Kubernetes-network</h4><p><a href="https://www.katacoda.com/courses/kubernetes/networking-introduction" target="_blank" rel="noopener">https://www.katacoda.com/courses/kubernetes/networking-introduction</a></p><blockquote><p>Kubernetes Services是一个抽象，它定义了有关如何访问一组Pod的策略和方法。通过服务访问的Pod集合基于标签选择器。</p></blockquote><h5 id="Cluster-IP"><a href="#Cluster-IP" class="headerlink" title="Cluster IP"></a>Cluster IP</h5><blockquote><p>创建Kubernetes服务时，群集IP是默认方法。为该服务分配了一个内部IP，其他组件可以使用该IP来访问Pod。</p><p>通过使用单个IP地址，它可以使服务在多个Pod之间实现负载平衡。 </p></blockquote><p>服务通过以下方式部署<code>kubectl apply -f clusterip.yaml</code></p><p>定义可以在以下位置查看<code>cat clusterip.yaml</code></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Service<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> webapp1<span class="token punctuation">-</span>clusterip<span class="token punctuation">-</span>svc  <span class="token key atrule">labels</span><span class="token punctuation">:</span>    <span class="token key atrule">app</span><span class="token punctuation">:</span> webapp1<span class="token punctuation">-</span>clusterip<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">ports</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">80</span>  <span class="token key atrule">selector</span><span class="token punctuation">:</span>    <span class="token key atrule">app</span><span class="token punctuation">:</span> webapp1<span class="token punctuation">-</span>clusterip<span class="token punctuation">---</span><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> extensions/v1beta1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Deployment<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> webapp1<span class="token punctuation">-</span>clusterip<span class="token punctuation">-</span>deployment<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">replicas</span><span class="token punctuation">:</span> <span class="token number">2</span>  <span class="token key atrule">template</span><span class="token punctuation">:</span>    <span class="token key atrule">metadata</span><span class="token punctuation">:</span>      <span class="token key atrule">labels</span><span class="token punctuation">:</span>        <span class="token key atrule">app</span><span class="token punctuation">:</span> webapp1<span class="token punctuation">-</span>clusterip    <span class="token key atrule">spec</span><span class="token punctuation">:</span>      <span class="token key atrule">containers</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> webapp1<span class="token punctuation">-</span>clusterip<span class="token punctuation">-</span>pod        <span class="token key atrule">image</span><span class="token punctuation">:</span> katacoda/docker<span class="token punctuation">-</span>http<span class="token punctuation">-</span>server<span class="token punctuation">:</span>latest        <span class="token key atrule">ports</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">containerPort</span><span class="token punctuation">:</span> <span class="token number">80</span><span class="token punctuation">---</span></code></pre><p>这将部署一个具有两个副本的Web应用程序，以展示负载平衡以及一项服务。可以在以下位置查看 pod    <code>kubectl get pods</code></p><pre class=" language-shell"><code class="language-shell">NAME                                            READY   STATUS              RESTARTS   AGEwebapp1-clusterip-deployment-669c7c65c4-pq9lw   0/1     ContainerCreating   0          40swebapp1-clusterip-deployment-669c7c65c4-smv5m   0/1     ContainerCreating   0          40s</code></pre><p>它还将部署服务<code>kubectl get svc</code></p><pre class=" language-shell"><code class="language-shell">NAME                    TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGEkubernetes              ClusterIP   10.96.0.1      <none>        443/TCP   42mwebapp1-clusterip-svc   ClusterIP   10.102.70.19   <none>        80/TCP    2m6s</code></pre><p>有关服务配置和活动端点（Pods）的更多详细信息，可以通过以下方式查看<code>kubectl describe svc/webapp1-clusterip-svc</code></p><pre class=" language-shell"><code class="language-shell">Name:              webapp1-clusterip-svcNamespace:         defaultLabels:            app=webapp1-clusteripAnnotations:       kubectl.kubernetes.io/last-applied-configuration:                     {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app":"webapp1-clusterip"},"name":"webapp1-clusterip-svc","name...Selector:          app=webapp1-clusteripType:              ClusterIPIP:                10.102.70.19Port:              <unset>  80/TCPTargetPort:        80/TCPEndpoints:         10.32.0.5:80,10.32.0.6:80Session Affinity:  NoneEvents:            <none></code></pre><p>部署后，可以通过分配的ClusterIP访问该服务。</p><pre class=" language-shell"><code class="language-shell">export CLUSTER_IP=$(kubectl get services/webapp1-clusterip-svc -o go-template='{{(index .spec.clusterIP)}}')echo CLUSTER_IP=$CLUSTER_IPcurl $CLUSTER_IP:80</code></pre><p>多个请求将展示基于公共标签选择器的跨多个Pod的服务负载平衡器。<code>curl $CLUSTER_IP:80</code></p><h5 id="Target-Ports"><a href="#Target-Ports" class="headerlink" title="Target Ports"></a>Target Ports</h5><blockquote><p>目标端口允许我们将应用程序可用的端口与应用程序正在侦听的端口分开。</p><p>TargetPort是应用程序配置为侦听的端口。 端口是从外部访问应用程序的方式。</p></blockquote><p>与以前类似，服务和额外的Pod通过<code>kubectl apply -f clusterip-target.yaml</code></p><p>以下命令将创建服务。</p><p><code>cat clusterip-target.yaml</code></p><pre class=" language-shell"><code class="language-shell">apiVersion: v1kind: Servicemetadata:  name: webapp1-clusterip-targetport-svc  labels:    app: webapp1-clusterip-targetportspec:  ports:  - port: 8080    targetPort: 80  selector:    app: webapp1-clusterip-targetport---apiVersion: extensions/v1beta1kind: Deploymentmetadata:  name: webapp1-clusterip-targetport-deploymentspec:  replicas: 2  template:    metadata:      labels:        app: webapp1-clusterip-targetport    spec:      containers:      - name: webapp1-clusterip-targetport-pod        image: katacoda/docker-http-server:latest        ports:        - containerPort: 80---</code></pre><pre class=" language-shell"><code class="language-shell">controlplane $ kubectl get svcNAME                               TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGEkubernetes                         ClusterIP   10.96.0.1        <none>        443/TCP    47mwebapp1-clusterip-svc              ClusterIP   10.102.70.19     <none>        80/TCP     8mwebapp1-clusterip-targetport-svc   ClusterIP   10.102.212.110   <none>        8080/TCP   2m27s</code></pre><pre class=" language-shell"><code class="language-shell">controlplane $ kubectl describe svc/webapp1-clusterip-targetport-svcName:              webapp1-clusterip-targetport-svcNamespace:         defaultLabels:            app=webapp1-clusterip-targetportAnnotations:       kubectl.kubernetes.io/last-applied-configuration:                     {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app":"webapp1-clusterip-targetport"},"name":"webapp1-clusterip...Selector:          app=webapp1-clusterip-targetportType:              ClusterIPIP:                10.102.212.110Port:              <unset>  8080/TCPTargetPort:        80/TCPEndpoints:         10.32.0.7:80,10.32.0.8:80Session Affinity:  NoneEvents:            <none></code></pre><p>部署服务和Pod之后，可以像以前一样通过群集IP访问它，但是这次是在定义的端口8080上进行的。</p><pre class=" language-shell"><code class="language-shell">controlplane $ export CLUSTER_IP=$(kubectl get services/webapp1-clusterip-targetport-svc -o go-template='{{(index .spec.clusterIP)}}')controlplane $ echo CLUSTER_IP=$CLUSTER_IPCLUSTER_IP=10.102.212.110controlplane $ curl $CLUSTER_IP:8080<h1>This request was processed by host: webapp1-clusterip-targetport-deployment-5599945ff4-ttv9c</h1>controlplane $ curl $CLUSTER_IP:8080<h1>This request was processed by host: webapp1-clusterip-targetport-deployment-5599945ff4-ttv9c</h1>controlplane $</code></pre><p>该应用程序本身仍配置为侦听端口80。Kubernetes Service管理二者之间的转换。</p><h5 id="NodePort"><a href="#NodePort" class="headerlink" title="NodePort"></a>NodePort</h5><blockquote><p>虽然TargetPort和ClusterIP使其可用于群集内部，但NodePort通过定义的静态端口将服务公开到每个Node的IP上。 无论访问群集中的哪个节点，都可以根据定义的端口号访问该服务。</p></blockquote><p><code>kubectl apply -f nodeport.yaml</code></p><pre class=" language-shell"><code class="language-shell">controlplane $ kubectl apply -f nodeport.yamlservice/webapp1-nodeport-svc createddeployment.extensions/webapp1-nodeport-deployment created</code></pre><p>查看服务定义时，请注意定义的其他类型和NodePort属性</p><pre class=" language-shell"><code class="language-shell">controlplane $ cat nodeport.yamlapiVersion: v1kind: Servicemetadata:  name: webapp1-nodeport-svc  labels:    app: webapp1-nodeportspec:  type: NodePort  ports:  - port: 80    nodePort: 30080  selector:    app: webapp1-nodeport---apiVersion: extensions/v1beta1kind: Deploymentmetadata:  name: webapp1-nodeport-deploymentspec:  replicas: 2  template:    metadata:      labels:        app: webapp1-nodeport    spec:      containers:      - name: webapp1-nodeport-pod        image: katacoda/docker-http-server:latest        ports:        - containerPort: 80---controlplane $ kubectl get svcNAME                               TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGEkubernetes                         ClusterIP   10.96.0.1        <none>        443/TCP        51mwebapp1-clusterip-svc              ClusterIP   10.102.70.19     <none>        80/TCP         11mwebapp1-clusterip-targetport-svc   ClusterIP   10.102.212.110   <none>        8080/TCP       5m47swebapp1-nodeport-svc               NodePort    10.111.49.13     <none>        80:30080/TCP   43scontrolplane $ kubectl describe svc/webapp1-nodeport-svcName:                     webapp1-nodeport-svcNamespace:                defaultLabels:                   app=webapp1-nodeportAnnotations:              kubectl.kubernetes.io/last-applied-configuration:                            {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app":"webapp1-nodeport"},"name":"webapp1-nodeport-svc","namesp...Selector:                 app=webapp1-nodeportType:                     NodePortIP:                       10.111.49.13Port:                     <unset>  80/TCPTargetPort:               80/TCPNodePort:                 <unset>  30080/TCPEndpoints:                10.32.0.10:80,10.32.0.9:80Session Affinity:         NoneExternal Traffic Policy:  ClusterEvents:                   <none></code></pre><p>现在可以通过定义的NodePort上的Node IP地址访问该服务。</p><pre class=" language-shell"><code class="language-shell">controlplane $ curl 172.17.0.63:30080<h1>This request was processed by host: webapp1-nodeport-deployment-677bd89b96-vjm24</h1></code></pre><h5 id="External-IPs"><a href="#External-IPs" class="headerlink" title="External IPs"></a>External IPs</h5><blockquote><p>使服务在群集外部可用的另一种方法是通过外部IP地址。</p></blockquote><p>使用以下命令将定义更新为当前集群的IP地址</p><pre class=" language-shell"><code class="language-shell">controlplane $ sed -i 's/HOSTIP/172.17.0.63/g' externalip.yamlcontrolplane $ cat externalip.yamlapiVersion: v1kind: Servicemetadata:  name: webapp1-externalip-svc  labels:    app: webapp1-externalipspec:  ports:  - port: 80  externalIPs:  - 172.17.0.63  selector:    app: webapp1-externalip---apiVersion: extensions/v1beta1kind: Deploymentmetadata:  name: webapp1-externalip-deploymentspec:  replicas: 2  template:    metadata:      labels:        app: webapp1-externalip    spec:      containers:      - name: webapp1-externalip-pod        image: katacoda/docker-http-server:latest        ports:        - containerPort: 80---controlplane $ kubectl apply -f externalip.yamlservice/webapp1-externalip-svc createddeployment.extensions/webapp1-externalip-deployment createdcontrolplane $ kubectl get svcNAME                               TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGEkubernetes                         ClusterIP   10.96.0.1        <none>        443/TCP        56mwebapp1-clusterip-svc              ClusterIP   10.102.70.19     <none>        80/TCP         16mwebapp1-clusterip-targetport-svc   ClusterIP   10.102.212.110   <none>        8080/TCP       10mwebapp1-externalip-svc             ClusterIP   10.101.191.29    172.17.0.63   80/TCP         7swebapp1-nodeport-svc               NodePort    10.111.49.13     <none>        80:30080/TCP   5m50scontrolplane $ kubectl describe svc/webapp1-externalip-svcName:              webapp1-externalip-svcNamespace:         defaultLabels:            app=webapp1-externalipAnnotations:       kubectl.kubernetes.io/last-applied-configuration:                     {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app":"webapp1-externalip"},"name":"webapp1-externalip-svc","na...Selector:          app=webapp1-externalipType:              ClusterIPIP:                10.101.191.29External IPs:      172.17.0.63Port:              <unset>  80/TCPTargetPort:        80/TCPEndpoints:         <none>Session Affinity:  NoneEvents:            <none></code></pre><p>现在，该服务已绑定到主节点的IP地址和端口80。</p><pre class=" language-shell"><code class="language-shell">controlplane $ curl 172.17.0.63<h1>This request was processed by host: webapp1-externalip-deployment-6446b488f8-5v2fj</h1></code></pre><h5 id="Load-Balancer"><a href="#Load-Balancer" class="headerlink" title="Load Balancer"></a>Load Balancer</h5><blockquote><p>在EC2或Azure等云中运行时，可以配置和分配通过云提供商发布的公共IP地址。 这将通过负载平衡器（例如ELB）发布。 这允许将其他公共IP地址分配给Kubernetes集群，而无需直接与云提供商进行交互。</p></blockquote><p>由于Katacoda不是云提供商，因此仍然可以为LoadBalancer类型的服务动态分配IP地址。这是通过使用以下方法部署云提供程序来完成的：</p><pre class=" language-shell"><code class="language-shell">controlplane $ kubectl apply -f cloudprovider.yamldaemonset.extensions/kube-keepalived-vip configuredconfigmap/vip-configmap configureddeployment.apps/keepalived-cloud-provider created</code></pre><blockquote><p>PS：在由云提供商提供的服务中运行时，这不是必需的。</p></blockquote><p>当服务请求负载平衡器时，提供程序将在配置中定义的10.10.0.0/26范围内分配一个。</p><pre class=" language-shell"><code class="language-shell">controlplane $ kubectl get pods -n kube-systemNAME                                        READY   STATUS              RESTARTS   AGEcoredns-fb8b8dccf-fd6jl                     0/1     ContainerCreating   0          45scoredns-fb8b8dccf-mnn9l                     0/1     ContainerCreating   0          45skatacoda-cloud-provider-5787995f6c-rxrn5    0/1     ContainerCreating   0          45skeepalived-cloud-provider-78fc4468b-s4kfk   0/1     ContainerCreating   0          45skube-keepalived-vip-548kd                   0/1     ContainerCreating   0          11skube-proxy-q7dng                            1/1     Running             0          45sweave-net-s2hvv                             2/2     Running             0          45scontrolplane $ kubectl apply -f loadbalancer.yamlservice/webapp1-loadbalancer-svc createddeployment.extensions</code></pre><p>通过负载均衡器配置服务，如· ·</p><pre class=" language-shell"><code class="language-shell">controlplane $ cat loadbalancer.yamlapiVersion: v1kind: Servicemetadata:  name: webapp1-loadbalancer-svc  labels:    app: webapp1-loadbalancerspec:  type: LoadBalancer  ports:  - port: 80  selector:    app: webapp1-loadbalancer---apiVersion: extensions/v1beta1kind: Deploymentmetadata:  name: webapp1-loadbalancer-deploymentspec:  replicas: 2  template:    metadata:      labels:        app: webapp1-loadbalancer    spec:      containers:      - name: webapp1-loadbalancer-pod        image: katacoda/docker-http-server:latest        ports:        - containerPort: 80---</code></pre><p>在定义IP地址时，服务将显示Pending（待定）。分配后，它将出现在服务列表中。</p><pre class=" language-shell"><code class="language-shell">controlplane $ kubectl get svcNAME                       TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGEkubernetes                 ClusterIP      10.96.0.1       <none>        443/TCP        2m47swebapp1-loadbalancer-svc   LoadBalancer   10.106.110.15   10.10.0.1     80:31226/TCP   103scontrolplane $ kubectl describe svc/webapp1-loadbalancer-svcName:                     webapp1-loadbalancer-svcNamespace:                defaultLabels:                   app=webapp1-loadbalancerAnnotations:              kubectl.kubernetes.io/last-applied-configuration:                            {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app":"webapp1-loadbalancer"},"name":"webapp1-loadbalancer-svc"...Selector:                 app=webapp1-loadbalancerType:                     LoadBalancerIP:                       10.106.110.15LoadBalancer Ingress:     10.10.0.1Port:                     <unset>  80/TCPTargetPort:               80/TCPNodePort:                 <unset>  31226/TCPEndpoints:                10.32.0.6:80,10.32.0.7:80Session Affinity:         NoneExternal Traffic Policy:  ClusterEvents:  Type    Reason                Age   From                Message  ----    ------                ----  ----                -------  Normal  CreatingLoadBalancer  103s  service-controller  Creating load balancer  Normal  CreatedLoadBalanc</code></pre><p>现在可以通过分配的IP地址（在这种情况下，从10.10.0.0/26范围）访问该服务。</p><pre class=" language-shell"><code class="language-shell">controlplane $ echo LoadBalancerIP=$LoadBalancerIPLoadBalancerIP=10.10.0.1controlplane $ curl $LoadBalancerIP<h1>This request was processed by host: webapp1-loadbalancer-deployment-f45b8d9cd-lgs2r</h1>controlplane $ curl $LoadBalancerIP<h1>This request was processed </code></pre>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker-网络模式</title>
      <link href="2020/11/16/container/docker-wang-luo-mo-shi/"/>
      <url>2020/11/16/container/docker-wang-luo-mo-shi/</url>
      
        <content type="html"><![CDATA[<h3 id="Docker四种网络模式"><a href="#Docker四种网络模式" class="headerlink" title="Docker四种网络模式"></a>Docker四种网络模式</h3><h4 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h4><p>Docker使用Linux桥接（参考<a href="https://www.jianshu.com/p/f86d4b88777d" target="_blank" rel="noopener">《Linux虚拟网络技术》</a>），在宿主机虚拟一个Docker容器网桥(docker0)，Docker启动一个容器时会根据Docker网桥的网段分配给容器一个IP地址，称为Container-IP，同时Docker网桥是每个容器的默认网关。因为在同一宿主机内的容器都接入同一个网桥，这样容器之间就能够通过容器的Container-IP直接通信。</p><p>Docker网桥是宿主机虚拟出来的，并不是真实存在的网络设备，外部网络是无法寻址到的，这也意味着外部网络无法通过直接Container-IP访问到容器。如果容器希望外部访问能够访问到，可以通过映射容器端口到宿主主机（端口映射），即docker run创建容器时候通过 -p 或 -P 参数来启用，访问容器的时候就通过[宿主机IP]:[容器端口]访问容器。</p><h4 id="四类网络模式"><a href="#四类网络模式" class="headerlink" title="四类网络模式"></a>四类网络模式</h4><table><thead><tr><th>Docker网络模式</th><th>配置</th><th>说明</th></tr></thead><tbody><tr><td>host模式</td><td>–net=host</td><td>容器和宿主机共享Network namespace。</td></tr><tr><td>container模式</td><td>–net=container:NAME_or_ID</td><td>容器和另外一个容器共享Network namespace。 kubernetes中的pod就是多个容器共享一个Network namespace。</td></tr><tr><td>none模式</td><td>–net=none</td><td>容器有独立的Network namespace，但并没有对其进行任何网络设置，如分配veth pair 和网桥连接，配置IP等。</td></tr><tr><td>bridge模式</td><td>–net=bridge</td><td>（默认为该模式）</td></tr></tbody></table><h5 id="host模式"><a href="#host模式" class="headerlink" title="host模式"></a>host模式</h5><p>如果启动容器的时候使用host模式，那么这个容器将不会获得一个独立的Network Namespace，而是和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。但是，容器的其他方面，如文件系统、进程列表等还是和宿主机隔离的。</p><p>使用host模式的容器可以直接使用宿主机的IP地址与外界通信，容器内部的服务端口也可以使用宿主机的端口，不需要进行NAT，host最大的优势就是网络性能比较好，但是docker host上已经使用的端口就不能再用了，网络的隔离性不好。</p><p>Host模式如下图所示：</p><p><a href="https://imgchr.com/i/DVgnLF" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/11/17/DVgnLF.png" alt="DVgnLF.png"></a></p><p>Host模式</p><h5 id="container模式"><a href="#container模式" class="headerlink" title="container模式"></a>container模式</h5><p>这个模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过 lo 网卡设备通信。</p><p>Container模式示意图：</p><p><a href="https://imgchr.com/i/DVgMdJ" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/11/17/DVgMdJ.png" alt="DVgMdJ.png"></a></p><p>Container网络模式</p><h5 id="none模式"><a href="#none模式" class="headerlink" title="none模式"></a>none模式</h5><p>使用none模式，Docker容器拥有自己的Network Namespace，但是，并不为Docker容器进行任何网络配置。也就是说，这个Docker容器没有网卡、IP、路由等信息。需要我们自己为Docker容器添加网卡、配置IP等。</p><p>这种网络模式下容器只有lo回环网络，没有其他网卡。none模式可以在容器创建时通过–network=none来指定。这种类型的网络没有办法联网，封闭的网络能很好的保证容器的安全性。</p><p>None模式示意图:</p><p><a href="https://imgchr.com/i/DVg3J1" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/11/17/DVg3J1.png" alt="DVg3J1.png"></a></p><p>None网络模式</p><h5 id="bridge模式"><a href="#bridge模式" class="headerlink" title="bridge模式"></a>bridge模式</h5><p>当Docker进程启动时，会在主机上创建一个名为docker0的虚拟网桥，此主机上启动的Docker容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。</p><p>从docker0子网中分配一个IP给容器使用，并设置docker0的IP地址为容器的默认网关。在主机上创建一对虚拟网卡veth pair设备，Docker将veth pair设备的一端放在新创建的容器中，并命名为eth0（容器的网卡），另一端放在主机中，以vethxxx这样类似的名字命名，并将这个网络设备加入到docker0网桥中。可以通过brctl show命令查看。</p><p>bridge模式是docker的默认网络模式，不写–net参数，就是bridge模式。使用docker run -p时，docker实际是在iptables做了DNAT规则，实现端口转发功能。可以使用iptables -t nat -vnL查看。</p><p>bridge模式如下图所示：</p><p><a href="https://imgchr.com/i/DVgYQK" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/11/17/DVgYQK.png" alt="DVgYQK.png"></a></p><p>Docker的网络实现</p>]]></content>
      
      
      <categories>
          
          <category> Interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes-二进制部署</title>
      <link href="2020/11/15/container/er-jin-zhi-an-zhuang-k8s-2020-11-15/"/>
      <url>2020/11/15/container/er-jin-zhi-an-zhuang-k8s-2020-11-15/</url>
      
        <content type="html"><![CDATA[<h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><h5 id="1-1-生产环境"><a href="#1-1-生产环境" class="headerlink" title="1.1 生产环境"></a><strong>1.1 生产环境</strong></h5><p><strong>可部署Kubernetes集群的两种方式</strong></p><p>目前生产部署Kubernetes集群主要有两种方式：</p><p><strong>·</strong> <strong>kubeadm</strong></p><p>Kubeadm是一个K8s部署工具，提供kubeadm init和kubeadm join，用于快速部署Kubernetes集群。</p><p>官方地址：<a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/" target="_blank" rel="noopener">https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/</a></p><p><strong>·</strong> <strong>二进制包</strong></p><p>从github下载发行版的二进制包，手动部署每个组件，组成Kubernetes集群。</p><p>Kubeadm降低部署门槛，但屏蔽了很多细节，遇到问题很难排查。如果想更容易可控，推荐使用二进制包部署Kubernetes集群，虽然手动部署麻烦点，期间可以学习很多工作原理，也利于后期维护。</p><h5 id="1-2-安装要求"><a href="#1-2-安装要求" class="headerlink" title="1.2 安装要求"></a><strong>1.2 安装要求</strong></h5><p>在开始之前，部署Kubernetes集群机器需要满足以下几个条件：</p><ul><li><p>· 一台或多台机器，操作系统 CentOS7.x-86_x64</p></li><li><p>· 硬件配置：2GB或更多RAM，2个CPU或更多CPU，硬盘30GB或更多</p></li><li><p>· 集群中所有机器之间网络互通</p></li><li><p>· 可以访问外网，需要拉取镜像，如果服务器不能上网，需要提前下载镜像并导入节点</p></li><li><p>· 禁止swap分区</p></li></ul><h5 id="1-3-准备环境"><a href="#1-3-准备环境" class="headerlink" title="1.3 准备环境"></a><strong>1.3 准备环境</strong></h5><p>软件环境：</p><table><thead><tr><th><strong>软件</strong></th><th><strong>版本</strong></th></tr></thead><tbody><tr><td>操作系统</td><td>CentOS7.8_x64 （mini）</td></tr><tr><td>Docker</td><td>19-ce</td></tr><tr><td>Kubernetes</td><td>1.18</td></tr></tbody></table><p>服务器整体规划：</p><table><thead><tr><th><strong>角色</strong></th><th><strong>IP</strong></th><th><strong>组件</strong></th></tr></thead><tbody><tr><td>k8s-master1</td><td>192.168.31.71</td><td>kube-apiserver，kube-controller-manager，kube-scheduler，etcd</td></tr><tr><td>k8s-master2</td><td>192.168.31.74</td><td>kube-apiserver，kube-controller-manager，kube-scheduler</td></tr><tr><td>k8s-node1</td><td>192.168.31.72</td><td>kubelet，kube-proxy，docker etcd</td></tr><tr><td>k8s-node2</td><td>192.168.31.73</td><td>kubelet，kube-proxy，docker，etcd</td></tr><tr><td>Load Balancer（Master）</td><td>192.168.31.81 ，192.168.31.88 (VIP)</td><td>Nginx L4</td></tr><tr><td>Load Balancer（Backup）</td><td>192.168.31. 82</td><td>Nginx L4</td></tr></tbody></table><p><strong>须知：考虑到有些朋友电脑配置较低，这么多虚拟机跑不动，所以这一套高可用集群分两部分实施，先部署一套单Master架构（192.168.31.71/72/73），再扩容为多Master架构（上述规划），顺便熟悉下Master扩容流程。</strong></p><p>单Master架构图：</p><p><a href="https://imgchr.com/i/DVcrKU" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/11/17/DVcrKU.png" alt="DVcrKU.png"></a></p><p>单Master服务器规划：</p><table><thead><tr><th><strong>角色</strong></th><th><strong>IP</strong></th><th><strong>组件</strong></th></tr></thead><tbody><tr><td>k8s-master</td><td>192.168.31.71</td><td>kube-apiserver，kube-controller-manager，kube-scheduler，etcd</td></tr><tr><td>k8s-node1</td><td>192.168.31.72</td><td>kubelet，kube-proxy，docker etcd</td></tr><tr><td>k8s-node2</td><td>192.168.31.73</td><td>kubelet，kube-proxy，docker，etcd</td></tr></tbody></table><h5 id="1-4-操作系统初始化配置"><a href="#1-4-操作系统初始化配置" class="headerlink" title="1.4 操作系统初始化配置"></a><strong>1.4 操作系统初始化配置</strong></h5><pre class=" language-shell"><code class="language-shell"># 关闭防火墙systemctl stop firewalldsystemctl disable firewalld# 关闭selinuxsed -i 's/enforcing/disabled/' /etc/selinux/config  # 永久setenforce 0  # 临时# 关闭swapswapoff -a  # 临时sed -ri 's/.*swap.*/#&/' /etc/fstab    # 永久# 根据规划设置主机名hostnamectl set-hostname <hostname># 在master添加hostscat >> /etc/hosts << EOF192.168.31.71 k8s-master192.168.31.72 k8s-node1192.168.31.73 k8s-node2EOF# 将桥接的IPv4流量传递到iptables的链cat > /etc/sysctl.d/k8s.conf << EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOFsysctl --system  # 生效# 时间同步yum install ntpdate -yntpdate time.windows.com</code></pre><h4 id="二、部署Etcd集群"><a href="#二、部署Etcd集群" class="headerlink" title="二、部署Etcd集群"></a><strong>二、部署Etcd集群</strong></h4><blockquote><p>Etcd 是一个分布式键值存储系统，Kubernetes使用Etcd进行数据存储，所以先准备一个Etcd数据库，为解决Etcd单点故障，应采用集群方式部署，这里使用3台组建集群，可容忍1台机器故障，当然，你也可以使用5台组建集群，可容忍2台机器故障。</p></blockquote><table><thead><tr><th><strong>节点名称</strong></th><th><strong>IP</strong></th></tr></thead><tbody><tr><td>etcd-1</td><td>192.168.31.71</td></tr><tr><td>etcd-2</td><td>192.168.31.72</td></tr><tr><td>etcd-3</td><td>192.168.31.73</td></tr></tbody></table><p>PS：为了节省机器，这里与K8s节点机器复用。也可以独立于k8s集群之外部署，只要apiserver能连接到就行。</p><h5 id="2-1-准备cfssl证书生成工具"><a href="#2-1-准备cfssl证书生成工具" class="headerlink" title="2.1 准备cfssl证书生成工具"></a><strong>2.1 准备cfssl证书生成工具</strong></h5><p>cfssl是一个开源的证书管理工具，使用json文件生成证书，相比openssl更方便使用。</p><p>找任意一台服务器操作，这里用Master节点。</p><h5 id="2-2-生成Etcd证书"><a href="#2-2-生成Etcd证书" class="headerlink" title="2.2 生成Etcd证书"></a><strong>2.2 生成Etcd证书</strong></h5><h6 id="1-自签证书颁发机构（CA）"><a href="#1-自签证书颁发机构（CA）" class="headerlink" title="1. 自签证书颁发机构（CA）"></a><strong>1. 自签证书颁发机构（CA）</strong></h6><p><strong>创建工作目录：</strong></p><pre class=" language-shell"><code class="language-shell">mkdir -p ~/TLS/{etcd,k8s}cd TLS/etcd</code></pre><p><strong>生成证书：</strong></p><pre class=" language-shell"><code class="language-shell">cat > ca-config.json << EOF{  "signing": {    "default": {      "expiry": "87600h"    },    "profiles": {      "www": {         "expiry": "87600h",         "usages": [            "signing",            "key encipherment",            "server auth",            "client auth"        ]      }    }  }}EOFcat > ca-csr.json << EOF{    "CN": "etcd CA",    "key": {        "algo": "rsa",        "size": 2048    },    "names": [        {            "C": "CN",            "L": "Beijing",            "ST": "Beijing"        }    ]}EOF</code></pre><h6 id="2-使用自签CA签发Etcd-HTTPS证书"><a href="#2-使用自签CA签发Etcd-HTTPS证书" class="headerlink" title="2. 使用自签CA签发Etcd HTTPS证书"></a><strong>2. 使用自签CA签发Etcd HTTPS证书</strong></h6><p><strong>创建证书申请文件：</strong></p><pre class=" language-shell"><code class="language-shell">cat > server-csr.json << EOF{    "CN": "etcd",    "hosts": [    "192.168.31.71",    "192.168.31.72",    "192.168.31.73"    ],    "key": {        "algo": "rsa",        "size": 2048    },    "names": [        {            "C": "CN",            "L": "BeiJing",            "ST": "BeiJing"        }    ]}EOF</code></pre><blockquote><p>PS：上述文件hosts字段中IP为所有etcd节点的集群内部通信IP，一个都不能少！为了方便后期扩容可以多写几个预留的IP。</p></blockquote><p><strong>生成证书：</strong></p><pre class=" language-shell"><code class="language-shell">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=www server-csr.json | cfssljson -bare serverls server*pemserver-key.pem  server.pem</code></pre><h5 id="2-3-从Github下载二进制文件"><a href="#2-3-从Github下载二进制文件" class="headerlink" title="2.3 从Github下载二进制文件"></a><strong>2.3 从Github下载二进制文件</strong></h5><p>下载地址：</p><p><a href="https://github.com/etcd-io/etcd/releases/download/v3.4.9/etcd-v3.4.9-linux-amd64.tar.gz" target="_blank" rel="noopener">https://github.com/etcd-io/etcd/releases/download/v3.4.9/etcd-v3.4.9-linux-amd64.tar.gz</a></p><h5 id="2-4-部署Etcd集群"><a href="#2-4-部署Etcd集群" class="headerlink" title="2.4 部署Etcd集群"></a><strong>2.4 部署Etcd集群</strong></h5><p>以下在节点1上操作，为简化操作，待会将节点1生成的所有文件拷贝到节点2和节点3.</p><h6 id="1-创建工作目录并解压二进制包"><a href="#1-创建工作目录并解压二进制包" class="headerlink" title="1. 创建工作目录并解压二进制包"></a><strong>1. 创建工作目录并解压二进制包</strong></h6><pre class=" language-shell"><code class="language-shell">mkdir /opt/etcd/{bin,cfg,ssl} -ptar zxvf etcd-v3.4.9-linux-amd64.tar.gzmv etcd-v3.4.9-linux-amd64/{etcd,etcdctl} /opt/etcd/bin/</code></pre><h6 id="2-创建etcd配置文件"><a href="#2-创建etcd配置文件" class="headerlink" title="2. 创建etcd配置文件"></a><strong>2. 创建etcd配置文件</strong></h6><pre class=" language-shell"><code class="language-shell">cat > /opt/etcd/cfg/etcd.conf << EOF#[Member]ETCD_NAME="etcd-1"ETCD_DATA_DIR="/var/lib/etcd/default.etcd"ETCD_LISTEN_PEER_URLS="https://192.168.31.71:2380"ETCD_LISTEN_CLIENT_URLS="https://192.168.31.71:2379"#[Clustering]ETCD_INITIAL_ADVERTISE_PEER_URLS="https://192.168.31.71:2380"ETCD_ADVERTISE_CLIENT_URLS="https://192.168.31.71:2379"ETCD_INITIAL_CLUSTER="etcd-1=https://192.168.31.71:2380,etcd-2=https://192.168.31.72:2380,etcd-3=https://192.168.31.73:2380"ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster"ETCD_INITIAL_CLUSTER_STATE="new"EOF</code></pre><blockquote><ul><li>· ETCD_NAME：节点名称，集群中唯一</li><li>· ETCD_DATA_DIR：数据目录</li><li>· ETCD_LISTEN_PEER_URLS：集群通信监听地址</li><li>· ETCD_LISTEN_CLIENT_URLS：客户端访问监听地址</li><li>· ETCD_INITIAL_ADVERTISE_PEER_URLS：集群通告地址</li><li>· ETCD_ADVERTISE_CLIENT_URLS：客户端通告地址</li><li>· ETCD_INITIAL_CLUSTER：集群节点地址</li><li>· ETCD_INITIAL_CLUSTER_TOKEN：集群Token</li><li>· ETCD_INITIAL_CLUSTER_STATE：加入集群的当前状态，new是新集群，existing表示加入已有集群</li></ul></blockquote><h6 id="3-systemd管理etcd"><a href="#3-systemd管理etcd" class="headerlink" title="3. systemd管理etcd"></a><strong>3. systemd管理etcd</strong></h6><pre class=" language-shell"><code class="language-shell">cat > /usr/lib/systemd/system/etcd.service << EOF[Unit]Description=Etcd ServerAfter=network.targetAfter=network-online.targetWants=network-online.target[Service]Type=notifyEnvironmentFile=/opt/etcd/cfg/etcd.confExecStart=/opt/etcd/bin/etcd \--cert-file=/opt/etcd/ssl/server.pem \--key-file=/opt/etcd/ssl/server-key.pem \--peer-cert-file=/opt/etcd/ssl/server.pem \--peer-key-file=/opt/etcd/ssl/server-key.pem \--trusted-ca-file=/opt/etcd/ssl/ca.pem \--peer-trusted-ca-file=/opt/etcd/ssl/ca.pem \--logger=zapRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF</code></pre><h6 id="4-拷贝刚才生成的证书"><a href="#4-拷贝刚才生成的证书" class="headerlink" title="4. 拷贝刚才生成的证书"></a><strong>4. 拷贝刚才生成的证书</strong></h6><p>把刚才生成的证书拷贝到配置文件中的路径：</p><pre class=" language-shell"><code class="language-shell">cp ~/TLS/etcd/ca*pem ~/TLS/etcd/server*pem /opt/etcd/ssl/</code></pre><h6 id="5-启动并设置开机启动"><a href="#5-启动并设置开机启动" class="headerlink" title="5. 启动并设置开机启动"></a><strong>5. 启动并设置开机启动</strong></h6><pre class=" language-shell"><code class="language-shell">systemctl daemon-reloadsystemctl start etcdsystemctl enable etcd</code></pre><h6 id="6-将上面节点1所有生成的文件拷贝到节点2和节点3"><a href="#6-将上面节点1所有生成的文件拷贝到节点2和节点3" class="headerlink" title="6. 将上面节点1所有生成的文件拷贝到节点2和节点3"></a><strong>6. 将上面节点1所有生成的文件拷贝到节点2和节点3</strong></h6><pre class=" language-shell"><code class="language-shell">scp -r /opt/etcd/ root@192.168.31.72:/opt/scp /usr/lib/systemd/system/etcd.service root@192.168.31.72:/usr/lib/systemd/system/scp -r /opt/etcd/ root@192.168.31.73:/opt/scp /usr/lib/systemd/system/etcd.service root@192.168.31.73:/usr/lib/systemd/system/</code></pre><p>然后在节点2和节点3分别修改etcd.conf配置文件中的节点名称和当前服务器IP：</p><pre class=" language-shell"><code class="language-shell">vi /opt/etcd/cfg/etcd.conf#[Member]ETCD_NAME="etcd-1"   # 修改此处，节点2改为etcd-2，节点3改为etcd-3ETCD_DATA_DIR="/var/lib/etcd/default.etcd"ETCD_LISTEN_PEER_URLS="https://192.168.31.71:2380"   # 修改此处为当前服务器IPETCD_LISTEN_CLIENT_URLS="https://192.168.31.71:2379" # 修改此处为当前服务器IP#[Clustering]ETCD_INITIAL_ADVERTISE_PEER_URLS="https://192.168.31.71:2380" # 修改此处为当前服务器IPETCD_ADVERTISE_CLIENT_URLS="https://192.168.31.71:2379" # 修改此处为当前服务器IPETCD_INITIAL_CLUSTER="etcd-1=https://192.168.31.71:2380,etcd-2=https://192.168.31.72:2380,etcd-3=https://192.168.31.73:2380"ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster"ETCD_INITIAL_CLUSTER_STATE="new"</code></pre><p>最后启动etcd并设置开机启动，同上。</p><h6 id="7-查看集群状态"><a href="#7-查看集群状态" class="headerlink" title="7. 查看集群状态"></a><strong>7. 查看集群状态</strong></h6><pre class=" language-shell"><code class="language-shell">ETCDCTL_API=3 /opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --cert=/opt/etcd/ssl/server.pem --key=/opt/etcd/ssl/server-key.pem --endpoints="https://192.168.31.71:2379,https://192.168.31.72:2379,https://192.168.31.73:2379" endpoint healthhttps://192.168.31.71:2379 is healthy: successfully committed proposal: took = 8.154404mshttps://192.168.31.73:2379 is healthy: successfully committed proposal: took = 9.044117mshttps://192.168.31.72:2379 is healthy: successfully committed proposal: took = 10.000825ms</code></pre><blockquote><ul><li>如果输出上面信息，就说明集群部署成功。</li><li>如果有问题第一步先看日志：/var/log/message 或 journalctl -u etcd</li></ul></blockquote><h4 id="三、安装Docker"><a href="#三、安装Docker" class="headerlink" title="三、安装Docker"></a><strong>三、安装Docker</strong></h4><blockquote><p>下载地址：<a href="https://download.docker.com/linux/static/stable/x86_64/docker-19.03.9.tgz" target="_blank" rel="noopener">https://download.docker.com/linux/static/stable/x86_64/docker-19.03.9.tgz</a></p><p>以下在所有节点操作。这里采用二进制安装，用yum安装也一样。</p></blockquote><h5 id="3-1-解压二进制包"><a href="#3-1-解压二进制包" class="headerlink" title="3.1 解压二进制包"></a><strong>3.1 解压二进制包</strong></h5><pre class=" language-shell"><code class="language-shell">tar zxvf docker-19.03.9.tgzmv docker/* /usr/bin</code></pre><h5 id="3-2-systemd管理docker"><a href="#3-2-systemd管理docker" class="headerlink" title="3.2 systemd管理docker"></a><strong>3.2 systemd管理docker</strong></h5><pre class=" language-shell"><code class="language-shell">cat > /usr/lib/systemd/system/docker.service << EOF[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.comAfter=network-online.target firewalld.serviceWants=network-online.target[Service]Type=notifyExecStart=/usr/bin/dockerdExecReload=/bin/kill -s HUP $MAINPIDLimitNOFILE=infinityLimitNPROC=infinityLimitCORE=infinityTimeoutStartSec=0Delegate=yesKillMode=processRestart=on-failureStartLimitBurst=3StartLimitInterval=60s[Install]WantedBy=multi-user.targetEOF</code></pre><h5 id="3-3-创建配置文件"><a href="#3-3-创建配置文件" class="headerlink" title="3.3 创建配置文件"></a><strong>3.3 创建配置文件</strong></h5><pre class=" language-shell"><code class="language-shell">mkdir /etc/dockercat > /etc/docker/daemon.json << EOF{  "registry-mirrors": ["https://b9pmyelo.mirror.aliyuncs.com"]}EOF</code></pre><p>· registry-mirrors 阿里云镜像加速器</p><h5 id="3-4-启动并设置开机启动"><a href="#3-4-启动并设置开机启动" class="headerlink" title="3.4 启动并设置开机启动"></a><strong>3.4 启动并设置开机启动</strong></h5><pre class=" language-shell"><code class="language-shell">systemctl daemon-reloadsystemctl start dockersystemctl enable docker</code></pre><h4 id="四、部署Master-Node"><a href="#四、部署Master-Node" class="headerlink" title="四、部署Master Node"></a><strong>四、部署Master Node</strong></h4><h5 id="4-1-生成kube-apiserver证书"><a href="#4-1-生成kube-apiserver证书" class="headerlink" title="4.1 生成kube-apiserver证书"></a><strong>4.1 生成kube-apiserver证书</strong></h5><h6 id="1-自签证书颁发机构（CA）-1"><a href="#1-自签证书颁发机构（CA）-1" class="headerlink" title="1. 自签证书颁发机构（CA）"></a><strong>1. 自签证书颁发机构（CA）</strong></h6><pre class=" language-shell"><code class="language-shell">cat > ca-config.json << EOF{  "signing": {    "default": {      "expiry": "87600h"    },    "profiles": {      "kubernetes": {         "expiry": "87600h",         "usages": [            "signing",            "key encipherment",            "server auth",            "client auth"        ]      }    }  }}EOFcat > ca-csr.json << EOF{    "CN": "kubernetes",    "key": {        "algo": "rsa",        "size": 2048    },    "names": [        {            "C": "CN",            "L": "Beijing",            "ST": "Beijing",            "O": "k8s",            "OU": "System"        }    ]}EOF</code></pre><p>生成证书：</p><pre class=" language-shell"><code class="language-shell">cfssl gencert -initca ca-csr.json | cfssljson -bare ca -ls *pemca-key.pem  ca.pem</code></pre><h6 id="2-使用自签CA签发kube-apiserver-HTTPS证书"><a href="#2-使用自签CA签发kube-apiserver-HTTPS证书" class="headerlink" title="2. 使用自签CA签发kube-apiserver HTTPS证书"></a><strong>2. 使用自签CA签发kube-apiserver HTTPS证书</strong></h6><p>创建证书申请文件：</p><pre class=" language-shell"><code class="language-shell">cd TLS/k8scat > server-csr.json << EOF{    "CN": "kubernetes",    "hosts": [      "10.0.0.1",      "127.0.0.1",      "192.168.31.71",      "192.168.31.72",      "192.168.31.73",      "192.168.31.74",      "192.168.31.81",      "192.168.31.82",      "192.168.31.88",      "kubernetes",      "kubernetes.default",      "kubernetes.default.svc",      "kubernetes.default.svc.cluster",      "kubernetes.default.svc.cluster.local"    ],    "key": {        "algo": "rsa",        "size": 2048    },    "names": [        {            "C": "CN",            "L": "BeiJing",            "ST": "BeiJing",            "O": "k8s",            "OU": "System"        }    ]}EOF</code></pre><blockquote><p>注：上述文件hosts字段中IP为所有Master/LB/VIP IP，一个都不能少！为了方便后期扩容可以多写几个预留的IP。</p></blockquote><p>生成证书：</p><pre class=" language-shell"><code class="language-shell">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes server-csr.json | cfssljson -bare serverls server*pemserver-key.pem  server.pem</code></pre><h5 id="4-2-从Github下载二进制文件"><a href="#4-2-从Github下载二进制文件" class="headerlink" title="4.2 从Github下载二进制文件"></a><strong>4.2 从Github下载二进制文件</strong></h5><p>下载地址： <a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.18.md#v1183" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.18.md#v1183</a></p><blockquote><p>注：打开链接你会发现里面有很多包，下载一个server包就够了，包含了Master和Worker Node二进制文件。</p></blockquote><h5 id="4-3-解压二进制包"><a href="#4-3-解压二进制包" class="headerlink" title="4.3 解压二进制包"></a><strong>4.3 解压二进制包</strong></h5><pre class=" language-shell"><code class="language-shell">mkdir -p /opt/kubernetes/{bin,cfg,ssl,logs} tar zxvf kubernetes-server-linux-amd64.tar.gzcd kubernetes/server/bincp kube-apiserver kube-scheduler kube-controller-manager /opt/kubernetes/bincp kubectl /usr/bin/</code></pre><h5 id="4-4-部署kube-apiserver"><a href="#4-4-部署kube-apiserver" class="headerlink" title="4.4 部署kube-apiserver"></a><strong>4.4 部署kube-apiserver</strong></h5><p><strong>首发地址**</strong>：**<a href="https://mp.weixin.qq.com/s/VYtyTU9_Dw9M5oHtvRfseA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/VYtyTU9_Dw9M5oHtvRfseA</a></p><h6 id="1-创建配置文件"><a href="#1-创建配置文件" class="headerlink" title="1. 创建配置文件"></a><strong>1. 创建配置文件</strong></h6><pre class=" language-shell"><code class="language-shell">cat > /opt/kubernetes/cfg/kube-apiserver.conf << EOFKUBE_APISERVER_OPTS="--logtostderr=false \\--v=2 \\--log-dir=/opt/kubernetes/logs \\--etcd-servers=https://192.168.31.71:2379,https://192.168.31.72:2379,https://192.168.31.73:2379 \\--bind-address=192.168.31.71 \\--secure-port=6443 \\--advertise-address=192.168.31.71 \\--allow-privileged=true \\--service-cluster-ip-range=10.0.0.0/24 \\--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota,NodeRestriction \\--authorization-mode=RBAC,Node \\--enable-bootstrap-token-auth=true \\--token-auth-file=/opt/kubernetes/cfg/token.csv \\--service-node-port-range=30000-32767 \\--kubelet-client-certificate=/opt/kubernetes/ssl/server.pem \\--kubelet-client-key=/opt/kubernetes/ssl/server-key.pem \\--tls-cert-file=/opt/kubernetes/ssl/server.pem  \\--tls-private-key-file=/opt/kubernetes/ssl/server-key.pem \\--client-ca-file=/opt/kubernetes/ssl/ca.pem \\--service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \\--etcd-cafile=/opt/etcd/ssl/ca.pem \\--etcd-certfile=/opt/etcd/ssl/server.pem \\--etcd-keyfile=/opt/etcd/ssl/server-key.pem \\--audit-log-maxage=30 \\--audit-log-maxbackup=3 \\--audit-log-maxsize=100 \\--audit-log-path=/opt/kubernetes/logs/k8s-audit.log"EOF</code></pre><blockquote><p>注：上面两个\ \ 第一个是转义符，第二个是换行符，使用转义符是为了使用EOF保留换行符。</p><p>· –logtostderr：启用日志</p><p>· —v：日志等级</p><p>· –log-dir：日志目录</p><p>· –etcd-servers：etcd集群地址</p><p>· –bind-address：监听地址</p><p>· –secure-port：https安全端口</p><p>· –advertise-address：集群通告地址</p><p>· –allow-privileged：启用授权</p><p>· –service-cluster-ip-range：Service虚拟IP地址段</p><p>· –enable-admission-plugins：准入控制模块</p><p>· –authorization-mode：认证授权，启用RBAC授权和节点自管理</p><p>· –enable-bootstrap-token-auth：启用TLS bootstrap机制</p><p>· –token-auth-file：bootstrap token文件</p><p>· –service-node-port-range：Service nodeport类型默认分配端口范围</p><p>· –kubelet-client-xxx：apiserver访问kubelet客户端证书</p><p>· –tls-xxx-file：apiserver https证书</p><p>· –etcd-xxxfile：连接Etcd集群证书</p><p>· –audit-log-xxx：审计日志</p></blockquote><h6 id="2-拷贝刚才生成的证书"><a href="#2-拷贝刚才生成的证书" class="headerlink" title="2. 拷贝刚才生成的证书"></a><strong>2. 拷贝刚才生成的证书</strong></h6><p>把刚才生成的证书拷贝到配置文件中的路径：</p><pre class=" language-shell"><code class="language-shell">cp ~/TLS/k8s/ca*pem ~/TLS/k8s/server*pem /opt/kubernetes/ssl/</code></pre><h6 id="3-启用-TLS-Bootstrapping-机制"><a href="#3-启用-TLS-Bootstrapping-机制" class="headerlink" title="3. 启用 TLS Bootstrapping 机制"></a><strong>3. 启用 TLS Bootstrapping 机制</strong></h6><blockquote><p>TLS Bootstraping：Master apiserver启用TLS认证后，Node节点kubelet和kube-proxy要与kube-apiserver进行通信，必须使用CA签发的有效证书才可以，当Node节点很多时，这种客户端证书颁发需要大量工作，同样也会增加集群扩展复杂度。为了简化流程，Kubernetes引入了TLS bootstraping机制来自动颁发客户端证书，kubelet会以一个低权限用户自动向apiserver申请证书，kubelet的证书由apiserver动态签署。所以强烈建议在Node上使用这种方式，目前主要用于kubelet，kube-proxy还是由我们统一颁发一个证书。</p></blockquote><p>TLS bootstraping 工作流程：</p><p><a href="https://imgchr.com/i/DVD6Qe" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/11/17/DVD6Qe.png" alt="DVD6Qe.png"></a></p><p>创建上述配置文件中token文件：</p><pre class=" language-shell"><code class="language-shell">cat > /opt/kubernetes/cfg/token.csv << EOFc47ffb939f5ca36231d9e3121a252940,kubelet-bootstrap,10001,"system:node-bootstrapper"EOF</code></pre><p>格式：token，用户名，UID，用户组</p><p>token也可自行生成替换：</p><pre class=" language-shell"><code class="language-shell">head -c 16 /dev/urandom | od -An -t x | tr -d ' '</code></pre><h6 id="4-systemd管理apiserver"><a href="#4-systemd管理apiserver" class="headerlink" title="4. systemd管理apiserver"></a><strong>4. systemd管理apiserver</strong></h6><pre class=" language-shell"><code class="language-shell">cat > /usr/lib/systemd/system/kube-apiserver.service << EOF[Unit]Description=Kubernetes API ServerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-apiserver.confExecStart=/opt/kubernetes/bin/kube-apiserver \$KUBE_APISERVER_OPTSRestart=on-failure[Install]WantedBy=multi-user.targetEOF</code></pre><h6 id="5-启动并设置开机启动-1"><a href="#5-启动并设置开机启动-1" class="headerlink" title="5. 启动并设置开机启动"></a><strong>5. 启动并设置开机启动</strong></h6><pre class=" language-shell"><code class="language-shell">systemctl daemon-reloadsystemctl start kube-apiserversystemctl enable kube-apiserver</code></pre><h6 id="6-授权kubelet-bootstrap用户允许请求证书"><a href="#6-授权kubelet-bootstrap用户允许请求证书" class="headerlink" title="6. 授权kubelet-bootstrap用户允许请求证书"></a><strong>6. 授权kubelet-bootstrap用户允许请求证书</strong></h6><pre class=" language-shell"><code class="language-shell">kubectl create clusterrolebinding kubelet-bootstrap \--clusterrole=system:node-bootstrapper \--user=kubelet-bootstrap</code></pre><h5 id="4-5-部署kube-controller-manager"><a href="#4-5-部署kube-controller-manager" class="headerlink" title="4.5 部署kube-controller-manager"></a><strong>4.5 部署kube-controller-manager</strong></h5><h6 id="1-创建配置文件-1"><a href="#1-创建配置文件-1" class="headerlink" title="1. 创建配置文件"></a><strong>1. 创建配置文件</strong></h6><pre class=" language-shell"><code class="language-shell">cat > /opt/kubernetes/cfg/kube-controller-manager.conf << EOFKUBE_CONTROLLER_MANAGER_OPTS="--logtostderr=false \\--v=2 \\--log-dir=/opt/kubernetes/logs \\--leader-elect=true \\--master=127.0.0.1:8080 \\--bind-address=127.0.0.1 \\--allocate-node-cidrs=true \\--cluster-cidr=10.244.0.0/16 \\--service-cluster-ip-range=10.0.0.0/24 \\--cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \\--cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem  \\--root-ca-file=/opt/kubernetes/ssl/ca.pem \\--service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem \\--experimental-cluster-signing-duration=87600h0m0s"EOF</code></pre><blockquote><p>· –master：通过本地非安全本地端口8080连接apiserver。</p><p>· –leader-elect：当该组件启动多个时，自动选举（HA）</p><p>· –cluster-signing-cert-file/–cluster-signing-key-file：自动为kubelet颁发证书的CA，与apiserver保持一致</p></blockquote><h6 id="2-systemd管理controller-manager"><a href="#2-systemd管理controller-manager" class="headerlink" title="2. systemd管理controller-manager"></a><strong>2. systemd管理controller-manager</strong></h6><pre class=" language-shell"><code class="language-shell">cat > /usr/lib/systemd/system/kube-controller-manager.service << EOF[Unit]Description=Kubernetes Controller ManagerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-controller-manager.confExecStart=/opt/kubernetes/bin/kube-controller-manager \$KUBE_CONTROLLER_MANAGER_OPTSRestart=on-failure[Install]WantedBy=multi-user.targetEOF</code></pre><p><strong>3. 启动并设置开机启动</strong></p><pre class=" language-shell"><code class="language-shell">systemctl daemon-reloadsystemctl start kube-controller-managersystemctl enable kube-controller-manager</code></pre><h5 id="4-6-部署kube-scheduler"><a href="#4-6-部署kube-scheduler" class="headerlink" title="4.6 部署kube-scheduler"></a><strong>4.6 部署kube-scheduler</strong></h5><h6 id="1-创建配置文件-2"><a href="#1-创建配置文件-2" class="headerlink" title="1. 创建配置文件"></a><strong>1. 创建配置文件</strong></h6><pre class=" language-shell"><code class="language-shell">cat > /opt/kubernetes/cfg/kube-scheduler.conf << EOFKUBE_SCHEDULER_OPTS="--logtostderr=false \--v=2 \--log-dir=/opt/kubernetes/logs \--leader-elect \--master=127.0.0.1:8080 \--bind-address=127.0.0.1"EOF</code></pre><blockquote><p>· –master：通过本地非安全本地端口8080连接apiserver。</p><p>· –leader-elect：当该组件启动多个时，自动选举（HA）</p></blockquote><h6 id="2-systemd管理scheduler"><a href="#2-systemd管理scheduler" class="headerlink" title="2. systemd管理scheduler"></a><strong>2. systemd管理scheduler</strong></h6><pre class=" language-shell"><code class="language-shell">cat > /usr/lib/systemd/system/kube-scheduler.service << EOF[Unit]Description=Kubernetes SchedulerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-scheduler.confExecStart=/opt/kubernetes/bin/kube-scheduler \$KUBE_SCHEDULER_OPTSRestart=on-failure[Install]WantedBy=multi-user.targetEOF</code></pre><h6 id="3-启动并设置开机启动"><a href="#3-启动并设置开机启动" class="headerlink" title="3. 启动并设置开机启动"></a><strong>3. 启动并设置开机启动</strong></h6><pre class=" language-shell"><code class="language-shell">systemctl daemon-reloadsystemctl start kube-schedulersystemctl enable kube-scheduler</code></pre><h6 id="4-查看集群状态"><a href="#4-查看集群状态" class="headerlink" title="4. 查看集群状态"></a><strong>4. 查看集群状态</strong></h6><blockquote><p>所有组件都已经启动成功，通过kubectl工具查看当前集群组件状态：</p></blockquote><pre class=" language-shell"><code class="language-shell">kubectl get csNAME                 STATUS    MESSAGE             ERRORscheduler            Healthy   ok                  controller-manager   Healthy   ok                  etcd-2               Healthy   {"health":"true"}   etcd-1               Healthy   {"health":"true"}   etcd-0               Healthy   {"health":"true"}  </code></pre><h4 id="五、部署Worker-Node"><a href="#五、部署Worker-Node" class="headerlink" title="五、部署Worker Node"></a><strong>五、部署Worker Node</strong></h4><blockquote><p><strong>下面还是在Master Node上操作，即同时作为Worker Node</strong></p></blockquote><h5 id="5-1-创建工作目录并拷贝二进制文件"><a href="#5-1-创建工作目录并拷贝二进制文件" class="headerlink" title="5.1 创建工作目录并拷贝二进制文件"></a><strong>5.1 创建工作目录并拷贝二进制文件</strong></h5><p>在所有worker node创建工作目录：</p><pre class=" language-shell"><code class="language-shell">mkdir -p /opt/kubernetes/{bin,cfg,ssl,logs} </code></pre><p>从master节点拷贝：</p><pre class=" language-shell"><code class="language-shell">cd kubernetes/server/bincp kubelet kube-proxy /opt/kubernetes/bin   # 本地拷贝</code></pre><h5 id="5-2-部署kubelet"><a href="#5-2-部署kubelet" class="headerlink" title="5.2 部署kubelet"></a><strong>5.2 部署kubelet</strong></h5><h6 id="1-创建配置文件-3"><a href="#1-创建配置文件-3" class="headerlink" title="1. 创建配置文件"></a><strong>1. 创建配置文件</strong></h6><pre class=" language-shell"><code class="language-shell">cat > /opt/kubernetes/cfg/kubelet.conf << EOFKUBELET_OPTS="--logtostderr=false \\--v=2 \\--log-dir=/opt/kubernetes/logs \\--hostname-override=k8s-master \\--network-plugin=cni \\--kubeconfig=/opt/kubernetes/cfg/kubelet.kubeconfig \\--bootstrap-kubeconfig=/opt/kubernetes/cfg/bootstrap.kubeconfig \\--config=/opt/kubernetes/cfg/kubelet-config.yml \\--cert-dir=/opt/kubernetes/ssl \\--pod-infra-container-image=lizhenliang/pause-amd64:3.0"EOF</code></pre><blockquote><p>· –hostname-override：显示名称，集群中唯一</p><p>· –network-plugin：启用CNI</p><p>· –kubeconfig：空路径，会自动生成，后面用于连接apiserver</p><p>· –bootstrap-kubeconfig：首次启动向apiserver申请证书</p><p>· –config：配置参数文件</p><p>· –cert-dir：kubelet证书生成目录</p><p>· –pod-infra-container-image：管理Pod网络容器的镜像</p></blockquote><h6 id="2-配置参数文件"><a href="#2-配置参数文件" class="headerlink" title="2. 配置参数文件"></a><strong>2. 配置参数文件</strong></h6><pre class=" language-shell"><code class="language-shell">cat > /opt/kubernetes/cfg/kubelet-config.yml << EOFkind: KubeletConfigurationapiVersion: kubelet.config.k8s.io/v1beta1address: 0.0.0.0port: 10250readOnlyPort: 10255cgroupDriver: cgroupfsclusterDNS:- 10.0.0.2clusterDomain: cluster.local failSwapOn: falseauthentication:  anonymous:    enabled: false  webhook:    cacheTTL: 2m0s    enabled: true  x509:    clientCAFile: /opt/kubernetes/ssl/ca.pem authorization:  mode: Webhook  webhook:    cacheAuthorizedTTL: 5m0s    cacheUnauthorizedTTL: 30sevictionHard:  imagefs.available: 15%  memory.available: 100Mi  nodefs.available: 10%  nodefs.inodesFree: 5%maxOpenFiles: 1000000maxPods: 110EOF</code></pre><p><strong>3. 生成bootstrap.kubeconfig文件</strong></p><pre class=" language-shell"><code class="language-shell">KUBE_APISERVER="https://192.168.31.71:6443" # apiserver IP:PORTTOKEN="c47ffb939f5ca36231d9e3121a252940" # 与token.csv里保持一致# 生成 kubelet bootstrap kubeconfig 配置文件kubectl config set-cluster kubernetes \  --certificate-authority=/opt/kubernetes/ssl/ca.pem \  --embed-certs=true \  --server=${KUBE_APISERVER} \  --kubeconfig=bootstrap.kubeconfigkubectl config set-credentials "kubelet-bootstrap" \  --token=${TOKEN} \  --kubeconfig=bootstrap.kubeconfigkubectl config set-context default \  --cluster=kubernetes \  --user="kubelet-bootstrap" \  --kubeconfig=bootstrap.kubeconfigkubectl config use-context default --kubeconfig=bootstrap.kubeconfig</code></pre><p>拷贝到配置文件路径：</p><pre class=" language-shell"><code class="language-shell">cp bootstrap.kubeconfig /opt/kubernetes/cfg</code></pre><h6 id="4-systemd管理kubelet"><a href="#4-systemd管理kubelet" class="headerlink" title="4. systemd管理kubelet"></a><strong>4. systemd管理kubelet</strong></h6><pre class=" language-shell"><code class="language-shell">cat > /usr/lib/systemd/system/kubelet.service << EOF[Unit]Description=Kubernetes KubeletAfter=docker.service[Service]EnvironmentFile=/opt/kubernetes/cfg/kubelet.confExecStart=/opt/kubernetes/bin/kubelet \$KUBELET_OPTSRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF</code></pre><h6 id="5-启动并设置开机启动-2"><a href="#5-启动并设置开机启动-2" class="headerlink" title="5. 启动并设置开机启动"></a><strong>5. 启动并设置开机启动</strong></h6><pre class=" language-shell"><code class="language-shell">systemctl daemon-reloadsystemctl start kubeletsystemctl enable kubelet</code></pre><h5 id="5-3-批准kubelet证书申请并加入集群"><a href="#5-3-批准kubelet证书申请并加入集群" class="headerlink" title="5.3 批准kubelet证书申请并加入集群"></a><strong>5.3 批准kubelet证书申请并加入集群</strong></h5><pre class=" language-shell"><code class="language-shell"># 查看kubelet证书请求kubectl get csrNAME                                                   AGE    SIGNERNAME                                    REQUESTOR           CONDITIONnode-csr-uCEGPOIiDdlLODKts8J658HrFq9CZ--K6M4G7bjhk8A   6m3s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending# 批准申请kubectl certificate approve node-csr-uCEGPOIiDdlLODKts8J658HrFq9CZ--K6M4G7bjhk8A# 查看节点kubectl get nodeNAME         STATUS     ROLES    AGE   VERSIONk8s-master   NotReady   <none>   7s    v1.18.3</code></pre><p>注：由于网络插件还没有部署，节点会没有准备就绪 NotReady</p><h5 id="5-4-部署kube-proxy"><a href="#5-4-部署kube-proxy" class="headerlink" title="5.4 部署kube-proxy"></a><strong>5.4 部署kube-proxy</strong></h5><h6 id="1-创建配置文件-4"><a href="#1-创建配置文件-4" class="headerlink" title="1. 创建配置文件"></a><strong>1. 创建配置文件</strong></h6><pre class=" language-shell"><code class="language-shell">cat > /opt/kubernetes/cfg/kube-proxy.conf << EOFKUBE_PROXY_OPTS="--logtostderr=false \\--v=2 \\--log-dir=/opt/kubernetes/logs \\--config=/opt/kubernetes/cfg/kube-proxy-config.yml"EOF</code></pre><h6 id="2-配置参数文件-1"><a href="#2-配置参数文件-1" class="headerlink" title="2. 配置参数文件"></a><strong>2. 配置参数文件</strong></h6><pre class=" language-shell"><code class="language-shell">cat > /opt/kubernetes/cfg/kube-proxy-config.yml << EOFkind: KubeProxyConfigurationapiVersion: kubeproxy.config.k8s.io/v1alpha1bindAddress: 0.0.0.0metricsBindAddress: 0.0.0.0:10249clientConnection:  kubeconfig: /opt/kubernetes/cfg/kube-proxy.kubeconfighostnameOverride: k8s-masterclusterCIDR: 10.0.0.0/24EOF</code></pre><h6 id="3-生成kube-proxy-kubeconfig文件"><a href="#3-生成kube-proxy-kubeconfig文件" class="headerlink" title="3. 生成kube-proxy.kubeconfig文件"></a><strong>3. 生成kube-proxy.kubeconfig文件</strong></h6><p>生成kube-proxy证书：</p><pre class=" language-shell"><code class="language-shell"># 切换工作目录cd TLS/k8s# 创建证书请求文件cat > kube-proxy-csr.json << EOF{  "CN": "system:kube-proxy",  "hosts": [],  "key": {    "algo": "rsa",    "size": 2048  },  "names": [    {      "C": "CN",      "L": "BeiJing",      "ST": "BeiJing",      "O": "k8s",      "OU": "System"    }  ]}EOF# 生成证书cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxyls kube-proxy*pemkube-proxy-key.pem  kube-proxy.pem</code></pre><p>生成kubeconfig文件：</p><pre class=" language-shell"><code class="language-shell">KUBE_APISERVER="https://192.168.31.71:6443"kubectl config set-cluster kubernetes \  --certificate-authority=/opt/kubernetes/ssl/ca.pem \  --embed-certs=true \  --server=${KUBE_APISERVER} \  --kubeconfig=kube-proxy.kubeconfigkubectl config set-credentials kube-proxy \  --client-certificate=./kube-proxy.pem \  --client-key=./kube-proxy-key.pem \  --embed-certs=true \  --kubeconfig=kube-proxy.kubeconfigkubectl config set-context default \  --cluster=kubernetes \  --user=kube-proxy \  --kubeconfig=kube-proxy.kubeconfigkubectl config use-context default --kubeconfig=kube-proxy.kubeconfig</code></pre><p>拷贝到配置文件指定路径：</p><pre class=" language-shell"><code class="language-shell">cp kube-proxy.kubeconfig /opt/kubernetes/cfg/</code></pre><h6 id="4-systemd管理kube-proxy"><a href="#4-systemd管理kube-proxy" class="headerlink" title="4. systemd管理kube-proxy"></a>4. systemd管理kube-proxy</h6><pre class=" language-shell"><code class="language-shell">cat > /usr/lib/systemd/system/kube-proxy.service << EOF[Unit]Description=Kubernetes ProxyAfter=network.target[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-proxy.confExecStart=/opt/kubernetes/bin/kube-proxy \$KUBE_PROXY_OPTSRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF</code></pre><h6 id="5-启动并设置开机启动-3"><a href="#5-启动并设置开机启动-3" class="headerlink" title="5. 启动并设置开机启动"></a><strong>5. 启动并设置开机启动</strong></h6><pre class=" language-shell"><code class="language-shell">systemctl daemon-reloadsystemctl start kube-proxysystemctl enable kube-proxy</code></pre><h5 id="5-5-部署CNI网络"><a href="#5-5-部署CNI网络" class="headerlink" title="5.5 部署CNI网络"></a><strong>5.5 部署CNI网络</strong></h5><p>先准备好CNI二进制文件：</p><p>下载地址：<a href="https://github.com/containernetworking/plugins/releases/download/v0.8.6/cni-plugins-linux-amd64-v0.8.6.tgz" target="_blank" rel="noopener">https://github.com/containernetworking/plugins/releases/download/v0.8.6/cni-plugins-linux-amd64-v0.8.6.tgz</a></p><p>解压二进制包并移动到默认工作目录：</p><pre class=" language-shell"><code class="language-shell">mkdir /opt/cni/bintar zxvf cni-plugins-linux-amd64-v0.8.6.tgz -C /opt/cni/bin######   部署CNI网络：wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.ymlsed -i -r "s#quay.io/coreos/flannel:.*-amd64#lizhenliang/flannel:v0.12.0-amd64#g" kube-flannel.yml######   默认镜像地址无法访问，修改为docker hub镜像仓库。kubectl apply -f kube-flannel.ymlkubectl get pods -n kube-systemNAME                          READY   STATUS    RESTARTS   AGEkube-flannel-ds-amd64-2pc95   1/1     Running   0          72skubectl get nodeNAME         STATUS   ROLES    AGE   VERSIONk8s-master   Ready    <none>   41m   v1.18.3</code></pre><p>部署好网络插件，Node准备就绪。</p><h6 id="5-6-授权apiserver访问kubelet"><a href="#5-6-授权apiserver访问kubelet" class="headerlink" title="5.6 授权apiserver访问kubelet"></a><strong>5.6 授权apiserver访问kubelet</strong></h6><pre class=" language-shell"><code class="language-shell">cat > apiserver-to-kubelet-rbac.yaml << EOFapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata:  annotations:    rbac.authorization.kubernetes.io/autoupdate: "true"  labels:    kubernetes.io/bootstrapping: rbac-defaults  name: system:kube-apiserver-to-kubeletrules:  - apiGroups:      - ""    resources:      - nodes/proxy      - nodes/stats      - nodes/log      - nodes/spec      - nodes/metrics      - pods/log    verbs:      - "*"---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata:  name: system:kube-apiserver  namespace: ""roleRef:  apiGroup: rbac.authorization.k8s.io  kind: ClusterRole  name: system:kube-apiserver-to-kubeletsubjects:  - apiGroup: rbac.authorization.k8s.io    kind: User    name: kubernetesEOFkubectl apply -f apiserver-to-kubelet-rbac.yaml</code></pre><h5 id="5-7-新增加Worker-Node"><a href="#5-7-新增加Worker-Node" class="headerlink" title="5.7 新增加Worker Node"></a><strong>5.7 新增加Worker Node</strong></h5><h6 id="1-拷贝已部署好的Node相关文件到新节点"><a href="#1-拷贝已部署好的Node相关文件到新节点" class="headerlink" title="1. 拷贝已部署好的Node相关文件到新节点"></a><strong>1. 拷贝已部署好的Node相关文件到新节点</strong></h6><p>在master节点将Worker Node涉及文件拷贝到新节点192.168.31.72/73</p><pre class=" language-shell"><code class="language-shell">scp -r /opt/kubernetes root@192.168.31.72:/opt/scp -r /usr/lib/systemd/system/{kubelet,kube-proxy}.service root@192.168.31.72:/usr/lib/systemd/systemscp -r /opt/cni/ root@192.168.31.72:/opt/scp /opt/kubernetes/ssl/ca.pem root@192.168.31.72:/opt/kubernetes/ssl</code></pre><h6 id="2-删除kubelet证书和kubeconfig文件"><a href="#2-删除kubelet证书和kubeconfig文件" class="headerlink" title="2. 删除kubelet证书和kubeconfig文件"></a><strong>2. 删除kubelet证书和kubeconfig文件</strong></h6><pre class=" language-shell"><code class="language-shell">rm /opt/kubernetes/cfg/kubelet.kubeconfig rm -f /opt/kubernetes/ssl/kubelet*</code></pre><p>注：这几个文件是证书申请审批后自动生成的，每个Node不同，必须删除重新生成。</p><h6 id="3-修改主机名"><a href="#3-修改主机名" class="headerlink" title="3. 修改主机名"></a><strong>3. 修改主机名</strong></h6><pre class=" language-shell"><code class="language-shell">vi /opt/kubernetes/cfg/kubelet.conf--hostname-override=k8s-node1vi /opt/kubernetes/cfg/kube-proxy-config.ymlhostnameOverride: k8s-node1</code></pre><h6 id="4-启动并设置开机启动"><a href="#4-启动并设置开机启动" class="headerlink" title="4. 启动并设置开机启动"></a><strong>4. 启动并设置开机启动</strong></h6><pre class=" language-shell"><code class="language-shell">systemctl daemon-reloadsystemctl start kubeletsystemctl enable kubeletsystemctl start kube-proxysystemctl enable kube-proxy</code></pre><h6 id="5-在Master上批准新Node-kubelet证书申请"><a href="#5-在Master上批准新Node-kubelet证书申请" class="headerlink" title="5. 在Master上批准新Node kubelet证书申请"></a><strong>5. 在Master上批准新Node kubelet证书申请</strong></h6><pre class=" language-shell"><code class="language-shell">kubectl get csrNAME                                                   AGE   SIGNERNAME                                    REQUESTOR           CONDITIONnode-csr-4zTjsaVSrhuyhIGqsefxzVoZDCNKei-aE2jyTP81Uro   89s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pendingkubectl certificate approve node-csr-4zTjsaVSrhuyhIGqsefxzVoZDCNKei-aE2jyTP81Uro</code></pre><h6 id="6-查看Node状态"><a href="#6-查看Node状态" class="headerlink" title="6. 查看Node状态"></a><strong>6. 查看Node状态</strong></h6><pre class=" language-shell"><code class="language-shell">kubectl get nodeNAME         STATUS     ROLES    AGE   VERSIONk8s-master   Ready      <none>   65m   v1.18.3k8s-node1    Ready      <none>   12m   v1.18.3k8s-node2    Ready      <none>   81s   v1.18.3</code></pre><p>Node2（192.168.31.73 ）节点同上。记得修改主机名！</p><h4 id="六、部署Dashboard和CoreDNS"><a href="#六、部署Dashboard和CoreDNS" class="headerlink" title="六、部署Dashboard和CoreDNS"></a><strong>六、部署Dashboard和CoreDNS</strong></h4><h5 id="6-1-部署Dashboard"><a href="#6-1-部署Dashboard" class="headerlink" title="6.1 部署Dashboard"></a><strong>6.1 部署Dashboard</strong></h5><pre class=" language-shell"><code class="language-shell">$ wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta8/aio/deploy/recommended.yaml</code></pre><p>默认Dashboard只能集群内部访问，修改Service为NodePort类型，暴露到外部：</p><pre class=" language-shell"><code class="language-shell"># vi recommended.yamlkind: ServiceapiVersion: v1metadata:  labels:    k8s-app: kubernetes-dashboard  name: kubernetes-dashboard  namespace: kubernetes-dashboardspec:  ports:    - port: 443      targetPort: 8443      nodePort: 30001  type: NodePort  selector:    k8s-app: kubernetes-dashboardkubectl apply -f recommended.yamlkubectl get pods,svc -n kubernetes-dashboardNAME                                             READY   STATUS              RESTARTS   AGEpod/dashboard-metrics-scraper-694557449d-z8gfb   1/1     Running             0          2m18spod/kubernetes-dashboard-9774cc786-q2gsx         1/1     Running             0          2m19sNAME                                TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)         AGEservice/dashboard-metrics-scraper   ClusterIP   10.0.0.141   <none>        8000/TCP        2m19sservice/kubernetes-dashboard        NodePort    10.0.0.239   <none>        443:30001/TCP   2m19s</code></pre><p>访问地址：<a href="https://NodeIP:30001" target="_blank" rel="noopener">https://NodeIP:30001</a></p><p>创建service account并绑定默认cluster-admin管理员集群角色：</p><pre class=" language-shell"><code class="language-shell">kubectl create serviceaccount dashboard-admin -n kube-systemkubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-adminkubectl describe secrets -n kube-system $(kubectl -n kube-system get secret | awk '/dashboard-admin/{print $1}')</code></pre><p>使用输出的token登录Dashboard。</p><p><a href="https://imgchr.com/i/DV6Np6" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/11/17/DV6Np6.png" alt="DV6Np6.png"></a></p><p><a href="https://imgchr.com/i/DV6dXD" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/11/17/DV6dXD.png" alt="DV6dXD.png"></a></p><h5 id="6-2-部署CoreDNS"><a href="#6-2-部署CoreDNS" class="headerlink" title="6.2 部署CoreDNS"></a><strong>6.2 部署CoreDNS</strong></h5><p>CoreDNS用于集群内部Service名称解析。</p><pre class=" language-shell"><code class="language-shell">kubectl apply -f coredns.yamlkubectl get pods -n kube-system NAME                          READY   STATUS    RESTARTS   AGEcoredns-5ffbfd976d-j6shb      1/1     Running   0          32skube-flannel-ds-amd64-2pc95   1/1     Running   0          38mkube-flannel-ds-amd64-7qhdx   1/1     Running   0          15mkube-flannel-ds-amd64-99cr8   1/1     Running   0          26m</code></pre><p>DNS解析测试：</p><pre class=" language-shell"><code class="language-shell">kubectl run -it --rm dns-test --image=busybox:1.28.4 shIf you don't see a command prompt, try pressing enter./ # nslookup kubernetesServer:    10.0.0.2Address 1: 10.0.0.2 kube-dns.kube-system.svc.cluster.localName:      kubernetesAddress 1: 10.0.0.1 kubernetes.default.svc.cluster.local</code></pre><p>解析没问题。</p><p>至此，单Master集群部署完成，下一篇扩容为多Master集群~</p>]]></content>
      
      
      <categories>
          
          <category> container </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>k8s资源监控</title>
      <link href="2020/11/14/monitor/prometheus-k8s-zi-yuan-jian-kong/"/>
      <url>2020/11/14/monitor/prometheus-k8s-zi-yuan-jian-kong/</url>
      
        <content type="html"><![CDATA[<h4 id="k8s-资源监控"><a href="#k8s-资源监控" class="headerlink" title="k8s 资源监控"></a>k8s 资源监控</h4><blockquote><p><code>kubernetes</code>新一代的监控模型由：核心指标流水线和第三方非核心监控流水线组成。核心指标流水线由<code>kubelet</code>、 <code>metric-server</code> 以及由<code>API-server</code>提供的<code>API</code>组成；负责<code>CPU</code>累积使用率、内存实时使用率、<code>POD</code>资源占用率、 <code>Container</code>磁盘占用率等。而第三方非核心监控流水线 负责从<code>OS</code>收集各种指标数据并提供给终端用户、存储系统、 以及<code>HPA</code>等。 监控系统收集两种指标： 资源指标与自定义指标。 </p></blockquote><blockquote><p><strong><code>Metrics-server</code></strong> 是资源指标<code>API</code> 。它提供核心指标，包括<code>CPU</code>累积使用率、内存实时使用率、<code>Pod</code> 的资源占用率及 容器的磁盘占用率。这些指标由<code>kubelet</code>、<code>metrics-server</code>以及由<code>API server</code>提供的。 </p></blockquote><blockquote><p><strong><code>Prometheus</code></strong>是自定义指标的提供者。它收集的数据还需要经过<code>kube-state-metrics</code>转换处理，再由 <code>k8s-prometheus-adapter</code> 输出为<code>metrics-ap</code>i 才能被 <code>kubernetes cluster</code> 所读取。用于从系统收集各种指标数据，并经过处理提供给 终端用户、存储系统以及 <code>HPA</code>，这些数据包括核心指标和许多非核心指标。</p></blockquote><blockquote><p> <strong>资源指标**</strong><code>API</code>** 负责收集各种资源指标，但它需要扩展<code>APIServer</code> 。 可以利用 <code>aggregator</code> 将 <code>metrics-server</code> 与 <code>APIServer</code>进行聚合，达到扩展功能的效果。这样 就可以利用扩展的 <code>API Server</code> 功能(即资源指标<code>API</code>)进行收集 各种资源指标(1.8+支持)。<code>kubectl top</code> 、<code>HPA</code>等功能组件 必须依赖资源指标 <code>API</code> （早期版本它们依赖<code>heapster</code>）。 </p></blockquote><blockquote><p><strong>``HPA`</strong>根据<code>CPU</code>、<code>Memory</code>、<code>IO</code>、<code>net connections</code>等指标进行扩展或收缩(早期的<code>heapster</code>只能提供<code>CPU</code>、<code>Memory</code>指标) </p></blockquote><h5 id="一、metrics-server"><a href="#一、metrics-server" class="headerlink" title="一、metrics-server"></a><strong>一、</strong>metrics-server</h5><blockquote><p>是托管在kubernetes cluster上的一个Pod ，再由 kube-aggregator 将它和原API Server 进行聚合，达到扩展API 的 效果。它是现在 kubectl top 、HPA的前提依赖。 </p></blockquote><p><strong>部署**</strong><code>metrics-server</code>** 如下： </p><p>参考 ：<a href="https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/metrics-server" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/metrics-server</a> </p><p>当metrics-server部署完毕后，如上所示可以查看到 metrics相关的API，并且可以使用kubectl top 命令查看node或 pod的资源占用情况 。 </p><p><strong>如果需要安装最新版本可以</strong> </p><p><code>git clone https://github.com/kubernetes-incubator/metrics-server.git</code> </p><p><code>cd metrics-server/deploy/1.8+/</code>     </p><p><code>kubectl apply -f ./</code> </p><p><strong>如果发现</strong><code>metrics-server</code><strong>的</strong><code>pod</code>可以正常启动，但在执行<strong>kubectl top node</strong>时提示<strong><code>metrics-server</code></strong> <strong>不可用</strong>，在执行 <code>kubectl log metrics-server-* -n kube-system</code> 时有错 误提示，很可能是因为：<code>resource-reader.yaml</code> 文件中 <code>ClusterRole</code> 的<code>rules</code>中缺少 <code>namespaces</code> 权限，以及<code>metrics-server-deployment.yaml</code>文件中<code>container</code>下缺少以下语句，以忽略<code>tls</code>认证。 </p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">command</span><span class="token punctuation">:</span>   <span class="token punctuation">-</span> /metrics<span class="token punctuation">-</span>server   <span class="token punctuation">-</span> <span class="token punctuation">-</span><span class="token punctuation">-</span>kubelet<span class="token punctuation">-</span>insecure<span class="token punctuation">-</span>tls   <span class="token punctuation">-</span> <span class="token punctuation">-</span><span class="token punctuation">-</span>kubelet<span class="token punctuation">-</span>preferred<span class="token punctuation">-</span>address<span class="token punctuation">-</span>types=InternalIP</code></pre><h5 id="二、Prometheus"><a href="#二、Prometheus" class="headerlink" title="二、Prometheus"></a>二、Prometheus</h5><p>官网 :   <a href="https://prometheus.io" target="_blank" rel="noopener">https://prometheus.io</a></p><p>Architecture</p><p><a href="https://imgchr.com/i/BNhGyF" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/31/BNhGyF.png" alt="BNhGyF.png"></a></p><blockquote><p>Prometheus 通过node_exporter获取各<strong>Nodes</strong>的信息。 <strong>node_exporter**</strong>它只负责节点级别的信息汇总，如果需要** </p><p><strong>采集其它指标数据，就需要部署专用的**</strong>exporter** 。 Prometheus 通过 metrics-url 地址到各<strong>Pods</strong>获取数据 。 </p><p>prometheus 提供了一个Restful 风格的<strong>PromQL</strong>接口，可以让用户输入查询表达式。但K8s的 API Server 无法查询 </p><p>其值 ，因为它们默认的数据格式不统一。数据需要<strong>kube-state-metrics</strong>组件将其处理、转换，然后由<strong>k8s</strong></p><p><strong>prometheus-adapter</strong>组件读取并聚合到API上，最后 kubernetes cluster 的API server 才能识别。 所以<strong>各节点需</strong> </p><p><strong>要部署**</strong>node_exporter** <strong>组件，然后**</strong>Prometheus<strong><strong>从各节点的</strong></strong>node_exporter<strong><strong>上获取</strong></strong>infomation<strong>**，然后就可以通过</strong> </p><p><strong>PromQL</strong> <strong>查询各种数据。这些数据的格式再由**</strong>kube-state-metrics<strong><strong>组件进行转换，然后再由</strong></strong>kube-prometheus**</p><p><strong>adapter**</strong>组件将转换后的数据输出为<strong>**Custom metrics API</strong> <strong>，并聚合到**</strong>API<strong>**上，以便用户使用</strong>。 </p></blockquote><p><a href="https://imgchr.com/i/BNhWFI" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/31/BNhWFI.png" alt="BNhWFI.png"></a></p><p><strong>部署**</strong>kubernetes**, 如下： </p><p>参考 ：<a href="https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/prometheus" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/prometheus</a> </p><p><strong>1)</strong> <strong>定义名称空间</strong> </p><pre class=" language-shell"><code class="language-shell">kubectl apply -f namespace.yaml</code></pre><p><strong>2)</strong> <strong>部署**</strong>node_exporter**</p><pre class=" language-shell"><code class="language-shell">cd node_exporter/ kubectl apply -f ./</code></pre><p><strong>3)</strong> <strong>部署**</strong>prometheus**</p><pre class=" language-shell"><code class="language-shell">cd ../prometheus/ kubectl apply -f ./</code></pre><p><strong>4)</strong> <strong>部署**</strong>kube-state-metrics**</p><pre class=" language-shell"><code class="language-shell">cd ../kube-state-metrics/ kubectl apply -f ./</code></pre><p><strong>5)</strong> <strong>部署**</strong>prometheus-adapter** </p><p>参考 ：<a href="https://github.com/DirectXMan12/k8s-prometheus-adapter/tree/master/deploy" target="_blank" rel="noopener">https://github.com/DirectXMan12/k8s-prometheus-adapter/tree/master/deploy</a></p><pre class=" language-shell"><code class="language-shell">cd ../k8s-prometheus-adapter/ grep secretName custom-metrics-apiserver-deployment.yaml cd /etc/kubernetes/pki/ (umask 077; openssl genrsa -out serving.key 2048)openssl req -new -key serving.key -out serving.csr -subj "/CN=serving" openssl x509 -req -in serving.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out serving.crt -days 3650 kubectl create secret generic cm-adapter-serving-certs --from-file=serving.crt=./serving.crt --from-file=serving.key=./serving.key -n prom kubectl get secret -n prom cd - kubectl apply -f ./</code></pre><p><strong>6)</strong> <strong>部署**</strong>alertmanager**</p><pre class=" language-shell"><code class="language-shell">cd ../alertmanager/ kubectl create secret generic dingtalk-secret --from- literal=token=fasdfsfsdfgsdfg944dsfgsdfgsadfsdfgsdfgsdfgsdfgsdfgsdfgsdfgfasert -n prom kubectl apply -f ./</code></pre><p>钉钉报警参考：<a href="https://github.com/cnych/alertmanager-dingtalk-hook" target="_blank" rel="noopener">https://github.com/cnych/alertmanager-dingtalk-hook</a></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">route</span><span class="token punctuation">:</span>   <span class="token key atrule">group_by</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'alertname'</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># 报警分组依据 </span>  <span class="token key atrule">group_wait</span><span class="token punctuation">:</span> 10s <span class="token comment" spellcheck="true"># 最初即第一次等待多久时间发送一组警报的通知 </span>  <span class="token key atrule">group_interval</span><span class="token punctuation">:</span> 10s <span class="token comment" spellcheck="true"># 在发送新警报前的等待时间 </span>  <span class="token key atrule">repeat_interval</span><span class="token punctuation">:</span> 5m <span class="token comment" spellcheck="true"># 发送重复警报的周期 对于email配置中，此项不可以设置过低，否则将会由于邮件发送太 多频繁，被smtp服务器拒绝 </span>  <span class="token key atrule">receiver</span><span class="token punctuation">:</span> <span class="token string">'email'</span> <span class="token comment" spellcheck="true"># 发送警报的接收者的名称，以下receivers name的名称</span></code></pre><h5 id="三、-Grafana"><a href="#三、-Grafana" class="headerlink" title="三、**Grafana**"></a><strong>三、**</strong>Grafana**</h5><blockquote><p>grafana 是一个可视化面板，有着非常漂亮的图表和布局展示，功能齐全的度量仪表盘和图形编辑器，支持 Graphite、zabbix、InflfluxDB、Prometheus、OpenTSDB、Elasticsearch 等作为数据源，比 Prometheus 自带的 图表展示功能强大太多，更加灵活，有丰富的插件，功能更加强大。(使用promQL语句查询出了一些数据，并且在 Prometheus 的 Dashboard 中进行了展示，但是明显可以感觉到 Prometheus 的图表功能相对较弱，所以一般会使用第三方的工具展示这些数据，例Grafana) </p></blockquote><p><strong>部署**</strong>Grafana** 参考 ：<a href="https://github.com/kubernetes/heapster/tree/master/deploy/kube-confifig/inflfluxdb" target="_blank" rel="noopener">https://github.com/kubernetes/heapster/tree/master/deploy/kube-confifig/inflfluxdb</a></p><pre class=" language-shell"><code class="language-shell">cd grafana/ kubectl apply -f grafana.yaml kubectl get pods -n prom</code></pre><blockquote><p>Grafana的使用，默认用户名密码都是admin，登录后首先添加数据源 (如果登录grafana web 时不用输入用户名、 密码即可操作，说明在grafana.yml 文件中的GF_AUTH_ANONYMOUS_ENABLED 项设置了true，导致匿名用户以 admin的角色登录；将其更改为 false，然后再次kubectl apply -f grafana.yml 即可解决 )</p></blockquote><p><a href="https://imgchr.com/i/BNtacT" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/30/BNtacT.png" alt="BNtacT.png"></a></p><h5 id="四、-Ingress-nginx"><a href="#四、-Ingress-nginx" class="headerlink" title="四、**Ingress-nginx**"></a><strong>四、**</strong>Ingress-nginx**</h5><pre class=" language-shell"><code class="language-shell"># cat ingress-rule-monitor-svc.yamlapiVersion: extensions/v1beta1 kind: Ingress metadata:   name: ingress-rule-monitor   namespace: prom   annotations:     kubernetes.io/ingress.class: "nginx"     nginx.ingress.kubernetes.io/whitelist-source-range: "10.0.0.0/8, 192.168.0.0/16" spec:   rules:   - host: grafana-devel.domain.cn     http:       paths:       - path: /v1        backend:           serviceName: monitoring-grafana           servicePort: 80   - host: prometheus-devel.domain.cn     http:       paths:       - path: /v1        backend:           serviceName: prometheus           servicePort: 9090 # kubectl apply -f ingress-rule-monitor-svc.yaml</code></pre><h5 id="五、-Exporters-and-integrations"><a href="#五、-Exporters-and-integrations" class="headerlink" title="五、**Exporters and integrations**"></a><strong>五、**</strong>Exporters and integrations**</h5><pre class=" language-shell"><code class="language-shell">--- apiVersion: v1 kind: Service metadata:   name: nginx-svc   labels:     app: nginx   annotations:     prometheus.io/scrape: "true"     prometheus.io/port: "9113" spec:   ports:   - port: 80     name: http   - port: 443     name: https   - port: 9113    name: exporter-port  selector:     app: nginx     #type: NodePort --- apiVersion: apps/v1 kind: Deployment metadata:   name: nginx spec:   replicas: 1   selector:     matchLabels:       app: nginx   template:     metadata:       labels:         app: nginx       annotations:         prometheus.io/scrape: "true"         prometheus.io/port: "9113"     spec:       containers:       - name: nginx         image: nginx:latest         imagePullPolicy: IfNotPresent         ports:         - containerPort: 80           name: http         - containerPort: 443           name: https       - name: nginx-exporter         image: nikosch86/nginx_exporter:latest         resources:          requests:            cpu: 100m            memory: 100Mi         ports:         - containerPort: 9113           name: exporter-port</code></pre>]]></content>
      
      
      <categories>
          
          <category> monitor </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SQL语句优化</title>
      <link href="2020/11/10/sql/sql-yu-ju-you-hua/"/>
      <url>2020/11/10/sql/sql-yu-ju-you-hua/</url>
      
        <content type="html"><![CDATA[<h2 id="1、注意通配符中Like的使用"><a href="#1、注意通配符中Like的使用" class="headerlink" title="1、注意通配符中Like的使用"></a>1、注意通配符中Like的使用</h2><p>以下写法会造成全表的扫描，例如：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> id<span class="token punctuation">,</span>name <span class="token keyword">from</span> userinfo <span class="token keyword">where</span> name <span class="token operator">like</span> <span class="token string">'%name%'</span><span class="token keyword">select</span> id<span class="token punctuation">,</span>name <span class="token keyword">from</span> userinfo <span class="token keyword">where</span> name <span class="token operator">like</span> <span class="token string">'%name'</span></code></pre><p>下面的写法执行效率快很多，因为它使用了索引</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> id<span class="token punctuation">,</span>name <span class="token keyword">from</span> userinfo <span class="token keyword">where</span> name <span class="token operator">like</span> <span class="token string">'name%'</span></code></pre><h2 id="2、避免在where子句中对字段进行函数操作"><a href="#2、避免在where子句中对字段进行函数操作" class="headerlink" title="2、避免在where子句中对字段进行函数操作"></a>2、避免在where子句中对字段进行函数操作</h2><pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> id <span class="token keyword">from</span> userinfo <span class="token keyword">where</span> substring<span class="token punctuation">(</span>name<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token string">'xiaomi'</span><span class="token keyword">select</span> id <span class="token keyword">from</span> userinfo <span class="token keyword">where</span> datediff<span class="token punctuation">(</span>day<span class="token punctuation">,</span>datefield<span class="token punctuation">,</span><span class="token string">'2017-05-17'</span><span class="token punctuation">)</span> <span class="token operator">>=</span> <span class="token number">0</span></code></pre><p>上面两句都对字段进行了函数处理，会导致查询分析器放弃了索引的使用。</p><p>正确的写法：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> id <span class="token keyword">from</span> userinfo <span class="token keyword">where</span> name <span class="token operator">like</span><span class="token string">'xiaomi%'</span><span class="token keyword">select</span> id <span class="token keyword">from</span> userinfo <span class="token keyword">where</span> datefield <span class="token operator">&lt;=</span> <span class="token string">'2017-05-17'</span></code></pre><p>通俗理解就是where子句‘=’ 左边不要出现函数、算数运算或者其他表达式运算</p><h2 id="3、在子查询当中，尽量用exists代替in"><a href="#3、在子查询当中，尽量用exists代替in" class="headerlink" title="3、在子查询当中，尽量用exists代替in"></a>3、在子查询当中，尽量用exists代替in</h2><pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> name <span class="token keyword">from</span> userinfo <span class="token number">a</span> <span class="token keyword">where</span> id <span class="token operator">in</span><span class="token punctuation">(</span><span class="token keyword">select</span> id <span class="token keyword">from</span> userinfo <span class="token number">b</span><span class="token punctuation">)</span>可以改为<span class="token keyword">select</span> name <span class="token keyword">from</span> userinfo <span class="token number">a</span> <span class="token keyword">where</span> <span class="token keyword">exists</span><span class="token punctuation">(</span><span class="token keyword">select</span> <span class="token number">1</span> <span class="token keyword">from</span> userinfo <span class="token number">b</span> <span class="token keyword">where</span> id <span class="token operator">=</span> <span class="token number">a</span><span class="token punctuation">.</span>id<span class="token punctuation">)</span></code></pre><h2 id="4、where子句中尽量不要使用is-null-或-is-not-null对字段进行判断"><a href="#4、where子句中尽量不要使用is-null-或-is-not-null对字段进行判断" class="headerlink" title="4、where子句中尽量不要使用is null 或 is not null对字段进行判断"></a>4、where子句中尽量不要使用is null 或 is not null对字段进行判断</h2><pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> id <span class="token keyword">from</span> userinfo <span class="token keyword">where</span> name <span class="token operator">is</span> <span class="token boolean">null</span></code></pre><p>尽量在数据库字段中不出现null，如果查询的时候条件为 is null ，索引将不会被使用，造成查询效率低，</p><p>因此数据库在设计的时候，尽可能将某个字段可能为空的时候设置默认值，那么查询的时候可以</p><p>根据默认值进行查询，比如name字段设置为0，查询语句可以修改为</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> id <span class="token keyword">from</span> userinfo <span class="token keyword">where</span> name<span class="token operator">=</span><span class="token number">0</span></code></pre><h2 id="5、避免在where子句使用or作为链接条件"><a href="#5、避免在where子句使用or作为链接条件" class="headerlink" title="5、避免在where子句使用or作为链接条件"></a>5、避免在where子句使用or作为链接条件</h2><pre class=" language-java"><code class="language-java">select id from userinfo where name<span class="token operator">=</span><span class="token string">'xiaoming'</span> or name<span class="token operator">=</span><span class="token string">'xiaowang'</span>可以改写为：select id from userinfo where name <span class="token operator">=</span> <span class="token string">'xiaoming'</span> union allselect id from userinfo where name <span class="token operator">=</span> <span class="token string">'xiaowang'</span></code></pre><h2 id="6、避免在-where-子句中使用-或-lt-gt-操作符。"><a href="#6、避免在-where-子句中使用-或-lt-gt-操作符。" class="headerlink" title="6、避免在 where 子句中使用 != 或 &lt;&gt; 操作符。"></a>6、避免在 where 子句中使用 != 或 &lt;&gt; 操作符。</h2><pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> name <span class="token keyword">from</span> userinfo <span class="token keyword">where</span> id <span class="token operator">&lt;></span> <span class="token number">0</span></code></pre><p>说明：数据库在查询时，对 != 或 &lt;&gt; 操作符不会使用索引，</p><p>而对于 &lt; 、 &lt;= 、 = 、 &gt; 、 &gt;= 、 BETWEEN AND，数据库才会使用索引。</p><p>因此对于上面的查询，正确写法可以改为：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> name <span class="token keyword">from</span> userinfo <span class="token keyword">where</span> id <span class="token operator">&lt;</span> <span class="token number">0</span> <span class="token keyword">union</span> <span class="token keyword">all</span><span class="token keyword">select</span> name <span class="token keyword">from</span> userinfo <span class="token keyword">where</span> id <span class="token operator">></span> <span class="token number">0</span></code></pre><h2 id="7、少用in-或-not-in"><a href="#7、少用in-或-not-in" class="headerlink" title="7、少用in 或 not in"></a>7、少用in 或 not in</h2><p>对于连续的数值范围查询尽量使用BETWEEN AND，例如：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> name <span class="token keyword">from</span> userinfo <span class="token keyword">where</span> id <span class="token operator">BETWEEN</span>  <span class="token number">10</span> <span class="token operator">AND</span> <span class="token number">70</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> SQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Interview </tag>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus</title>
      <link href="2020/10/29/monitor/prometheus/"/>
      <url>2020/10/29/monitor/prometheus/</url>
      
        <content type="html"><![CDATA[<h4 id="Prometheus"><a href="#Prometheus" class="headerlink" title="Prometheus"></a><code>Prometheus</code></h4><h5 id="架构介绍"><a href="#架构介绍" class="headerlink" title="架构介绍"></a>架构介绍</h5><h6 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h6><blockquote><p>1.一套开源的系统监控报警框架。</p><ol start="2"><li><p><code>Prometheus</code>基于<code>Golang</code>编写，不存在任何的第三方依赖。</p></li><li><p>由 <code>SoundCloud</code> 开源监控告警解决方案。</p></li><li><p>单一节点就可以存储百万的监控指标，每秒处理数十万的数据点。</p></li><li><p>简单的可扩展性，<code>Prometheus</code>对于联邦集群的支持，可以让多个<code>Prometheus</code>实例产生一个逻辑集群，当单实例<code>Prometheus Server</code>处理的任务量过大时，</p><p>通过使用功能分区(<code>sharding</code>)+联邦集群(<code>federation</code>)可以对其进行扩展。</p></li><li><p>开放性，使用<code>Prometheus</code>的<code>client library</code>的输出格式不止支持<code>Prometheus</code>的格式化数据，也可以输出支持其它监控系统的格式化数据，</p><p>比如<code>Graphite</code>。<br><a href="https://prometheus.io/docs/instrumenting/clientlibs/" target="_blank" rel="noopener">https://prometheus.io/docs/instrumenting/clientlibs/</a></p></li></ol></blockquote><h6 id="优劣势"><a href="#优劣势" class="headerlink" title="优劣势"></a>优劣势</h6><blockquote><p>易管理性:</p><p><code>Prometheus</code>核心部分只有一个单独的二进制文件，可直接在本地工作，不依赖于分布式存储。<br><code>Nagios/zabbix</code>: 需要有专业的人员进行安装，配置和管理，并且过程很复杂。</p><p>业务数据相关性:<br>监控服务的运行状态，基于<code>Prometheus</code>丰富的Client库，用户可以轻松的在应用程序中添加对Prometheus的支持，</p><p>从而让用户可以获取服务和应用内部真正的运行状态。<a href="https://prometheus.io/docs/instrumenting/clientlibs/" target="_blank" rel="noopener">https://prometheus.io/docs/instrumenting/clientlibs/</a></p><p>Nagios/zabbix:大部分的监控能力都是围绕系统的一些边缘性的问题，主要针对系统服务和资源的状态以及应用程序的可用性。</p><p>高效：单一<code>Prometheus</code>可以处理数以百万的监控指标；每秒处理数十万的数据点。<br>易于伸缩：通过使用功能分区（<code>sharing</code>）+联邦集群（<code>federation</code>）可以对<code>Prometheus</code>进行扩展，形成一个逻辑集群；</p><p><code>Prometheus</code>提供多种语言的客户端<code>SDK</code>，这些<code>SDK</code>可以快速让应用程序纳入到<code>Prometheus</code>的监控当中。</p><p>良好的可视化：<code>Prometheus</code>除了自带有<code>Prometheus UI</code>，<code>Prometheus</code>还提供了一个独立的基于<code>Ruby On Rails的Dashboard</code>解决方案<code>Promdash</code>。</p><p>另外最新的<code>Grafana</code>可视化工具也提供了完整的<code>Proetheus</code>支持，基于<code>Prometheus</code>提供的<code>API</code>还可以实现自己的监控可视化<code>UI</code>。</p><p>由于数据采集可能会有丢失，所以 Prometheus 不适用对采集数据要 100% 准确的情形。</p><p>但如果用于记录时间序列数据，Prometheus 具有很大的查询优势，此外，Prometheus 适用于微服务的体系架构。</p></blockquote><h6 id="工作过程："><a href="#工作过程：" class="headerlink" title="工作过程："></a>工作过程：</h6><blockquote><ol><li>Prometheus server定期从配置好</li><li>的jobs或者exporters中拉取metrics， 或者接收来自Pushgateway发送过来的metrics，或者从其它的Prometheus server中拉metrics。<ol start="2"><li>Prometheus server在本地存储收集到的metrics，并运行定义好的alerts.rules，记录新的时间序列或者向Alert manager推送警报。</li><li>Alertmanager根据配置文件，对接收到的警报进行处理，发出告警。</li><li>在图形界面中，可视化采集数据。</li></ol></li></ol></blockquote><h5 id="server安装"><a href="#server安装" class="headerlink" title="server安装"></a><code>server</code>安装</h5><blockquote><p>下载地址：<a href="https://prometheus.io/download/" target="_blank" rel="noopener">https://prometheus.io/download/</a></p></blockquote><h6 id="安装-server"><a href="#安装-server" class="headerlink" title="安装 server"></a>安装 <code>server</code></h6><pre class=" language-shell"><code class="language-shell">解压：[root@node2 soft]# tar xf prometheus-2.17.2.linux-amd64.tar.gz -C /usr/local/启动：[root@node2 prometheus-2.17.2.linux-amd64]# ./prometheus --config.file=./prometheus.yml验证：[root@node2 ~]# lsof -i :9090 </code></pre><h6 id="默认配置"><a href="#默认配置" class="headerlink" title="默认配置"></a>默认配置</h6><pre class=" language-shell"><code class="language-shell">global: 主要有四个属性scrape_interval: 拉取 targets 的默认时间间隔。scrape_timeout: 拉取一个 target 的超时时间。evaluation_interval: 执行 rules 的时间间隔。external_labels: 额外的属性，会添加到拉取的数据并存到数据库中。</code></pre><h6 id="数据浏览"><a href="#数据浏览" class="headerlink" title="数据浏览"></a>数据浏览</h6><pre class=" language-shell"><code class="language-shell">查看所有metrics：         http://192.168.204.132:9090/metrics图形查看：         http://192.168.204.132:9090/graphUsing the expression browser:          promhttp_metric_handler_requests_total：server所有请求          promhttp_metric_handler_requests_total{code="200"}          count(promhttp_metric_handler_requests_total)Using the graphing interface:          rate(promhttp_metric_handler_requests_total{code="200"}[1m])：每秒请求率Grafana图形展示：          http://192.168.204.132:3000</code></pre><h5 id="node-exporter安装"><a href="#node-exporter安装" class="headerlink" title="node_exporter安装"></a><code>node_exporter</code>安装</h5><h6 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h6><blockquote><p>负责数据的汇报，不同的Exporter负责不同的业务。<br>是一个独立运行的进程，对外暴露一个用于获取监控数据的HTTP服务。<br>其统一命名格式：xx_exporter。系统：node_exporter，MySQL：mysqld_exporter</p></blockquote><h6 id="下载-amp-安装"><a href="#下载-amp-安装" class="headerlink" title="下载&amp;安装"></a>下载&amp;安装</h6><blockquote><p>地址：<a href="https://prometheus.io/download/#node_exporter" target="_blank" rel="noopener">https://prometheus.io/download/#node_exporter</a></p><p>可以获取到所在主机大量的运行数据，典型的包括CPU、内存，磁盘、网络等等监控样本。<br>采用Golang编写，并且不存在任何的第三方依赖，只需要下载，解压即可运行。</p></blockquote><pre class=" language-shell"><code class="language-shell">解压：[root@node3 soft]# tar xf node_exporter-0.18.1.linux-amd64.tar.gz -C /usr/local/启动：[root@node3 node_exporter-0.18.1.linux-amd64]# ./node_exporter 验证：[root@node3 ~]# lsof -i:9100</code></pre><h6 id="数据查看"><a href="#数据查看" class="headerlink" title="数据查看"></a>数据查看</h6><pre class=" language-shell"><code class="language-shell">http://192.168.204.133:9100/metrics其他指标：node_boot_time：系统启动时间node_cpu：系统CPU使用量node_disk*：磁盘IOnode_filesystem*：文件系统用量node_load1：系统负载node_memeory*：内存使用量node_network*：网络带宽node_time：当前系统时间go_*：node exporter中go相关指标process_*：node exporter自身进程相关运行指标</code></pre><h6 id="Server端配置"><a href="#Server端配置" class="headerlink" title="Server端配置"></a><code>Server</code>端配置</h6><pre class=" language-shell"><code class="language-shell">添加静态配置：发现node3节点[root@node2 prometheus-2.17.2.linux-amd64]# vim prometheus.yml - job_name: 'node'    static_configs:    - targets: ['192.168.204.133:9100']重启server：[root@node2 prometheus-2.17.2.linux-amd64]# ./prometheus --config.file=./prometheus.yml数据浏览：http://192.168.204.132:9090/graph测试metric：node_load1</code></pre><h6 id="Grafana数据展示"><a href="#Grafana数据展示" class="headerlink" title="Grafana数据展示"></a><code>Grafana</code>数据展示</h6><blockquote><p>地址：<a href="https://grafana.com/grafana/dashboards?direction=asc&amp;orderBy=name" target="_blank" rel="noopener">https://grafana.com/grafana/dashboards?direction=asc&amp;orderBy=name</a></p></blockquote><p>其他</p><blockquote><p><a href="https://prometheus.io/docs/instrumenting/exporters/#exporters-and-integrations" target="_blank" rel="noopener">https://prometheus.io/docs/instrumenting/exporters/#exporters-and-integrations</a></p><p>用户自定义：<br>      除了直接使用社区提供的Exporter程序以外，用户还可以基于Prometheus提供的Client Library创建自己的Exporter程序，</p><p>目前Promthues社区官方提供了对以下编程语言的支持：Go、Java/Scala、Python、Ruby。</p><p>同时还有第三方实现的如：Bash、C++、Common Lisp、Erlang,、Haskeel、Lua、Node.js、PHP、Rust等。</p></blockquote><h5 id="mysqld-exporter安装"><a href="#mysqld-exporter安装" class="headerlink" title="mysqld_exporter安装"></a><code>mysqld_exporter</code>安装</h5><h6 id="架构-1"><a href="#架构-1" class="headerlink" title="架构"></a>架构</h6><blockquote><p>负责数据的汇报，不同的Exporter负责不同的业务。<br>是一个独立运行的进程，对外暴露一个用于获取监控数据的HTTP服务。<br>其统一命名格式：xx_exporter。系统：node_exporter，MySQL：mysqld_exporter</p></blockquote><h6 id="下载-amp-安装-1"><a href="#下载-amp-安装-1" class="headerlink" title="下载&amp;安装"></a>下载&amp;安装</h6><blockquote><p>地址：<a href="https://prometheus.io/download/#mysqld_exporter" target="_blank" rel="noopener">https://prometheus.io/download/#mysqld_exporter</a></p><p>可以获取到所在MySQL大量的运行数据，典型的包括连接数、QPS、慢SQL等等监控样本。<br>采用Golang编写，并且不存在任何的第三方依赖，只需要下载，解压即可运行。</p></blockquote><pre class=" language-shell"><code class="language-shell">mysqld_exporter Node3节点MySQL 8.0建立账户：mysql> CREATE USER 'exporter'@'localhost' IDENTIFIED BY 'Exporter123%';mysql> GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO 'exporter'@'localhost';解压mysqld_exporter：[root@node3 soft]# tar xf mysqld_exporter-0.12.1.linux-amd64.tar.gz -C /usr/local 配置mysqld_exporter：[root@node3 mysqld_exporter-0.12.1.linux-amd64]# more .my.cnf [client]user=exporterpassword=Exporter123%启动：[root@node3 mysqld_exporter-0.12.1.linux-amd64]# ./mysqld_exporter --config.my-cnf=".my.cnf"</code></pre><h6 id="数据查看-1"><a href="#数据查看-1" class="headerlink" title="数据查看"></a>数据查看</h6><blockquote><p><a href="http://192.168.204.133:9104/metrics" target="_blank" rel="noopener">http://192.168.204.133:9104/metrics</a></p></blockquote><h6 id="Server端配置-1"><a href="#Server端配置-1" class="headerlink" title="Server端配置"></a><code>Server</code>端配置</h6><pre class=" language-shell"><code class="language-shell">添加静态配置：发现node3节点[root@node2 prometheus-2.17.2.linux-amd64]# vim prometheus.yml  - job_name: 'mysqld'    static_configs:    - targets: ['192.168.204.133:9104']重启server：[root@node2 prometheus-2.17.2.linux-amd64]# ./prometheus --config.file=./prometheus.yml数据浏览：http://192.168.204.132:9090/graph测试metric：mysql_global_status_threads_running</code></pre><h6 id="Grafana数据展示-1"><a href="#Grafana数据展示-1" class="headerlink" title="Grafana数据展示"></a><code>Grafana</code>数据展示</h6><blockquote><p><a href="https://github.com/percona/grafana-dashboards" target="_blank" rel="noopener">https://github.com/percona/grafana-dashboards</a></p></blockquote><h5 id="pushgateway"><a href="#pushgateway" class="headerlink" title="pushgateway"></a><code>pushgateway</code></h5><h6 id="架构-2"><a href="#架构-2" class="headerlink" title="架构"></a>架构</h6><blockquote><p>prometheus还是采用pull方式来采集pushgateway的数据，采集端通过push方式把数据push给pushgateway，来完成数据的上报。<br>主要解决：<br>         1. prometheus无法直接连接采集节点。<br>                  2. 采集节点执行太快，prometheus可能拉取不及时。</p></blockquote><h6 id="下载、安装、启动"><a href="#下载、安装、启动" class="headerlink" title="下载、安装、启动"></a>下载、安装、启动</h6><pre class=" language-shell"><code class="language-shell">地址：https://prometheus.io/download/#pushgateway安装：[root@node2 soft]# tar xf pushgateway-1.2.0.linux-amd64.tar.gz -C /usr/local/启动pushgateway：[root@node2 pushgateway-1.2.0.linux-amd64]# ./pushgateway </code></pre><h6 id="自定义采集端"><a href="#自定义采集端" class="headerlink" title="自定义采集端"></a>自定义采集端</h6><pre class=" language-shell"><code class="language-shell">[root@node2 pushgateway-1.2.0.linux-amd64]# vim push_memory.sh#!/bin/bash # desc push memory info total_memory=$(free  |awk '/Mem/{print $2}')used_memory=$(free  |awk '/Mem/{print $3}')job_name="custom_memory"instance_name="192.168.204.132"cat <<EOF | curl --data-binary @- http://192.168.204.132:9091/metrics/job/$job_name/instance/$instance_name#TYPE custom_memory_total  gaugecustom_memory_total $total_memory#TYPE custom_memory_used  gaugecustom_memory_used $used_memoryEOF执行采集端：[root@node2 pushgateway-1.2.0.linux-amd64]# sh push_memory.sh </code></pre><h6 id="Pushgateway查看"><a href="#Pushgateway查看" class="headerlink" title="Pushgateway查看"></a>Pushgateway查看</h6><blockquote><p><a href="http://192.168.204.132:9091" target="_blank" rel="noopener">http://192.168.204.132:9091</a></p></blockquote><h6 id="Prometheus集成pushgateway"><a href="#Prometheus集成pushgateway" class="headerlink" title="Prometheus集成pushgateway"></a>Prometheus集成pushgateway</h6><pre class=" language-shell"><code class="language-shell">[root@node2 prometheus-2.17.2.linux-amd64]# vim prometheus.yml - job_name: "pushgateway"   honor_labels: true #使用采集端自定义标签   static configs :   - targets:["192.168.204.132:9091"]重启prometheus server：[root@node2 prometheus-2.17.2.linux-amd64]# ./prometheus --config.file=./prometheus.yml </code></pre><h5 id="自定义exporter"><a href="#自定义exporter" class="headerlink" title="自定义exporter"></a>自定义exporter</h5><pre class=" language-shell"><code class="language-shell">需求：添加Logical_CPU_core_total（逻辑cpu个数）编写脚本：[root@node3 node_exporter-0.18.1.linux-amd64]# mkdir key[root@node3 node_exporter-0.18.1.linux-amd64]# cd key/[root@node3 key]# vim key_runner#! /bin/bashecho Logical_CPU_core_total  `cat /proc/cpuinfo| grep "processor"| wc -l`运行：[root@node3 key]# sh key_runner >  key.prom启动node_exporter：[root@node3 node_exporter-0.18.1.linux-amd64]# ./node_exporter --collector.textfile.directory=/usr/local/node_exporter-0.18.1.linux-amd64/key/</code></pre><h4 id="PromQL基本概念"><a href="#PromQL基本概念" class="headerlink" title="PromQL基本概念"></a>PromQL基本概念</h4><blockquote><p>PromQL (Prometheus Query Language) 是 Prometheus 自己开发的数据查询 DSL 语言。</p></blockquote><pre class=" language-shell"><code class="language-shell">数据解读 （node3节点）：# HELP node_load1 1m load average. # TYPE node_load1 gauge node_load1 0.05 # HELP node_load15 15m load average. # TYPE node_load15 gauge node_load15 0.05在time-series中的每一个点称为一个样本（sample），样本由以下三部分组成：指标(metric)：监控项的名称;时间戳(timestamp)：一个精确到毫秒的时间戳;样本值(value)： 一个float64的浮点型。</code></pre><h6 id="指标和标签"><a href="#指标和标签" class="headerlink" title="指标和标签"></a>指标和标签</h6><pre class=" language-shell"><code class="language-shell">在形式上，所有的指标(Metric)都通过如下格式标示：         <metric name>{<label name>=<label value>, ...}指标的名称(metric name)可以反映被监控样本的含义。标签(label)反映了当前样本的特征维度，通过这些维度Promtheus可以对样本数据进行过滤，聚合等。比如：# HELP node_filesystem_avail_bytes Filesystem space available to non-root users in bytes. # TYPE node_filesystem_avail_bytes gaugenode_filesystem_avail_bytes{device="/dev/sda1",fstype="xfs",mountpoint="/boot"} 7.927808e+07 node_filesystem_avail_bytes{device="/dev/sda3",fstype="xfs",mountpoint="/"} 3.5899379712e+10 node_filesystem_avail_bytes{device="rootfs",fstype="rootfs",mountpoint="/"} 3.5899379712e+10 node_filesystem_avail_bytes{device="tmpfs",fstype="tmpfs",mountpoint="/run"} 1.4524416e+09 node_filesystem_avail_bytes{device="tmpfs",fstype="tmpfs",mountpoint="/run/user/0"} 2.9749248e+08</code></pre><h6 id="Metric类型-四种"><a href="#Metric类型-四种" class="headerlink" title="Metric类型-四种"></a>Metric类型-四种</h6><blockquote><p>Counter(计数器类型)<br>Counter类型的指标的工作方式和计数器一样，只增不减（除非系统发生了重置）。</p><p>Counter一般用于累计值，例如记录请求次数、任务完成数、错误发生次数。<br>例如：node_network_receive_bytes_total{device=”ens33”} 2.873766021e+09</p><p>Gauge(仪表盘类型)<br>Gauge是可增可减的指标类，可以用于反应当前应用的状态。比如在监控主机时，主机当前的内容大小(node_memory_MemFree)，</p><p>可用内存大小（node_memory_MemAvailable）。或者时容器当前的cpu使用率，内存使用率。<br>例如：node_load1 0.05</p><p>Histogram(直方图类型)<br>主要用于表示一段时间范围内对数据进行采样（通常是请求持续时间或响应大小），</p><p>并能够对其指定区间以及总数进行统计，通常它采集的数据展示为直方图。<br>例如：# TYPE prometheus_tsdb_compaction_chunk_range_seconds histogram </p><p>Summary(摘要类型)<br>Summary类型和Histogram类型相似，主要用于表示一段时间内数据采样结果（通常时请求持续时间或响应大小），</p><p>它直接存储了quantile（分位数）数据，而不是根据统计区间计算出来的。<br>例如：# TYPE go_gc_duration_seconds summary</p></blockquote><h6 id="Histogram与Summary存在价值"><a href="#Histogram与Summary存在价值" class="headerlink" title="Histogram与Summary存在价值"></a>Histogram与Summary存在价值</h6><blockquote><p>一般情况下人们都倾向于使用某些量化指标的平均值，例如CPU的平均使用率、页面的平均响应时间。</p><p>我们以系统API调用的平均响应时间为例：如果大多数API请求都维持在100ms的响应时间范围内，</p><p>而个别请求的响应时间需要5s，那么就会导致某些WEB页面的响应时间落到中位数的情况，而这种现象被称为长尾问题。</p><p>为了区分是平均的慢还是长尾的慢，最简单的方式就是按照请求延迟的范围进行分组。<br>例如，统计延迟在0<del>10ms之间的请求数有多少，而10</del>20ms之间的请求数又有多少。</p><p>通过这种方式可以快速分析系统慢的原因。Histogram和Summary都是为了能够解决这样问题的存在，</p><p>通过Histogram和Summary类型的监控指标，我们可以快速了解监控样本的分布情况。</p></blockquote><h6 id="Histogram与Summary联系"><a href="#Histogram与Summary联系" class="headerlink" title="Histogram与Summary联系"></a>Histogram与Summary联系</h6><pre class=" language-shell"><code class="language-shell">Histogram转换Summary：通过histogram_quantile()函数计算出其值的分位数。例如： histogram_quantile(0.5, prometheus_tsdb_compaction_chunk_range_seconds_bucket)Histogram通过histogram_quantile函数是在服务器端计算的分位数，而Sumamry的分位数则是直接在客户端计算完成。因此对于分位数的计算而言，Summary在通过PromQL进行查询时有更好的性能表现，而Histogram则会消耗更多的资源。反之对于客户端而言Histogram消耗的资源更少。在选择这两种方式时用户应该按照自己的实际场景进行选择。</code></pre><h5 id="PromQL基本查询"><a href="#PromQL基本查询" class="headerlink" title="PromQL基本查询"></a>PromQL基本查询</h5><h6 id="查询时间序列"><a href="#查询时间序列" class="headerlink" title="查询时间序列"></a>查询时间序列</h6><pre class=" language-shell"><code class="language-shell">例如：prometheus_http_requests_total             prometheus_http_requests_total{handler="/metrics"}             {code="200"}完全匹配：=和!=两种：label=valuelabel!=value正则匹配：~和~!两种，多个用|分隔label=~regxlabel!=~regx如：prometheus_http_requests_total{handler=~"/metrics|/api/v1/query_range"}</code></pre><h6 id="范围查询"><a href="#范围查询" class="headerlink" title="范围查询"></a>范围查询</h6><pre class=" language-shell"><code class="language-shell">prometheus_http_requests_total{handler="/metrics"}[1m]其他单位：s - 秒m - 分钟h - 小时d - 天w - 周y - 年时间位移：prometheus_http_requests_total{handler="/metrics"}[1m] offset 1d</code></pre><h6 id="聚合查询"><a href="#聚合查询" class="headerlink" title="聚合查询"></a>聚合查询</h6><pre class=" language-shell"><code class="language-shell">求和：        count(prometheus_http_requests_total)   -- 瞬时数据        sum(prometheus_http_requests_total)平均值：        avg(prometheus_http_requests_total) by (code)平均增长：         increase(prometheus_http_requests_total{handler="/metrics"}[1m])平均增长速率：长尾问题irate        rate(prometheus_http_requests_total{handler="/metrics"}[1m])       长尾问题：irate解决</code></pre><h6 id="标量和瞬时数据"><a href="#标量和瞬时数据" class="headerlink" title="标量和瞬时数据"></a>标量和瞬时数据</h6><pre class=" language-shell"><code class="language-shell">标量：纯数值，没有时序         10瞬时数据：有时序          count(prometheus_http_requests_total) 转换：          scalar(count(prometheus_http_requests_total))</code></pre><h6 id="PromQL操作符"><a href="#PromQL操作符" class="headerlink" title="PromQL操作符"></a>PromQL操作符</h6><h6 id="数学运算"><a href="#数学运算" class="headerlink" title="数学运算"></a>数学运算</h6><pre class=" language-shell"><code class="language-shell">按MB展示：        node_memory_MemFree_bytes / 1024 / 1024相加：        node_disk_written_bytes_total + node_disk_read_bytes_total        工作模式：依次找到与左边向量元素匹配（标签完全一致）的右边向量元素进行运算，如果没找到匹配元素，则直接丢弃。其他运算符：+ (加法)- (减法)* (乘法)/ (除法)% (求余)^ (幂运算)</code></pre><h6 id="布尔-集合运算"><a href="#布尔-集合运算" class="headerlink" title="布尔/集合运算"></a>布尔/集合运算</h6><blockquote><p>布尔操作：0/1</p><p>用处：<br>     prometheus_http_requests_total{handler=”/metrics”} &gt; bool 1000</p><p>集合：<br>and (并且)<br>or (或者)<br>unless (排除)<br>vector1 and vector2 会产生一个由vector1的元素组成的新的向量。该向量包含vector1中完全匹配vector2中的元素组成。（1,2,3/1,2,3）<br>vector1 or vector2 会产生一个新的向量，该向量包含vector1中所有的样本数据，以及vector2中没有与vector1匹配到的样本数据。（1,2,3/3,4）<br>vector1 unless vector2 会产生一个新的向量，新向量中的元素由vector1中没有与vector2匹配的元素组成。（1,2,3/3,4）<br>注意：默认与右向量中的所有元素进行匹配</p></blockquote><h6 id="匹配模式"><a href="#匹配模式" class="headerlink" title="匹配模式"></a>匹配模式</h6><blockquote><p>典型两种：<br>      一对一（one-to-one）, 多对一（many-to-one）或一对多（one-to-many）。</p><p>一对一匹配： ignoreing匹配时忽略某些便签。而on匹配限定在某些便签之内。<br>prometheus_http_requests_total{code=”200”,handler=”/metrics”,instance=”localhost:9090”,job=”prometheus”} /  ignoring(handler)<br>promhttp_metric_handler_requests_total{code=”200”,instance=”localhost:9090”,job=”prometheus”}</p><p>多对一： group_left或者group_right来确定哪一个向量具有更高的基数（充当“多”的角色）。<br>prometheus_http_requests_total{code=”200”} / ignoring(handler) group_left promhttp_metric_handler_requests_total{code=”200”,instance=”localhost:9090”,job=”prometheus”}</p></blockquote><h6 id="PromQL聚合操作"><a href="#PromQL聚合操作" class="headerlink" title="PromQL聚合操作"></a>PromQL聚合操作</h6><p>内置聚合运算</p><pre class=" language-shell"><code class="language-shell">sum：         sum(prometheus_http_requests_total)  without：移除标签  by：保留标签其他：sum (求和)min (最小值)max (最大值)avg (平均值)stddev (标准差)stdvar (标准差异)count (计数)count_values (对value进行计数)bottomk (后n条时序)topk (前n条时序)quantile (分布统计)count_values：统计每一个样本出现的次数            count_values("cishu", prometheus_http_requests_total) quantile：计算分位数quantile(φ, express)其中0 ≤ φ ≤ 1            quantile(0.9, prometheus_http_requests_total)</code></pre><h6 id="增长率-counter类型"><a href="#增长率-counter类型" class="headerlink" title="增长率-counter类型"></a>增长率-counter类型</h6><blockquote><p>增长量：increase(v range-vector)<br>   increase(prometheus_http_requests_total{handler=”/metrics”}[1m])</p><p>增长率：rate(v range-vector)<br>   increase(prometheus_http_requests_total{handler=”/metrics”}[1m]) / 60<br>   rate(prometheus_http_requests_total{handler=“/metrics”}[1m])  – 长尾问题<br>   irate(prometheus_http_requests_total{handler=“/metrics”}[1m])  – 瞬时增长率<br>   – irate函数是通过区间向量中最后两个样本数据来计算区间向量的增长速率。这种方式可以避免在时间窗口范围内的“长尾问题”，</p><p>并且体现出更好的灵敏度，通过irate函数绘制的图标能够更好的反应样本数据的瞬时变化状态。<br>   – irate函数相比于rate函数提供了更高的灵敏度，不过当需要分析长期趋势或者在告警规则中，irate的这种灵敏度反而容器造成干扰。</p><p>因此在长期趋势分析或者告警中更推荐使用rate函数。</p></blockquote><h6 id="预测-gauge类型"><a href="#预测-gauge类型" class="headerlink" title="预测-gauge类型"></a>预测-gauge类型</h6><blockquote><p>​        在告警中，如果业务是线性增长，那么告警可以起到作用。告警出现，相关人员进行处理。<br>​        比如监控文件系统剩余情况，但是有可能某些情况增长不是线性的，当你设置&lt;10GB告警，有可能突然就满了，造成系统不可用。</p><p>预测时间序列v在t秒后的值：predict_linear(v range-vector, t scalar)<br>          predict_linear(node_memory_Active_file_bytes[6h], 10*3600) / 1024/1024<br>          – 基于简单线性回归模型</p></blockquote><h6 id="分位数-Histogram-summary类型"><a href="#分位数-Histogram-summary类型" class="headerlink" title="分位数-Histogram/summary类型"></a>分位数-Histogram/summary类型</h6><blockquote><p>Histogram和Summary用于体现数据分布情况。</p><p>TYPE prometheus_tsdb_compaction_chunk_size_bytes histogram<br>TYPE go_gc_duration_seconds summary</p><p>转换Histogram –&gt;  Summary：<br>        histogram_quantile(0.5, prometheus_tsdb_compaction_chunk_size_bytes_bucket)</p><p>区别：<br>        Summary是直接在客户端计算了数据分布的分位数情况。<br>        histogram_quantile函数是在服务器端计算的分位数。</p></blockquote><h6 id="动态标签替换"><a href="#动态标签替换" class="headerlink" title="动态标签替换"></a>动态标签替换</h6><pre class=" language-shell"><code class="language-shell">uplabel_replace(v instant-vector, dst_label string, replacement string, src_label string, regex string) label_replace(up, "ljp", "$1", "instance",  "(.*):.*")label_join(v instant-vector, dst_label string, separator string, src_label_1 string, src_label_2 string, ...)label_join(up, "ljp", "-----", "instance", "job")</code></pre><h5 id="PromQL-HTTP查询"><a href="#PromQL-HTTP查询" class="headerlink" title="PromQL HTTP查询"></a>PromQL HTTP查询</h5><h6 id="固定查询"><a href="#固定查询" class="headerlink" title="固定查询"></a>固定查询</h6><blockquote><p>Prometheus提供HTTP API接口：/api/v1</p><pre class=" language-shell"><code class="language-shell">[root@node2 ~]# curl 'http://localhost:9090/api/v1/query?query=up' |python -m json.tool</code></pre></blockquote><h6 id="更多参数"><a href="#更多参数" class="headerlink" title="更多参数"></a>更多参数</h6><pre class=" language-shell"><code class="language-shell">query=<string>: Prometheus expression query string.time=<rfc3339 | unix_timestamp>: Evaluation timestamp. Optional.timeout=<duration>: Evaluation timeout. Optional. Defaults to and is capped by the value of the -query.timeout flag.[root@node2 ~]# curl 'http://localhost:9090/api/v1/query?query=up&time=1588411186'|python -m json.tool</code></pre><h6 id="范围查询-1"><a href="#范围查询-1" class="headerlink" title="范围查询"></a>范围查询</h6><pre class=" language-shell"><code class="language-shell">接口：/api/v1/query_rangequery=<string>: Prometheus expression query string.start=<rfc3339 | unix_timestamp>: Start timestamp.end=<rfc3339 | unix_timestamp>: End timestamp.step=<duration | float>: Query resolution step width in duration format or float number of seconds.timeout=<duration>: Evaluation timeout. Optional. Defaults to and is capped by the value of the -query.timeout flag.[root@node2 ~]# curl 'http://localhost:9090/api/v1/query_range?query=up&start=2020-05-02T09:10:30.781Z&end=2020-05-02T09:11:30.781Z&step=15s'| python -m json.tool</code></pre><h6 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h6><blockquote><p>地址：<a href="https://prometheus.io/docs/prometheus/latest/querying/api/" target="_blank" rel="noopener">https://prometheus.io/docs/prometheus/latest/querying/api/</a></p></blockquote><h4 id="告警规则设置"><a href="#告警规则设置" class="headerlink" title="告警规则设置"></a>告警规则设置</h4><blockquote><p>Prometheus检测阈值，Alertmanager进一步处理（分组、抑制、静默等），最后发给接收端。</p></blockquote><h6 id="规则设置（阈值）"><a href="#规则设置（阈值）" class="headerlink" title="规则设置（阈值）"></a>规则设置（阈值）</h6><pre class=" language-shell"><code class="language-shell">1. 指定规则文件[root@node2 prometheus-2.17.2.linux-amd64]# vim prometheus.yml rule_file:  - "alert_rules.yaml"  # - "second_rules.yaml"2. 配置规则[root@node2 prometheus-2.17.2.linux-amd64]# vim alert_rules.yml groups:  - name: os_monitor    rules:    - alert: 系统告警1      expr: up == 0      # for: 2m      labels:        environment: product      annotations:        Alert_type: 系统告警        Server: '{{$labels.instance}}'        explain: "我还是曾经那个少年，。。。系统挂了：{{ $value }}"    - alert: 系统告警2      expr: node_load15 >= 0.01      for: 2m      labels:        environment: product      annotations:        Alert_type: 系统告警        Server: '{{$labels.instance}}'        explain: "当前CPU负载：{{ $value }}"</code></pre><h6 id="告警查看"><a href="#告警查看" class="headerlink" title="告警查看"></a>告警查看</h6><blockquote><ol><li>Web（实时告警）：<a href="http://192.168.204.132:9090/alerts（rules）" target="_blank" rel="noopener">http://192.168.204.132:9090/alerts（rules）</a></li><li>Metric（历史告警）：ALERTS</li></ol></blockquote><h5 id="关联alertmanager"><a href="#关联alertmanager" class="headerlink" title="关联alertmanager"></a>关联alertmanager</h5><h6 id="Email告警"><a href="#Email告警" class="headerlink" title="Email告警"></a>Email告警</h6><blockquote><p>Prometheus检测阈值，Alertmanager进一步处理（分组、抑制、静默等），最后发给接收端。</p></blockquote><h6 id="alertmanager安装"><a href="#alertmanager安装" class="headerlink" title="alertmanager安装"></a>alertmanager安装</h6><pre class=" language-shell"><code class="language-shell">软件地址：https://prometheus.io/download/#alertmanager安装：[root@node2 soft]# tar xf alertmanager-0.20.0.linux-amd64.tar.gz  -C /usr/local/目录结构：[root@node2 soft]# cd /usr/local/alertmanager-0.20.0.linux-amd64/[root@node2 alertmanager-0.20.0.linux-amd64]# lltotal 48292-rwxr-xr-x 1 3434 3434 26971621 Dec 11 22:13 alertmanager （服务）-rw-r--r-- 1 3434 3434      380 Dec 11 22:51 alertmanager.yml （配置文件）-rwxr-xr-x 1 3434 3434 22458246 Dec 11 22:14 amtool （检测工具）-rw-r--r-- 1 3434 3434    11357 Dec 11 22:51 LICENSE-rw-r--r-- 1 3434 3434      457 Dec 11 22:51 NOTICE</code></pre><h6 id="alertmanager配置（邮件告警）"><a href="#alertmanager配置（邮件告警）" class="headerlink" title="alertmanager配置（邮件告警）"></a>alertmanager配置（邮件告警）</h6><pre class=" language-shell"><code class="language-shell"># 全局配置，可以设置发送账户信息  global:# 路由，根据标签告警发给谁route: <route># 接受端，设置接收端用户信息receivers:  - <receiver> ...# 抑制规则，可以屏蔽告警inhibit_rules:  [ - <inhibit_rule> ... ]    # 模板，生成最终告警页面格式templates:  [ - <filepath> ... ] </code></pre><pre class=" language-shell"><code class="language-shell"># vim alertmanager.yml global:  smtp_from: 'lijinpeng@xx.com.cn'  smtp_smarthost: 'mail.xx.com.cn:25'  smtp_hello: 'xx.com.cn'  smtp_auth_username: 'lijinpeng@xx.com.cn'  smtp_auth_password: 'xxxxxx'  smtp_require_tls: false  resolve_timeout: 5mroute:  receiver: 'email'  group_by: [...]  group_wait: 5s  group_interval: 5s  repeat_interval: 5mreceivers:- name: 'email'  email_configs:  - to: 'lijinpeng@xx.com.cn'    send_resolved: true</code></pre><blockquote><p>Prometheus关联alertmanager</p><p>Prometheus负责产生告警，而Alertmanager负责告警产生后的后续处理。因此Alertmanager部署完成后，</p><p>需要在Prometheus中设置Alertmanager相关的信息。</p><p>配置prometheus：<br>[root@node2 prometheus-2.17.2.linux-amd64]# vim prometheus.yml </p><pre class=" language-shell"><code class="language-shell"># Alertmanager configurationalerting: alertmanagers:  - static_configs:    - targets:      - localhost:9093</code></pre><p>重启prometheus：<br>[root@node2 prometheus-2.17.2.linux-amd64]# ./prometheus –config.file=./prometheus.yml  &amp;</p></blockquote><h6 id="route路由详解"><a href="#route路由详解" class="headerlink" title="route路由详解"></a>route路由详解</h6><h6 id="分组机制"><a href="#分组机制" class="headerlink" title="分组机制"></a>分组机制</h6><blockquote><p>作用场景：<br>          将告警信息合并成一个通知。由于系统宕机可能导致大量的告警被同时触发，这时就利用分组机制，将所有告警合并成一个。</p></blockquote><h6 id="Route路由特性"><a href="#Route路由特性" class="headerlink" title="Route路由特性"></a>Route路由特性</h6><blockquote><p>用来设置报警的分发策略，它是一个基于标签匹配规则的树状结构，按照深度优先从左向右的顺序进行匹配。<br>每一个告警都会从配置中的顶级路由(route)进入路由树，根据标签匹配规则进入到不同的子路由，并且根据子路由设置的接收器发送告警。</p><p>如果未设置，将从父节点继承。<br>系统告警发给系统管理员、数据库告警发给数据库管理员：</p></blockquote><p><a href="https://imgtu.com/i/gpCnYD" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/26/gpCnYD.png" alt="gpCnYD.png"></a></p><h6 id="其他参数"><a href="#其他参数" class="headerlink" title="其他参数"></a>其他参数</h6><blockquote><p>match、match_re</p><p>continue：<br>     false 告警在匹配到第一个子节点之后就直接发送。<br>     true 报警则会继续进行后续子节点的匹配。</p></blockquote><h5 id="抑制规则inhibit与临时静默"><a href="#抑制规则inhibit与临时静默" class="headerlink" title="抑制规则inhibit与临时静默"></a>抑制规则inhibit与临时静默</h5><h6 id="屏蔽告警"><a href="#屏蔽告警" class="headerlink" title="屏蔽告警"></a>屏蔽告警</h6><blockquote><p>两种：</p><ol><li><p>抑制inhibit：根据配置规则自动屏蔽告警。</p></li><li><p>临时静默：web上手动屏蔽告警。</p></li></ol></blockquote><h6 id="抑制规则"><a href="#抑制规则" class="headerlink" title="抑制规则"></a>抑制规则</h6><blockquote><p>作用场景：<br>       Alertmanager的抑制机制可以避免当某种问题告警产生之后用户接收到大量由此问题导致的一系列的其它告警通知。<br>      例如当集群不可用时，用户可能只希望接收到一条告警（不是一组），目的是告诉我们这时候是集群出现了问题，</p><p>而不要再发大量其他告警（如集群中的应用异常、中间件服务异常的告警通知了）</p><p>注意，与分组不同，分组是将多个告警合并成一个发送（根据标签，一个邮件告警中包含10个告警信息）<br>          抑制，发一个告警（邮件中只有一个告警信息）可以是不同标签<br>                   优势，间接的帮你定位了问题根源。</p></blockquote><blockquote><h6 id="需求："><a href="#需求：" class="headerlink" title="需求："></a>需求：</h6><p>两个告警，一个cpu负载，一个gc相关。假设cpu告警了，gc就不报警了。</p><p>Prometheus server端增加gc告警规则：<br>[root@node2 prometheus-2.17.2.linux-amd64]# vim alert_rules.yml</p><p><a href="https://imgtu.com/i/gpCjcd" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/26/gpCjcd.png" alt="gpCjcd.png"></a></p><p>重启prometheus：<br>[root@node2 prometheus-2.17.2.linux-amd64]# ./prometheus –config.file=./prometheus.yml &amp;</p></blockquote><blockquote><h6 id="Alertmanager增加抑制策略："><a href="#Alertmanager增加抑制策略：" class="headerlink" title="Alertmanager增加抑制策略："></a>Alertmanager增加抑制策略：</h6><p>[root@node2 alertmanager-0.20.0.linux-amd64]# vim alertmanager.yml</p><p><a href="https://imgtu.com/i/gpPpHP" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/26/gpPpHP.png" alt="gpPpHP.png"></a></p><p>重启alertmanager：<br>[root@node2 alertmanager-0.20.0.linux-amd64]# ./alertmanager –config.file=alertmanager.yml  </p></blockquote><h5 id="钉钉告警"><a href="#钉钉告警" class="headerlink" title="钉钉告警"></a>钉钉告警</h5><pre class=" language-shell"><code class="language-shell">安装go环境软件获取：https://gomirrors.org/安装：[root@node2 soft]# tar xf go1.14.2.linux-amd64.tar.gz -C /usr/local/设置环境变量：[root@node2 local]# vim /etc/profileexport GOROOT=/usr/local/go #设置为go安装的路径export GOPATH=/u01/soft/gocode  #默认安装包的路径export PATH=$PATH:$GOROOT/bin:$GOPATH/bingolangci-lint安装：[root@node2 ~]# mkdir -p /u01/soft/gocode[root@node2 gocode]# curl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s v1.26.0   #会将golangci-lint下载到/u01/soft/gocode/bin[root@node2 bin]# chmod a+x golangci-lint  # 授权</code></pre><h6 id="安装webhook-dingding"><a href="#安装webhook-dingding" class="headerlink" title="安装webhook-dingding"></a>安装webhook-dingding</h6><pre class=" language-shell"><code class="language-shell">软件获取：https://github.com/timonwong/prometheus-webhook-dingtalk下载：[root@node2 soft]# mkdir -p /u01/soft/gocode/src/github.com/timonwong/[root@node2 soft]# cd /u01/soft/gocode/src/github.com/timonwong/[root@node2 timonwong]# git clone  https://github.com/timonwong/prometheus-webhook-dingtalk.git开始编译：[root@node2 timonwong]# cd prometheus-webhook-dingtalk/[root@node2 prometheus-webhook-dingtalk-master]# make-- 看我的日志make.txt结果：[root@node2 prometheus-webhook-dingtalk]# ll prometheus-webhook-dingtalk-rwxr-xr-x 1 root root 15684553 May  9 20:49 prometheus-webhook-dingtalk申请钉钉token：https://oapi.dingtalk.com/robot/send?access_token=xxxxxxx</code></pre><h6 id="启动dingding-webhook"><a href="#启动dingding-webhook" class="headerlink" title="启动dingding-webhook"></a>启动dingding-webhook</h6><pre class=" language-shell"><code class="language-shell">启动：[root@node2 prometheus-webhook-dingtalk]# ./prometheus-webhook-dingtalk --ding.profile="webhook1=https://oapi.dingtalk.com/robot/send?access_token=xxxxxxx“验证：[root@node2 prometheus-webhook-dingtalk]# lsof -i:8060COMMAND     PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAMEprometheu 13847 root    6u  IPv6  63543      0t0  TCP *:8060 (LISTEN)</code></pre><h6 id="配置alertmanager"><a href="#配置alertmanager" class="headerlink" title="配置alertmanager"></a>配置alertmanager</h6><blockquote><p>[root@node2 alertmanager-0.20.0.linux-amd64]# vim alertmanager.yml </p><p><a href="https://imgtu.com/i/gpPEcj" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/26/gpPEcj.png" alt="gpPEcj.png"></a></p><p>重启alertmanager<br>[root@node2 alertmanager-0.20.0.linux-amd64]# ./alertmanager –config.file=alertmanager.yml </p></blockquote><h6 id="基于文件的自动发现"><a href="#基于文件的自动发现" class="headerlink" title="基于文件的自动发现"></a>基于文件的自动发现</h6><blockquote><p>我们之前都是通过static_configs（静态）的方式，来让prometheus来pull（拉取）监控指标的。</p><p>如果我们再新增一个exporter监控程序，那么还得重启prometheus server。</p><p>那么现在我们需要一种不重启的，可以通过服务发现的方式，可以配置到file_sd<br>中。Prometheus server定时去扫这个文件，看看是否有新的exporter程序，就不需要进行重启server了。</p></blockquote><h6 id="编辑自动发现文件"><a href="#编辑自动发现文件" class="headerlink" title="编辑自动发现文件"></a>编辑自动发现文件</h6><pre class=" language-shell"><code class="language-shell">[root@node2 prometheus-2.17.2.linux-amd64]# vim targets.json [  {    "targets": ["192.168.204.133:9100"],    "labels": {      "job": "node",      "env": "prod"    }  }]</code></pre><h6 id="配置自动发现"><a href="#配置自动发现" class="headerlink" title="配置自动发现"></a>配置自动发现</h6><blockquote><p>[root@node2 prometheus-2.17.2.linux-amd64]# vim prometheus.yml</p><p><a href="https://imgtu.com/i/gpPYuR" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/04/26/gpPYuR.png" alt="gpPYuR.png"></a></p><p>重启server：<br>[root@node2 prometheus-2.17.2.linux-amd64]# ./prometheus –config.file=./prometheus.yml &amp;</p></blockquote><h5 id="基于consul的自动发现"><a href="#基于consul的自动发现" class="headerlink" title="基于consul的自动发现"></a>基于consul的自动发现</h5><h6 id="自动发现"><a href="#自动发现" class="headerlink" title="自动发现"></a>自动发现</h6><blockquote><p>static_configs: # 静态服务发现<br>file_sd_configs: # 文件服务发现<br>dns_sd_configs: # DNS 服务发现<br>kubernetes_sd_configs: # Kubernetes 服务发现<br>consul_sd_configs: # Consul 服务发现</p></blockquote><h6 id="Consul下载、安装、启动"><a href="#Consul下载、安装、启动" class="headerlink" title="Consul下载、安装、启动"></a>Consul下载、安装、启动</h6><blockquote><p>Consul 是基于 GO 语言开发的开源工具，主要面向分布式，服务化的系统提供服务注册、服务发现和配置管理的功能。<br>Consul 提供服务注册/发现、健康检查、Key/Value存储、多数据中心和分布式一致性保证等功能。</p><p>地址：<a href="https://www.consul.io/downloads.html" target="_blank" rel="noopener">https://www.consul.io/downloads.html</a></p><p>安装：[root@node2 soft]# mv consul /usr/local/bin/</p><p>启动：（单一节点）<br>[root@node2 soft]# consul agent -server -bind=0.0.0.0 -client=0.0.0.0 -bootstrap-expect=1 -data-dir=/u01/consul_data -node=node2 -ui</p></blockquote><h6 id="http注册"><a href="#http注册" class="headerlink" title="http注册"></a>http注册</h6><pre class=" language-shell"><code class="language-shell">注册node_exporter：[root@node2 ~]# curl -X PUT -d '{"id": "node","name": "node","address": "192.168.204.133","port": 9100,"tags": ["node"],"checks": [{"http": "http://192.168.204.133:9100/metrics", "interval": "5s"}]}'  http://192.168.204.132:8500/v1/agent/service/register注册mysqld_exporter：[root@node2 ~]# curl -X PUT -d '{"id": ",mysqld","name": "mysqld","address": "192.168.204.133","port": 9104,"tags": ["mysqld"],"checks": [{"http": "http://192.168.204.133:9104/metrics", "interval": "5s"}]}'  http://192.168.204.132:8500/v1/agent/service/register</code></pre><h6 id="Prometheus关联consul"><a href="#Prometheus关联consul" class="headerlink" title="Prometheus关联consul"></a>Prometheus关联consul</h6><blockquote><p>[root@node2 prometheus-2.17.2.linux-amd64]# vim prometheus.yml </p><pre class=" language-yaml"><code class="language-yaml">  <span class="token punctuation">-</span> <span class="token key atrule">job_name</span><span class="token punctuation">:</span> <span class="token string">'consul'</span>    <span class="token key atrule">consul_sd_configs</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">server</span><span class="token punctuation">:</span> <span class="token string">'192.168.204.132:8500'</span>      <span class="token key atrule">services</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></code></pre><p>重启prometheus server：<br>[root@node2 prometheus-2.17.2.linux-amd64]# ./prometheus –config.file=./prometheus.yml </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> monitor </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>influxdb+grafana监控网络情况</title>
      <link href="2020/10/26/monitor/influxdb-grafana-jian-kong-wang-luo-qing-kuang/"/>
      <url>2020/10/26/monitor/influxdb-grafana-jian-kong-wang-luo-qing-kuang/</url>
      
        <content type="html"><![CDATA[<h3 id="influxdb-grafana监控网络情况"><a href="#influxdb-grafana监控网络情况" class="headerlink" title="influxdb+grafana监控网络情况"></a>influxdb+grafana监控网络情况</h3><h5 id="一、-部署InfluxDB"><a href="#一、-部署InfluxDB" class="headerlink" title="一、 部署InfluxDB"></a>一、 部署InfluxDB</h5><pre class=" language-shell"><code class="language-shell">docker run -d -p 8086:8086 --name=influxdb influxdb</code></pre><p>以上命令dcoker会自动从仓库下载最新版本的influxdb镜像，后台运行一个名为influxdb的容器并映射主机8086端口到容器8086端口。</p><p>若想将数据存储到宿主机而非容器内，可使用以下命令启动挂载本地目录到容器内。</p><pre class=" language-shell"><code class="language-shell"># $pwd为当前工作目录，可替换为其它宿主机目录[root@localhost influxdb]# pwd/opt/influxdb[root@localhost influxdb]# docker run -d -p 8086:8086 -v $PWD:/var/lib/influxdb --name=influxdb influxdb</code></pre><p>启动InfluxDB容器后，通过http接口访问进行测试。</p><pre><code>curl -G http://localhost:8086/query --data-urlencode &quot;q=show databases&quot;</code></pre><p>若influxdb运行正常，则会返回如下结果：</p><pre><code># 链接查询参数为show databases 数据库会返回所有的数据库名，新安装的influxdb默认只有一个&quot;_internal&quot;# 数据库。{&quot;results&quot;:[{&quot;statement_id&quot;:0,&quot;series&quot;:[{&quot;name&quot;:&quot;databases&quot;,&quot;columns&quot;:[&quot;name&quot;],&quot;values&quot;:[[&quot;telegraf&quot;],[&quot;_internal&quot;],[&quot;network&quot;]]}]}]}</code></pre><h5 id="二、-启动influxdb，使用"><a href="#二、-启动influxdb，使用" class="headerlink" title="二、 启动influxdb，使用"></a>二、 启动influxdb，使用</h5><blockquote><p>PS：<a href="https://jasper-zhang1.gitbooks.io/influxdb/content/Introduction/getting_start.html" target="_blank" rel="noopener">InfluxDB中文文档</a>    </p><p>​        <a href="https://docs.influxdata.com/" target="_blank" rel="noopener">官网地址</a></p><p>其他命令请自行查看文档</p></blockquote><h6 id="1-进入容器"><a href="#1-进入容器" class="headerlink" title="1. 进入容器"></a>1. 进入容器</h6><pre class=" language-shell"><code class="language-shell">[root@localhost influxdb]# docker exec -it influxdb /bin/bash</code></pre><p>PS： 因为实验，所以 我使用的是默认 <code>influxdb</code> 的配置文件，可以自行查看官网修改</p><h6 id="2-启动influxdb，并且使用"><a href="#2-启动influxdb，并且使用" class="headerlink" title="2. 启动influxdb，并且使用"></a>2. 启动influxdb，并且使用</h6><ol><li>创建一个<code>mydb</code>数据库：</li></ol><pre class=" language-sql"><code class="language-sql"><span class="token operator">></span> <span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> network</code></pre><ol start="2"><li>现在数据库<code>mydb</code>已经创建好了，我们可以用<code>SHOW DATABASES</code>语句来看看已存在的数据库：</li></ol><pre><code>&gt; SHOW DATABASESname: databases---------------name_internalmydb</code></pre><blockquote><p>说明：<code>_internal</code>数据库是用来存储InfluxDB内部的实时监控数据的。</p></blockquote><p>不像<code>SHOW DATABASES</code>，大部分InfluxQL需要作用在一个特定的数据库上。你当然可以在每一个查询语句上带上你想查的数据库的名字，但是CLI提供了一个更为方便的方式<code>USE &lt;db-name&gt;</code>，这会为你后面的所以的请求设置到这个数据库上。例如：</p><pre><code>&gt; USE mydbUsing database mydb&gt;</code></pre><h6 id="3-使用HTTP接口创建数据库"><a href="#3-使用HTTP接口创建数据库" class="headerlink" title="3. 使用HTTP接口创建数据库"></a>3. 使用HTTP接口创建数据库</h6><p>使用<code>POST</code>方式发送到URL的<code>/query</code>路径，参数<code>q</code>为<code>CREATE DATABASE &lt;new_database_name&gt;</code>，下面的例子发送一个请求到本地运行的InfluxDB创建数据库<code>mydb</code>:</p><pre><code>curl -i -XPOST http://localhost:8086/query --data-urlencode &quot;q=CREATE DATABASE mydb&quot;</code></pre><h6 id="4-使用HTTP接口查询数据"><a href="#4-使用HTTP接口查询数据" class="headerlink" title="4. 使用HTTP接口查询数据"></a>4. 使用HTTP接口查询数据</h6><p>HTTP接口是InfluxDB查询数据的主要方式。通过发送一个<code>GET</code>请求到<code>/query</code>路径，并设置URL的<code>db</code>参数为目标数据库，设置URL参数<code>q</code>为查询语句。下面的例子是查询在<a href="https://jasper-zhang1.gitbooks.io/influxdb/content/Guide/writing_data.html" target="_blank" rel="noopener">写数据</a>里写入的数据点。</p><pre><code>curl -G &#39;http://localhost:8086/query?pretty=true&#39; --data-urlencode &quot;db=mydb&quot; --data-urlencode &quot;q=SELECT \&quot;value\&quot; FROM \&quot;cpu_load_short\&quot; WHERE \&quot;region\&quot;=&#39;us-west&#39;&quot;</code></pre><blockquote><p>InfluxDB返回一个json值，你查询的结果在<code>result</code>列表中，如果有错误发送，InfluxDB会在<code>error</code>这个key里解释错误发生的原因。</p></blockquote><h6 id="5-用户管理"><a href="#5-用户管理" class="headerlink" title="5. 用户管理"></a>5. 用户管理</h6><pre><code>&gt;shouw users (查看用户)&gt;create user &quot;username&quot; with password &#39;password&#39; (创建普通用户)&gt;create user &quot;username&quot; with password &#39;password&#39; with all privileges (创建管理员用户)&gt;drop user &quot;username&quot; (删除用户)&gt;auth (用户认证，设置密码后的登录认证)</code></pre><h6 id="6-shell脚本插入数据"><a href="#6-shell脚本插入数据" class="headerlink" title="6. shell脚本插入数据"></a>6. shell脚本插入数据</h6><blockquote><p>PS: 首先创建一个 数据库+用户+密码都为<code>network</code> <strong>（实验环境）</strong>    请自行搞定</p></blockquote><p>脚本地址：</p><p><a href="https://github.com/cyylog/Script/blob/master/Grafana/Ping/network_insert%20_InfluxDB.sh" target="_blank" rel="noopener">My Github</a></p><p>为方便 <code>grafana</code> 的可观性，请自行修改<code>dic</code> </p><p>放到计划任务中，可以看到表中已经有数据写入</p><pre class=" language-shell"><code class="language-shell">> use networkUsing database network> show MEASUREMENTSname: measurementsname----SG_BRlatenSG_BRlossSG_VNlatenSG_VNloss> </code></pre><h5 id="三、-部署Grafana"><a href="#三、-部署Grafana" class="headerlink" title="三、 部署Grafana"></a>三、 部署Grafana</h5><p>Grafana同样采用官方docker镜像进行快速部署。</p><pre class=" language-bash"><code class="language-bash">docker run -d -p 3000:3000 --name<span class="token operator">=</span>grafana grafana/grafana</code></pre><p>以上命令docker会拉取最新版grafana镜像，运行名为grafana的容器，并映射宿主机3000端口。</p><p>初次启动，grafana会创建数据库，时间稍长，稍后即可访问<code>http://localhost:3000</code>打开grafana登录页面。<br>输入默认用户名密码登录（admin）。</p><p><a href="https://imgchr.com/i/BneM2n" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/26/BneM2n.png" alt="BneM2n.png"></a></p><p>按照主页向导完成初次配置。</p><h6 id="1-添加数据源"><a href="#1-添加数据源" class="headerlink" title="1 添加数据源"></a>1 添加数据源</h6><p>点击添加数据源，按照下图配置选择influxdb添加一个influxdb数据源。</p><p>url需配置成正确的宿主机ip和端口（防火墙需放行8086），若不想暴露数据库端口，可换成influxdb容器的ip地址（需自行进入容器查看，容器重启后可能会发生变化）避免数据库暴露至公网。</p><p>InfluxDB Details需填写数据名（默认telegraf）、用户名和密码（默认均为root）。</p><p>填写完成后，点击<code>Save&amp;Test</code>按钮，若访问正常，会出现<code>Data source is working</code>提示，否则请检查配置内容以及网络（防火墙）。</p><p><a href="https://imgchr.com/i/Bne1K0" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/26/Bne1K0.png" alt="Bne1K0.png"></a></p><p><a href="https://imgchr.com/i/Bne3rV" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/26/Bne3rV.png" alt="Bne3rV.png"></a></p><h6 id="2-添加仪表板"><a href="#2-添加仪表板" class="headerlink" title="2 添加仪表板"></a>2 添加仪表板</h6><p> <strong>返回主页，点击添加仪表板按钮添加新仪表板，点击<code>Graph</code>创建一个Graph Panel。</strong></p><p><a href="https://imgchr.com/i/BneJVU" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/26/BneJVU.png" alt="BneJVU.png"></a></p><p><strong>配置好数据源，然后添加面板展示数据</strong></p><p><a href="https://imgchr.com/i/BneTZ8" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/26/BneTZ8.png" alt="BneTZ8.png"></a></p><p><strong>最后的结果如下</strong></p><p><a href="https://imgchr.com/i/Bne7dS" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/26/Bne7dS.png" alt="Bne7dS.png"></a></p><h5 id="PS-文章中使用的脚本"><a href="#PS-文章中使用的脚本" class="headerlink" title="PS:  文章中使用的脚本"></a>PS:  文章中使用的脚本</h5><p>地址： <a href="https://github.com/cyylog/Script/tree/master/Grafana/Ping" target="_blank" rel="noopener">https://github.com/cyylog/Script/tree/master/Grafana/Ping</a></p>]]></content>
      
      
      <categories>
          
          <category> monitor </category>
          
      </categories>
      
      
        <tags>
            
            <tag> influxdb </tag>
            
            <tag> grafana </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>K8S 原理</title>
      <link href="2020/10/25/interview/mian-shi-wen-dao-liao-k8s-yuan-li-hua-5-fen-zhong-lai-zong-jie-xia-yi-hou-zai-ye-bu-pa-liao/"/>
      <url>2020/10/25/interview/mian-shi-wen-dao-liao-k8s-yuan-li-hua-5-fen-zhong-lai-zong-jie-xia-yi-hou-zai-ye-bu-pa-liao/</url>
      
        <content type="html"><![CDATA[<h4 id="面试问到了K8S原理，花5分钟来总结下，以后再也不怕了"><a href="#面试问到了K8S原理，花5分钟来总结下，以后再也不怕了" class="headerlink" title="面试问到了K8S原理，花5分钟来总结下，以后再也不怕了"></a>面试问到了K8S原理，花5分钟来总结下，以后再也不怕了</h4><p>原创DevOps笔记2020-10-25 22:32:59</p><h5 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h5><p><img src="https://p1-tt.byteimg.com/origin/pgc-image/dd588922f3fe45c19362df0825722254?from=pc" alt="面试问到了K8S原理，花5分钟来总结下，以后再也不怕了"></p><p>K8S</p><p>K8S现在是一项必会的技能，它为软件工程师提供了强大的容器编排能力，模糊了开发和运维之间的边界，让我们开发、管理和维护一个大型的分布式系统和项目变得更加容易，并且每次面试多多少少都会问到，笔者也是被问到了很多次。本文就准备用最短的篇幅来介绍下K8S的工作过程。</p><h5 id="K8S架构组成"><a href="#K8S架构组成" class="headerlink" title="K8S架构组成"></a>K8S架构组成</h5><p>Kubernetes最初源于谷歌内部的Borg，提供了面向应用的容器集群部署和管理系统。Kubernetes借鉴了Borg的设计理念，比如Pod、Service、Labels和单Pod单IP等。</p><p><img src="https://p6-tt.byteimg.com/origin/pgc-image/6682804788b04ad7babe00c81a399a9b?from=pc" alt="面试问到了K8S原理，花5分钟来总结下，以后再也不怕了"></p><p>K8S架构图</p><p><strong>Kubernetes主要由以下几个核心组件组成：</strong></p><ul><li>etcd保存了整个集群的状态；</li><li>apiserver提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制；</li><li>controller manager负责维护集群的状态，比如故障检测、自动扩展、滚动更新等；</li><li>scheduler负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上；</li><li>kubelet负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理；</li><li>Container runtime负责镜像管理以及Pod和容器的真正运行（CRI）；</li><li>kube-proxy负责为Service提供cluster内部的服务发现和负载均衡；</li></ul><p><strong>除了核心组件，还有一些推荐的Add-ons：</strong></p><ul><li>kube-dns负责为整个集群提供DNS服务</li><li>Ingress Controller为服务提供外网入口</li><li>Heapster提供资源监控</li><li>Dashboard提供GUI</li><li>Federation提供跨可用区的集群</li><li>Fluentd-elasticsearch提供集群日志采集、存储与查询</li></ul><h5 id="k8s各组件间工作流程"><a href="#k8s各组件间工作流程" class="headerlink" title="k8s各组件间工作流程"></a>k8s各组件间工作流程</h5><p><img src="https://p6-tt.byteimg.com/origin/pgc-image/d89315f973f445a297cc5266814e60de?from=pc" alt="面试问到了K8S原理，花5分钟来总结下，以后再也不怕了"></p><p>K8S工作过程</p><p>①运维人员向kube-apiserver发出指令（我想干什么，我期望事情是什么状态）</p><p>（以下kube-apiserver简称apiserver、kube-controller-manager简称controller、kube-scheduler简称scheduler）</p><p>②api响应命令,通过一系列认证授权,把pod数据存储到etcd,创建deployment资源并初始化。(期望状态）</p><p>③controller通过list-watch机制,监测发现新的deployment,将该资源加入到内部工作队列,发现该资源没有关联的pod和replicaset,启用deployment controller创建replicaset资源,再启用replicaset controller创建pod。</p><p>④所有controller被创建完成后.将deployment,replicaset,pod资源更新存储到etcd。</p><p>⑤scheduler通过list-watch机制,监测发现新的pod,经过主机过滤、主机打分规则,将pod绑定(binding)到合适的主机。</p><p>⑥将绑定结果存储到etcd。</p><p>⑦kubelet每隔 20s(可以自定义)向apiserver通过NodeName 获取自身Node上所要运行的pod清单.通过与自己的内部缓存进行比较,新增加pod。</p><p>⑧kubelet创建pod。</p><p>⑨kube-proxy为新创建的pod注册动态DNS到CoreOS。给pod的service添加iptables/ipvs规则，用于服务发现和负载均衡。</p><p>⑩controller通过control loop（控制循环）将当前pod状态与用户所期望的状态做对比，如果当前状态与用户期望状态不同，则controller会将pod修改为用户期望状态，实在不行会将此pod删掉，然后重新创建pod。</p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p><img src="https://p6-tt.byteimg.com/origin/pgc-image/ec520fbb771643eaa85e245d77f26bb5?from=pc" alt="面试问到了K8S原理，花5分钟来总结下，以后再也不怕了"></p><p>K8S</p><p>Kubernetes的架构设计，理清楚之后，其实还是很简单的。面试的时候问到K8S原理，对于大部分人来说能答出这些，基本上就差不多了。Kubernetes深入的实现原理，还需要单独分析，本文只是一个抛砖引玉，如果有错误，欢迎大家批评指正。大家一起努力进步！</p><blockquote><p>原文地址：<a href="https://www.toutiao.com/i6887565254440518147/?tt_from=weixin&amp;utm_campaign=client_share&amp;wxshare_count=1&amp;timestamp=1618473782&amp;app=news_article&amp;utm_source=weixin&amp;utm_medium=toutiao_android&amp;use_new_style=1&amp;req_id=202104151603020101511991050002EFEE&amp;share_token=9d1e8f78-e9ae-4838-beed-445bb79b726f&amp;group_id=6887565254440518147&amp;wid=1618474130537" target="_blank" rel="noopener">https://www.toutiao.com/i6887565254440518147/?tt_from=weixin&amp;utm_campaign=client_share&amp;wxshare_count=1&amp;timestamp=1618473782&amp;app=news_article&amp;utm_source=weixin&amp;utm_medium=toutiao_android&amp;use_new_style=1&amp;req_id=202104151603020101511991050002EFEE&amp;share_token=9d1e8f78-e9ae-4838-beed-445bb79b726f&amp;group_id=6887565254440518147&amp;wid=1618474130537</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> Interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zabbix-原理</title>
      <link href="2020/10/24/monitor/zabbix-yuan-li/"/>
      <url>2020/10/24/monitor/zabbix-yuan-li/</url>
      
        <content type="html"><![CDATA[<p>​               </p><blockquote><p>想要用好zabbix进行监控，那么我们首要需要了解下zabbix这个软件的实现原理及它的架构。建议多阅读官方文档。</p><p>官网地址：<a href="https://www.zabbix.com/documentation/4.0/zh/manual" target="_blank" rel="noopener">https://www.zabbix.com/documentation/4.0/zh/manual</a></p></blockquote><h4 id="一、zabbix架构图"><a href="#一、zabbix架构图" class="headerlink" title="一、zabbix架构图"></a>一、zabbix架构图</h4><p><a href="https://imgchr.com/i/B8SPUg" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/28/B8SPUg.png" alt="B8SPUg.png"></a></p><h4 id="二、zabbix组件"><a href="#二、zabbix组件" class="headerlink" title="二、zabbix组件"></a>二、zabbix组件</h4><h5 id="组件部分"><a href="#组件部分" class="headerlink" title="组件部分"></a>组件部分</h5><h6 id="1、Zabbix-Server"><a href="#1、Zabbix-Server" class="headerlink" title="1、Zabbix Server"></a>1、Zabbix Server</h6><blockquote><p>负责接收agent发送的报告信息的核心组件，所有配置，统计数据及操作数据均由其组织进行；</p></blockquote><h6 id="2、Database-Storage"><a href="#2、Database-Storage" class="headerlink" title="2、Database Storage"></a>2、Database Storage</h6><blockquote><p>专用于存储所有配置信息，以及由zabbix收集的数据；</p></blockquote><h6 id="3、Web-interface"><a href="#3、Web-interface" class="headerlink" title="3、Web interface"></a>3、Web interface</h6><blockquote><p>zabbix的GUI接口，通常与Server运行在同一台主机上；</p></blockquote><h6 id="4、Proxy"><a href="#4、Proxy" class="headerlink" title="4、Proxy"></a>4、Proxy</h6><blockquote><p>可选组件，常用于监控节点很多的分布式环境中，代理server收集部分数据转发到server，可以减轻server的压力；</p></blockquote><h6 id="5、Agent"><a href="#5、Agent" class="headerlink" title="5、Agent"></a>5、Agent</h6><blockquote><p>部署在被监主机上，负责收集本地数据并发往Server端或Proxy端；</p></blockquote><h4 id="三、相关术语"><a href="#三、相关术语" class="headerlink" title="三、相关术语"></a>三、相关术语</h4><h6 id="1、主机（host）"><a href="#1、主机（host）" class="headerlink" title="1、主机（host）"></a>1、主机（host）</h6><blockquote><p>要监控的网络设备，可由IP或DNS名称指定；</p></blockquote><h6 id="2、主机组（host-group）"><a href="#2、主机组（host-group）" class="headerlink" title="2、主机组（host group）"></a>2、主机组（host group）</h6><blockquote><p>主机的逻辑容器，可以包含主机和模板，但同一个组织内的主机和模板不能互相链接；主机组通常在给用户或用户组指派监控权限时使用；</p></blockquote><h6 id="3、监控项（item）"><a href="#3、监控项（item）" class="headerlink" title="3、监控项（item）"></a>3、监控项（item）</h6><blockquote><p>一个特定监控指标的相关的数据；这些数据来自于被监控对象；item是zabbix进行数据收集的核心，相对某个监控对象，每个item都由”key”标识；</p></blockquote><h6 id="4、触发器（trigger）"><a href="#4、触发器（trigger）" class="headerlink" title="4、触发器（trigger）"></a>4、触发器（trigger）</h6><blockquote><p>一个表达式，用于评估某监控对象的特定item内接收到的数据是否在合理范围内，也就是阈值；接收的数据量大于阈值时，触发器状态将从”OK”转变为”Problem”，当数据再次恢复到合理范围，又转变为”OK”；</p></blockquote><h6 id="5、事件（event）"><a href="#5、事件（event）" class="headerlink" title="5、事件（event）"></a>5、事件（event）</h6><blockquote><p>触发一个值得关注的事情，比如触发器状态转变，新的agent或重新上线的agent的自动注册等；</p></blockquote><h6 id="6、动作（action）"><a href="#6、动作（action）" class="headerlink" title="6、动作（action）"></a>6、动作（action）</h6><blockquote><p>指对于特定事件事先定义的处理方法，如发送通知，何时执行操作；</p></blockquote><h6 id="7、报警媒介类型（media）"><a href="#7、报警媒介类型（media）" class="headerlink" title="7、报警媒介类型（media）"></a>7、报警媒介类型（media）</h6><blockquote><p>发送通知的手段或者通道，如Email、Jabber或者SMS等；</p></blockquote><h6 id="8、模板（template）"><a href="#8、模板（template）" class="headerlink" title="8、模板（template）"></a>8、模板（template）</h6><blockquote><p>用于快速定义被监控主机的预设条目集合，通常包含了item、trigger、graph、screen、application以及low-level discovery rule；模板可以直接链接至某个主机；</p></blockquote><h6 id="9、前端（frontend）"><a href="#9、前端（frontend）" class="headerlink" title="9、前端（frontend）"></a>9、前端（frontend）</h6><blockquote><p>Zabbix的web接口</p></blockquote><h4 id="四、监控流程"><a href="#四、监控流程" class="headerlink" title="四、监控流程"></a>四、监控流程</h4><h5 id="监控系统运行流程"><a href="#监控系统运行流程" class="headerlink" title="监控系统运行流程"></a>监控系统运行流程</h5><blockquote><p>agentd需要安装到被监控的主机上，它负责定期收集各项数据，并发送到zabbix server端，zabbix server将数据存储到数据库中，zabbix web根据数据在前端进行展现和绘图。<br>这里agentd收集数据分为主动和被动两种模式：</p></blockquote><h5 id="主动"><a href="#主动" class="headerlink" title="主动"></a>主动</h5><blockquote><p>agent请求server获取主动的监控项列表，并主动将监控项内需要检测的数据提交给server/proxy</p></blockquote><p>【主动监测】通信过程如下：</p><blockquote><p>zabbix首先向ServerActive配置的IP请求获取active items，获取并提交active items数据值server或者proxy。很多人会提出疑问：zabbix多久获取一次active items？它会根据配置文件中的RefreshActiveChecks的频率进行，如果获取失败，那么将会在60秒之后重试。分两个部分</p></blockquote><h6 id="获取ACTIVE-ITEMS列表"><a href="#获取ACTIVE-ITEMS列表" class="headerlink" title="获取ACTIVE ITEMS列表"></a>获取ACTIVE ITEMS列表</h6><blockquote><p>• Agent打开TCP连接<br>• Agent请求items检测列表<br>• Server返回items列表<br>• Agent 处理响应<br>• 关闭TCP连接<br>• Agent开始收集数据</p></blockquote><h6 id="主动检测提交数据过程如下"><a href="#主动检测提交数据过程如下" class="headerlink" title="主动检测提交数据过程如下"></a>主动检测提交数据过程如下</h6><blockquote><p>• Agent建立TCP连接<br>• Agent提交items列表收集的数据<br>• Server处理数据，并返回响应状态<br>• 关闭TCP连接</p></blockquote><h5 id="被动"><a href="#被动" class="headerlink" title="被动"></a>被动</h5><blockquote><p>server向agent请求获取监控项的数据，agent返回数据。</p></blockquote><h6 id="【被动监测】通信过程如下："><a href="#【被动监测】通信过程如下：" class="headerlink" title="【被动监测】通信过程如下："></a>【被动监测】通信过程如下：</h6><blockquote><p>• Server打开一个TCP连接<br>• Server发送请求agent.ping\n<br>• Agent接收到请求并且响应<br>• Server处理接收到的数据1<br>• 关闭TCP连接</p></blockquote><p><strong>从以上过程我们可以看出来，被动模式每次都需要打开一个tcp连接，这样当监控项越来越多时，就会出现server端性能问题了。</strong><br><strong>还有人会问，那实际监控中是用主动的还是被动的呢？这里主要涉及两个地方：</strong><br>1、新建监控项目时，选择的是zabbix代理还是zabbix端点代理程式（主动式），前者是被动模式，后者是主动模式。<br>2、agentd配置文件中StartAgents参数的设置，如果为0，表示禁止被动模式，否则开启。一般建议不要设置为0，因为监控项目很多时，可以部分使用主动，部分使用被动模式。</p>]]></content>
      
      
      <categories>
          
          <category> monitor </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zabbix </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维面试题-01</title>
      <link href="2020/10/16/interview/yun-wei-mian-shi-ti-01/"/>
      <url>2020/10/16/interview/yun-wei-mian-shi-ti-01/</url>
      
        <content type="html"><![CDATA[<p>PS：以下内容，网友提供    欢迎投稿     <a href="mailto:cyylog@aliyun.com">cyylog@aliyun.com</a></p><h3 id="三剑客"><a href="#三剑客" class="headerlink" title="三剑客"></a>三剑客</h3><h4 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h4><ol><li>统计日志中某个时间范围的 IP 访问量，并进行排序</li></ol><pre class=" language-shell"><code class="language-shell">$ start_dt='10/May/2018:23:47:43$ end_dt='10/May/2018:23:49:05'$ awk -v st=${start_dt} -v ent=${end_dt} -F'[][ ]' '$5 == st,$5 == ent  {print $1}' app.log  |sort |uniq -c |sort -nr |head -n 10     66 223.13.142.15      6 110.183.13.212      4 1.69.17.127      1 113.25.94.69      1 110.183.58.144</code></pre><pre class=" language-shell"><code class="language-shell">awk '$4>="[30/May/2020:01:08:25" && $4<="[30/May/2020:01:10:25"{a[$2]++} END {for(v in a) print v,a[v]}' access.logawk '$4>="[29/May/2020:20:39:11" && $4<="[30/May/2020:01:08:27" {a[$1]++} END {for(v in a)print  v,a[v]}' access.log[29/May/2020:18:53:53[29/May/2020:18:54:23</code></pre><ol start="2"><li>按URL的请求数排序，出访问这些url的ｉｐ</li></ol><pre class=" language-shell"><code class="language-shell">按URL的请求数排序awk -F\" '{print $2}' access.log | awk '{print $2}' | sort | uniq -c | sort -r找出访问这些url的ｉｐawk -F\" '($2 ~ "/phpmyadmin/index.php"){print $1}' access.log | awk '{print $1}' | sort | uniq -c | sort -r</code></pre><ol start="3"><li>查看http的并发请求数与其TCP连接状态**</li></ol><pre class=" language-shell"><code class="language-shell">netstat -n |awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'</code></pre><h4 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h4><ol><li><p>关闭selinux</p><pre class=" language-shell"><code class="language-shell">sed -ri s/SELINUX=enforcing/SELINUX=disabled/g /etc/selinux/configsetenforce 0</code></pre></li><li><p>将nginx.conf中的所有server_name中baidu.com替换成linkdood.cn</p></li></ol><pre class=" language-shell"><code class="language-shell">sed -ri s/server\_name/baidu\.com/g nginx.conf</code></pre><h4 id="grep"><a href="#grep" class="headerlink" title="grep"></a>grep</h4><ol><li>用命令如何查找/opt/目录下文件名qypay.conf的文件中是否有redis=127.0.0.1的配置</li></ol><pre class=" language-shell"><code class="language-shell">grep "redis\=127\.0\.0\.1"/opt/qypay.conf </code></pre><h4 id="find"><a href="#find" class="headerlink" title="find"></a>find</h4><ol><li>查找/data目录下5天前，大于100M的文件并删除    </li></ol><pre class=" language-shell"><code class="language-shell">find /data -type -size +100M -atime +5 -exec rm -rf {} \;  find /data -type -size +100M -atime +5|xargs -i rm -rf </code></pre><h3 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h3><ol><li>写脚本找到本机的IP地址</li></ol><pre><code>获取当前主机ens33的ipifconfig ens33 | grep &quot;inet &quot; | sed &#39;s/^.*inet //g&#39; | sed &#39;s/ *netmask.*$//g&#39;ip addr | awk &#39;/^[0-9]+: / {}; /inet.*global/ {print gensub(/(.*)\/(.*)/, &quot;\\1&quot;, &quot;g&quot;, $2)}&#39;ip addr | awk &#39;/^[0-9]+: / {}; /inet.*global/ {print gensub(/(.*)\/(.*)/, &quot;\\1&quot;, &quot;g&quot;, $2)}&#39;命令解释 ifconfig -a  　　　　 和window下执行此命令一样道理，返回本机所有ip信息 grep inet               　   截取包含ip的行 grep -v 127.0.0.1      去掉本地指向的那行 grep -v inet6             去掉包含inet6的行 awk { print $2}         $2 表示默认以空格分割的第二组 同理 $1表示第一组​ tr -d &quot;addr:               删除&quot;addr:&quot;这个字符串</code></pre><ol start="2"><li>如何查看系统每个ip的连接数</li></ol><pre class=" language-shell"><code class="language-shell">netstat -tan| awk '/tcp & gt; /{ split ($5,ip,":"); count[ip[1]]++} END {for(i in count) { print i, count[i]} }'</code></pre><ol start="3"><li><p>统计80端口所有连接状态</p><pre class=" language-shell"><code class="language-shell">netstat -tn|grep ":80" |awk '{print $6}'|sort|uniq -c</code></pre></li><li><p>编写脚本，快速找出192.168.1.0/24网段中已经使用的IP地址</p></li></ol><pre class=" language-shell"><code class="language-shell">#!/bin/bash/env bashecho "-----------------------------------------"echo "可以 ping 通的 ip 在当前目录的111.txt文件"echo "不可以 ping 通的 ip 在当前目录的222.txt文件"echo "-----------------------------------------"echo > ./111.txtecho > ./222.txtread -p "请输入IP的第三位数字即可：" num3i=1IP3="192.168.$num3"for i in {1..254}do        {        ping -c1 $IP3.$i >>/dev/null        if [ $? -eq 0 ];then        echo "$IP3.$i" >>./111.txt        else        echo "$IP3.$i" >>./222.txt        fi        }  &donewaitecho "finish...ok"</code></pre><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><ol><li>HAproxy，  LVS， Nginx   有何区别，工作中会怎么选择</li></ol><pre class=" language-shell"><code class="language-shell">LVS： 是基于四层的转发HAproxy： 是基于四层和七层的转发，是专业的代理服务器Nginx： 是WEB服务器，缓存服务器，又是反向代理服务器，可以做七层的转发区别： LVS由于是基于四层的转发所以只能做端口的转发而基于URL的、基于目录的这种转发LVS就做不了工作选择：HAproxy和Nginx由于可以做七层的转发，所以URL和目录的转发都可以做在很大并发量的时候我们就要选择LVS，像中小型公司的话并发量没那么大选择HAproxy或者Nginx足已，由于HAproxy由是专业的代理服务器配置简单，所以中小型企业推荐使用HAproxy</code></pre><h3 id="灰度发布"><a href="#灰度发布" class="headerlink" title="灰度发布"></a>灰度发布</h3><ol><li>灰度发布过程中出现问题，数据库中有脏数据怎么解决</li></ol><pre class=" language-txt"><code class="language-txt">灰度发布大部分用户都是公司中的人，少部分是外面的用户，如果出现错误，叫DBA进行数据库回滚就可以的，在灰度发布的数据中都有标记，外面的用户只能叫DBA进行修改</code></pre><h3 id="Iptables"><a href="#Iptables" class="headerlink" title="Iptables"></a>Iptables</h3><ol><li>本地80端口的请求转发到8080端口，当前主机IP为192.168.2.1</li></ol><pre class=" language-shell"><code class="language-shell">iptables -t nat -A PREROUTING -d 192.168.2.1 -p tcp -dport 80 -j DNAT -to 192.168.2.1:8080 </code></pre><ol start="2"><li>允许本机对外连接80端口（本机能连外界服务器为80）</li></ol><pre class=" language-shell"><code class="language-shell">iptables -A OUTPUT -p tcp –dport 80 -j ACCEPT  </code></pre><ol start="3"><li>禁止外界ping本服务器</li></ol><pre class=" language-shell"><code class="language-shell">iptables -A INPUT -p icmp -j DROP</code></pre><h3 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h3><ol><li>查看最近一次innodb表锁记录</li></ol><pre class=" language-mysql"><code class="language-mysql">show ENGINE INNODB STATUS ;</code></pre><ol start="2"><li>列出数据库所有线程</li></ol><pre class=" language-mysql"><code class="language-mysql">show full processlist</code></pre><ol start="3"><li>MySQL 的每天的数据量，主从，mysql主库数据量大造成从库同步延迟怎么办</li></ol><pre class=" language-shell"><code class="language-shell">带宽，配置不当，性能不一致,待补充</code></pre><ol start="4"><li>用SQL语名查询年龄小于平均年龄的作者姓名、图书名、出版社并按姓名降序排序。 图书(图书号，图书名，作者编号，出版社，出版日期)  作者(作者姓名，作者编号，年龄，性别)</li></ol><pre class=" language-MYSQL"><code class="language-MYSQL">select aname,bname,pub from anthor a join book b on (a.ano = b.ano) where age < (select avg(age) from author)</code></pre><ol start="5"><li><strong>mysql的innodb如何定位锁问题，mysql如何减少主从复制延迟？</strong></li></ol><pre class=" language-shell"><code class="language-shell">mysql的innodb如何定位锁问题:在使用 show engine innodb status检查引擎状态时，发现了死锁问题在5.5中，information_schema 库中增加了三个关于锁的表（MEMORY引擎）innodb_trx ## 当前运行的所有事务innodb_locks ## 当前出现的锁innodb_lock_waits ## 锁等待的对应关系mysql如何减少主从复制延迟:如果延迟比较大，就先确认以下几个因素：1. 从库硬件比主库差，导致复制延迟2. 主从复制单线程，如果主库写并发太大，来不及传送到从库就会导致延迟。更高版本的mysql可以支持多线程复制3. 慢SQL语句过多4. 网络延迟5. master负载主库读写压力大，导致复制延迟，架构的前端要加buffer及缓存层6. slave负载一般的做法是，使用多台slave来分摊读请求，再从这些slave中取一台专用的服务器只作为备份用，不进行其他任何操作.另外， 2个可以减少延迟的参数:–slave-net-timeout=seconds 单位为秒 默认设置为 3600秒#参数含义：当slave从主数据库读取log数据失败后，等待多久重新建立连接并获取数据–master-connect-retry=seconds 单位为秒 默认设置为 60秒#参数含义：当重新建立主从连接时，如果连接建立失败，间隔多久后重试通常配置以上2个参数可以减少网络问题导致的主从数据同步延迟MySQL数据库主从同步延迟解决方案最简单的减少slave同步延时的方案就是在架构上做优化，尽量让主库的DDL快速执行还有就是主库是写，对数据安全性较高，比如sync_binlog=1，innodb_flush_log_at_trx_commit= 1 之类的设置，而slave则不需要这么高的数据安全，完全可以讲sync_binlog设置为0或者关闭binloginnodb_flushlog也可以设置为0来提高sql的执行效率。另外就是使用比主库更好的硬件设备作为slave</code></pre><h3 id="网络基础"><a href="#网络基础" class="headerlink" title="网络基础"></a>网络基础</h3><ol><li>从技术角度描述一下用户打开<a href="https://cyylog.netlify.app所经过的所有过程，越详细越好。" target="_blank" rel="noopener">https://cyylog.netlify.app所经过的所有过程，越详细越好。</a>   （DNS+HTTP协议）</li></ol><pre class=" language-txt"><code class="language-txt">1. 域名解析2. 发起TCP的3次握手3. 建立TCP连接后发起HTTP请求4. 服务器端响应http请求，浏览器得到html代码5. 浏览器解析html代码，并请求html代码中的资源6. 浏览器对页面进行渲染呈现给用户</code></pre><ol start="2"><li>tcpdump 抓本机 192.168.23.1 的80端口</li></ol><pre class=" language-shell"><code class="language-shell">tcpdump -i ens33 host 192.168.23.1 port 80</code></pre><h3 id="CICD"><a href="#CICD" class="headerlink" title="CICD"></a>CICD</h3><h3 id="Zabbix"><a href="#Zabbix" class="headerlink" title="Zabbix"></a>Zabbix</h3><h3 id="ELK"><a href="#ELK" class="headerlink" title="ELK"></a>ELK</h3><h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><h3 id="常用web服务器"><a href="#常用web服务器" class="headerlink" title="常用web服务器"></a>常用web服务器</h3><blockquote><p>Apache、Nginx、Tomcat</p></blockquote><h3 id="Ansible"><a href="#Ansible" class="headerlink" title="Ansible"></a>Ansible</h3><h3 id="docker"><a href="#docker" class="headerlink" title="docker"></a>docker</h3><h3 id="K8S"><a href="#K8S" class="headerlink" title="K8S"></a>K8S</h3><h3 id="Other"><a href="#Other" class="headerlink" title="Other"></a>Other</h3><h6 id="Keepalived的工作原理"><a href="#Keepalived的工作原理" class="headerlink" title="Keepalived的工作原理"></a><strong>Keepalived的工作原理</strong></h6><blockquote><p>在一个虚拟路由器中，只有作为MASTER的VRRP路由器会一直发送VRRP通告信息,</p><p>BACKUP不会抢占MASTER，除非它的优先级更高。当MASTER不可用时(BACKUP收不到通告信息)</p><p>多台BACKUP中优先级最高的这台会被抢占为MASTER。这种抢占是非常快速的(&lt;1s)，以保证服务的连续性</p><p>由于安全性考虑，VRRP包使用了加密协议进行加密。BACKUP不会发送通告信息，只会接收通告信息</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes-Pod-生命周期</title>
      <link href="2020/10/06/container/kubernetes-gong-zuo-fu-zai-pod-de-sheng-ming-zhou-qi/"/>
      <url>2020/10/06/container/kubernetes-gong-zuo-fu-zai-pod-de-sheng-ming-zhou-qi/</url>
      
        <content type="html"><![CDATA[<h1 id="Pod-的生命周期"><a href="#Pod-的生命周期" class="headerlink" title="Pod 的生命周期"></a>Pod 的生命周期</h1><p>本页面讲述 Pod 的生命周期。 Pod 遵循一个预定义的生命周期，起始于 <code>Pending</code> <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#pod-phase" target="_blank" rel="noopener">阶段</a>，如果至少 其中有一个主要容器正常启动，则进入 <code>Running</code>，之后取决于 Pod 中是否有容器以 失败状态结束而进入 <code>Succeeded</code> 或者 <code>Failed</code> 阶段。</p><p>在 Pod 运行期间，<code>kubelet</code> 能够重启容器以处理一些失效场景。 在 Pod 内部，Kubernetes 跟踪不同容器的<a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#container-states" target="_blank" rel="noopener">状态</a> 并处理可能出现的状况。</p><p>在 Kubernetes API 中，Pod 包含规约部分和实际状态部分。 Pod 对象的状态包含了一组 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#pod-conditions" target="_blank" rel="noopener">Pod 状况（Conditions）</a>。 如果应用需要的话，你也可以向其中注入<a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#pod-readiness-gate" target="_blank" rel="noopener">自定义的就绪性信息</a>。</p><p>Pod 在其生命周期中只会被<a href="https://kubernetes.io/zh/docs/concepts/scheduling-eviction/" target="_blank" rel="noopener">调度</a>一次。 一旦 Pod 被调度（分派）到某个节点，Pod 会一直在该节点运行，直到 Pod 停止或者 被<a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination" target="_blank" rel="noopener">终止</a>。</p><h2 id="Pod-生命期"><a href="#Pod-生命期" class="headerlink" title="Pod 生命期"></a>Pod 生命期</h2><p>和一个个独立的应用容器一样，Pod 也被认为是相对临时性（而不是长期存在）的实体。 Pod 会被创建、赋予一个唯一的 ID（<a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/names/#uids" target="_blank" rel="noopener">UID</a>）， 并被调度到节点，并在终止（根据重启策略）或删除之前一直运行在该节点。</p><p>如果一个<a href="https://kubernetes.io/zh/docs/concepts/architecture/nodes/" target="_blank" rel="noopener">节点</a>死掉了，调度到该节点 的 Pod 也被计划在给定超时期限结束后<a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#pod-garbage-collection" target="_blank" rel="noopener">删除</a>。</p><p>Pod 自身不具有自愈能力。如果 Pod 被调度到某<a href="https://kubernetes.io/zh/docs/concepts/architecture/nodes/" target="_blank" rel="noopener">节点</a> 而该节点之后失效，或者调度操作本身失效，Pod 会被删除；与此类似，Pod 无法在节点资源 耗尽或者节点维护期间继续存活。Kubernetes 使用一种高级抽象，称作 <a href="https://kubernetes.io/docs/admin/kube-controller-manager/" target="_blank" rel="noopener">控制器</a>，来管理这些相对而言 可随时丢弃的 Pod 实例。</p><p>任何给定的 Pod （由 UID 定义）从不会被“重新调度（rescheduled）”到不同的节点； 相反，这一 Pod 可以被一个新的、几乎完全相同的 Pod 替换掉。 如果需要，新 Pod 的名字可以不变，但是其 UID 会不同。</p><p>如果某物声称其生命期与某 Pod 相同，例如存储<a href="https://kubernetes.io/zh/docs/concepts/storage/volumes/" target="_blank" rel="noopener">卷</a>， 这就意味着该对象在此 Pod （UID 亦相同）存在期间也一直存在。 如果 Pod 因为任何原因被删除，甚至某完全相同的替代 Pod 被创建时， 这个相关的对象（例如这里的卷）也会被删除并重建。</p><p><img src="https://d33wubrfki0l68.cloudfront.net/aecab1f649bc640ebef1f05581bfcc91a48038c4/728d6/images/docs/pod.svg" alt="img">Pod 结构图例</p><p><em>一个包含多个容器的 Pod 中包含一个用来拉取文件的程序和一个 Web 服务器， 均使用持久卷作为容器间共享的存储。</em></p><h2 id="Pod-阶段"><a href="#Pod-阶段" class="headerlink" title="Pod 阶段"></a>Pod 阶段</h2><p>Pod 的 <code>status</code> 字段是一个 <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#podstatus-v1-core" target="_blank" rel="noopener">PodStatus</a> 对象，其中包含一个 <code>phase</code> 字段。</p><p>Pod 的阶段（Phase）是 Pod 在其生命周期中所处位置的简单宏观概述。 该阶段并不是对容器或 Pod 状态的综合汇总，也不是为了成为完整的状态机。</p><p>Pod 阶段的数量和含义是严格定义的。 除了本文档中列举的内容外，不应该再假定 Pod 有其他的 <code>phase</code> 值。</p><p>下面是 <code>phase</code> 可能的值：</p><table><thead><tr><th>取值</th><th>描述</th></tr></thead><tbody><tr><td><code>Pending</code>（悬决）</td><td>Pod 已被 Kubernetes 系统接受，但有一个或者多个容器尚未创建亦未运行。此阶段包括等待 Pod 被调度的时间和通过网络下载镜像的时间，</td></tr><tr><td><code>Running</code>（运行中）</td><td>Pod 已经绑定到了某个节点，Pod 中所有的容器都已被创建。至少有一个容器仍在运行，或者正处于启动或重启状态。</td></tr><tr><td><code>Succeeded</code>（成功）</td><td>Pod 中的所有容器都已成功终止，并且不会再重启。</td></tr><tr><td><code>Failed</code>（失败）</td><td>Pod 中的所有容器都已终止，并且至少有一个容器是因为失败终止。也就是说，容器以非 0 状态退出或者被系统终止。</td></tr><tr><td><code>Unknown</code>（未知）</td><td>因为某些原因无法取得 Pod 的状态。这种情况通常是因为与 Pod 所在主机通信失败。</td></tr></tbody></table><p>如果某节点死掉或者与集群中其他节点失联，Kubernetes 会实施一种策略，将失去的节点上运行的所有 Pod 的 <code>phase</code> 设置为 <code>Failed</code>。</p><h2 id="容器状态"><a href="#容器状态" class="headerlink" title="容器状态"></a>容器状态</h2><p>Kubernetes 会跟踪 Pod 中每个容器的状态，就像它跟踪 Pod 总体上的<a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#pod-phase" target="_blank" rel="noopener">阶段</a>一样。 你可以使用<a href="https://kubernetes.io/zh/docs/concepts/containers/container-lifecycle-hooks/" target="_blank" rel="noopener">容器生命周期回调</a> 来在容器生命周期中的特定时间点触发事件。</p><p>一旦<a href="https://kubernetes.io/docs/reference/generated/kube-scheduler/" target="_blank" rel="noopener">调度器</a>将 Pod 分派给某个节点，<code>kubelet</code> 就通过 <a href="https://kubernetes.io/docs/reference/generated/container-runtime" target="_blank" rel="noopener">容器运行时</a> 开始为 Pod 创建容器。 容器的状态有三种：<code>Waiting</code>（等待）、<code>Running</code>（运行中）和 <code>Terminated</code>（已终止）。</p><p>要检查 Pod 中容器的状态，你可以使用 <code>kubectl describe pod &lt;pod 名称&gt;</code>。 其输出中包含 Pod 中每个容器的状态。</p><p>每种状态都有特定的含义：</p><h3 id="Waiting-（等待）"><a href="#Waiting-（等待）" class="headerlink" title="Waiting （等待）"></a><code>Waiting</code> （等待）</h3><p>如果容器并不处在 <code>Running</code> 或 <code>Terminated</code> 状态之一，它就处在 <code>Waiting</code> 状态。 处于 <code>Waiting</code> 状态的容器仍在运行它完成启动所需要的操作：例如，从某个容器镜像 仓库拉取容器镜像，或者向容器应用 <a href="https://kubernetes.io/zh/docs/concepts/configuration/secret/" target="_blank" rel="noopener">Secret</a> 数据等等。 当你使用 <code>kubectl</code> 来查询包含 <code>Waiting</code> 状态的容器的 Pod 时，你也会看到一个 Reason 字段，其中给出了容器处于等待状态的原因。</p><h3 id="Running（运行中）"><a href="#Running（运行中）" class="headerlink" title="Running（运行中）"></a><code>Running</code>（运行中）</h3><p><code>Running</code> 状态表明容器正在执行状态并且没有问题发生。 如果配置了 <code>postStart</code> 回调，那么该回调已经执行完成。 如果你使用 <code>kubectl</code> 来查询包含 <code>Running</code> 状态的容器的 Pod 时，你也会看到 关于容器进入 <code>Running</code> 状态的信息。</p><h3 id="Terminated（已终止）"><a href="#Terminated（已终止）" class="headerlink" title="Terminated（已终止）"></a><code>Terminated</code>（已终止）</h3><p>处于 <code>Terminated</code> 状态的容器已经开始执行并且或者正常结束或者因为某些原因失败。 如果你使用 <code>kubectl</code> 来查询包含 <code>Terminated</code> 状态的容器的 Pod 时，你会看到 容器进入此状态的原因、退出代码以及容器执行期间的起止时间。</p><p>如果容器配置了 <code>preStop</code> 回调，则该回调会在容器进入 <code>Terminated</code> 状态之前执行。</p><h2 id="容器重启策略"><a href="#容器重启策略" class="headerlink" title="容器重启策略"></a>容器重启策略</h2><p>Pod 的 <code>spec</code> 中包含一个 <code>restartPolicy</code> 字段，其可能取值包括 Always、OnFailure 和 Never。默认值是 Always。</p><p><code>restartPolicy</code> 适用于 Pod 中的所有容器。<code>restartPolicy</code> 仅针对同一节点上 <code>kubelet</code> 的容器重启动作。当 Pod 中的容器退出时，<code>kubelet</code> 会按指数回退 方式计算重启的延迟（10s、20s、40s、…），其最长延迟为 5 分钟。 一旦某容器执行了 10 分钟并且没有出现问题，<code>kubelet</code> 对该容器的重启回退计时器执行 重置操作。</p><h2 id="Pod-状况"><a href="#Pod-状况" class="headerlink" title="Pod 状况"></a>Pod 状况</h2><p>Pod 有一个 PodStatus 对象，其中包含一个 <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#podcondition-v1-core" target="_blank" rel="noopener">PodConditions</a> 数组。Pod 可能通过也可能未通过其中的一些状况测试。</p><ul><li><code>PodScheduled</code>：Pod 已经被调度到某节点；</li><li><code>ContainersReady</code>：Pod 中所有容器都已就绪；</li><li><code>Initialized</code>：所有的 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/init-containers/" target="_blank" rel="noopener">Init 容器</a> 都已成功启动；</li><li><code>Ready</code>：Pod 可以为请求提供服务，并且应该被添加到对应服务的负载均衡池中。</li></ul><table><thead><tr><th>字段名称</th><th>描述</th></tr></thead><tbody><tr><td><code>type</code></td><td>Pod 状况的名称</td></tr><tr><td><code>status</code></td><td>表明该状况是否适用，可能的取值有 “<code>True</code>“, “<code>False</code>“ 或 “<code>Unknown</code>“</td></tr><tr><td><code>lastProbeTime</code></td><td>上次探测 Pod 状况时的时间戳</td></tr><tr><td><code>lastTransitionTime</code></td><td>Pod 上次从一种状态转换到另一种状态时的时间戳</td></tr><tr><td><code>reason</code></td><td>机器可读的、驼峰编码（UpperCamelCase）的文字，表述上次状况变化的原因</td></tr><tr><td><code>message</code></td><td>人类可读的消息，给出上次状态转换的详细信息</td></tr></tbody></table><h3 id="Pod-就绪态"><a href="#Pod-就绪态" class="headerlink" title="Pod 就绪态"></a>Pod 就绪态</h3><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.14 [stable]</code></p><p>你的应用可以向 PodStatus 中注入额外的反馈或者信号：<em>Pod Readiness（Pod 就绪态）</em>。 要使用这一特性，可以设置 Pod 规约中的 <code>readinessGates</code> 列表，为 kubelet 提供一组额外的状况供其评估 Pod 就绪态时使用。</p><p>就绪态门控基于 Pod 的 <code>status.conditions</code> 字段的当前值来做决定。 如果 Kubernetes 无法在 <code>status.conditions</code> 字段中找到某状况，则该状况的 状态值默认为 “<code>False</code>“。</p><p>这里是一个例子：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">kind</span><span class="token punctuation">:</span> Pod<span class="token punctuation">...</span><span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">readinessGates</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">conditionType</span><span class="token punctuation">:</span> <span class="token string">"www.example.com/feature-1"</span><span class="token key atrule">status</span><span class="token punctuation">:</span>  <span class="token key atrule">conditions</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">type</span><span class="token punctuation">:</span> Ready                              <span class="token comment" spellcheck="true"># 内置的 Pod 状况</span>      <span class="token key atrule">status</span><span class="token punctuation">:</span> <span class="token string">"False"</span>      <span class="token key atrule">lastProbeTime</span><span class="token punctuation">:</span> <span class="token null important">null</span>      <span class="token key atrule">lastTransitionTime</span><span class="token punctuation">:</span> <span class="token datetime number">2018-01-01T00:00:00Z</span>    <span class="token punctuation">-</span> <span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"www.example.com/feature-1"</span>        <span class="token comment" spellcheck="true"># 额外的 Pod 状况</span>      <span class="token key atrule">status</span><span class="token punctuation">:</span> <span class="token string">"False"</span>      <span class="token key atrule">lastProbeTime</span><span class="token punctuation">:</span> <span class="token null important">null</span>      <span class="token key atrule">lastTransitionTime</span><span class="token punctuation">:</span> <span class="token datetime number">2018-01-01T00:00:00Z</span>  <span class="token key atrule">containerStatuses</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">containerID</span><span class="token punctuation">:</span> docker<span class="token punctuation">:</span>//abcd<span class="token punctuation">...</span>      <span class="token key atrule">ready</span><span class="token punctuation">:</span> <span class="token boolean important">true</span><span class="token punctuation">...</span></code></pre><p>你所添加的 Pod 状况名称必须满足 Kubernetes <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set" target="_blank" rel="noopener">标签键名格式</a>。</p><h3 id="Pod-就绪态的状态"><a href="#Pod-就绪态的状态" class="headerlink" title="Pod 就绪态的状态"></a>Pod 就绪态的状态</h3><p>命令 <code>kubectl patch</code> 不支持修改对象的状态。 如果需要设置 Pod 的 <code>status.conditions</code>，应用或者 <a href="https://kubernetes.io/zh/docs/concepts/extend-kubernetes/operator/" target="_blank" rel="noopener">Operators</a> 需要使用 <code>PATCH</code> 操作。 你可以使用 <a href="https://kubernetes.io/zh/docs/reference/using-api/client-libraries/" target="_blank" rel="noopener">Kubernetes 客户端库</a> 之一来编写代码，针对 Pod 就绪态设置定制的 Pod 状况。</p><p>对于使用定制状况的 Pod 而言，只有当下面的陈述都适用时，该 Pod 才会被评估为就绪：</p><ul><li>Pod 中所有容器都已就绪；</li><li><code>readinessGates</code> 中的所有状况都为 <code>True</code> 值。</li></ul><p>当 Pod 的容器都已就绪，但至少一个定制状况没有取值或者取值为 <code>False</code>， <code>kubelet</code> 将 Pod 的<a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#pod-conditions" target="_blank" rel="noopener">状况</a>设置为 <code>ContainersReady</code>。</p><h2 id="容器探针"><a href="#容器探针" class="headerlink" title="容器探针"></a>容器探针</h2><p><a href="https://kubernetes.io/zh/docs/reference/generated/kubernetes-api/v1.19/#probe-v1-core" target="_blank" rel="noopener">探针</a> 是由 <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kubelet/" target="_blank" rel="noopener">kubelet</a> 对容器执行的定期诊断。 要执行诊断，kubelet 调用由容器实现的 <a href="https://kubernetes.io/zh/docs/reference/generated/kubernetes-api/v1.19/#handler-v1-core" target="_blank" rel="noopener">Handler</a> （处理程序）。有三种类型的处理程序：</p><ul><li><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#execaction-v1-core" target="_blank" rel="noopener">ExecAction</a>： 在容器内执行指定命令。如果命令退出时返回码为 0 则认为诊断成功。</li><li><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#tcpsocketaction-v1-core" target="_blank" rel="noopener">TCPSocketAction</a>： 对容器的 IP 地址上的指定端口执行 TCP 检查。如果端口打开，则诊断被认为是成功的。</li><li><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#httpgetaction-v1-core" target="_blank" rel="noopener">HTTPGetAction</a>： 对容器的 IP 地址上指定端口和路径执行 HTTP Get 请求。如果响应的状态码大于等于 200 且小于 400，则诊断被认为是成功的。</li></ul><p>每次探测都将获得以下三种结果之一：</p><ul><li><code>Success</code>（成功）：容器通过了诊断。</li><li><code>Failure</code>（失败）：容器未通过诊断。</li><li><code>Unknown</code>（未知）：诊断失败，因此不会采取任何行动。</li></ul><p>针对运行中的容器，<code>kubelet</code> 可以选择是否执行以下三种探针，以及如何针对探测结果作出反应：</p><ul><li><code>livenessProbe</code>：指示容器是否正在运行。如果存活态探测失败，则 kubelet 会杀死容器， 并且容器将根据其<a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy" target="_blank" rel="noopener">重启策略</a>决定未来。如果容器不提供存活探针， 则默认状态为 <code>Success</code>。</li><li><code>readinessProbe</code>：指示容器是否准备好为请求提供服务。如果就绪态探测失败， 端点控制器将从与 Pod 匹配的所有服务的端点列表中删除该 Pod 的 IP 地址。 初始延迟之前的就绪态的状态值默认为 <code>Failure</code>。 如果容器不提供就绪态探针，则默认状态为 <code>Success</code>。</li><li><code>startupProbe</code>: 指示容器中的应用是否已经启动。如果提供了启动探针，则所有其他探针都会被 禁用，直到此探针成功为止。如果启动探测失败，<code>kubelet</code> 将杀死容器，而容器依其 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy" target="_blank" rel="noopener">重启策略</a>进行重启。 如果容器没有提供启动探测，则默认状态为 <code>Success</code>。</li></ul><p>如欲了解如何设置存活态、就绪态和启动探针的进一步细节，可以参阅 <a href="https://kubernetes.io/zh/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/" target="_blank" rel="noopener">配置存活态、就绪态和启动探针</a>。</p><h3 id="何时该使用存活态探针"><a href="#何时该使用存活态探针" class="headerlink" title="何时该使用存活态探针?"></a>何时该使用存活态探针?</h3><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.0 [stable]</code></p><p>如果容器中的进程能够在遇到问题或不健康的情况下自行崩溃，则不一定需要存活态探针; <code>kubelet</code> 将根据 Pod 的<code>restartPolicy</code> 自动执行修复操作。</p><p>如果你希望容器在探测失败时被杀死并重新启动，那么请指定一个存活态探针， 并指定<code>restartPolicy</code> 为 “<code>Always</code>“ 或 “<code>OnFailure</code>“。</p><h3 id="何时该使用就绪态探针"><a href="#何时该使用就绪态探针" class="headerlink" title="何时该使用就绪态探针?"></a>何时该使用就绪态探针?</h3><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.0 [stable]</code></p><p>如果要仅在探测成功时才开始向 Pod 发送请求流量，请指定就绪态探针。 在这种情况下，就绪态探针可能与存活态探针相同，但是规约中的就绪态探针的存在意味着 Pod 将在启动阶段不接收任何数据，并且只有在探针探测成功后才开始接收数据。</p><p>如果你的容器需要加载大规模的数据、配置文件或者在启动期间执行迁移操作，可以添加一个 就绪态探针。</p><p>如果你希望容器能够自行进入维护状态，也可以指定一个就绪态探针，检查某个特定于 就绪态的因此不同于存活态探测的端点。</p><blockquote><p><strong>说明：</strong> 请注意，如果你只是想在 Pod 被删除时能够排空请求，则不一定需要使用就绪态探针； 在删除 Pod 时，Pod 会自动将自身置于未就绪状态，无论就绪态探针是否存在。 等待 Pod 中的容器停止期间，Pod 会一直处于未就绪状态。</p></blockquote><h3 id="何时该使用启动探针？"><a href="#何时该使用启动探针？" class="headerlink" title="何时该使用启动探针？"></a>何时该使用启动探针？</h3><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.16 [alpha]</code></p><p>对于所包含的容器需要较长时间才能启动就绪的 Pod 而言，启动探针是有用的。 你不再需要配置一个较长的存活态探测时间间隔，只需要设置另一个独立的配置选定， 对启动期间的容器执行探测，从而允许使用远远超出存活态时间间隔所允许的时长。</p><p>如果你的容器启动时间通常超出 <code>initialDelaySeconds + failureThreshold × periodSeconds</code> 总值，你应该设置一个启动探测，对存活态探针所使用的同一端点执行检查。 <code>periodSeconds</code> 的默认值是 30 秒。你应该将其 <code>failureThreshold</code> 设置得足够高， 以便容器有充足的时间完成启动，并且避免更改存活态探针所使用的默认值。 这一设置有助于减少死锁状况的发生。</p><h2 id="Pod-的终止"><a href="#Pod-的终止" class="headerlink" title="Pod 的终止"></a>Pod 的终止</h2><p>由于 Pod 所代表的是在集群中节点上运行的进程，当不再需要这些进程时允许其体面地 终止是很重要的。一般不应武断地使用 <code>KILL</code> 信号终止它们，导致这些进程没有机会 完成清理操作。</p><p>设计的目标是令你能够请求删除进程，并且知道进程何时被终止，同时也能够确保删除 操作终将完成。当你请求删除某个 Pod 时，集群会记录并跟踪 Pod 的体面终止周期， 而不是直接强制地杀死 Pod。在存在强制关闭设施的前提下， <a href="https://kubernetes.io/docs/reference/generated/kubelet" target="_blank" rel="noopener">kubelet</a> 会尝试体面地终止 Pod。</p><p>通常情况下，容器运行时会发送一个 TERM 信号到每个容器中的主进程。 一旦超出了体面终止限期，容器运行时会向所有剩余进程发送 KILL 信号，之后 Pod 就会被从 <a href="https://kubernetes.io/docs/reference/generated/kube-apiserver/" target="_blank" rel="noopener">API 服务器</a> 上移除。如果 <code>kubelet</code> 或者容器运行时的管理服务在等待进程终止期间被重启， 集群会从头开始重试，赋予 Pod 完整的体面终止限期。</p><p>下面是一个例子：</p><ol><li><p>你使用 <code>kubectl</code> 工具手动删除某个特定的 Pod，而该 Pod 的体面终止限期是默认值（30 秒）。</p></li><li><p>API 服务器中的 Pod 对象被更新，记录涵盖体面终止限期在内 Pod 的最终死期，超出所计算时间点则认为 Pod 已死（dead）。 如果你使用 <code>kubectl describe</code> 来查验你正在删除的 Pod，该 Pod 会显示为 “Terminating” （正在终止）。 在 Pod 运行所在的节点上：<code>kubelet</code> 一旦看到 Pod 被标记为正在终止（已经设置了体面终止限期），<code>kubelet</code> 即开始本地的 Pod 关闭过程。</p><ol><li><p>如果 Pod 中的容器之一定义了 <code>preStop</code> <a href="https://kubernetes.io/zh/docs/concepts/containers/container-lifecycle-hooks/#hook-details" target="_blank" rel="noopener">回调</a>， <code>kubelet</code> 开始在容器内运行该回调逻辑。如果超出体面终止限期时，<code>preStop</code> 回调逻辑 仍在运行，<code>kubelet</code> 会请求给予该 Pod 的宽限期一次性增加 2 秒钟。</p><blockquote><p><strong>说明：</strong> 如果 <code>preStop</code> 回调所需要的时间长于默认的体面终止限期，你必须修改 <code>terminationGracePeriodSeconds</code> 属性值来使其正常工作。</p></blockquote></li><li><p><code>kubelet</code> 接下来触发容器运行时发送 TERM 信号给每个容器中的进程 1。</p><blockquote><p><strong>说明：</strong> Pod 中的容器会在不同时刻收到 TERM 信号，接收顺序也是不确定的。 如果关闭的顺序很重要，可以考虑使用 <code>preStop</code> 回调逻辑来协调。</p></blockquote></li></ol></li><li><p>与此同时，<code>kubelet</code> 启动体面关闭逻辑，控制面会将 Pod 从对应的端点列表（以及端点切片列表， 如果启用了的话）中移除，过滤条件是 Pod 被对应的 <a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/" target="_blank" rel="noopener">服务</a>以某 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/labels/" target="_blank" rel="noopener">选择算符</a>选定。 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/replicaset/" target="_blank" rel="noopener">ReplicaSets</a>和其他工作负载资源 不再将关闭进程中的 Pod 视为合法的、能够提供服务的副本。关闭动作很慢的 Pod 也无法继续处理请求数据，因为负载均衡器（例如服务代理）已经在终止宽限期开始的时候 将其从端点列表中移除。</p></li><li><p>超出终止宽限期线时，<code>kubelet</code> 会触发强制关闭过程。容器运行时会向 Pod 中所有容器内 仍在运行的进程发送 <code>SIGKILL</code> 信号。 <code>kubelet</code> 也会清理隐藏的 <code>pause</code> 容器，如果容器运行时使用了这种容器的话。</p></li><li><p><code>kubelet</code> 触发强制从 API 服务器上删除 Pod 对象的逻辑，并将体面终止限期设置为 0 （这意味着马上删除）。</p></li><li><p>API 服务器删除 Pod 的 API 对象，从任何客户端都无法再看到该对象。</p></li></ol><h3 id="强制终止-Pod"><a href="#强制终止-Pod" class="headerlink" title="强制终止 Pod"></a>强制终止 Pod</h3><blockquote><p><strong>注意：</strong> 对于某些工作负载及其 Pod 而言，强制删除很可能会带来某种破坏。</p></blockquote><p>默认情况下，所有的删除操作都会附有 30 秒钟的宽限期限。 <code>kubectl delete</code> 命令支持 <code>--grace-period=&lt;seconds&gt;</code> 选项，允许你重载默认值， 设定自己希望的期限值。</p><p>将宽限期限强制设置为 <code>0</code> 意味着立即从 API 服务器删除 Pod。 如果 Pod 仍然运行于某节点上，强制删除操作会触发 <code>kubelet</code> 立即执行清理操作。</p><blockquote><p><strong>说明：</strong> 你必须在设置 <code>--grace-period=0</code> 的同时额外设置 <code>--force</code> 参数才能发起强制删除请求。</p></blockquote><p>执行强制删除操作时，API 服务器不再等待来自 <code>kubelet</code> 的、关于 Pod 已经在原来运行的节点上终止执行的确认消息。 API 服务器直接删除 Pod 对象，这样新的与之同名的 Pod 即可以被创建。 在节点侧，被设置为立即终止的 Pod 仍然会在被强行杀死之前获得一点点的宽限时间。</p><p>如果你需要强制删除 StatefulSet 的 Pod，请参阅 <a href="https://kubernetes.io/zh/docs/tasks/run-application/force-delete-stateful-set-pod/" target="_blank" rel="noopener">从 StatefulSet 中删除 Pod</a> 的任务文档。</p><h3 id="失效-Pod-的垃圾收集"><a href="#失效-Pod-的垃圾收集" class="headerlink" title="失效 Pod 的垃圾收集"></a>失效 Pod 的垃圾收集</h3><p>对于已失败的 Pod 而言，对应的 API 对象仍然会保留在集群的 API 服务器上，直到 用户或者<a href="https://kubernetes.io/docs/admin/kube-controller-manager/" target="_blank" rel="noopener">控制器</a>进程显式地 将其删除。</p><p>控制面组件会在 Pod 个数超出所配置的阈值 （根据 <code>kube-controller-manager</code> 的 <code>terminated-pod-gc-threshold</code> 设置）时 删除已终止的 Pod（阶段值为 <code>Succeeded</code> 或 <code>Failed</code>）。 这一行为会避免随着时间演进不断创建和终止 Pod 而引起的资源泄露问题。</p>]]></content>
      
      
      <categories>
          
          <category> container </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes-Pod-Pods</title>
      <link href="2020/10/06/container/kubernetes-gong-zuo-fu-zai-pods/"/>
      <url>2020/10/06/container/kubernetes-gong-zuo-fu-zai-pods/</url>
      
        <content type="html"><![CDATA[<h1 id="Pods"><a href="#Pods" class="headerlink" title="Pods"></a>Pods</h1><p><em>Pod</em> 是可以在 Kubernetes 中创建和管理的、最小的可部署的计算单元。</p><p><em>Pod</em> （就像在鲸鱼荚或者豌豆荚中）是一组（一个或多个） <a href="https://kubernetes.io/zh/docs/concepts/overview/what-is-kubernetes/#why-containers" target="_blank" rel="noopener">容器</a>； 这些容器共享存储、网络、以及怎样运行这些容器的声明。 Pod 中的内容总是并置（colocated）的并且一同调度，在共享的上下文中运行。 Pod 所建模的是特定于应用的“逻辑主机”，其中包含一个或多个应用容器， 这些容器是相对紧密的耦合在一起的。 在非云环境中，在相同的物理机或虚拟机上运行的应用类似于 在同一逻辑主机上运行的云应用。</p><p>除了应用容器，Pod 还可以包含在 Pod 启动期间运行的 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/init-containers/" target="_blank" rel="noopener">Init 容器</a>。 你也可以在集群中支持<a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/ephemeral-containers/" target="_blank" rel="noopener">临时性容器</a> 的情况外，为调试的目的注入临时性容器。</p><h2 id="什么是-Pod？"><a href="#什么是-Pod？" class="headerlink" title="什么是 Pod？"></a>什么是 Pod？</h2><blockquote><p><strong>说明：</strong> 除了 Docker 之外，Kubernetes 支持 很多其他<a href="https://kubernetes.io/docs/reference/generated/container-runtime" target="_blank" rel="noopener">容器运行时</a>， <a href="https://www.docker.com/" target="_blank" rel="noopener">Docker</a> 是最有名的运行时， 使用 Docker 的术语来描述 Pod 会很有帮助。</p></blockquote><p>Pod 的共享上下文包括一组 Linux 名字空间、控制组（cgroup）和可能一些其他的隔离 方面，即用来隔离 Docker 容器的技术。 在 Pod 的上下文中，每个独立的应用可能会进一步实施隔离。</p><p>就 Docker 概念的术语而言，Pod 类似于共享名字空间和文件系统卷的一组 Docker 容器。</p><h2 id="使用-Pod"><a href="#使用-Pod" class="headerlink" title="使用 Pod"></a>使用 Pod</h2><p>通常你不需要直接创建 Pod，甚至单实例 Pod。 相反，你会使用诸如 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/" target="_blank" rel="noopener">Deployment</a> 或 <a href="https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion" target="_blank" rel="noopener">Job</a> 这类工作负载资源 来创建 Pod。如果 Pod 需要跟踪状态， 可以考虑 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/statefulset/" target="_blank" rel="noopener">StatefulSet</a> 资源。</p><p>Kubernetes 集群中的 Pod 主要有两种用法：</p><ul><li><p><strong>运行单个容器的 Pod</strong>。”每个 Pod 一个容器”模型是最常见的 Kubernetes 用例； 在这种情况下，可以将 Pod 看作单个容器的包装器，并且 Kubernetes 直接管理 Pod，而不是容器。</p></li><li><p><strong>运行多个协同工作的容器的 Pod</strong>。 Pod 可能封装由多个紧密耦合且需要共享资源的共处容器组成的应用程序。 这些位于同一位置的容器可能形成单个内聚的服务单元 —— 一个容器将文件从共享卷提供给公众， 而另一个单独的“挂斗”（sidecar）容器则刷新或更新这些文件。 Pod 将这些容器和存储资源打包为一个可管理的实体。</p><blockquote><p><strong>说明：</strong> 将多个并置、同管的容器组织到一个 Pod 中是一种相对高级的使用场景。 只有在一些场景中，容器之间紧密关联时你才应该使用这种模式。</p></blockquote></li></ul><p>每个 Pod 都旨在运行给定应用程序的单个实例。如果希望横向扩展应用程序（例如，运行多个实例 以提供更多的资源），则应该使用多个 Pod，每个实例使用一个 Pod。 在 Kubernetes 中，这通常被称为 <em>副本（Replication）</em>。 通常使用一种工作负载资源及其<a href="https://kubernetes.io/docs/admin/kube-controller-manager/" target="_blank" rel="noopener">控制器</a> 来创建和管理一组 Pod 副本。</p><p>参见 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/#pods-and-controllers" target="_blank" rel="noopener">Pod 和控制器</a>以了解 Kubernetes 如何使用工作负载资源及其控制器以实现应用的扩缩和自动修复。</p><h3 id="Pod-怎样管理多个容器"><a href="#Pod-怎样管理多个容器" class="headerlink" title="Pod 怎样管理多个容器"></a>Pod 怎样管理多个容器</h3><p>Pod 被设计成支持形成内聚服务单元的多个协作过程（形式为容器）。 Pod 中的容器被自动安排到集群中的同一物理机或虚拟机上，并可以一起进行调度。 容器之间可以共享资源和依赖、彼此通信、协调何时以及何种方式终止自身。</p><p>例如，你可能有一个容器，为共享卷中的文件提供 Web 服务器支持，以及一个单独的 “sidecar（挂斗）”容器负责从远端更新这些文件，如下图所示：</p><p><img src="https://d33wubrfki0l68.cloudfront.net/aecab1f649bc640ebef1f05581bfcc91a48038c4/728d6/images/docs/pod.svg" alt="example pod diagram"></p><p>有些 Pod 具有 <a href="https://kubernetes.io/zh/docs/reference/glossary/?all=true#term-init-container" target="_blank" rel="noopener">Init 容器</a> 和 <a href="https://kubernetes.io/zh/docs/reference/glossary/?all=true#term-app-container" target="_blank" rel="noopener">应用容器</a>。 Init 容器会在启动应用容器之前运行并完成。</p><p>Pod 天生地为其成员容器提供了两种共享资源：<a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/#pod-networking" target="_blank" rel="noopener">网络</a>和 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/#pod-storage" target="_blank" rel="noopener">存储</a>。</p><h2 id="使用-Pod-1"><a href="#使用-Pod-1" class="headerlink" title="使用 Pod"></a>使用 Pod</h2><p>你很少在 Kubernetes 中直接创建一个个的 Pod，甚至是单实例（Singleton）的 Pod。 这是因为 Pod 被设计成了相对临时性的、用后即抛的一次性实体。 当 Pod 由你或者间接地由 <a href="https://kubernetes.io/docs/admin/kube-controller-manager/" target="_blank" rel="noopener">控制器</a> 创建时，它被调度在集群中的<a href="https://kubernetes.io/zh/docs/concepts/architecture/nodes/" target="_blank" rel="noopener">节点</a>上运行。 Pod 会保持在该节点上运行，直到 Pod 结束执行、Pod 对象被删除、Pod 因资源不足而被 <em>驱逐</em> 或者节点失效为止。</p><blockquote><p><strong>说明：</strong> 重启 Pod 中的容器不应与重启 Pod 混淆。 Pod 不是进程，而是容器运行的环境。 在被删除之前，Pod 会一直存在。</p></blockquote><p>当你为 Pod 对象创建清单时，要确保所指定的 Pod 名称是合法的 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/names#dns-subdomain-names" target="_blank" rel="noopener">DNS 子域名</a>。</p><h3 id="Pod-和控制器"><a href="#Pod-和控制器" class="headerlink" title="Pod 和控制器"></a>Pod 和控制器</h3><p>你可以使用工作负载资源来创建和管理多个 Pod。 资源的控制器能够处理副本的管理、上线，并在 Pod 失效时提供自愈能力。 例如，如果一个节点失败，控制器注意到该节点上的 Pod 已经停止工作， 就可以创建替换性的 Pod。调度器会将替身 Pod 调度到一个健康的节点执行。</p><p>下面是一些管理一个或者多个 Pod 的工作负载资源的示例：</p><ul><li><a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/" target="_blank" rel="noopener">Deployment</a></li><li><a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/statefulset/" target="_blank" rel="noopener">StatefulSet</a></li><li><a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/daemonset/" target="_blank" rel="noopener">DaemonSet</a></li></ul><h3 id="Pod-模版"><a href="#Pod-模版" class="headerlink" title="Pod 模版"></a>Pod 模版</h3><p><a href="https://kubernetes.io/zh/docs/concepts/workloads/" target="_blank" rel="noopener">负载</a>资源的控制器通常使用 <em>Pod 模板（Pod Template）</em> 来替你创建 Pod 并管理它们。</p><p>Pod 模板是包含在工作负载对象中的规范，用来创建 Pod。这类负载资源包括 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/" target="_blank" rel="noopener">Deployment</a>、 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/job/" target="_blank" rel="noopener">Job</a> 和 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/daemonset/" target="_blank" rel="noopener">DaemonSets</a>等。</p><p>工作负载的控制器会使用负载对象中的 <code>PodTemplate</code> 来生成实际的 Pod。 <code>PodTemplate</code> 是你用来运行应用时指定的负载资源的目标状态的一部分。</p><p>下面的示例是一个简单的 Job 的清单，其中的 <code>template</code> 指示启动一个容器。 该 Pod 中的容器会打印一条消息之后暂停。</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> batch/v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Job<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> hello<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">template</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 这里是 Pod 模版</span>    <span class="token key atrule">spec</span><span class="token punctuation">:</span>      <span class="token key atrule">containers</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> hello        <span class="token key atrule">image</span><span class="token punctuation">:</span> busybox        <span class="token key atrule">command</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'sh'</span><span class="token punctuation">,</span> <span class="token string">'-c'</span><span class="token punctuation">,</span> <span class="token string">'echo "Hello, Kubernetes!" &amp;&amp; sleep 3600'</span><span class="token punctuation">]</span>      <span class="token key atrule">restartPolicy</span><span class="token punctuation">:</span> OnFailure    <span class="token comment" spellcheck="true"># 以上为 Pod 模版</span></code></pre><p>修改 Pod 模版或者切换到新的 Pod 模版都不会对已经存在的 Pod 起作用。 Pod 不会直接收到模版的更新。相反， 新的 Pod 会被创建出来，与更改后的 Pod 模版匹配。</p><p>例如，Deployment 控制器针对每个 Deployment 对象确保运行中的 Pod 与当前的 Pod 模版匹配。如果模版被更新，则 Deployment 必须删除现有的 Pod，基于更新后的模版 创建新的 Pod。每个工作负载资源都实现了自己的规则，用来处理对 Pod 模版的更新。</p><p>在节点上，<a href="https://kubernetes.io/docs/reference/generated/kubelet" target="_blank" rel="noopener">kubelet</a>并不直接监测 或管理与 Pod 模版相关的细节或模版的更新，这些细节都被抽象出来。 这种抽象和关注点分离简化了整个系统的语义，并且使得用户可以在不改变现有代码的 前提下就能扩展集群的行为。</p><h3 id="资源共享和通信"><a href="#资源共享和通信" class="headerlink" title="资源共享和通信"></a>资源共享和通信</h3><p>Pod 使它的成员容器间能够进行数据共享和通信。</p><h3 id="Pod-中的存储"><a href="#Pod-中的存储" class="headerlink" title="Pod 中的存储"></a>Pod 中的存储</h3><p>一个 Pod 可以设置一组共享的存储<a href="https://kubernetes.io/zh/docs/concepts/storage/volumes/" target="_blank" rel="noopener">卷</a>。 Pod 中的所有容器都可以访问该共享卷，从而允许这些容器共享数据。 卷还允许 Pod 中的持久数据保留下来，即使其中的容器需要重新启动。 有关 Kubernetes 如何在 Pod 中实现共享存储并将其提供给 Pod 的更多信息， 请参考<a href="https://kubernetes.io/zh/docs/concepts/storage/" target="_blank" rel="noopener">卷</a>。</p><h3 id="Pod-联网"><a href="#Pod-联网" class="headerlink" title="Pod 联网"></a>Pod 联网</h3><p>每个 Pod 都在每个地址族中获得一个唯一的 IP 地址。 Pod 中的每个容器共享网络名字空间，包括 IP 地址和网络端口。 <em>Pod 内</em> 的容器可以使用 <code>localhost</code> 互相通信。 当 Pod 中的容器与 <em>Pod 之外</em> 的实体通信时，它们必须协调如何使用共享的网络资源 （例如端口）。</p><p>在同一个 Pod 内，所有容器共享一个 IP 地址和端口空间，并且可以通过 <code>localhost</code> 发现对方。 他们也能通过如 SystemV 信号量或 POSIX 共享内存这类标准的进程间通信方式互相通信。 不同 Pod 中的容器的 IP 地址互不相同，没有 <a href="https://kubernetes.io/zh/docs/concepts/policy/pod-security-policy/" target="_blank" rel="noopener">特殊配置</a> 就不能使用 IPC 进行通信。 如果某容器希望与运行于其他 Pod 中的容器通信，可以通过 IP 联网的方式实现。</p><p>Pod 中的容器所看到的系统主机名与为 Pod 配置的 <code>name</code> 属性值相同。 <a href="https://kubernetes.io/zh/docs/concepts/cluster-administration/networking/" target="_blank" rel="noopener">网络</a>部分提供了更多有关此内容的信息。</p><h2 id="容器的特权模式"><a href="#容器的特权模式" class="headerlink" title="容器的特权模式"></a>容器的特权模式</h2><p>Pod 中的任何容器都可以使用容器规约中的 <a href="https://kubernetes.io/docs/tasks/configure-pod-container/security-context/" target="_blank" rel="noopener">安全性上下文</a>中的 <code>privileged</code> 参数启用特权模式。 这对于想要使用使用操作系统管理权能（Capabilities，如操纵网络堆栈和访问设备） 的容器很有用。 容器内的进程几乎可以获得与容器外的进程相同的特权。</p><blockquote><p><strong>说明：</strong> 你的<a href="https://kubernetes.io/docs/reference/generated/container-runtime" target="_blank" rel="noopener">容器运行时</a>必须支持 特权容器的概念才能使用这一配置。</p></blockquote><h2 id="静态-Pod"><a href="#静态-Pod" class="headerlink" title="静态 Pod"></a>静态 Pod</h2><p><em>静态 Pod（Static Pod）</em> 直接由特定节点上的 <code>kubelet</code> 守护进程管理， 不需要<a href="https://kubernetes.io/docs/reference/generated/kube-apiserver/" target="_blank" rel="noopener">API 服务器</a>看到它们。 尽管大多数 Pod 都是通过控制面（例如，<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/" target="_blank" rel="noopener">Deployment</a>） 来管理的，对于静态 Pod 而言，<code>kubelet</code> 直接监控每个 Pod，并在其失效时重启之。</p><p>静态 Pod 通常绑定到某个节点上的 <a href="https://kubernetes.io/docs/reference/generated/kubelet" target="_blank" rel="noopener">kubelet</a>。 其主要用途是运行自托管的控制面。 在自托管场景中，使用 <code>kubelet</code> 来管理各个独立的 <a href="https://kubernetes.io/zh/docs/concepts/overview/components/#control-plane-components" target="_blank" rel="noopener">控制面组件</a>。</p><p><code>kubelet</code> 自动尝试为每个静态 Pod 在 Kubernetes API 服务器上创建一个 <a href="https://kubernetes.io/zh/docs/reference/glossary/?all=true#term-mirror-pod" target="_blank" rel="noopener">镜像 Pod</a>。 这意味着在节点上运行的 Pod 在 API 服务器上是可见的，但不可以通过 API 服务器来控制。</p>]]></content>
      
      
      <categories>
          
          <category> container </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis-哨兵</title>
      <link href="2020/10/05/sql/redis-shao-bing/"/>
      <url>2020/10/05/sql/redis-shao-bing/</url>
      
        <content type="html"><![CDATA[<h2 id="Redis宕机后如何实现快速恢复"><a href="#Redis宕机后如何实现快速恢复" class="headerlink" title="Redis宕机后如何实现快速恢复"></a>Redis宕机后如何实现快速恢复</h2><h3 id="一、部署模式"><a href="#一、部署模式" class="headerlink" title="一、部署模式"></a>一、部署模式</h3><p>Redis在部署时，可以采用多种方式部署，每种部署方式对应不同的可用级别。</p><ol><li><strong>单节点部署</strong> ：只有一个节点提供服务，读写均在此节点，此节点宕机则数据全部丢失，直接影响业务。</li><li><strong>master-slave方式部署</strong> ：两个节点组成master-slave模式，在master上写入，slave上读取，读写分离提高访问性能，master宕机后，需要手动把slave提升为master，业务影响程度取决于手动提升master的延迟。</li><li><strong>master-slave+哨兵方式部署</strong> ：master-slave与上述相同，不同的是增加一组哨兵节点，用于实时检查master的健康状态，在master宕机后自动提升slave为新的master，最大程度降低不可用的时间，对业务影响时间较短。</li></ol><p>从上面几种部署模式可以看出，提高Redis可用性的关键是：多副本部署 + 自动故障恢复，而多副本正是依赖主从复制。</p><h3 id="二、哨兵介绍"><a href="#二、哨兵介绍" class="headerlink" title="二、哨兵介绍"></a>二、哨兵介绍</h3><p>哨兵是Redis高可用的解决方案，它是一个管理多个Redis实例的服务工具，可以实现对Redis实例的监控、通知、自动故障转移。</p><p>在部署哨兵时，我们只需要在配置文件中配置需要管理的master节点，哨兵节点就可以根据配置，对Redis节点进行管理，实现高可用。</p><p><a href="https://imgchr.com/i/0ODWQS" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/10/18/0ODWQS.png" alt="0ODWQS.png"></a></p><p>一般我们需要部署多个哨兵节点，这是因为在分布式场景下，要想确定某个机器的某个节点上否发生故障，只用一台机器去检测可能是不准确的，很有可能这两台机器的网络发生了故障，而节点本身并没有问题。</p><p>所以对于节点健康检测的场景，一般都会采用多个节点同时去检测，且多个节点分布在不同机器上，节点数量为奇数个，避免因为网络分区导致哨兵决策错误。这样多个哨兵节点互相交换检测信息，最终决策才能确认某个节点上否真正发生了问题。</p><p>哨兵节点部署并配置完成后，哨兵就会自动地对配置的master-slave进行管理，在master发生故障时，及时地提升slave为新的master，保证可用性。</p><h4 id="三、哨兵原理"><a href="#三、哨兵原理" class="headerlink" title="三、哨兵原理"></a>三、哨兵原理</h4><p>哨兵的工作流程主要分为以下几个阶段：</p><ul><li>状态感知</li><li>心跳检测</li><li>选举哨兵领导者</li><li>选择新的master</li><li>故障恢复</li><li>客户端感知新master</li></ul><h4 id="1-状态感知"><a href="#1-状态感知" class="headerlink" title="1. 状态感知"></a>1. 状态感知</h4><p>哨兵启动后只指定了master的地址，哨兵要想在master故障时进行故障恢复，就需要知道每个master对应的slave信息。每个master可能不止一个slave，因此哨兵需要知道整个集群中完整的的拓扑关系，如何拿到这些信息？</p><p>哨兵每隔10秒会向每个master节点发送info命令，info命令返回的信息中，包含了主从拓扑关系，其中包括每个slave的地址和端口号。有了这些信息后，哨兵就会记住这些节点的拓扑信息，在后续发生故障时，选择合适的slave节点进行故障恢复。</p><p>哨兵除了向master发送info之外，还会向每个master节点特殊的pubsub中发送master当前的状态信息和哨兵自身的信息，其他哨兵节点通过订阅这个pubsub，就可以拿到每个哨兵发来的信息。</p><p>这么做的目的主要有2个：</p><ul><li>哨兵节点可以发现其他哨兵的加入，进而方便多个哨兵节点通信，为后续共同协商提供基础</li><li>与其他哨兵节点交换master的状态信息，为后续判断master是否故障提供依据</li></ul><h4 id="2-心跳检测"><a href="#2-心跳检测" class="headerlink" title="2. 心跳检测"></a>2. 心跳检测</h4><p>在故障发生时，需要立即启动故障恢复机制，那么如何保证及时性呢？</p><p>每个哨兵节点每隔1秒向master、slave、其他哨兵节点发送ping命令，如果对方能在指定时间内响应，说明节点健康存活。如果未在规定时间内（可配置）响应，那么该哨兵节点认为此节点主观下线。</p><h4 id="3-为什么叫做主观下线？"><a href="#3-为什么叫做主观下线？" class="headerlink" title="3. 为什么叫做主观下线？"></a>3. 为什么叫做主观下线？</h4><p>因为当前哨兵节点探测对方没有得到响应，很有可能这两个机器之间的网络发生了故障，而master节点本身没有任何问题，此时就认为master故障是不正确的。</p><p>要想确认master节点是否真正发生故障，就需要多个哨兵节点共同确认才行。</p><p>每个哨兵节点通过向其他哨兵节点询问此master的状态，来共同确认此节点上否真正故障。</p><p>如果超过指定数量（可配置）的哨兵节点都认为此节点主观下线，那么才会把这个节点标记为客观下线。</p><h4 id="4-选举哨兵领导者"><a href="#4-选举哨兵领导者" class="headerlink" title="4. 选举哨兵领导者"></a>4. 选举哨兵领导者</h4><p>确认这个节点真正故障后，就需要进入到故障恢复阶段。如何进行故障恢复，也需要经历一系列流程。</p><p>首先需要选举出一个哨兵领导者，由这个专门的哨兵领导者来进行故障恢复操作，不用多个哨兵都参与故障恢复。选举哨兵领导者的过程，需要多个哨兵节点共同协商来选出。</p><p>这个选举协商的过程，在分布式领域中叫做达成共识，协商的算法叫做共识算法。</p><p>共识算法主要为了解决在分布式场景下，多个节点如何针对某一个场景达成一致的结果。</p><p>共识算法包括很多种，例如Paxos、Raft、Gossip算法等，感兴趣的同学可以自行搜索相关资料，这里不再展开来讲。</p><p>哨兵选举领导者的过程类似于Raft算法，它的算法足够简单易理解。</p><p>简单来讲流程如下：</p><ul><li>每个哨兵都设置一个随机超时时间，超时后向其他哨兵发送申请成为领导者的请求</li><li>其他哨兵只能对收到的第一个请求进行回复确认</li><li>首先达到多数确认选票的哨兵节点，成为领导者</li><li>如果在确认回复后，所有哨兵都无法达到多数选票的结果，那么进行重新选举，直到选出领导者为止<br>选择出哨兵领导者后，之后的故障恢复操作都由这个哨兵领导者进行操作。</li></ul><h4 id="5-选择新的master"><a href="#5-选择新的master" class="headerlink" title="5. 选择新的master"></a>5. 选择新的master</h4><p>哨兵领导者针对发生故障的master节点，需要在它的slave节点中，选择一个节点来代替其工作。</p><p>这个选择新master过程也是有优先级的，在多个slave的场景下，优先级按照：slave-priority配置 &gt; 数据完整性 &gt; runid较小者进行选择。</p><p>也就是说优先选择slave-priority最小值的slave节点，如果所有slave此配置相同，那么选择数据最完整的slave节点，如果数据也一样，最后选择runid较小的slave节点。</p><h4 id="6-提升新的master"><a href="#6-提升新的master" class="headerlink" title="6.提升新的master"></a>6.提升新的master</h4><p>经过优先级选择，选出了备选的master节点后，下一步就是要进行真正的主从切换了。</p><p>哨兵领导者给备选的master节点发送slaveof no one命令，让该节点成为master。</p><p>之后，哨兵领导者会给故障节点的所有slave发送slaveof $newmaster命令，让这些slave成为新master的从节点，开始从新的master上同步数据。</p><p>最后哨兵领导者把故障节点降级为slave，并写入到自己的配置文件中，待这个故障节点恢复后，则自动成为新master节点的slave。</p><p>至此，整个故障切换完成。</p><h4 id="7-客户端感知新master"><a href="#7-客户端感知新master" class="headerlink" title="7. 客户端感知新master"></a>7. 客户端感知新master</h4><p>最后，客户端如何拿到最新的master地址呢？</p><p>哨兵在故障切换完成之后，会向自身节点的指定pubsub中写入一条信息，客户端可以订阅这个pubsub来感知master的变化通知。我们的客户端也可以通过在哨兵节点主动查询当前最新的master，来拿到最新的master地址。</p><p>另外，哨兵还提供了“钩子”机制，我们也可以在哨兵配置文件中配置一些脚本逻辑，在故障切换完成时，触发“钩子”逻辑，通知客户端发生了切换，让客户端重新在哨兵上获取最新的master地址。</p><p>一般来说，推荐采用第一种方式进行处理，很多客户端SDK中已经集成好了从哨兵节点获取最新master的方法，我们直接使用即可。</p><h3 id="四、PS"><a href="#四、PS" class="headerlink" title="四、PS"></a>四、PS</h3><p>可见，为了保证Redis的高可用，哨兵节点要准确无误地判断故障的发生，并且快速的选出新的节点来代替其提供服务，这中间的流程还是比较复杂的。</p><p>中间涉及到了分布式共识、分布式协商等知识，目的都是为了保证故障切换的准确性。</p><p>我们有必要了解Redis高可用的工作原理，这样我们在使用Redis时能更准确地使用它。</p>]]></content>
      
      
      <categories>
          
          <category> SQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes架构-控制器</title>
      <link href="2020/10/03/container/kubernetes-jia-gou-kong-zhi-qi/"/>
      <url>2020/10/03/container/kubernetes-jia-gou-kong-zhi-qi/</url>
      
        <content type="html"><![CDATA[<h1 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h1><p>在机器人技术和自动化领域，控制回路（Control Loop）是一个非终止回路，用于调节系统状态。</p><p>这是一个控制环的例子：房间里的温度自动调节器。</p><p>当你设置了温度，告诉了温度自动调节器你的<em>期望状态（Desired State）</em>。 房间的实际温度是<em>当前状态（Current State）</em>。 通过对设备的开关控制，温度自动调节器让其当前状态接近期望状态。</p><p>控制器通过 </p><p>apiserver</p><p> 监控集群的公共状态，并致力于将当前状态转变为期望的状态。</p><h2 id="控制器模式"><a href="#控制器模式" class="headerlink" title="控制器模式"></a>控制器模式</h2><p>一个控制器至少追踪一种类型的 Kubernetes 资源。这些 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/kubernetes-objects/" target="_blank" rel="noopener">对象</a> 有一个代表期望状态的 <code>spec</code> 字段。 该资源的控制器负责确保其当前状态接近期望状态。</p><p>控制器可能会自行执行操作；在 Kubernetes 中更常见的是一个控制器会发送信息给 <a href="https://kubernetes.io/docs/reference/generated/kube-apiserver/" target="_blank" rel="noopener">API 服务器</a>，这会有副作用。 具体可参看后文的例子。</p><h3 id="通过-API-服务器来控制"><a href="#通过-API-服务器来控制" class="headerlink" title="通过 API 服务器来控制"></a>通过 API 服务器来控制</h3><p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion" target="_blank" rel="noopener">Job</a> 控制器是一个 Kubernetes 内置控制器的例子。 内置控制器通过和集群 API 服务器交互来管理状态。</p><p>Job 是一种 Kubernetes 资源，它运行一个或者多个 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/" target="_blank" rel="noopener">Pod</a>， 来执行一个任务然后停止。 （一旦<a href="https://kubernetes.io/zh/docs/concepts/scheduling-eviction/" target="_blank" rel="noopener">被调度了</a>，对 <code>kubelet</code> 来说 Pod 对象就会变成了期望状态的一部分）。</p><p>在集群中，当 Job 控制器拿到新任务时，它会保证一组 Node 节点上的 <code>kubelet</code> 可以运行正确数量的 Pod 来完成工作。 Job 控制器不会自己运行任何的 Pod 或者容器。Job 控制器是通知 API 服务器来创建或者移除 Pod。 <a href="https://kubernetes.io/zh/docs/reference/glossary/?all=true#term-control-plane" target="_blank" rel="noopener">控制面</a>中的其它组件 根据新的消息作出反应（调度并运行新 Pod）并且最终完成工作。</p><p>创建新 Job 后，所期望的状态就是完成这个 Job。Job 控制器会让 Job 的当前状态不断接近期望状态：创建为 Job 要完成工作所需要的 Pod，使 Job 的状态接近完成。</p><p>控制器也会更新配置对象。例如：一旦 Job 的工作完成了，Job 控制器会更新 Job 对象的状态为 <code>Finished</code>。</p><p>（这有点像温度自动调节器关闭了一个灯，以此来告诉你房间的温度现在到你设定的值了）。</p><h3 id="直接控制"><a href="#直接控制" class="headerlink" title="直接控制"></a>直接控制</h3><p>相比 Job 控制器，有些控制器需要对集群外的一些东西进行修改。</p><p>例如，如果你使用一个控制环来保证集群中有足够的<a href="https://kubernetes.io/zh/docs/concepts/architecture/nodes/" target="_blank" rel="noopener">节点</a>，那么控制就需要当前集群外的一些服务在需要时创建新节点。</p><p>和外部状态交互的控制器从 API 服务器获取到它想要的状态，然后直接和外部系统进行通信并使当前状态更接近期望状态。</p><p>（实际上有一个控制器可以水平地扩展集群中的节点。请参阅 <a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/cluster-management/#cluster-autoscaling" target="_blank" rel="noopener">集群自动扩缩容</a>）。</p><h2 id="期望状态与当前状态"><a href="#期望状态与当前状态" class="headerlink" title="期望状态与当前状态"></a>期望状态与当前状态</h2><p>Kubernetes 采用了系统的云原生视图，并且可以处理持续的变化。</p><p>在任务执行时，集群随时都可能被修改，并且控制回路会自动修复故障。这意味着很可能集群永远不会达到稳定状态。</p><p>只要集群中控制器的在运行并且进行有效的修改，整体状态的稳定与否是无关紧要的。</p><h2 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h2><p>作为设计原则之一，Kubernetes 使用了很多控制器，每个控制器管理集群状态的一个特定方面。 最常见的一个特定的控制器使用一种类型的资源作为它的期望状态， 控制器管理控制另外一种类型的资源向它的期望状态演化。</p><p>使用简单的控制器而不是一组相互连接的单体控制回路是很有用的。 控制器会失败，所以 Kubernetes 的设计正是考虑到了这一点。</p><blockquote><p>说明：</p><p>可以有多个控制器来创建或者更新相同类型的对象。 在后台，Kubernetes 控制器确保它们只关心与其控制资源相关联的资源。</p><p>例如，你可以创建 Deployment 和 Job；它们都可以创建 Pod。 Job 控制器不会删除 Deployment 所创建的 Pod，因为有信息 （<a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/labels/" target="_blank" rel="noopener">标签</a>）让控制器可以区分这些 Pod。</p></blockquote><h2 id="运行控制器的方式"><a href="#运行控制器的方式" class="headerlink" title="运行控制器的方式"></a>运行控制器的方式</h2><p>Kubernetes 内置一组控制器，运行在 <a href="https://kubernetes.io/docs/reference/generated/kube-controller-manager/" target="_blank" rel="noopener">kube-controller-manager</a> 内。 这些内置的控制器提供了重要的核心功能。</p><p>Deployment 控制器和 Job 控制器是 Kubernetes 内置控制器的典型例子。 Kubernetes 允许你运行一个稳定的控制平面，这样即使某些内置控制器失败了， 控制平面的其他部分会接替它们的工作。</p><p>你会遇到某些控制器运行在控制面之外，用以扩展 Kubernetes。 或者，如果你愿意，你也可以自己编写新控制器。 你可以以一组 Pod 来运行你的控制器，或者运行在 Kubernetes 之外。 最合适的方案取决于控制器所要执行的功能是什么。</p>]]></content>
      
      
      <categories>
          
          <category> container </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes架构-节点</title>
      <link href="2020/10/03/container/kubernetes-jia-gou-jie-dian/"/>
      <url>2020/10/03/container/kubernetes-jia-gou-jie-dian/</url>
      
        <content type="html"><![CDATA[<h1 id="节点"><a href="#节点" class="headerlink" title="节点"></a>节点</h1><p>Kubernetes 通过将容器放入在节点（Node）上运行的 Pod 中来执行你的工作负载。 节点可以是一个虚拟机或者物理机器，取决于所在的集群配置。每个节点都包含用于运行 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/" target="_blank" rel="noopener">Pod</a> 所需要的服务，这些服务由 <a href="https://kubernetes.io/zh/docs/reference/glossary/?all=true#term-control-plane" target="_blank" rel="noopener">控制面</a>负责管理。</p><p>通常集群中会有若干个节点；而在一个学习用或者资源受限的环境中，你的集群中也可能 只有一个节点。</p><p>节点上的<a href="https://kubernetes.io/zh/docs/concepts/overview/components/#node-components" target="_blank" rel="noopener">组件</a>包括 <a href="https://kubernetes.io/docs/reference/generated/kubelet" target="_blank" rel="noopener">kubelet</a>、 <a href="https://kubernetes.io/docs/reference/generated/container-runtime" target="_blank" rel="noopener">容器运行时</a>以及 <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-proxy/" target="_blank" rel="noopener">kube-proxy</a>。</p><h2 id="管理"><a href="#管理" class="headerlink" title="管理"></a>管理</h2><p>向 <a href="https://kubernetes.io/docs/reference/generated/kube-apiserver/" target="_blank" rel="noopener">API 服务器</a>添加节点的方式主要有两种：</p><ol><li>节点上的 <code>kubelet</code> 向控制面执行自注册；</li><li>你，或者别的什么人，手动添加一个 Node 对象。</li></ol><p>在你创建了 Node 对象或者节点上的 <code>kubelet</code> 执行了自注册操作之后， 控制面会检查新的 Node 对象是否合法。例如，如果你使用下面的 JSON 对象来创建 Node 对象：</p><pre class=" language-json"><code class="language-json"><span class="token punctuation">{</span>  <span class="token property">"kind"</span><span class="token operator">:</span> <span class="token string">"Node"</span><span class="token punctuation">,</span>  <span class="token property">"apiVersion"</span><span class="token operator">:</span> <span class="token string">"v1"</span><span class="token punctuation">,</span>  <span class="token property">"metadata"</span><span class="token operator">:</span> <span class="token punctuation">{</span>    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"10.240.79.157"</span><span class="token punctuation">,</span>    <span class="token property">"labels"</span><span class="token operator">:</span> <span class="token punctuation">{</span>      <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"my-first-k8s-node"</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>Kubernetes 会在内部创建一个 Node 对象作为节点的表示。Kubernetes 检查 <code>kubelet</code> 向 API 服务器注册节点时使用的 <code>metadata.name</code> 字段是否匹配。 如果节点是健康的（即所有必要的服务都在运行中），则该节点可以用来运行 Pod。 否则，直到该节点变为健康之前，所有的集群活动都会忽略该节点。</p><blockquote><p><strong>说明：</strong> Kubernetes 会一直保存着非法节点对应的对象，并持续检查该节点是否已经 变得健康。 你，或者某个<a href="https://kubernetes.io/docs/admin/kube-controller-manager/" target="_blank" rel="noopener">控制器</a>必需显式地 删除该 Node 对象以停止健康检查操作。</p></blockquote><p>Node 对象的名称必须是合法的 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/names#dns-subdomain-names" target="_blank" rel="noopener">DNS 子域名</a>。</p><h3 id="节点自注册"><a href="#节点自注册" class="headerlink" title="节点自注册"></a>节点自注册</h3><p>当 kubelet 标志 <code>--register-node</code> 为 true（默认）时，它会尝试向 API 服务注册自己。 这是首选模式，被绝大多数发行版选用。</p><p>对于自注册模式，kubelet 使用下列参数启动：</p><ul><li><code>--kubeconfig</code> - 用于向 API 服务器表明身份的凭据路径。</li><li><code>--cloud-provider</code> - 与某<a href="https://kubernetes.io/zh/docs/reference/glossary/?all=true#term-cloud-provider" target="_blank" rel="noopener">云驱动</a> 进行通信以读取与自身相关的元数据的方式。</li><li><code>--register-node</code> - 自动向 API 服务注册。</li><li><code>--register-with-taints</code> - 使用所给的污点列表（逗号分隔的 <code>&lt;key&gt;=&lt;value&gt;:&lt;effect&gt;</code>）注册节点。 当 <code>register-node</code> 为 false 时无效。</li><li><code>--node-ip</code> - 节点 IP 地址。</li><li><code>--node-labels</code> - 在集群中注册节点时要添加的 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/labels/" target="_blank" rel="noopener">标签</a>。 （参见 <a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/admission-controllers/#noderestriction" target="_blank" rel="noopener">NodeRestriction 准入控制插件</a>所实施的标签限制）。</li><li><code>--node-status-update-frequency</code> - 指定 kubelet 向控制面发送状态的频率。</li></ul><p>启用<a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/node/" target="_blank" rel="noopener">节点授权模式</a>和 <a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/admission-controllers/#noderestriction" target="_blank" rel="noopener">NodeRestriction 准入插件</a> 时，仅授权 <code>kubelet</code> 创建或修改其自己的节点资源。</p><h4 id="手动节点管理"><a href="#手动节点管理" class="headerlink" title="手动节点管理"></a>手动节点管理</h4><p>你可以使用 <a href="https://kubernetes.io/docs/user-guide/kubectl-overview/" target="_blank" rel="noopener">kubectl</a> 来创建和修改 Node 对象。</p><p>如果你希望手动创建节点对象时，请设置 kubelet 标志 <code>--register-node=false</code>。</p><p>你可以修改 Node 对象（忽略 <code>--register-node</code> 设置）。 例如，修改节点上的标签或标记其为不可调度。</p><p>你可以结合使用节点上的标签和 Pod 上的选择算符来控制调度。 例如，你可以限制某 Pod 只能在符合要求的节点子集上运行。</p><p>如果标记节点为不可调度（unschedulable），将阻止新 Pod 调度到该节点之上，但不会 影响任何已经在其上的 Pod。 这是重启节点或者执行其他维护操作之前的一个有用的准备步骤。</p><p>要标记一个节点为不可调度，执行以下命令：</p><pre class=" language-shell"><code class="language-shell">kubectl cordon $NODENAME</code></pre><blockquote><p><strong>说明：</strong> 被 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/daemonset/" target="_blank" rel="noopener">DaemonSet</a> 控制器创建的 Pod 能够容忍节点的不可调度属性。 DaemonSet 通常提供节点本地的服务，即使节点上的负载应用已经被腾空，这些服务也仍需 运行在节点之上。</p></blockquote><h2 id="节点状态"><a href="#节点状态" class="headerlink" title="节点状态"></a>节点状态</h2><p>一个节点的状态包含以下信息:</p><ul><li><a href="https://kubernetes.io/zh/docs/concepts/architecture/nodes/#addresses" target="_blank" rel="noopener">地址</a></li><li><a href="https://kubernetes.io/zh/docs/concepts/architecture/nodes/#condition" target="_blank" rel="noopener">状况</a></li><li><a href="https://kubernetes.io/zh/docs/concepts/architecture/nodes/#capacity" target="_blank" rel="noopener">容量与可分配</a></li><li><a href="https://kubernetes.io/zh/docs/concepts/architecture/nodes/#info" target="_blank" rel="noopener">信息</a></li></ul><p>你可以使用 <code>kubectl</code> 来查看节点状态和其他细节信息：</p><pre class=" language-shell"><code class="language-shell">kubectl describe node <节点名称></code></pre><p>下面对每个部分进行详细描述。</p><h3 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h3><p>这些字段的用法取决于你的云服务商或者物理机配置。</p><ul><li>HostName：由节点的内核设置。可以通过 kubelet 的 <code>--hostname-override</code> 参数覆盖。</li><li>ExternalIP：通常是节点的可外部路由（从集群外可访问）的 IP 地址。</li><li>InternalIP：通常是节点的仅可在集群内部路由的 IP 地址。</li></ul><h3 id="状况"><a href="#状况" class="headerlink" title="状况"></a>状况</h3><p><code>conditions</code> 字段描述了所有 <code>Running</code> 节点的状态。状况的示例包括：</p><blockquote><p><strong>说明：</strong> 如果使用命令行工具来打印已保护（Cordoned）节点的细节，其中的 Condition 字段可能 包括 <code>SchedulingDisabled</code>。<code>SchedulingDisabled</code> 不是 Kubernetes API 中定义的 Condition，被保护起来的节点在其规约中被标记为不可调度（Unschedulable）。</p></blockquote><p>节点条件使用 JSON 对象表示。例如，下面的响应描述了一个健康的节点。</p><pre class=" language-json"><code class="language-json"><span class="token property">"conditions"</span><span class="token operator">:</span> <span class="token punctuation">[</span>  <span class="token punctuation">{</span>    <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"Ready"</span><span class="token punctuation">,</span>    <span class="token property">"status"</span><span class="token operator">:</span> <span class="token string">"True"</span><span class="token punctuation">,</span>    <span class="token property">"reason"</span><span class="token operator">:</span> <span class="token string">"KubeletReady"</span><span class="token punctuation">,</span>    <span class="token property">"message"</span><span class="token operator">:</span> <span class="token string">"kubelet is posting ready status"</span><span class="token punctuation">,</span>    <span class="token property">"lastHeartbeatTime"</span><span class="token operator">:</span> <span class="token string">"2019-06-05T18:38:35Z"</span><span class="token punctuation">,</span>    <span class="token property">"lastTransitionTime"</span><span class="token operator">:</span> <span class="token string">"2019-06-05T11:41:27Z"</span>  <span class="token punctuation">}</span><span class="token punctuation">]</span></code></pre><p>如果 Ready 条件处于 <code>Unknown</code> 或者 <code>False</code> 状态的时间超过了 <code>pod-eviction-timeout</code> 值， （一个传递给 <a href="https://kubernetes.io/docs/reference/generated/kube-controller-manager/" target="_blank" rel="noopener">kube-controller-manager</a> 的参数）， 节点上的所有 Pod 都会被节点控制器计划删除。默认的逐出超时时长为 <strong>5 分钟</strong>。 某些情况下，当节点不可达时，API 服务器不能和其上的 kubelet 通信。 删除 Pod 的决定不能传达给 kubelet，直到它重新建立和 API 服务器的连接为止。 与此同时，被计划删除的 Pod 可能会继续在游离的节点上运行。</p><p>节点控制器在确认 Pod 在集群中已经停止运行前，不会强制删除它们。 你可以看到这些可能在无法访问的节点上运行的 Pod 处于 <code>Terminating</code> 或者 <code>Unknown</code> 状态。 如果 kubernetes 不能基于下层基础设施推断出某节点是否已经永久离开了集群， 集群管理员可能需要手动删除该节点对象。 从 Kubernetes 删除节点对象将导致 API 服务器删除节点上所有运行的 Pod 对象并释放它们的名字。</p><p>节点生命周期控制器会自动创建代表状况的 <a href="https://kubernetes.io/zh/docs/concepts/scheduling-eviction/taint-and-toleration/" target="_blank" rel="noopener">污点</a>。 当调度器将 Pod 指派给某节点时，会考虑节点上的污点。 Pod 则可以通过容忍度（Toleration）表达所能容忍的污点。</p><p><code>capacity</code> 块中的字段标示节点拥有的资源总量。 <code>allocatable</code> 块指示节点上可供普通 Pod 消耗的资源量。</p><p>可以在学习如何在节点上<a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable" target="_blank" rel="noopener">预留计算资源</a> 的时候了解有关容量和可分配资源的更多信息。</p><p>第二个是保持节点控制器内的节点列表与云服务商所提供的可用机器列表同步。 如果在云环境下运行，只要某节点不健康，节点控制器就会询问云服务是否节点的虚拟机仍可用。 如果不可用，节点控制器会将该节点从它的节点列表删除。</p><p>第三个是监控节点的健康情况。节点控制器负责在节点不可达 （即，节点控制器因为某些原因没有收到心跳，例如节点宕机）时， 将节点状态的 <code>NodeReady</code> 状况更新为 “<code>Unknown</code>“。 如果节点接下来持续处于不可达状态，节点控制器将逐出节点上的所有 Pod（使用体面终止）。 默认情况下 40 秒后开始报告 “<code>Unknown</code>“，在那之后 5 分钟开始逐出 Pod。 节点控制器每隔 <code>--node-monitor-period</code> 秒检查每个节点的状态。</p><p><code>kubelet</code> 负责创建和更新 <code>NodeStatus</code> 和 <code>Lease</code> 对象。</p><p>当一个可用区域（Availability Zone）中的节点变为不健康时，节点的驱逐行为将发生改变。 节点控制器会同时检查可用区域中不健康（NodeReady 状况为 Unknown 或 False） 的节点的百分比。如果不健康节点的比例超过 <code>--unhealthy-zone-threshold</code> （默认为 0.55）， 驱逐速率将会降低：如果集群较小（意即小于等于 <code>--large-cluster-size-threshold</code> 个节点 - 默认为 50），驱逐操作将会停止，否则驱逐速率将降为每秒 <code>--secondary-node-eviction-rate</code> 个（默认为 0.01）。 在单个可用区域实施这些策略的原因是当一个可用区域可能从控制面脱离时其它可用区域 可能仍然保持连接。 如果你的集群没有跨越云服务商的多个可用区域，那（整个集群）就只有一个可用区域。</p><p>跨多个可用区域部署你的节点的一个关键原因是当某个可用区域整体出现故障时， 工作负载可以转移到健康的可用区域。 因此，如果一个可用区域中的所有节点都不健康时，节点控制器会以正常的速率 <code>--node-eviction-rate</code> 进行驱逐操作。 在所有的可用区域都不健康（也即集群中没有健康节点）的极端情况下， 节点控制器将假设控制面节点的连接出了某些问题， 它将停止所有驱逐动作直到一些连接恢复。</p><p>节点控制器还负责驱逐运行在拥有 <code>NoExecute</code> 污点的节点上的 Pod， 除非这些 Pod 能够容忍此污点。 节点控制器还负责根据节点故障（例如节点不可访问或没有就绪）为其添加 <a href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/" target="_blank" rel="noopener">污点</a>。 这意味着调度器不会将 Pod 调度到不健康的节点上。</p><blockquote><p><strong>注意：</strong> <code>kubectl cordon</code> 会将节点标记为“不可调度（Unschedulable）”。 此操作的副作用是，服务控制器会将该节点从负载均衡器中之前的目标节点列表中移除， 从而使得来自负载均衡器的网络请求不会到达被保护起来的节点。</p></blockquote><p>Kubernetes <a href="https://kubernetes.io/docs/reference/generated/kube-scheduler/" target="_blank" rel="noopener">调度器</a>保证节点上 有足够的资源供其上的所有 Pod 使用。它会检查节点上所有容器的请求的总和不会超过节点的容量。 总的请求包括由 kubelet 启动的所有容器，但不包括由容器运行时直接启动的容器， 也不包括不受 <code>kubelet</code> 控制的其他进程。</p><blockquote><p><strong>说明：</strong> 如果要为非 Pod 进程显式保留资源。请参考 <a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/reserve-compute-resources/#system-reserved" target="_blank" rel="noopener">为系统守护进程预留资源</a>。</p></blockquote><h2 id="节点拓扑"><a href="#节点拓扑" class="headerlink" title="节点拓扑"></a>节点拓扑</h2><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.16 [alpha]</code></p><p>如果启用了 <code>TopologyManager</code> <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/feature-gates/" target="_blank" rel="noopener">特性门控</a>， <code>kubelet</code> 可以在作出资源分配决策时使用拓扑提示。 参考<a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/topology-manager/" target="_blank" rel="noopener">控制节点上拓扑管理策略</a> 了解详细信息。</p>]]></content>
      
      
      <categories>
          
          <category> container </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes架构—组件</title>
      <link href="2020/10/03/container/kubernetes-jia-gou-zu-jian/"/>
      <url>2020/10/03/container/kubernetes-jia-gou-zu-jian/</url>
      
        <content type="html"><![CDATA[<h1 id="Kubernetes-组件"><a href="#Kubernetes-组件" class="headerlink" title="Kubernetes 组件"></a>Kubernetes 组件</h1><p>当你部署完 Kubernetes, 即拥有了一个完整的集群。</p><p>一个 Kubernetes 集群包含 集群由一组被称作节点的机器组成。这些节点上运行 Kubernetes 所管理的容器化应用。集群具有至少一个工作节点和至少一个主节点。</p><p>工作节点托管作为应用程序组件的 Pod 。主节点管理集群中的工作节点和 Pod 。多个主节点用于为集群提供故障转移和高可用性。</p><p>本文档概述了交付正常运行的 Kubernetes 集群所需的各种组件。</p><p>这张图表展示了包含所有相互关联组件的 Kubernetes 集群。</p><p><img src="https://d33wubrfki0l68.cloudfront.net/7016517375d10c702489167e704dcb99e570df85/7bb53/images/docs/components-of-kubernetes.png" alt="Kubernetes 组件"></p><h2 id="控制平面组件（Control-Plane-Components）"><a href="#控制平面组件（Control-Plane-Components）" class="headerlink" title="控制平面组件（Control Plane Components）"></a>控制平面组件（Control Plane Components）</h2><p>控制平面的组件对集群做出全局决策(比如调度)，以及检测和响应集群事件（例如，当不满足部署的 <code>replicas</code> 字段时，启动新的 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/" target="_blank" rel="noopener">pod</a>）。</p><p>控制平面组件可以在集群中的任何节点上运行。 然而，为了简单起见，设置脚本通常会在同一个计算机上启动所有控制平面组件，并且不会在此计算机上运行用户容器。 请参阅<a href="https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/high-availability/" target="_blank" rel="noopener">构建高可用性集群</a> 中对于多主机 VM 的设置示例。</p><h3 id="kube-apiserver"><a href="#kube-apiserver" class="headerlink" title="kube-apiserver"></a>kube-apiserver</h3><p>主节点上负责提供 Kubernetes API 服务的组件；它是 Kubernetes 控制面的前端。</p><p>kube-apiserver 在设计上考虑了水平扩缩的需要。 换言之，通过部署多个实例可以实现扩缩。 参见<a href="https://kubernetes.io/docs/admin/high-availability/" target="_blank" rel="noopener">构造高可用集群</a>。</p><h3 id="etcd"><a href="#etcd" class="headerlink" title="etcd"></a>etcd</h3><p>etcd 是兼具一致性和高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。</p><p>您的 Kubernetes 集群的 etcd 数据库通常需要有个备份计划。要了解 etcd 更深层次的信息，请参考 <a href="https://etcd.io/docs" target="_blank" rel="noopener">etcd 文档</a>。</p><h3 id="kube-scheduler"><a href="#kube-scheduler" class="headerlink" title="kube-scheduler"></a>kube-scheduler</h3><p>主节点上的组件，该组件监视那些新创建的未指定运行节点的 Pod，并选择节点让 Pod 在上面运行。</p><p>调度决策考虑的因素包括单个 Pod 和 Pod 集合的资源需求、硬件/软件/策略约束、亲和性和反亲和性规范、数据位置、工作负载间的干扰和最后时限。</p><h3 id="kube-controller-manager"><a href="#kube-controller-manager" class="headerlink" title="kube-controller-manager"></a>kube-controller-manager</h3><p>在主节点上运行<a href="https://kubernetes.io/docs/admin/kube-controller-manager/" target="_blank" rel="noopener">控制器</a>的组件。</p><p>从逻辑上讲，每个<a href="https://kubernetes.io/docs/admin/kube-controller-manager/" target="_blank" rel="noopener">控制器</a>都是一个单独的进程，但是为了降低复杂性，它们都被编译到同一个可执行文件，并在一个进程中运行。</p><p>这些控制器包括:</p><ul><li>节点控制器（Node Controller）: 负责在节点出现故障时进行通知和响应。</li><li>副本控制器（Replication Controller）: 负责为系统中的每个副本控制器对象维护正确数量的 Pod。</li><li>端点控制器（Endpoints Controller）: 填充端点(Endpoints)对象(即加入 Service 与 Pod)。</li><li>服务帐户和令牌控制器（Service Account &amp; Token Controllers）: 为新的命名空间创建默认帐户和 API 访问令牌.</li></ul><h3 id="cloud-controller-manager"><a href="#cloud-controller-manager" class="headerlink" title="cloud-controller-manager"></a>cloud-controller-manager</h3><p>云控制器管理器是 1.8 的 alpha 特性。在未来发布的版本中，这是将 Kubernetes 与任何其他云集成的最佳方式。</p><p><code>cloud-controller-manager</code> 进运行特定于云平台的控制回路。 如果你在自己的环境中运行 Kubernetes，或者在本地计算机中运行学习环境， 所部属的环境中不需要云控制器管理器。</p><p>与 <code>kube-controller-manager</code> 类似，<code>cloud-controller-manager</code> 将若干逻辑上独立的 控制回路组合到同一个可执行文件中，供你以同一进程的方式运行。 你可以对其执行水平扩容（运行不止一个副本）以提升性能或者增强容错能力。</p><p>下面的控制器都包含对云平台驱动的依赖：</p><ul><li>节点控制器（Node Controller）: 用于在节点终止响应后检查云提供商以确定节点是否已被删除</li><li>路由控制器（Route Controller）: 用于在底层云基础架构中设置路由</li><li>服务控制器（Service Controller）: 用于创建、更新和删除云提供商负载均衡器</li></ul><h2 id="Node-组件"><a href="#Node-组件" class="headerlink" title="Node 组件"></a>Node 组件</h2><p>节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。</p><h3 id="kubelet"><a href="#kubelet" class="headerlink" title="kubelet"></a>kubelet</h3><p>一个在集群中每个节点上运行的代理。它保证容器都运行在 Pod 中。</p><p>kubelet 接收一组通过各类机制提供给它的 PodSpecs，确保这些 PodSpecs 中描述的容器处于运行状态且健康。kubelet 不会管理不是由 Kubernetes 创建的容器。</p><h3 id="kube-proxy"><a href="#kube-proxy" class="headerlink" title="kube-proxy"></a>kube-proxy</h3><p><a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy/" target="_blank" rel="noopener">kube-proxy</a> 是集群中每个节点上运行的网络代理,实现 Kubernetes <a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/" target="_blank" rel="noopener">Service</a> 概念的一部分。</p><p>kube-proxy 维护节点上的网络规则。这些网络规则允许从集群内部或外部的网络会话与 Pod 进行网络通信。</p><p>如果操作系统提供了数据包过滤层并可用的话，kube-proxy会通过它来实现网络规则。否则，kube-proxy 仅转发流量本身。</p><h3 id="容器运行时（Container-Runtime）"><a href="#容器运行时（Container-Runtime）" class="headerlink" title="容器运行时（Container Runtime）"></a>容器运行时（Container Runtime）</h3><p>容器运行环境是负责运行容器的软件。</p><p>Kubernetes 支持多个容器运行环境: <a href="http://www.docker.com/" target="_blank" rel="noopener">Docker</a>、 <a href="https://containerd.io/" target="_blank" rel="noopener">containerd</a>、<a href="https://cri-o.io/" target="_blank" rel="noopener">cri-o</a>、 <a href="https://github.com/kubernetes-incubator/rktlet" target="_blank" rel="noopener">rktlet</a> 以及任何实现 <a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md" target="_blank" rel="noopener">Kubernetes CRI (容器运行环境接口)</a>。</p><h2 id="插件（Addons）"><a href="#插件（Addons）" class="headerlink" title="插件（Addons）"></a>插件（Addons）</h2><p>插件使用 Kubernetes 资源（<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/daemonset/" target="_blank" rel="noopener">DaemonSet</a>、 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/" target="_blank" rel="noopener">Deployment</a>等）实现集群功能。 因为这些插件提供集群级别的功能，插件中命名空间域的资源属于 <code>kube-system</code> 命名空间。</p><p>下面描述众多插件中的几种。有关可用插件的完整列表，请参见 <a href="https://kubernetes.io/zh/docs/concepts/cluster-administration/addons/" target="_blank" rel="noopener">插件（Addons）</a>。</p><h3 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h3><p>尽管其他插件都并非严格意义上的必需组件，但几乎所有 Kubernetes 集群都应该 有<a href="https://kubernetes.io/zh/docs/concepts/services-networking/dns-pod-service/" target="_blank" rel="noopener">集群 DNS</a>， 因为很多示例都需要 DNS 服务。</p><p>集群 DNS 是一个 DNS 服务器，和环境中的其他 DNS 服务器一起工作，它为 Kubernetes 服务提供 DNS 记录。</p><p>Kubernetes 启动的容器自动将此 DNS 服务器包含在其 DNS 搜索列表中。</p><h3 id="Web-界面（仪表盘）"><a href="#Web-界面（仪表盘）" class="headerlink" title="Web 界面（仪表盘）"></a>Web 界面（仪表盘）</h3><p><a href="https://kubernetes.io/zh/docs/tasks/access-application-cluster/web-ui-dashboard/" target="_blank" rel="noopener">Dashboard</a> 是K ubernetes 集群的通用的、基于 Web 的用户界面。 它使用户可以管理集群中运行的应用程序以及集群本身并进行故障排除。</p><h3 id="容器资源监控"><a href="#容器资源监控" class="headerlink" title="容器资源监控"></a>容器资源监控</h3><p><a href="https://kubernetes.io/zh/docs/tasks/debug-application-cluster/resource-usage-monitoring/" target="_blank" rel="noopener">容器资源监控</a> 将关于容器的一些常见的时间序列度量值保存到一个集中的数据库中，并提供用于浏览这些数据的界面。</p><h3 id="集群层面日志"><a href="#集群层面日志" class="headerlink" title="集群层面日志"></a>集群层面日志</h3><p><a href="https://kubernetes.io/zh/docs/concepts/cluster-administration/logging/" target="_blank" rel="noopener">集群层面日志</a> 机制负责将容器的日志数据 保存到一个集中的日志存储中，该存储能够提供搜索和浏览接口。</p>]]></content>
      
      
      <categories>
          
          <category> container </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Shell脚本加密经验分享</title>
      <link href="2020/10/01/linux/shell-jiao-ben-jia-mi-jing-yan-fen-xiang/"/>
      <url>2020/10/01/linux/shell-jiao-ben-jia-mi-jing-yan-fen-xiang/</url>
      
        <content type="html"><![CDATA[<h5 id="为啥要加密shell脚本"><a href="#为啥要加密shell脚本" class="headerlink" title="为啥要加密shell脚本"></a><strong>为啥要加密shell脚本</strong></h5><p>以我个人的需求为例，我要做一个自动远程登录的脚本，每次手动输密码太慢，而且输的多了密码也容易泄露；直接把密码写在脚本里，快确实是快，但是安全性让人无法忍受，写脚本的时候都有可能被过路的不小心看到密码，这就太蛋疼了。</p><p><strong>shell脚本加密常用的有三种方法：*</strong>gzexe,shc,upx*</p><h6 id="第一种，gzexe"><a href="#第一种，gzexe" class="headerlink" title="第一种，gzexe"></a><strong>第一种，gzexe</strong></h6><p><strong>特点是不用安装，加解密极其简单，我个人的操作环境是macOS,直接就可以用，命令简单粗暴</strong></p><pre><code>加密gzexe l.sh解密gzexe -d l.sh 复制</code></pre><p><strong>结论:</strong>gzexe其实就是个压缩工具，能起到隐藏文件内容的效果，执行速度几乎和脚本一样(在脚本不太大的情况下),但是如果加密文件本身被偷走，那就凉凉，轻松可以破解，当然高手也可以二段加密，比如手动修改加密后的文件什么的，但是这就是一个道高一尺魔高一丈的事了。</p><h6 id="第二种-shc"><a href="#第二种-shc" class="headerlink" title="第二种,shc"></a><strong>第二种,shc</strong></h6><p>安装方法略过，大家可以自行百度，这里直接实战。<br>shc加密以后，原文件不会变，会生成一个原文件名.x的加密后的文件，我这里就是l.sh.x了<br><strong>加密命令</strong></p><pre><code>shc -r -f l.sh 复制</code></pre><p><strong>但是shc有个问题，对于我来说是很严重的，就是加密后的脚本执行非常慢</strong><br><strong>vim test.sh</strong></p><pre><code>#!/bin/bash# 加密前start=$(date &quot;+%s&quot;)for i in {1..100}{    ./l.sh}end=$(date &quot;+%s&quot;)echo 加密前执行用时:$[$end-$start]&quot;秒&quot;# 加密后start=$(date &quot;+%s&quot;)./l.sh.xend=$(date &quot;+%s&quot;)echo 加密后执行用时:$[$end-$start]&quot;秒&quot; 复制</code></pre><p><strong>原始脚本执行100遍，用时不到1秒，shc加密后执行一次用时3秒，这tm慢如狗哇，如果每次执行脚本都是这个速度,完全不能忍!</strong><br><strong>总结:shc安全性稍好，至少解密起来不太容易，但是加密后执行速度太慢，无法忍受。</strong></p><h6 id="第三种-upx"><a href="#第三种-upx" class="headerlink" title="第三种,upx"></a><strong>第三种,upx</strong></h6><p><strong>upx是一个加壳工具，主要用来给可执行文件加密用的，但是网上也有文章说可以给shell脚本加密，所以我们就来试试。</strong><br><strong>upx安装不废话了，大家可以自行百度，这里直接操练。</strong></p><pre><code>upx加密命令# 最快压缩upx -1 l.sh# 最强压缩upx -9 l.sh 复制</code></pre><p><strong>出师不利，upx不能压缩太小文件，而脚本众所周知一般都不大，upx对shell脚本价值减少90%。</strong></p><p>我后来又给脚本加了一堆注释，强行增大了脚本，upx加密是能加密了，但是执行不了有毛用啊！怀疑是脚本不算可执行文件，用gzexe把脚本搞成了可执行文件，又压缩了一遍，这回确定了，upx加密后的脚本就是没法执行，upx对shell脚本价值减小为0。<br>有不信邪的朋友可以自己试试，我在macOS上尝试的结果是这样的，或许其他平台会有不一样的表现呢。</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> shell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mycat</title>
      <link href="2020/09/28/sql/mycat/"/>
      <url>2020/09/28/sql/mycat/</url>
      
        <content type="html"><![CDATA[<h2 id="MySQL-Replication"><a href="#MySQL-Replication" class="headerlink" title="MySQL-Replication"></a>MySQL-Replication</h2><h3 id="MySQL-Replication-1"><a href="#MySQL-Replication-1" class="headerlink" title="MySQL Replication"></a>MySQL Replication</h3><p>主从复制（也称 AB 复制）允许将来自一个MySQL数据库服务器（主服务器）的数据复制到一个或多个MySQL数据库服务器（从服务器）。</p><blockquote><p>复制是异步的 从站不需要永久连接以接收来自主站的更新。</p></blockquote><p>根据配置，您可以复制数据库中的所有数据库，所选数据库甚至选定的表。</p><p>MySQL中复制的优点包括：</p><ul><li>横向扩展解决方案 - 在多个从站之间分配负载以提高性能。在此环境中，所有写入和更新都必须在主服务器上进行。但是，读取可以在一个或多个从设备上进行。该模型可以提高写入性能（因为主设备专用于更新），同时显着提高了越来越多的从设备的读取速度。</li><li>数据安全性 - 因为数据被复制到从站，并且从站可以暂停复制过程，所以可以在从站上运行备份服务而不会破坏相应的主数据。</li><li>分析 - 可以在主服务器上创建实时数据，而信息分析可以在从服务器上进行，而不会影响主服务器的性能。</li><li>远程数据分发 - 您可以使用复制为远程站点创建数据的本地副本，而无需永久访问主服务器。</li></ul><h3 id="Replication的原理"><a href="#Replication的原理" class="headerlink" title="Replication的原理"></a>Replication的原理</h3><p><img src="https://i.loli.net/2019/08/13/b8YDSUo3ZM6wLtx.jpg" alt=""></p><p>前提是作为主服务器角色的数据库服务器必须开启二进制日志</p><pre><code>主服务器上面的任何修改都会通过自己的 I/O tread(I/O 线程)保存在二进制日志 Binary log 里面。从服务器上面也启动一个 I/O thread，通过配置好的用户名和密码, 连接到主服务器上面请求读取二进制日志，然后把读取到的二进制日志写到本地的一个Realy log（中继日志）里面。从服务器上面同时开启一个 SQL thread 定时检查 Realy log(这个文件也是二进制的)，如果发现有更新立即把更新的内容在本机的数据库上面执行一遍。每个从服务器都会收到主服务器二进制日志的全部内容的副本。从服务器设备负责决定应该执行二进制日志中的哪些语句。除非另行指定，否则主从二进制日志中的所有事件都在从站上执行。如果需要，您可以将从服务器配置为仅处理一些特定数据库或表的事件。重要: 您无法将主服务器配置为仅记录特定事件。每个从站(从服务器)都会记录二进制日志坐标：     文件名     文件中它已经从主站读取和处理的位置。由于每个从服务器都分别记录了自己当前处理二进制日志中的位置，因此可以断开从服务器的连接，重新连接然后恢复继续处理。</code></pre><h5 id="一主多从"><a href="#一主多从" class="headerlink" title="一主多从"></a>一主多从</h5><p>如果一主多从的话，这时主库既要负责写又要负责为几个从库提供二进制日志。此时可以稍做调整，将二进制日志只给某一从，这一从再开启二进制日志并将自己的二进制日志再发给其它从。或者是干脆这个从不记录只负责将二进制日志转发给其它从，这样架构起来性能可能要好得多，而且数据之间的延时应该也稍微要好一些。工作原理图如下：</p><p><img src="https://i.loli.net/2019/08/13/1e8xfpo5rMt3Blg.jpg" alt=""></p><p>练习题:</p><pre class=" language-reStructuredText"><code class="language-reStructuredText">使用三台机器搭建一主多从的mysql架构并能够实现数据同步, 部署形式不限<脚本、手动都可></code></pre><h4 id="关于二进制日志"><a href="#关于二进制日志" class="headerlink" title="关于二进制日志"></a>关于二进制日志</h4><p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Frefman%2F5.7%2Fen%2Fmysqld.html" target="_blank" rel="noopener"><strong>mysqld</strong></a>将数字扩展名附加到二进制日志基本名称以生成二进制日志文件名。每次服务器创建新日志文件时，该数字都会增加，从而创建一系列有序的文件。每次启动或刷新日志时，服务器都会在系列中创建一个新文件。服务器还会在当前日志大小达到<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Frefman%2F5.7%2Fen%2Freplication-options-binary-log.html%23sysvar_max_binlog_size" target="_blank" rel="noopener"><code>max_binlog_size</code></a>参数设置的大小后自动创建新的二进制日志文件 。二进制日志文件可能会比<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Frefman%2F5.7%2Fen%2Freplication-options-binary-log.html%23sysvar_max_binlog_size" target="_blank" rel="noopener"><code>max_binlog_size</code></a>使用大型事务时更大， 因为事务是以一个部分写入文件，而不是在文件之间分割。</p><p>为了跟踪已使用的二进制日志文件， <a href="https://links.jianshu.com/go?to=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Frefman%2F5.7%2Fen%2Fmysqld.html" target="_blank" rel="noopener"><strong>mysqld</strong></a>还创建了一个二进制日志索引文件，其中包含所有使用的二进制日志文件的名称。默认情况下，它具有与二进制日志文件相同的基本名称，并带有扩展名<code>&#39;.index&#39;</code>。在<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Frefman%2F5.7%2Fen%2Fmysqld.html" target="_blank" rel="noopener"><strong>mysqld</strong></a>运行时，您不应手动编辑此文件。</p><p>术语<code>二进制日志文件</code>通常表示包含数据库事件的单个编号文件。</p><p>术语 <code>二进制日志</code>  表示含编号的二进制日志文件集加上索引文件。</p><p><code>SUPER</code> 权限的用户可以使用<code>SET sql_log_bin=0</code>语句禁用其当前环境下自己的语句的二进制日志记录</p><h3 id="配置Replication"><a href="#配置Replication" class="headerlink" title="配置Replication"></a>配置Replication</h3><h5 id="配置步骤："><a href="#配置步骤：" class="headerlink" title="配置步骤："></a>配置步骤：</h5><ol><li>在主服务器上，您必须启用二进制日志记录并配置唯一的服务器ID。需要重启服务器。</li></ol><p>编辑主服务器的配置文件 <code>my.cnf</code>，添加如下内容</p><pre><code>[mysqld]log-bin=/var/log/mysql/mysql-binserver-id=1</code></pre><p>创建日志目录并赋予权限</p><pre><code>[root@mysql ~]#  mkdir /var/log/mysql[root@mysql ~]# chown mysql.mysql /var/log/mysql</code></pre><p>重启服务</p><pre><code>[root@mysql ~]# systemctl restart mysqld</code></pre><p><strong>注意：：</strong></p><pre><code>如果省略server-id（或将其显式设置为默认值0），则主服务器拒绝来自从服务器的任何连接。为了在使用带事务的InnoDB进行复制设置时尽可能提高持久性和一致性，您应该在master my.cnf文件中使用以下配置项：innodb_flush_log_at_trx_commit = 1sync_binlog = 1确保未在复制主服务器上启用skip-networking选项。如果已禁用网络，则从站无法与主站通信，并且复制失败。</code></pre><p>2.应该创建一个专门用于复制数据的用户</p><p>每个从服务器需要使用MySQL 主服务器上的用户名和密码连接到主站。</p><p>例如，计划使用用户 <code>repl</code> 可以从任何主机上连接到 <code>master</code> 上进行复制操作, 并且用户 <code>repl</code> 仅可以使用复制的权限。</p><p>在 <code>主服务器</code> 上执行如下操作</p><pre><code>mysql&gt; CREATE USER &#39;repl&#39;@&#39;%&#39; mysql&gt; GRANT REPLICATION SLAVE ON *.*  TO  &#39;repl&#39;@&#39;%&#39;  identified by  &#39;123&#39;;mysql&gt; </code></pre><p>3.在<code>从服务器</code>上使用刚才的用户进行测试连接</p><pre><code>[root@mysql ~]# mysql -urepl -p&#39;123&#39; -hmysql-master1</code></pre><p>下面的操作根据如下情况继续</p><h5 id="主服务器中有数据"><a href="#主服务器中有数据" class="headerlink" title="主服务器中有数据"></a>主服务器中有数据</h5><ul><li>如果在启动复制之前有现有数据需要与从属设备同步，请保持客户端正常运行，以便锁定保持不变。这可以防止进行任何进一步的更改，以便复制到从站的数据与主站同步。</li></ul><ol><li>在主服务器中导出先有的数据</li></ol><p>如果主数据库包含现有数据，则必须将此数据复制到每个从站。有多种方法可以实现:</p><ul><li>使用<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Frefman%2F5.7%2Fen%2Fmysqldump.html" target="_blank" rel="noopener"><strong>mysqldump</strong></a>工具创建要复制的所有数据库的转储。这是推荐的方法，尤其是在使用时 <a href="https://links.jianshu.com/go?to=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Frefman%2F5.7%2Fen%2Finnodb-storage-engine.html" target="_blank" rel="noopener"><code>InnoDB</code></a>。</li></ul><pre><code>[root@mysql ~]# mysqldump  -u用户名  -p密码  --all-databases  --master-data=1 &gt; dbdump.db这里的用户是主服务器的用户</code></pre><p>如果不使用 <code>--master-data</code> 参数，则需要手动锁定单独会话中的所有表。</p><ol start="2"><li>从主服务器中使用 <code>scp</code> 或 <code>rsync</code> 等工具，把备份出来的数据传输到从服务器中。</li></ol><p>在主服务中执行如下命令</p><pre><code>[root@mysql ~]# scp  dbdump.db root@mysql-slave1:/root/这里的 mysql-slave1 需要能被主服务器解析出 IP 地址，或者说可以在主服务器中 ping 通。</code></pre><ol start="3"><li>配置从服务器，并重启<br>在<code>从服务器</code> 上编辑其配置文件 <code>my.cnf</code> 并添加如下内容</li></ol><pre><code>// my.cnf 文件[mysqld]server-id=2</code></pre><ol start="4"><li>导入数据到从服务器，并配置连接到主服务器的相关信息</li></ol><p>登录到从服务器上，执行如下操作</p><pre><code>/*导入数据*/mysql&gt; source   /root/fulldb.dump</code></pre><p>在从服务器配置连接到主服务器的相关信息</p><pre><code>mysql&gt; CHANGE MASTER TOMASTER_HOST=&#39;mysql-master1&#39;,  -- 主服务器的主机名(也可以是 IP) MASTER_USER=&#39;repl&#39;,           -- 连接到主服务器的用户MASTER_PASSWORD=&#39;123&#39;;        -- 到主服务器的密码</code></pre><ol start="5"><li><p>启动从服务器的复制线程</p><pre><code>mysql&gt; start slave;Query OK, 0 rows affected (0.09 sec)</code></pre></li></ol><p>检查是否成功</p><p>在从服务上执行如下操作，加长从服务器端 IO线程和 SQL 线程是否是 <code>OK</code></p><pre><code>mysql&gt; show slave status\G</code></pre><p>输出结果中应该看到 I/O 线程和 SQL 线程都是 <code>YES</code>, 就表示成功。</p><p>执行此过程后，在主服务上操作的修改数据的操作都会在从服务器中执行一遍，这样就保证了数据的一致性。</p><h5 id="主服务器中无数据"><a href="#主服务器中无数据" class="headerlink" title="主服务器中无数据"></a>主服务器中无数据</h5><p><strong>主服务器中设置</strong></p><ol><li><code>my.cnf</code>配置文件</li></ol><pre><code>[mysqld]log-bin=/var/log/mysql/mysql-binserver-id=1</code></pre><p>创建日志目录并赋予权限</p><pre><code>[root@mysql ~]#  mkdir /var/log/mysql[root@mysql ~]#  chown mysql.mysql /var/log/mysql</code></pre><p>重启服务</p><p><strong>从服务器设置</strong></p><ol><li><code>my.cnf</code>配置文件</li></ol><pre><code>[mysqld]server-id=3</code></pre><p>重启服务</p><ol start="2"><li>查看主服务器的二进制日志的名称</li></ol><p>通过使用命令行客户端连接到主服务器来启动主服务器上的会话，并通过执行以下 <code>FLUSH TABLES WITH READ LOCK</code>  语句来刷新所有表和阻止写语句：</p><pre><code>mysql&gt; FLUSH TABLES WITH READ LOCK;mysql&gt; show master status \G****************** 1. row ****************             File: mysql-bin.000001         Position: 0     Binlog_Do_DB: Binlog_Ignore_DB:Executed_Gtid_Set:1 row in set (0.00 sec)</code></pre><ol start="3"><li>在从服务器的 mysql 中执行如下语句</li></ol><pre><code>mysql&gt; CHANGE MASTER TOMASTER_HOST=&#39;mysql-master1&#39;,MASTER_USER=&#39;repl&#39;,MASTER_PASSWORD=&#39;123&#39;,MASTER_LOG_FILE=&#39;mysql-bin.000001&#39;,MASTER_LOG_POS=0;mysql&gt; start slave;</code></pre><p><strong>查看</strong></p><p>在master上执行show binlog events命令，可以看到第一个binlog文件的内容。</p><pre><code>mysql&gt; show binlog events\G*************************** 1. row ***************************   Log_name: mysql-bin.000001        Pos: 4 Event_type: Format_desc  Server_id: 1End_log_pos: 107       Info: Server ver: 5.5.28-0ubuntu0.12.10.2-log, Binlog ver: 4*************************** 2. row ***************************   Log_name: mysql-bin.000001        Pos: 107 Event_type: Query  Server_id: 1End_log_pos: 181       Info: create user rep*************************** 3. row ***************************   Log_name: mysql-bin.000001        Pos: 181 Event_type: Query  Server_id: 1End_log_pos: 316       Info: grant replication slave on *.* to rep identified by &#39;123456&#39;3 rows in set (0.00 sec)Log_name 是二进制日志文件的名称，一个事件不能横跨两个文件Pos 这是该事件在文件中的开始位置Event_type 事件的类型，事件类型是给slave传递信息的基本方法，每个新的binlog都以Format_desc类型开始，以Rotate类型结束Server_id 创建该事件的服务器idEnd_log_pos 该事件的结束位置，也是下一个事件的开始位置，因此事件范围为Pos~End_log_pos  -  1Info 事件信息的可读文本，不同的事件有不同的信息</code></pre><h4 id="在从站上暂停复制"><a href="#在从站上暂停复制" class="headerlink" title="在从站上暂停复制"></a>在从站上暂停复制</h4><p>您可以使用<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Frefman%2F5.7%2Fen%2Fstop-slave.html" target="_blank" rel="noopener"><code>STOP SLAVE</code></a>和 <a href="https://links.jianshu.com/go?to=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Frefman%2F5.7%2Fen%2Fstart-slave.html" target="_blank" rel="noopener"><code>START SLAVE</code></a>语句停止并启动从站上的复制 。</p><p>要停止从主服务器处理二进制日志，请使用 <a href="https://links.jianshu.com/go?to=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Frefman%2F5.7%2Fen%2Fstop-slave.html" target="_blank" rel="noopener"><code>STOP SLAVE</code></a>：</p><pre><code>mysql&gt; STOP SLAVE;</code></pre><p>当复制停止时，从I / O线程停止从主二进制日志读取事件并将它们写入中继日志，并且SQL线程停止从中继日志读取事件并执行它们。您可以通过指定线程类型单独暂停I / O或SQL线程：</p><pre><code>mysql&gt; STOP SLAVE IO_THREAD;mysql&gt; STOP SLAVE SQL_THREAD;</code></pre><p>要再次开始执行，请使用以下<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Frefman%2F5.7%2Fen%2Fstart-slave.html" target="_blank" rel="noopener"><code>START SLAVE</code></a>语句：</p><pre><code>mysql&gt; START SLAVE;</code></pre><p>要启动特定线程，请指定线程类型：</p><pre><code>mysql&gt; START SLAVE IO_THREAD;mysql&gt; START SLAVE SQL_THREAD;</code></pre><pre><code>复制原理实现细节（了解）MySQL复制功能使用三个线程实现，一个在主服务器上，两个在从服务器上：Binlog转储线程 主设备创建一个线程，以便在从设备连接时将二进制日志内容发送到从设备。可以SHOW PROCESSLIST在主服务器的输出中将此线程标识为Binlog Dump线程。二进制日志转储线程获取主机二进制日志上的锁，用于读取要发送到从机的每个事件。一旦读取了事件，即使在事件发送到从站之前，锁也会被释放。从属 I/O线程 在从属服务器上发出 START SLAVE 语句时，从属服务器会创建一个 I/O 线程，该线程连接到主服务器并要求主服务器发送其在二进制日志中的更新记录。从属 I/O线程读取主Binlog Dump线程发送的更新 （请参阅上一项）并将它们复制到包含从属中继日志的本地文件。此线程的状态显示为 Slave_IO_running输出 SHOW SLAVE STATUS或 Slave_running输出中的状态SHOW STATUS。从属SQL线程 从属设备创建一个SQL线程来读取由从属 I/O 线程写入的中继日志，并执行其中包含的事件。当从属服务器从放的事件，追干上主服务器的事件后，从属服务器的 I/O 线程将会处于休眠状态，直到主服务器的事件有更新时，被主服务器发送的信号唤醒。在前面的描述中，每个主/从连接有三个线程。具有多个从站的主站为每个当前连接的从站创建一个二进制日志转储线程，每个从站都有自己的I / O和SQL线程。从站使用两个线程将读取更新与主站分开并将它们执行到独立任务中。因此，如果语句执行缓慢，则不会减慢读取语句的任务。例如，如果从服务器尚未运行一段时间，则当从服务器启动时，其I / O线程可以快速从主服务器获取所有二进制日志内容，即使SQL线程远远落后。如果从服务器在SQL线程执行了所有获取的语句之前停止，则I / O线程至少已获取所有内容，以便语句的安全副本本地存储在从属的中继日志中，准备在下次执行时执行奴隶开始。</code></pre><h3 id="配置Replication-gtid方式"><a href="#配置Replication-gtid方式" class="headerlink" title="配置Replication(gtid方式)"></a>配置Replication(gtid方式)</h3><p>基于事务的Replication，就是利用GTID来实现的复制</p><p>GTID（全局事务标示符）最初由google实现，在MySQL 5.6中引入.GTID在事务提交时生成，由UUID和事务ID组成.uuid会在第一次启动MySQL时生成，保存在数据目录下的auto .cnf文件里，事务ID则从1开始自增使用GTID的好处主要有两点：</p><ol><li>不再需要指定传统复制中的master_log_files和master_log_pos，使主从复制更简单可靠</li><li>可以实现基于库的多线程复制，减小主从复制的延迟</li></ol><p><strong>实验环境要求： 5.7.6 以上版本</strong></p><h5 id="主库配置"><a href="#主库配置" class="headerlink" title="主库配置"></a>主库配置</h5><pre><code>[mysqld]log-bin=/var/log/mysql/mysql-binserver-id=1gtid_mode=ONenforce_gtid_consistency=1   # 强制执行GTID一致性。</code></pre><p>重启服务</p><p>其他和之前的一样</p><ul><li>创建专属用户并授权</li><li>假如有数据导出数据</li></ul><pre><code>mysql&gt; CREATE USER &#39;repl&#39;@&#39;%&#39; IDENTIFIED BY &#39;123&#39;;mysql&gt; GRANT REPLICATION SLAVE ON *.* TO &#39;repl&#39;@&#39;%&#39;;mysql&gt; </code></pre><h5 id="从库配置"><a href="#从库配置" class="headerlink" title="从库配置"></a>从库配置</h5><p>测试用户有效性</p><pre><code>mysql -urepl -p&#39;123&#39; -hmysql-master1</code></pre><pre><code>[mysqld]server-id=2gtid_mode=ONenforce_gtid_consistency=1# 可选项, 把连接到 master 的信息存到数据库中的表中master-info-repository=TABLErelay-log-info-repository=TABLE</code></pre><p>重启服务</p><p>假如有数据，先导入数据</p><pre><code>mysql&gt; source dump.db</code></pre><p>Mysql 终端执行连接信息</p><pre><code>mysql&gt; CHANGE MASTER TOMASTER_HOST=&#39;172.16.153.10&#39;,MASTER_USER=&#39;repl&#39;,MASTER_PASSWORD=&#39;123&#39;,MASTER_AUTO_POSITION=1;&gt; start slave;</code></pre><h3 id="Replication故障排除"><a href="#Replication故障排除" class="headerlink" title="Replication故障排除"></a>Replication故障排除</h3><h4 id="开启-GTID-后的导出导入数据的注意点"><a href="#开启-GTID-后的导出导入数据的注意点" class="headerlink" title="开启 GTID 后的导出导入数据的注意点"></a>开启 GTID 后的导出导入数据的注意点</h4><blockquote><p>Warning: A partial dump from a server that has GTIDs will by default include the GTIDs of all transactions, even those that changed suppressed parts of the database. If you don’t want to restore GTIDs, pass –set-gtid-purged=OFF. To make a complete dump, pass –all-databases –triggers –routines –events</p></blockquote><p>意思是： 当前数据库实例中开启了 GTID 功能, 在开启有 GTID 功能的数据库实例中, 导出其中任何一个库, 如果没有显示地指定–set-gtid-purged参数, 都会提示这一行信息. 意思是默认情况下, 导出的库中含有 GTID 信息, 如果不想导出包含有 GTID 信息的数据库, 需要显示地添加–set-gtid-purged=OFF参数.</p><pre><code>mysqldump -uroot  -p  --set-gtid-purged=OFF   --all-databases &gt; alldb.db</code></pre><p>导入数据是就可以相往常一样导入了。</p><h4 id="UUID一致，导致主从复制I-O线程不是yes"><a href="#UUID一致，导致主从复制I-O线程不是yes" class="headerlink" title="UUID一致，导致主从复制I/O线程不是yes"></a>UUID一致，导致主从复制I/O线程不是yes</h4><blockquote><p>Fatal error: The slave I/O thread stops because master and slave have equal MySQL server UUIDs; these UUIDs must be different for replication to work</p></blockquote><p>致命错误：由于master和slave具有相同的mysql服务器uuid，从I/O线程将停止；这些uuid必须不同才能使复制工作。</p><p>问题提示主从使用了相同的server UUID，一个个的检查：</p><p>检查主从server_id</p><p>主库：</p><p>mysql&gt;  show variables like ‘server_id’;<br>+—————+——-+<br>| Variable_name | Value |<br>+—————+——-+<br>| server_id     | 1     |<br>+—————+——-+<br>1 row in set (0.01 sec)</p><p>从库：</p><p>mysql&gt;  show variables like ‘server_id’;<br>+—————+——-+<br>| Variable_name | Value |<br>+—————+——-+<br>| server_id     | 2     |<br>+—————+——-+<br>1 row in set (0.01 sec)</p><p>server_id不一样，排除。</p><p>检查主从状态：</p><p>主库：</p><p>mysql&gt; show master status;<br>+——————+———-+————–+——————+——————-+<br>| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |<br>+——————+———-+————–+——————+——————-+<br>| mysql-bin.000001 |      154 |              |                  |                   |<br>+——————+———-+————–+——————+——————-+<br>1 row in set (0.00 sec)<br>从库：</p><p>mysql&gt; show master status;<br>+——————+———-+————–+——————+——————-+<br>| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |<br>+——————+———-+————–+——————+——————-+<br>| mysql-bin.000001 |      306 |              |                  |                   |<br>+——————+———-+————–+——————+——————-+<br>1 row in set (0.00 sec)</p><p>File一样，排除。</p><p>最后检查发现他们的auto.cnf中的server-uuid是一样的。。。</p><p>[root@localhost ~]# vim /var/lib/mysql/auto.cnf</p><p>[auto]</p><p>server-uuid=4f37a731-9b79-11e8-8013-000c29f0700f</p><p>修改uuid并重启服务</p><h3 id="数据库中间MyCAT读写分离实现-重要！！！"><a href="#数据库中间MyCAT读写分离实现-重要！！！" class="headerlink" title="数据库中间MyCAT读写分离实现 (重要！！！)"></a>数据库中间MyCAT读写分离实现 (重要！！！)</h3><p>Mycat 是一个开源的分布式数据库系统，但是由于真正的数据库需要存储引擎，而 Mycat 并没有存 储引擎，所以并不是完全意义的分布式数据库系统。 那么 Mycat 是什么？Mycat 是数据库中间件，就是介于数据库与应用之间，进行数据处理与交互的中间服 务。</p><p><img src="https://i.loli.net/2019/08/12/ZXJxhqTER2UFak5.jpg" alt=""></p><p>MyCAT 是使用 JAVA 语言进行编写开发，使用前需要先安装 JAVA 运行环境(JRE),由于 MyCAT 中使用了 JDK7 中的一些特性，所以要求必须在 JDK7 以上的版本上运行。</p><h4 id="部署环境"><a href="#部署环境" class="headerlink" title="部署环境"></a>部署环境</h4><p>1下载JDK</p><pre><code>[root@mycat ~]# wget --no-cookies \--no-check-certificate \--header \&quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; \http://download.oracle.com/otn-pub/java/jdk/8u181-\b13/96a7b8442fe848ef90c96a2fad6ed6d1/jdk-8u181-linux-\x64.tar.gz// --no-check-certificate 表示不校验SSL证书，因为中间的两个302会访问https，会涉及到证书的问题，不校验能快一点，影响不大.</code></pre><p>2.解压文件</p><pre><code>[root@mycat ~]# tar -xf jdk-8u181-linux-x64.tar.gz   -C  /usr/local/[root@mycat ~]# ln -s /usr/local/jdk1.8.0_181/ /usr/local/java</code></pre><p>3.配置环境变量</p><pre><code>[root@mycat ~]# vim /etc/profile.d/java.shexport JAVA_HOME=/usr/local/javaexport PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar使环境变量生效[root@mycat ~]# source /etc/profile.d/java.sh</code></pre><h4 id="部署Mycat"><a href="#部署Mycat" class="headerlink" title="部署Mycat"></a>部署Mycat</h4><p><img src="https://i.loli.net/2019/08/12/zlZOf4dv95xPkS1.jpg" alt=""></p><pre><code>下载[root@mycat ~]# wget http://dl.mycat.io/1.6.5/Mycat-server-1.6.5-release-20180122220033-linux.tar.gz解压[root@mycat ~]# tar xf Mycat-server-1.6.5-release-20180122220033-linux.tar.gz -C /usr/local/</code></pre><h5 id="配置Mycat"><a href="#配置Mycat" class="headerlink" title="配置Mycat"></a>配置Mycat</h5><p>认识配置文件</p><p>MyCAT 目前主要通过配置文件的方式来定义逻辑库和相关配置:</p><p>/usr/local/mycat/conf/server.xml             定义用户以及系统相关变量，如端口等。其中用户信息是前端应用程序连接 mycat 的用户信息。</p><p>/usr/local/mycat/conf/schema.xml       定义逻辑库，表、分片节点等内容。</p><h5 id="配置-server-xml"><a href="#配置-server-xml" class="headerlink" title="配置 server.xml"></a>配置 server.xml</h5><p>以下为代码片段</p><p>下面的用户和密码是应用程序连接到 MyCat 使用的，可以自定义配置</p><p>而其中的schemas 配置项所对应的值是逻辑数据库的名字，也可以自定义，但是这个名字需要和后面 schema.xml 文件中配置的一致。</p><pre><code>vim server.xml&lt;!--下面的用户和密码是应用程序连接到 MyCat 使用的.schemas 配置项所对应的值是逻辑数据库的名字,这个名字需要和后面 schema.xml 文件中配置的一致。--&gt;       &lt;user name=&quot;mycatdb&quot; defaultAccount=&quot;true&quot;&gt;                &lt;property name=&quot;password&quot;&gt;1&lt;/property&gt;                &lt;property name=&quot;schemas&quot;&gt;mycat_db&lt;/property&gt;                &lt;!-- 表级 DML 权限设置 --&gt;                &lt;!--                            &lt;privileges check=&quot;false&quot;&gt;                        &lt;schema name=&quot;TESTDB&quot; dml=&quot;0110&quot; &gt;                                &lt;table name=&quot;tb01&quot; dml=&quot;0000&quot;&gt;&lt;/table&gt;                                &lt;table name=&quot;tb02&quot; dml=&quot;1111&quot;&gt;&lt;/table&gt;                        &lt;/schema&gt;                &lt;/privileges&gt;                            --&gt;        &lt;/user&gt;&lt;!--下面是另一个用户，并且设置的访问 TESTED 逻辑数据库的权限是 只读        &lt;user name=&quot;mycatuser&quot;&gt;                &lt;property name=&quot;password&quot;&gt;123&lt;/property&gt;                &lt;property name=&quot;schemas&quot;&gt;mycat_db&lt;/property&gt;                &lt;property name=&quot;readOnly&quot;&gt;true&lt;/property&gt;        &lt;/user&gt;--&gt;&lt;/mycat:server&gt;</code></pre><p>== 上面的配置中，假如配置了用户访问的逻辑库，那么必须在 <code>schema.xml</code> 文件中也配置这个逻辑库，否则报错，启动 mycat 失败 ==</p><h5 id="配置schema-xml"><a href="#配置schema-xml" class="headerlink" title="配置schema.xml"></a>配置schema.xml</h5><p>以下是配置文件中的每个部分的配置块儿</p><p><strong>逻辑库和分表设置</strong></p><pre><code>&lt;schema name=&quot;mycat_db&quot;           // 逻辑库名称,与server.xml的一致        checkSQLschema=&quot;false&quot;    // 不检查        sqlMaxLimit=&quot;100&quot;         // 最大连接数        dataNode=&quot;tiger1&quot;&gt;        //  数据节点名称&lt;!--这里定义的是分表的信息--&gt;        &lt;/schema&gt;</code></pre><p><strong>数据节点</strong></p><pre><code>&lt;dataNode name=&quot;tiger1&quot;             // 此数据节点的名称          dataHost=&quot;localhost1&quot;     // 主机组          database=&quot;mycat_test&quot; /&gt;  // 真实的数据库名称</code></pre><p><strong>主机组</strong></p><pre><code>&lt;dataHost name=&quot;localhost1&quot;                       // 主机组          maxCon=&quot;1000&quot; minCon=&quot;10&quot;               // 连接          balance=&quot;0&quot;                             // 负载均衡          writeType=&quot;0&quot;                           // 写模式配置          dbType=&quot;mysql&quot; dbDriver=&quot;native&quot;        // 数据库配置          switchType=&quot;1&quot;  slaveThreshold=&quot;100&quot;&gt;&lt;!--这里可以配置关于这个主机组的成员信息，和针对这些主机的健康检查语句--&gt;&lt;/dataHost&gt;</code></pre><pre><code>balance 属性负载均衡类型,目前的取值有 3 种:1. balance=&quot;0&quot;, 不开启读写分离机制,所有读操作都发送到当前可用的 writeHost 上。2. balance=&quot;1&quot;, 全部的 readHost 与 stand by writeHost 参与 select 语句的负载均衡,简单的说,当双主双从模式(M1-&gt;S1,M2-&gt;S2,并且 M1 与 M2     互为主备),正常情况下,M2,S1,S2 都参与 select 语句的负载均衡。4. balance=&quot;2&quot;, 所有读操作都随机的在 writeHost、readhost 上分发。5. balance=&quot;3&quot;, 所有读请求随机的分发到 wiriterHost 对应的 readhost 执行,writerHost 不负担读压力,注意 balance=3 只在 1.4 及其以后版本有,1.3 没有。writeType 属性负载均衡类型,目前的取值有 3 种:1. writeType=&quot;0&quot;, 所有写操作发送到配置的第一个 writeHost,第一个挂了切到还生存的第二个writeHost,重新启动后已切换后的为准.2. writeType=&quot;1&quot;,所有写操作都随机的发送到配置的 writeHost,1.5 以后废弃不推荐。</code></pre><p><strong>健康检查</strong></p><pre><code>&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;</code></pre><p><strong>读写配置</strong></p><pre><code>&lt;writeHost host=&quot;hostM1&quot; url=&quot;192.168.19.176:3306&quot; user=&quot;root&quot; password=&quot;1&quot;&gt;                        &lt;!-- can have multi read hosts --&gt;       &lt;readHost host=&quot;hostS2&quot; url=&quot;192.168.19.177:3306&quot; user=&quot;root&quot; password=&quot;1&quot; /&gt;&lt;/writeHost&gt;</code></pre><p>以下是组合为完整的配置文件，适用于一主一从的架构</p><pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt;  &lt;schema name=&quot;mycat_db&quot;         checkSQLschema=&quot;false&quot;         sqlMaxLimit=&quot;100&quot;         dataNode=&quot;tiger1&quot;&gt;    &lt;!--这里定义的是分库分表的信息--&gt;        &lt;/schema&gt;  &lt;dataNode name=&quot;tiger1&quot;           dataHost=&quot;localhost1&quot; database=&quot;mycat_test&quot; /&gt;  &lt;dataHost name=&quot;localhost1&quot;             maxCon=&quot;1000&quot; minCon=&quot;10&quot;             balance=&quot;0&quot;            writeType=&quot;0&quot;             dbType=&quot;mysql&quot; dbDriver=&quot;native&quot;             switchType=&quot;1&quot;  slaveThreshold=&quot;100&quot;&gt;   &lt;heartbeat&gt;select user()&lt;/heartbeat&gt;       &lt;!-- can have multi write hosts --&gt;   &lt;writeHost host=&quot;hostM1&quot; url=&quot;192.168.19.176:3306&quot;               user=&quot;root&quot;  password=&quot;1&quot;&gt;      &lt;!-- can have multi read hosts --&gt;      &lt;readHost host=&quot;hostS2&quot; url=&quot;192.168.19.177:3306&quot;                 user=&quot;root&quot; password=&quot;1&quot; /&gt;     &lt;/writeHost&gt;   &lt;/dataHost&gt;&lt;/mycat:schema&gt;</code></pre><h4 id="启动-mycat"><a href="#启动-mycat" class="headerlink" title="启动 mycat"></a>启动 mycat</h4><pre><code>[root@mycat ~]# /usr/local/mycat/bin/mycat  start支持一下参数start | restart |stop | status</code></pre><h4 id="在真实的-master-数据库上给用户授权"><a href="#在真实的-master-数据库上给用户授权" class="headerlink" title="在真实的 master 数据库上给用户授权"></a>在真实的 master 数据库上给用户授权</h4><pre><code>mysql&gt; grant all on mycat_test.* to root@&#39;%&#39; identified by &#39;1&#39;;mysql&gt; flush privileges;</code></pre><h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><p>在 mycat 的机器上测试用户权限有效性</p><p>测试是否能正常登录上 主服务器</p><pre><code>mysql -uroot -p&#39;123&#39; -h192.168.19.176</code></pre><p>继续测试是否能登录上从服务器</p><pre><code>mysql -uroot -p&#39;123&#39; -h192.168.19.177</code></pre><p>通过客户端进行测试是否能登录到 mycat 上</p><p>192.168.19.178 是 mycat 的主机地址</p><p>注意端口号是 <code>8066</code></p><pre><code>[root@mysqlclient ~]# mysql -umycatdb -p1 -h192.168.19.178 -P8066MySQL [(none)]&gt; show databases;+----------+| DATABASE |+----------+| mycat_db |+----------+1 row in set (0.00 sec)</code></pre><p>继续测试读写分离策略</p><p>使用  <code>mysql</code> 客户端工具使用  <code>mycat</code> 的账户和密码登录 <code>mycat</code> ,<br> 之后执行 <code>select</code> 语句。</p><p>之后查询 <code>mycat</code> 主机上 <code>mycat</code> 安装目录下的 <code>logs/mycat.log</code> 日志。</p><p>在日志重搜索查询的语句或者查询 从库的 ip 地址，应该能搜索到</p>]]></content>
      
      
      <categories>
          
          <category> SQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
            <tag> Mycat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql-游标</title>
      <link href="2020/07/16/sql/mysql-you-biao/"/>
      <url>2020/07/16/sql/mysql-you-biao/</url>
      
        <content type="html"><![CDATA[<h5 id="mysql游标的用法及作用"><a href="#mysql游标的用法及作用" class="headerlink" title="[mysql游标的用法及作用]"></a>[mysql游标的用法及作用]</h5><p>例子：</p><p>当前有三张表A、B、C其中A和B是一对多关系，B和C是一对多关系，现在需要将B中A表的主键存到C中；<br>常规思路就是将B中查询出来然后通过一个update语句来更新C表就可以了，但是B表中有2000多条数据，<br>难道要执行2000多次？显然是不现实的；最终找到写一个存储过程然后通过循环来更新C表，<br>然而存储过程中的写法用的就是游标的形式。</p><h5 id="【简介】"><a href="#【简介】" class="headerlink" title="【简介】"></a>【简介】</h5><p>​    游标实际上是一种能从包括多条数据记录的结果集中每次提取一条记录的机制。</p><p>​    游标充当指针的作用。</p><p>​    尽管游标能遍历结果中的所有行，但他一次只指向一行。</p><p>​    游标的作用就是用于对查询数据库所返回的记录进行遍历，以便进行相应的操作。</p><h5 id="【用法】"><a href="#【用法】" class="headerlink" title="【用法】"></a>【用法】</h5><p>​    一、声明一个游标: declare 游标名称 CURSOR for table;(这里的table可以是你查询出来的任意集合)<br>​    二、打开定义的游标:open 游标名称;<br>​    三、获得下一行数据:FETCH  游标名称 into testrangeid,versionid;<br>​    四、需要执行的语句(增删改查):这里视具体情况而定<br>​    五、释放游标:CLOSE 游标名称;<br>  注:mysql存储过程每一句后面必须用;结尾，使用的临时字段需要在定义游标之前进行声明。</p><h5 id="【实例】"><a href="#【实例】" class="headerlink" title="【实例】"></a>【实例】</h5><pre class=" language-sql"><code class="language-sql"><span class="token operator">-</span>  <span class="token keyword">BEGIN</span>  <span class="token comment" spellcheck="true">--定义变量  </span><span class="token keyword">declare</span> testrangeid <span class="token keyword">BIGINT</span><span class="token punctuation">;</span>  <span class="token keyword">declare</span> versionid <span class="token keyword">BIGINT</span><span class="token punctuation">;</span>   <span class="token keyword">declare</span> done <span class="token keyword">int</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">--创建游标，并存储数据  </span><span class="token keyword">declare</span> cur_test <span class="token keyword">CURSOR</span> <span class="token keyword">for</span>      <span class="token keyword">select</span> id <span class="token keyword">as</span> testrangeid<span class="token punctuation">,</span>version_id <span class="token keyword">as</span> versionid <span class="token keyword">from</span> tp_testrange<span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">--游标中的内容执行完后将done设置为1  </span> <span class="token keyword">DECLARE</span> <span class="token keyword">CONTINUE</span> <span class="token keyword">HANDLER</span> <span class="token keyword">FOR</span> <span class="token operator">NOT</span> FOUND <span class="token keyword">SET</span> done<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">;</span>   <span class="token comment" spellcheck="true">--打开游标  </span><span class="token keyword">open</span> cur_test<span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">--执行循环  </span>  posLoop:LOOP  <span class="token comment" spellcheck="true">--判断是否结束循环  </span>        <span class="token keyword">IF</span> done<span class="token operator">=</span><span class="token number">1</span> <span class="token keyword">THEN</span>          LEAVE posLoop<span class="token punctuation">;</span>      <span class="token keyword">END</span> <span class="token keyword">IF</span><span class="token punctuation">;</span>   <span class="token comment" spellcheck="true">--取游标中的值  </span>    <span class="token keyword">FETCH</span>  cur_test <span class="token keyword">into</span> testrangeid<span class="token punctuation">,</span>versionid<span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">--执行更新操作  </span>    <span class="token keyword">update</span> tp_data_execute <span class="token keyword">set</span> version_id<span class="token operator">=</span>versionid <span class="token keyword">where</span> testrange_id <span class="token operator">=</span> testrangeid<span class="token punctuation">;</span>    <span class="token keyword">END</span> LOOP posLoop<span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">--释放游标  </span><span class="token keyword">CLOSE</span> cur_test<span class="token punctuation">;</span>  <span class="token keyword">END</span>  <span class="token operator">-</span>  </code></pre><p> 例子2：</p><p>我们现在要用存储过程做一个功能，统计iphone的总库存是多少，并把总数输出到控制台。</p><pre class=" language-sql"><code class="language-sql"><span class="token comment" spellcheck="true">--在windows系统中写存储过程时，如果需要使用declare声明变量，需要添加这个关键字，否则会报错。  </span><span class="token keyword">delimiter</span> <span class="token comment" spellcheck="true">//  </span><span class="token keyword">drop</span> <span class="token keyword">procedure</span> <span class="token keyword">if</span> <span class="token keyword">exists</span> StatisticStore<span class="token punctuation">;</span>  <span class="token keyword">CREATE</span> <span class="token keyword">PROCEDURE</span> StatisticStore<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token keyword">BEGIN</span>      <span class="token comment" spellcheck="true">--创建接收游标数据的变量  </span>    <span class="token keyword">declare</span> <span class="token number">c</span> <span class="token keyword">int</span><span class="token punctuation">;</span>      <span class="token keyword">declare</span> n <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token comment" spellcheck="true">--创建总数变量  </span>    <span class="token keyword">declare</span> total <span class="token keyword">int</span> <span class="token keyword">default</span> <span class="token number">0</span><span class="token punctuation">;</span>      <span class="token comment" spellcheck="true">--创建结束标志变量  </span>    <span class="token keyword">declare</span> done <span class="token keyword">int</span> <span class="token keyword">default</span> <span class="token boolean">false</span><span class="token punctuation">;</span>      <span class="token comment" spellcheck="true">--创建游标  </span>    <span class="token keyword">declare</span> cur <span class="token keyword">cursor</span> <span class="token keyword">for</span> <span class="token keyword">select</span> name<span class="token punctuation">,</span>count <span class="token keyword">from</span> store <span class="token keyword">where</span> name <span class="token operator">=</span> <span class="token string">'iphone'</span><span class="token punctuation">;</span>      <span class="token comment" spellcheck="true">--指定游标循环结束时的返回值  </span>    <span class="token keyword">declare</span> <span class="token keyword">continue</span> <span class="token keyword">HANDLER</span> <span class="token keyword">for</span> <span class="token operator">not</span> found <span class="token keyword">set</span> done <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>      <span class="token comment" spellcheck="true">--设置初始值  </span>    <span class="token keyword">set</span> total <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>      <span class="token comment" spellcheck="true">--打开游标  </span>    <span class="token keyword">open</span> cur<span class="token punctuation">;</span>      <span class="token comment" spellcheck="true">--开始循环游标里的数据  </span>    read_loop:loop      <span class="token comment" spellcheck="true">--根据游标当前指向的一条数据  </span>    <span class="token keyword">fetch</span> cur <span class="token keyword">into</span> n<span class="token punctuation">,</span><span class="token number">c</span><span class="token punctuation">;</span>      <span class="token comment" spellcheck="true">--判断游标的循环是否结束  </span>    <span class="token keyword">if</span> done <span class="token keyword">then</span>          leave read_loop<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">--跳出游标循环  </span>    <span class="token keyword">end</span> <span class="token keyword">if</span><span class="token punctuation">;</span>      <span class="token comment" spellcheck="true">--获取一条数据时，将count值进行累加操作，这里可以做任意你想做的操作，  </span>    <span class="token keyword">set</span> total <span class="token operator">=</span> total <span class="token operator">+</span> <span class="token number">c</span><span class="token punctuation">;</span>      <span class="token comment" spellcheck="true">--结束游标循环  </span>    <span class="token keyword">end</span> loop<span class="token punctuation">;</span>      <span class="token comment" spellcheck="true">--关闭游标  </span>    <span class="token keyword">close</span> cur<span class="token punctuation">;</span>      <span class="token comment" spellcheck="true">--输出结果  </span>    <span class="token keyword">select</span> total<span class="token punctuation">;</span>  <span class="token keyword">END</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">--调用存储过程  </span><span class="token keyword">call</span> StatisticStore<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  </code></pre><p> fetch是获取游标当前指向的数据行，并将指针指向下一行，当游标已经指向最后一行时继续执行会造成游标溢出。<br>使用loop循环游标时，他本身是不会监控是否到最后一条数据了，像下面代码这种写法，就会造成死循环；</p><pre class=" language-sql"><code class="language-sql">read_loop:loop  <span class="token keyword">fetch</span> cur <span class="token keyword">into</span> n<span class="token punctuation">,</span><span class="token number">c</span><span class="token punctuation">;</span>  <span class="token keyword">set</span> total <span class="token operator">=</span> total<span class="token operator">+</span><span class="token number">c</span><span class="token punctuation">;</span>  <span class="token keyword">end</span> loop<span class="token punctuation">;</span>  </code></pre><p>在MySql中，造成游标溢出时会引发mysql预定义的NOT FOUND错误，所以在上面使用下面的代码指定了当引发not found错误时定义一个continue 的事件，指定这个事件发生时修改done变量的值。</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">declare</span> <span class="token keyword">continue</span> <span class="token keyword">HANDLER</span> <span class="token keyword">for</span> <span class="token operator">not</span> found <span class="token keyword">set</span> done <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>  </code></pre><p>所以在循环时加上了下面这句代码：</p><pre class=" language-sql"><code class="language-sql"><span class="token comment" spellcheck="true">--判断游标的循环是否结束  </span><span class="token keyword">if</span> done <span class="token keyword">then</span>      leave read_loop<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">--跳出游标循环  </span><span class="token keyword">end</span> <span class="token keyword">if</span><span class="token punctuation">;</span>  </code></pre><p>如果done的值是true，就结束循环。继续执行下面的代码</p><p>使用方式</p><p>游标有三种使用方式：<br>第一种就是上面的实现，使用loop循环；<br>第二种方式如下，使用while循环：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">drop</span> <span class="token keyword">procedure</span> <span class="token keyword">if</span> <span class="token keyword">exists</span> StatisticStore1<span class="token punctuation">;</span>  <span class="token keyword">CREATE</span> <span class="token keyword">PROCEDURE</span> StatisticStore1<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token keyword">BEGIN</span>      <span class="token keyword">declare</span> <span class="token number">c</span> <span class="token keyword">int</span><span class="token punctuation">;</span>      <span class="token keyword">declare</span> n <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token keyword">declare</span> total <span class="token keyword">int</span> <span class="token keyword">default</span> <span class="token number">0</span><span class="token punctuation">;</span>      <span class="token keyword">declare</span> done <span class="token keyword">int</span> <span class="token keyword">default</span> <span class="token boolean">false</span><span class="token punctuation">;</span>      <span class="token keyword">declare</span> cur <span class="token keyword">cursor</span> <span class="token keyword">for</span> <span class="token keyword">select</span> name<span class="token punctuation">,</span>count <span class="token keyword">from</span> store <span class="token keyword">where</span> name <span class="token operator">=</span> <span class="token string">'iphone'</span><span class="token punctuation">;</span>      <span class="token keyword">declare</span> <span class="token keyword">continue</span> <span class="token keyword">HANDLER</span> <span class="token keyword">for</span> <span class="token operator">not</span> found <span class="token keyword">set</span> done <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>      <span class="token keyword">set</span> total <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>      <span class="token keyword">open</span> cur<span class="token punctuation">;</span>      <span class="token keyword">fetch</span> cur <span class="token keyword">into</span> n<span class="token punctuation">,</span><span class="token number">c</span><span class="token punctuation">;</span>      <span class="token keyword">while</span><span class="token punctuation">(</span><span class="token operator">not</span> done<span class="token punctuation">)</span> <span class="token keyword">do</span>          <span class="token keyword">set</span> total <span class="token operator">=</span> total <span class="token operator">+</span> <span class="token number">c</span><span class="token punctuation">;</span>          <span class="token keyword">fetch</span> cur <span class="token keyword">into</span> n<span class="token punctuation">,</span><span class="token number">c</span><span class="token punctuation">;</span>      <span class="token keyword">end</span> <span class="token keyword">while</span><span class="token punctuation">;</span>      <span class="token keyword">close</span> cur<span class="token punctuation">;</span>      <span class="token keyword">select</span> total<span class="token punctuation">;</span>  <span class="token keyword">END</span><span class="token punctuation">;</span>  <span class="token keyword">call</span> StatisticStore1<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  </code></pre><p>第三种方式是使用repeat执行：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">drop</span> <span class="token keyword">procedure</span> <span class="token keyword">if</span> <span class="token keyword">exists</span> StatisticStore2<span class="token punctuation">;</span>  <span class="token keyword">CREATE</span> <span class="token keyword">PROCEDURE</span> StatisticStore2<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token keyword">BEGIN</span>      <span class="token keyword">declare</span> <span class="token number">c</span> <span class="token keyword">int</span><span class="token punctuation">;</span>      <span class="token keyword">declare</span> n <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token keyword">declare</span> total <span class="token keyword">int</span> <span class="token keyword">default</span> <span class="token number">0</span><span class="token punctuation">;</span>      <span class="token keyword">declare</span> done <span class="token keyword">int</span> <span class="token keyword">default</span> <span class="token boolean">false</span><span class="token punctuation">;</span>      <span class="token keyword">declare</span> cur <span class="token keyword">cursor</span> <span class="token keyword">for</span> <span class="token keyword">select</span> name<span class="token punctuation">,</span>count <span class="token keyword">from</span> store <span class="token keyword">where</span> name <span class="token operator">=</span> <span class="token string">'iphone'</span><span class="token punctuation">;</span>      <span class="token keyword">declare</span> <span class="token keyword">continue</span> <span class="token keyword">HANDLER</span> <span class="token keyword">for</span> <span class="token operator">not</span> found <span class="token keyword">set</span> done <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>      <span class="token keyword">set</span> total <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>      <span class="token keyword">open</span> cur<span class="token punctuation">;</span>      repeat      <span class="token keyword">fetch</span> cur <span class="token keyword">into</span> n<span class="token punctuation">,</span><span class="token number">c</span><span class="token punctuation">;</span>      <span class="token keyword">if</span> <span class="token operator">not</span> done <span class="token keyword">then</span>          <span class="token keyword">set</span> total <span class="token operator">=</span> total <span class="token operator">+</span> <span class="token number">c</span><span class="token punctuation">;</span>      <span class="token keyword">end</span> <span class="token keyword">if</span><span class="token punctuation">;</span>      until done <span class="token keyword">end</span> repeat<span class="token punctuation">;</span>      <span class="token keyword">close</span> cur<span class="token punctuation">;</span>      <span class="token keyword">select</span> total<span class="token punctuation">;</span>  <span class="token keyword">END</span><span class="token punctuation">;</span>  <span class="token keyword">call</span> StatisticStore2<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h5 id="游标嵌套"><a href="#游标嵌套" class="headerlink" title="游标嵌套"></a>游标嵌套</h5><p>在mysql中，每个begin end 块都是一个独立的scope区域，由于MySql中同一个error的事件只能定义一次，如果多定义的话在编译时会提示Duplicate handler declared in the same block。</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">drop</span> <span class="token keyword">procedure</span> <span class="token keyword">if</span> <span class="token keyword">exists</span> StatisticStore3<span class="token punctuation">;</span>  <span class="token keyword">CREATE</span> <span class="token keyword">PROCEDURE</span> StatisticStore3<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token keyword">BEGIN</span>      <span class="token keyword">declare</span> _n <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token keyword">declare</span> done <span class="token keyword">int</span> <span class="token keyword">default</span> <span class="token boolean">false</span><span class="token punctuation">;</span>      <span class="token keyword">declare</span> cur <span class="token keyword">cursor</span> <span class="token keyword">for</span> <span class="token keyword">select</span> name <span class="token keyword">from</span> store <span class="token keyword">group</span> <span class="token keyword">by</span> name<span class="token punctuation">;</span>      <span class="token keyword">declare</span> <span class="token keyword">continue</span> <span class="token keyword">HANDLER</span> <span class="token keyword">for</span> <span class="token operator">not</span> found <span class="token keyword">set</span> done <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>      <span class="token keyword">open</span> cur<span class="token punctuation">;</span>      read_loop:loop      <span class="token keyword">fetch</span> cur <span class="token keyword">into</span> _n<span class="token punctuation">;</span>      <span class="token keyword">if</span> done <span class="token keyword">then</span>          leave read_loop<span class="token punctuation">;</span>      <span class="token keyword">end</span> <span class="token keyword">if</span><span class="token punctuation">;</span>      <span class="token keyword">begin</span>          <span class="token keyword">declare</span> <span class="token number">c</span> <span class="token keyword">int</span><span class="token punctuation">;</span>          <span class="token keyword">declare</span> n <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>          <span class="token keyword">declare</span> total <span class="token keyword">int</span> <span class="token keyword">default</span> <span class="token number">0</span><span class="token punctuation">;</span>          <span class="token keyword">declare</span> done <span class="token keyword">int</span> <span class="token keyword">default</span> <span class="token boolean">false</span><span class="token punctuation">;</span>          <span class="token keyword">declare</span> cur <span class="token keyword">cursor</span> <span class="token keyword">for</span> <span class="token keyword">select</span> name<span class="token punctuation">,</span>count <span class="token keyword">from</span> store <span class="token keyword">where</span> name <span class="token operator">=</span> <span class="token string">'iphone'</span><span class="token punctuation">;</span>          <span class="token keyword">declare</span> <span class="token keyword">continue</span> <span class="token keyword">HANDLER</span> <span class="token keyword">for</span> <span class="token operator">not</span> found <span class="token keyword">set</span> done <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>          <span class="token keyword">set</span> total <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>          <span class="token keyword">open</span> cur<span class="token punctuation">;</span>          iphone_loop:loop          <span class="token keyword">fetch</span> cur <span class="token keyword">into</span> n<span class="token punctuation">,</span><span class="token number">c</span><span class="token punctuation">;</span>          <span class="token keyword">if</span> done <span class="token keyword">then</span>              leave iphone_loop<span class="token punctuation">;</span>          <span class="token keyword">end</span> <span class="token keyword">if</span><span class="token punctuation">;</span>          <span class="token keyword">set</span> total <span class="token operator">=</span> total <span class="token operator">+</span> <span class="token number">c</span><span class="token punctuation">;</span>          <span class="token keyword">end</span> loop<span class="token punctuation">;</span>          <span class="token keyword">close</span> cur<span class="token punctuation">;</span>          <span class="token keyword">select</span> _n<span class="token punctuation">,</span>n<span class="token punctuation">,</span>total<span class="token punctuation">;</span>      <span class="token keyword">end</span><span class="token punctuation">;</span>      <span class="token keyword">begin</span>              <span class="token keyword">declare</span> <span class="token number">c</span> <span class="token keyword">int</span><span class="token punctuation">;</span>              <span class="token keyword">declare</span> n <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>              <span class="token keyword">declare</span> total <span class="token keyword">int</span> <span class="token keyword">default</span> <span class="token number">0</span><span class="token punctuation">;</span>              <span class="token keyword">declare</span> done <span class="token keyword">int</span> <span class="token keyword">default</span> <span class="token boolean">false</span><span class="token punctuation">;</span>              <span class="token keyword">declare</span> cur <span class="token keyword">cursor</span> <span class="token keyword">for</span> <span class="token keyword">select</span> name<span class="token punctuation">,</span>count <span class="token keyword">from</span> store <span class="token keyword">where</span> name <span class="token operator">=</span> <span class="token string">'android'</span><span class="token punctuation">;</span>              <span class="token keyword">declare</span> <span class="token keyword">continue</span> <span class="token keyword">HANDLER</span> <span class="token keyword">for</span> <span class="token operator">not</span> found <span class="token keyword">set</span> done <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>              <span class="token keyword">set</span> total <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>              <span class="token keyword">open</span> cur<span class="token punctuation">;</span>              android_loop:loop              <span class="token keyword">fetch</span> cur <span class="token keyword">into</span> n<span class="token punctuation">,</span><span class="token number">c</span><span class="token punctuation">;</span>              <span class="token keyword">if</span> done <span class="token keyword">then</span>                  leave android_loop<span class="token punctuation">;</span>              <span class="token keyword">end</span> <span class="token keyword">if</span><span class="token punctuation">;</span>              <span class="token keyword">set</span> total <span class="token operator">=</span> total <span class="token operator">+</span> <span class="token number">c</span><span class="token punctuation">;</span>              <span class="token keyword">end</span> loop<span class="token punctuation">;</span>              <span class="token keyword">close</span> cur<span class="token punctuation">;</span>          <span class="token keyword">select</span> _n<span class="token punctuation">,</span>n<span class="token punctuation">,</span>total<span class="token punctuation">;</span>      <span class="token keyword">end</span><span class="token punctuation">;</span>      <span class="token keyword">begin</span>      <span class="token keyword">end</span><span class="token punctuation">;</span>      <span class="token keyword">end</span> loop<span class="token punctuation">;</span>      <span class="token keyword">close</span> cur<span class="token punctuation">;</span>  <span class="token keyword">END</span><span class="token punctuation">;</span>  <span class="token keyword">call</span> StatisticStore3<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  </code></pre><p>上面就是实现一个嵌套循环，当然这个例子比较牵强。凑合看看就行。</p><h5 id="动态SQL"><a href="#动态SQL" class="headerlink" title="动态SQL"></a>动态SQL</h5><p>Mysql 支持动态SQL的功能</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> <span class="token variable">@sqlStr</span><span class="token operator">=</span><span class="token string">'select * from table where condition1 = ?'</span><span class="token punctuation">;</span>  prepare s1 <span class="token keyword">for</span> <span class="token variable">@sqlStr</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">--如果有多个参数用逗号分隔  </span><span class="token keyword">execute</span> s1 <span class="token keyword">using</span> <span class="token variable">@condition1</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">--手工释放，或者是 connection 关闭时， server 自动回收  </span><span class="token keyword">deallocate</span> prepare s1<span class="token punctuation">;</span>  </code></pre>]]></content>
      
      
      <categories>
          
          <category> SQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python-fabric</title>
      <link href="2020/05/31/devops/python-zhi-fabric-mo-kuai/"/>
      <url>2020/05/31/devops/python-zhi-fabric-mo-kuai/</url>
      
        <content type="html"><![CDATA[<h3 id="python-之-fabric-模块"><a href="#python-之-fabric-模块" class="headerlink" title="python 之 fabric 模块"></a>python 之 fabric 模块</h3><p>Fabric 是一个用 Python 开发的部署工具，最大特点是不用登录远程服务器，在本地运行远程命令，几行 Python 脚本就可以轻松部署。</p><pre><code># doc http://docs.fabfile.org/en/2.5/getting-started.html# pip install fabric -i http://mirrors.aliyun.com/pypi/simple/</code></pre><h5 id="G站部署脚本-参考-示范"><a href="#G站部署脚本-参考-示范" class="headerlink" title="G站部署脚本 参考 示范"></a>G站部署脚本 参考 示范</h5><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> fabric <span class="token keyword">import</span> Connection<span class="token punctuation">,</span> task<span class="token keyword">from</span> fabric<span class="token punctuation">.</span>api <span class="token keyword">import</span> env<span class="token punctuation">,</span>hosts<span class="token punctuation">,</span>run<span class="token punctuation">,</span>execute@task<span class="token keyword">def</span> <span class="token function">deploy</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">with</span> Connection<span class="token punctuation">(</span><span class="token string">'root@x.x.x.x'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> c<span class="token punctuation">:</span>        c<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">"rm -rf giligili"</span><span class="token punctuation">)</span>        c<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">"git clone https://github.com/bydmm/giligili.git"</span><span class="token punctuation">,</span> pty<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        c<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"docker-compose.yml"</span><span class="token punctuation">,</span> <span class="token string">"giligili/docker-compose.yml"</span><span class="token punctuation">)</span>        c<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">"cd giligili &amp;&amp; docker-compose build &amp;&amp; docker-compose rm -fsv &amp;&amp; docker-compose up --build -d"</span><span class="token punctuation">,</span> pty<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        c<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">"sleep 15 &amp;&amp; docker logs -f gili-api"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># doc http://docs.fabfile.org/en/2.5/getting-started.html</span><span class="token comment" spellcheck="true"># apt install python-pip</span><span class="token comment" spellcheck="true"># pip install fabric -i http://mirrors.aliyun.com/pypi/simple/</span><span class="token comment" spellcheck="true"># fab deploy</span></code></pre><p>以上定义了pack和deploy两个任务，如果我们用Fabric部署，只需简单地输入两条命令：</p><pre><code>$ fab pack$ fab deploy</code></pre><p>Fabric提供几个简单的API来完成所有的部署，最常用的是local()和run()，分别在本地和远程执行命令，put()可以把本地文件上传到远程，当需要在远程指定当前目录时，只需用with cd(‘/path/to/dir/‘):即可。</p><p>默认情况下，当命令执行失败时，Fabric会停止执行后续命令。有时，我们允许忽略失败的命令继续执行，比如run(‘rm /tmp/abc’)在文件不存在的时候有可能失败，这时可以用with settings(warn_only=True):执行命令，这样Fabric只会打出警告信息而不会中断执行。</p><p>Fabric是如何在远程执行命令的呢？其实Fabric所有操作都是基于SSH执行的，必要时它会提示输入口令，所以非常安全。更好的办法是在指定的部署服务器上用证书配置无密码的ssh连接。</p><p>如果是基于团队开发，可以让Fabric利用版本库自动检出代码，自动执行测试、打包、部署的任务。由于Fabric运行的命令都是基本的Linux命令，所以根本不需要用Fabric本身来扩展，会敲Linux命令就能用Fabric部署。</p><p>利用Fabric部署Python、Ruby、PHP这样的非编译型网站应用非常方便，而对于编译型的Java、C#等就麻烦了，编译本身就是一个极其复杂的大工程，需要依赖特定工具或者IDE，很难做到自动化。</p><h4 id="fab命令常用参数"><a href="#fab命令常用参数" class="headerlink" title="fab命令常用参数"></a><strong>fab命令常用参数</strong></h4><pre class=" language-shell"><code class="language-shell"># fab --help   查看帮助## 常用参数-l 显示定义好的任务函数名-f 指定fab入口文件，默认入口文件名为fabfile.py.. 即指定fabfile文件-g 指定网关（中转）设备，即HOST逗号分隔要操作的主机, 比如堡垒机环境，填写堡垒机IP即可.-H 指定目标主机，多台主机用‘,’号分隔-p 远程账号的密码，fab执行时默认使用root账户-P 以异步并行方式运行多主机任务，默认为串行运行-R 指定role（角色），以角色名区分不同业务组设备-t 设置设备连接超时时间（秒）-T 设置远程主机命令执行超时时间（秒）-w 当命令执行失败，发出警告，而非默认中止任务。</code></pre><pre class=" language-shell"><code class="language-shell">其他参数:--set=KEY=VALUE,...   逗号分隔，设置环境变量--shortlist       简短打印可用命令-c PATH         指定本地配置文件-D           不加载用户known_hosts文件-i PATH         指定私钥文件-k           不加载来自~/.``ssh``下的私钥文件--port=PORT       指定SSH连接端口-R ROLES        根据角色操作，逗号分隔-s SHELL        指定新shell，默认是``'/bin/bash -l -c'--show=LEVELS      以逗号分隔的输出--ssh-config-path=PATH SSH配置文件路径-T N          设置远程命令超时时间，单位秒-u USER         连接远程主机用户名-x HOSTS        以逗号分隔排除主机-z INT         并发进程数</code></pre><h4 id="fabfile全局属性-env对象"><a href="#fabfile全局属性-env对象" class="headerlink" title="fabfile全局属性 (env对象)"></a>fabfile全局属性 (env对象)</h4><p><img src="https://s1.ax1x.com/2020/05/31/t1Gv3F.png" alt="t1Gv3F.png"></p>]]></content>
      
      
      <categories>
          
          <category> DevOps </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计划任务及日志管理</title>
      <link href="2020/05/30/linux/ji-hua-ren-wu-ji-ri-zhi-guan-li/"/>
      <url>2020/05/30/linux/ji-hua-ren-wu-ji-ri-zhi-guan-li/</url>
      
        <content type="html"><![CDATA[<h4 id="循环调度执行cron"><a href="#循环调度执行cron" class="headerlink" title="循环调度执行cron"></a>循环调度执行cron</h4><h5 id="1-1简介cron"><a href="#1-1简介cron" class="headerlink" title="1.1简介cron"></a>1.1简介cron</h5><pre class=" language-reStructuredText"><code class="language-reStructuredText">    crond的概念和crontab是不可分割的。crontab是一个命令，常见于Unix和类Unix的操作系统之中，用于设置周期性被执行的指令。该命令从标准输入设备读取指令，并将其存放于“crontab”文件中，以供之后读取和执行</code></pre><h5 id="1-2认识crond进程"><a href="#1-2认识crond进程" class="headerlink" title="1.2认识crond进程"></a>1.2认识crond进程</h5><pre class=" language-shell"><code class="language-shell">[root@JX01 ~]# systemctl status crond● crond.service - Command Scheduler   Loaded: loaded (/usr/lib/systemd/system/crond.service; enabled; vendor preset: enabled)   Active: active (running) since 三 2018-08-01 07:03:23 CST; 17min ago Main PID: 671 (crond)   CGroup: /system.slice/crond.service           └─671 /usr/sbin/crond -n8月 01 07:03:23 JX01 systemd[1]: Started Command Scheduler.8月 01 07:03:23 JX01 systemd[1]: Starting Command Scheduler...8月 01 07:03:23 JX01 crond[671]: (CRON) INFO (RANDOM_DELAY will be scaled with factor 2% if used.)8月 01 07:03:23 JX01 crond[671]: (CRON) INFO (running with inotify support)[root@JX01 ~]#[root@JX01 ~]# ps aux | grep crondroot        671  0.0  0.0 126280  1668 ?        Ss   07:03   0:00 /usr/sbin/crond -nroot       1440  0.0  0.0 112720   980 pts/0    R+   07:21   0:00 grep --color=auto crond[root@JX01 ~]#</code></pre><h5 id="1-3创建计划任务"><a href="#1-3创建计划任务" class="headerlink" title="1.3创建计划任务"></a>1.3创建计划任务</h5><pre class=" language-shell"><code class="language-shell">#计划任务存储的位置[root@JX01 ~]# ls /var/spool/cron/root jack alice#管理计划任务的命令crontab:  -l     Displays the current crontab on standard output.  -r     Removes the current crontab.  -e     Edits  the current crontab using the editor specified.#计划任务书写的格式.---------------- minute (0 - 59)| .-------------- hour (0 - 23)| | .------------ day of month (1 - 31)| | | .---------- month (1 - 12) OR jan,feb,mar,apr ...| | | | .-------- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat| | | | |* * * * * command#计划任务案例00 02 * * *    ls        //每天2:00整00 02 1 * *    ls        //每月1号2:00整00 02 14 2 * ls        //每年2月14号2:00整00 02 * * 7 ls        //每周日2:00整00 02 * 6 5 ls        //每年6月的周五2:00整（特殊）00 02 14 * 7 ls        //每月14号2:00整 或者 每周日2:00整，这两个时间都执行00 02 14 2 7 ls        //每年2月14号2:00整 或者 每周日2:00整，这两个时间都执行00 02 * * * ls        //每天2:00整* 02 * * * ls        //每天2:00中的每一分钟* * * * * ls        //每分钟执行ls* * 14 2 * ls        //2月14号的每分钟 1440分钟*/5 * * * * ls        //每隔5分钟00 02 1,5,8 * * ls    //每月1,5,8号的2:00整00 02 1-8 * * ls    //每月1到8号的2:00整00 02 * 1-10 * ls#测试计划任务的执行效果1 编写执行脚本.vim /crontab.sh touch /root/`date +%F-%X`.txt2 编排任务计划[root@localhost ~]# crontab -e* * 1 1 * bash /crontab.sh3 修改日期时间为1月2日3点4分date 01020304修改时间为1点2分3秒date -s 01:02:034 监控当前目录watch -n 0.5 'ls /root/*.txt'5 测试目标* * * * 1    //每周1            每分钟会执行* * * 1 *    //1月每日          每分钟会执行* * * 1 1    //1月的周1         每分钟会执行* * 1 * *    //每月1日          每分钟会执行* * 1 * 1    //每月1日和每月周1 每分钟会执行* * 1 1 *    //1月1日           每分钟会执行* * 1 1 1    //1月1日和1月的周1 每分钟都会执行</code></pre><h4 id="日志管理"><a href="#日志管理" class="headerlink" title="日志管理"></a>日志管理</h4><pre><code>    日志：在现代社会里,为了维护自身系统资源的运行状况,计算机系统一般都会有相应的日志记录系统有关日常事件或者误操作警报的日期及时间戳信息。这些日志信息对计算机犯罪调查人员非常有用,但计算机日记是按正常工作状态记录的,所以冗余量很大,对查找与分析有用信息造成很大困难。#Linux系统中存在的日志都在哪里？/var/log/    # tail /var/log/messages             //系统主日志文件    # tail -20 /var/log/messages    # tail -f /var/log/messages         //动态查看日志文件的尾部    # tailf /var/log/secure                 //认证、安全    # tail /var/log/maillog                 //跟邮件postfix相关 prefix    # tail /var/log/cron                //crond、at进程产生的日志    # tail /var/log/dmesg                 //和系统启动相关    # tail /var/log/audit/audit.log        //系统审计日志    # tail /var/log/yum.log                 //yum    # tail /var/log/mysqld.log             //MySQL    # tail /var/log/xferlog             //和访问FTP服务器相关    # tail  /var/log/wtmp                 //当前登录的用户（命令：w）    # tail  /var/log/btmp                 //最近登录的用户（命令last）    # tail  /var/log/lastlog            //所有用户的登录情况（命令lastlog）#Linux系统是什么进程程序在管理日志？rsyslog</code></pre><pre class=" language-shell"><code class="language-shell">##rsyslogrsyslog：linux系统中管理日志的服务所产生的进程是: rsyslogd -nlinux中的配置文件:    linux中所有的服务或者工具,都是由配置文件驱动工作的;    Linux中的工具或服务都是遵循配置文件中的规则工作的;/etc/rsyslog.conf:    这个文件定义了系统中所有的服务或者工具,它们所产生的日志,根据特定的级别需要存储在特定的位置日志等级:    等级由低到高：debug<info<warn<Error<Fatal系统或服务的排错:    根据配置文件的对错有一下两种方案供给选择:        1. 查看rsyslog的 journalctl -xe 找出服务或系统的报错信息        2. 根据服务自身的检测机制,去检查配置文件的语法        3. 系统常用排错指令 journalctl -xe\\ systemctl status service.name\\ 服务自带检测工具bash -nx    检测shell脚本的语法问题httpd -t    检测apache web服务的配置文件语法问题nginx -t    检测nginx web服务的配置文件语法问题[root@JX02 ~]# vim /etc/rsyslog.conf#### RULES ##### Log all kernel messages to the console.# Logging much else clutters up the screen.#kern.*                                                 /dev/console# Log anything (except mail) of level info or higher.# Don't log private authentication messages!*.info;mail.none;authpriv.none;cron.none                /var/log/messages# The authpriv file has restricted access.authpriv.*                                              /var/log/secure# Log all the mail messages in one place.mail.*                                                  -/var/log/maillog# Log cron stuffcron.*                                                  /var/log/cron# Everybody gets emergency messages*.emerg                                                 :omusrmsg:*# Save news errors of level crit and higher in a special file.uucp,news.crit                                          /var/log/spooler# Save boot messages also to boot.loglocal7.*                                                /var/log/boot.log</code></pre><pre class=" language-shell"><code class="language-shell">##logrotate#认识一下logrotate为了节省空间和整理方便，日志文件经常需要按！时间或！大小等维度分成多份，删除时间久远的日志文件。这就是通常说的日志滚动(log rotation)logrotate本身不是系统守护进程，它是通过计划任务crond每天执行#logrotate配置文件：主文件：/etc/logrotate.conf (决定每个日志文件如何轮转)子文件夹：/etc/logrotate.d/*#认识logrotate的选项含义==================全局设置==================weekly                              //轮转周期，一周轮转rotate 4                            //保留4份create                              //轮转后创建新文件dateext                             //使用日期作为后缀compress                            //是否压缩include /etc/logrotate.d            //包含该目录下的文件/var/log/wtmp {                     //对该日志文件设置轮转的方法    monthly                         //一个月轮转一次    create 0664 root utmp           //轮转后创建新文件，并设置权限    minsize 1M                      //最小达到1M才轮转    rotate 1                        //保留一份}/var/log/btmp {    missingok                       //丢失不提示    monthly    create 0600 root utmp    rotate 1}=========================================参数========================================compress             通过gzip 压缩转储以后的日志nocompress           不做gzip压缩处理copytruncate         用于还在打开中的日志文件，把当前日志备份并截断；是先拷贝再清空的方式，拷贝和清空之间有一个时间差，可能会丢失部分日志数据。nocopytruncate              备份日志文件不过不截断create mode owner group    轮转时指定创建新文件的属性，如create 0777 nobody nobodynocreate                   不建立新的日志文件delaycompress              和compress 一起使用时，转储的日志文件到下一次转储时才压缩nodelaycompress            覆盖 delaycompress 选项，转储同时压缩missingok                  如果日志丢失，不报错继续滚动下一个日志errors address             专储时的错误信息发送到指定的Email 地址ifempty                    即使日志文件为空文件也做轮转，这个是logrotate的缺省选项notifempty                 当日志文件为空时，不进行轮转mail address               把转储的日志文件发送到指定的E-mail 地址nomail                     转储时不发送日志文件olddir directory           转储后的日志文件放入指定的目录，必须和当前日志文件在同一个文件系统noolddir                   转储后的日志文件和当前日志文件放在同一个目录下sharedscripts运行postrotate脚本，作用是在所有日志都轮转后统一执行一次脚本。如果没有配置这个，那么每个日志轮转后都会执行一次脚本prerotate        在logrotate转储之前需要执行的指令，例如修改文件的属性等动作；必须独立成行postrotate       在logrotate转储之后需要执行的指令，例如重新启动 (kill -HUP) 某个服务！必须独立成行daily                      指定转储周期为每天weekly                     指定转储周期为每周monthly                    指定转储周期为每月rotate count               指定日志文件删除之前转储的次数，0 指没有备份，5 指保留5 个备份dateext                    使用当期日期作为命名格式dateformat .%s配合dateext使用，紧跟在下一行出现，定义文件切割后的文件名，必须配合dateext使用，只支持 %Y %m %d %s 这四个参数size(或minsize) log-size当日志文件到达指定的大小时才轮转，log-size能指定bytes(缺省)及KB (sizek)或MB(sizem).当日志文件 >= log-size 的时候就转储。 以下为合法格式：（其他格式的单位大小写没有试过）size = 5 或 size 5 （>= 5 个字节就转储）size = 100k 或 size 100ksize = 100M 或 size 100M=================================================================================#案例一:普通切割[root@JX02 ~]# vim  /etc/logrotate.d/yum/var/log/yum.log {missingok            //丢失不执行# notifempty        //空文件不轮转# size 30k            //达到30k轮转, daily or size# yearly            //或者一年一轮转daily                //缩小周期到1天rotate 3            //轮转保留3次create 0777 root root}[root@JX02 ~]# /usr/sbin/logrotate -f /etc/logrotate.conf        //强制轮转日志[root@JX02 ~]# ll /var/log/yum*                                    //发现日志已经被切割了#案例二:切割前后执行动作[root@JX02 ~]# vim /etc/logrotate.d/httpd/var/log/httpd/* {prerotatechattr -a /var/log/httpdendscript#notifemptydailycreate 0600 root rootmissingokrotate 5postrotatechattr +a /var/log/httpdendscript}[root@JX02 logrotate.d]# /usr/sbin/logrotate -f /etc/logrotate.conf#案例三:切割多个日志文件[root@JX02 ~]# vim /etc/logrotate.d/web/var/log/httpd_test.log/var/log/nginx_test.log/var/log/tomcat_test.log{dailycreate 0600 root rootmissingokrotate 5}[root@JX02 ~]# /usr/sbin/logrotate -f /etc/logrotate.conf#案例四:切割一个文件夹下的所有日志[root@JX02 ~]# vim /etc/logrotate.d/apache/var/log/apache/*log {dailycreate 0600 root rootmissingokrotate 5}[root@JX02 logrotate.d]# /usr/sbin/logrotate -f /etc/logrotate.conf</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins_流水线语法_002</title>
      <link href="2020/05/30/devops/jenkins-liu-shui-xian-yu-fa-002/"/>
      <url>2020/05/30/devops/jenkins-liu-shui-xian-yu-fa-002/</url>
      
        <content type="html"><![CDATA[<h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><p><code>parameters</code> 指令提供了一个用户在触发流水线时应该提供的参数列表。这些用户指定参数的值可通过 <code>params</code> 对象提供给流水线步骤, 了解更多请参考<a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#parameters-example" target="_blank" rel="noopener">示例</a>。</p><table><thead><tr><th align="left">Required</th><th>No</th></tr></thead><tbody><tr><td align="left">Parameters</td><td><em>None</em></td></tr><tr><td align="left">Allowed</td><td>Only once, inside the <code>pipeline</code> block.</td></tr></tbody></table><h5 id="可用参数"><a href="#可用参数" class="headerlink" title="可用参数"></a>可用参数</h5><ul><li><p>string</p><p>字符串类型的参数, 例如: <code>parameters { string(name: &#39;DEPLOY_ENV&#39;, defaultValue: &#39;staging&#39;, description: &#39;&#39;) }</code></p></li><li><p>booleanParam</p><p>布尔参数, 例如: <code>parameters { booleanParam(name: &#39;DEBUG_BUILD&#39;, defaultValue: true, description: &#39;&#39;) }</code></p></li></ul><h5 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h5><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    parameters <span class="token punctuation">{</span>        <span class="token function">string</span><span class="token punctuation">(</span>name<span class="token punctuation">:</span> <span class="token string">'PERSON'</span><span class="token punctuation">,</span> defaultValue<span class="token punctuation">:</span> <span class="token string">'Mr Jenkins'</span><span class="token punctuation">,</span> description<span class="token punctuation">:</span> <span class="token string">'Who should I say hello to?'</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">"Hello ${params.PERSON}"</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><table><thead><tr><th></th><th>一份完整的可用参数列表正在等待 <a href="https://issues.jenkins-ci.org/browse/INFRA-1053" target="_blank" rel="noopener">INFRA-1503</a>的完成。</th></tr></thead><tbody><tr><td></td><td></td></tr></tbody></table><h4 id="触发器"><a href="#触发器" class="headerlink" title="触发器"></a>触发器</h4><p><code>triggers</code> 指令定义了流水线被重新触发的自动化方法。对于集成了源（ 比如 GitHub 或 BitBucket）的流水线, 可能不需要 <code>triggers</code> ，因为基于 web 的集成很肯能已经存在。 当前可用的触发器是 <code>cron</code>, <code>pollSCM</code> 和 <code>upstream</code>。</p><table><thead><tr><th align="left">Required</th><th>No</th></tr></thead><tbody><tr><td align="left">Parameters</td><td><em>None</em></td></tr><tr><td align="left">Allowed</td><td>Only once, inside the <code>pipeline</code> block.</td></tr></tbody></table><ul><li><p>cron</p><p>接收 cron 样式的字符串来定义要重新触发流水线的常规间隔 ,比如: <code>triggers { cron(&#39;H */4 * * 1-5&#39;) }</code></p></li><li><p>pollSCM</p><p>接收 cron 样式的字符串来定义一个固定的间隔，在这个间隔中，Jenkins 会检查新的源代码更新。如果存在更改, 流水线就会被重新触发。例如: <code>triggers { pollSCM(&#39;H */4 * * 1-5&#39;) }</code></p></li><li><p>upstream</p><p>接受逗号分隔的工作字符串和阈值。 当字符串中的任何作业以最小阈值结束时，流水线被重新触发。例如: <code>triggers { upstream(upstreamProjects: &#39;job1,job2&#39;, threshold: hudson.model.Result.SUCCESS) }</code></p></li></ul><table><thead><tr><th></th><th><code>pollSCM</code> 只在Jenkins 2.22 及以上版本中可用。</th></tr></thead><tbody><tr><td></td><td></td></tr></tbody></table><h5 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h5><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    triggers <span class="token punctuation">{</span>        <span class="token function">cron</span><span class="token punctuation">(</span><span class="token string">'H */4 * * 1-5'</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Hello World'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><h4 id="stage"><a href="#stage" class="headerlink" title="stage"></a>stage</h4><p><code>stage</code> 指令在 <code>stages</code> 部分进行，应该包含一个 实际上, 流水巷所做的所有实际工作都将封装进一个或多个 <code>stage</code> 指令中。</p><table><thead><tr><th align="left">Required</th><th>At least one</th></tr></thead><tbody><tr><td align="left">Parameters</td><td>One mandatory parameter, a string for the name of the stage.</td></tr><tr><td align="left">Allowed</td><td>Inside the <code>stages</code> section.</td></tr></tbody></table><h5 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h5><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Hello World'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><h4 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h4><p>定义自动安装和放置 <code>PATH</code> 的工具的一部分。如果 <code>agent none</code> 指定，则忽略该操作。</p><table><thead><tr><th align="left">Required</th><th>No</th></tr></thead><tbody><tr><td align="left">Parameters</td><td><em>None</em></td></tr><tr><td align="left">Allowed</td><td>Inside the <code>pipeline</code> block or a <code>stage</code> block.</td></tr></tbody></table><h5 id="支持工具"><a href="#支持工具" class="headerlink" title="支持工具"></a>支持工具</h5><ul><li>maven</li><li>jdk</li><li>gradle</li></ul><h5 id="示例-3"><a href="#示例-3" class="headerlink" title="示例"></a>示例</h5><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    tools <span class="token punctuation">{</span>        maven <span class="token string">'apache-maven-3.0.1'</span>     <span class="token punctuation">}</span>    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            steps <span class="token punctuation">{</span>                sh <span class="token string">'mvn --version'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><table><thead><tr><th></th><th>The tool name must be pre-configured in Jenkins under <strong>Manage Jenkins</strong> → <strong>Global Tool Configuration</strong>.</th></tr></thead><tbody><tr><td></td><td>工具名称必须在Jenkins中的Manage Jenkins→全局工具配置下预先配置。</td></tr></tbody></table><h4 id="input"><a href="#input" class="headerlink" title="input"></a>input</h4><p><code>stage</code> 的 <code>input</code> 指令允许你使用 <a href="https://jenkins.io/doc/pipeline/steps/pipeline-input-step/#input-wait-for-interactive-input" target="_blank" rel="noopener"><code>input</code> step</a>提示输入。 在应用了 <code>options</code> 后，进入 <code>stage</code> 的 <code>agent</code> 或评估 <code>when</code> 条件前， <code>stage</code> 将暂停。 如果 <code>input</code> 被批准, <code>stage</code> 将会继续。 作为 <code>input</code> 提交的一部分的任何参数都将在环境中用于其他 <code>stage</code>。</p><h5 id="配置项"><a href="#配置项" class="headerlink" title="配置项"></a>配置项</h5><ul><li><p>message</p><p>必需的。 这将在用户提交 <code>input</code> 时呈现给用户。</p></li><li><p>id</p><p><code>input</code> 的可选标识符， 默认为 <code>stage</code> 名称。</p></li><li><p>ok</p><p><code>input</code>表单上的”ok” 按钮的可选文本。</p></li><li><p>submitter</p><p>可选的以逗号分隔的用户列表或允许提交 <code>input</code> 的外部组名。默认允许任何用户。</p></li><li><p>submitterParameter</p><p>环境变量的可选名称。如果存在，用 <code>submitter</code> 名称设置。</p></li><li><p>parameters</p><p>提示提交者提供的一个可选的参数列表。 更多信息参见 <a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#parameters" target="_blank" rel="noopener">[parameters]</a>。</p></li></ul><h5 id="示例-4"><a href="#示例-4" class="headerlink" title="示例"></a>示例</h5><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            input <span class="token punctuation">{</span>                message <span class="token string">"Should we continue?"</span>                ok <span class="token string">"Yes, we should."</span>                submitter <span class="token string">"alice,bob"</span>                parameters <span class="token punctuation">{</span>                    <span class="token function">string</span><span class="token punctuation">(</span>name<span class="token punctuation">:</span> <span class="token string">'PERSON'</span><span class="token punctuation">,</span> defaultValue<span class="token punctuation">:</span> <span class="token string">'Mr Jenkins'</span><span class="token punctuation">,</span> description<span class="token punctuation">:</span> <span class="token string">'Who should I say hello to?'</span><span class="token punctuation">)</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">"Hello, ${PERSON}, nice to meet you."</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><h4 id="when"><a href="#when" class="headerlink" title="when"></a>when</h4><p><code>when</code> 指令允许流水线根据给定的条件决定是否应该执行阶段。 <code>when</code> 指令必须包含至少一个条件。 如果 <code>when</code> 指令包含多个条件, 所有的子条件必须返回True，阶段才能执行。 这与子条件在 <code>allOf</code> 条件下嵌套的情况相同 (参见下面的<a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#when-example" target="_blank" rel="noopener">示例</a>)。</p><p>使用诸如 <code>not</code>, <code>allOf</code>, 或 <code>anyOf</code> 的嵌套条件可以构建更复杂的条件结构 can be built 嵌套条件刻意潜逃到任意深度。</p><table><thead><tr><th align="left">Required</th><th>No</th></tr></thead><tbody><tr><td align="left">Parameters</td><td><em>None</em></td></tr><tr><td align="left">Allowed</td><td>Inside a <code>stage</code> directive</td></tr></tbody></table><h5 id="内置条件"><a href="#内置条件" class="headerlink" title="内置条件"></a>内置条件</h5><ul><li><p>branch</p><p>当正在构建的分支与模式给定的分支匹配时，执行这个阶段, 例如: <code>when { branch &#39;master&#39; }</code>。注意，这只适用于多分支流水线。</p></li><li><p>environment</p><p>当指定的环境变量是给定的值时，执行这个步骤, 例如: <code>when { environment name: &#39;DEPLOY_TO&#39;, value: &#39;production&#39; }</code></p></li><li><p>expression</p><p>当指定的Groovy表达式评估为true时，执行这个阶段, 例如: <code>when { expression { return params.DEBUG_BUILD } }</code></p></li><li><p>not</p><p>当嵌套条件是错误时，执行这个阶段,必须包含一个条件，例如: <code>when { not { branch &#39;master&#39; } }</code></p></li><li><p>allOf</p><p>当所有的嵌套条件都正确时，执行这个阶段,必须包含至少一个条件，例如: <code>when { allOf { branch &#39;master&#39;; environment name: &#39;DEPLOY_TO&#39;, value: &#39;production&#39; } }</code></p></li><li><p>anyOf</p><p>当至少有一个嵌套条件为真时，执行这个阶段,必须包含至少一个条件，例如: <code>when { anyOf { branch &#39;master&#39;; branch &#39;staging&#39; } }</code></p></li></ul><h5 id="在进入-stage-的-agent-前评估-when"><a href="#在进入-stage-的-agent-前评估-when" class="headerlink" title="在进入 stage 的 agent 前评估 when"></a>在进入 <code>stage</code> 的 <code>agent</code> 前评估 <code>when</code></h5><p>默认情况下, 如果定义了某个阶段的代理，在进入该<code>stage</code> 的 <code>agent</code> 后该 <code>stage</code> 的 <code>when</code> 条件将会被评估。但是, 可以通过在 <code>when</code> 块中指定 <code>beforeAgent</code> 选项来更改此选项。 如果 <code>beforeAgent</code> 被设置为 <code>true</code>, 那么就会首先对 <code>when</code> 条件进行评估 , 并且只有在 <code>when</code> 条件验证为真时才会进入 <code>agent</code> 。</p><h5 id="示例-5"><a href="#示例-5" class="headerlink" title="示例"></a>示例</h5><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example Build'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Hello World'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example Deploy'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            when <span class="token punctuation">{</span>                branch <span class="token string">'production'</span>            <span class="token punctuation">}</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Deploying'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example Build'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Hello World'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example Deploy'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            when <span class="token punctuation">{</span>                branch <span class="token string">'production'</span>                environment name<span class="token punctuation">:</span> <span class="token string">'DEPLOY_TO'</span><span class="token punctuation">,</span> value<span class="token punctuation">:</span> <span class="token string">'production'</span>            <span class="token punctuation">}</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Deploying'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example Build'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Hello World'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example Deploy'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            when <span class="token punctuation">{</span>                allOf <span class="token punctuation">{</span>                    branch <span class="token string">'production'</span>                    environment name<span class="token punctuation">:</span> <span class="token string">'DEPLOY_TO'</span><span class="token punctuation">,</span> value<span class="token punctuation">:</span> <span class="token string">'production'</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Deploying'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example Build'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Hello World'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example Deploy'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            when <span class="token punctuation">{</span>                branch <span class="token string">'production'</span>                anyOf <span class="token punctuation">{</span>                    environment name<span class="token punctuation">:</span> <span class="token string">'DEPLOY_TO'</span><span class="token punctuation">,</span> value<span class="token punctuation">:</span> <span class="token string">'production'</span>                    environment name<span class="token punctuation">:</span> <span class="token string">'DEPLOY_TO'</span><span class="token punctuation">,</span> value<span class="token punctuation">:</span> <span class="token string">'staging'</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Deploying'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example Build'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Hello World'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example Deploy'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            when <span class="token punctuation">{</span>                expression <span class="token punctuation">{</span> BRANCH_NAME <span class="token operator">==~</span> <span class="token string">/(production|staging)/</span> <span class="token punctuation">}</span>                anyOf <span class="token punctuation">{</span>                    environment name<span class="token punctuation">:</span> <span class="token string">'DEPLOY_TO'</span><span class="token punctuation">,</span> value<span class="token punctuation">:</span> <span class="token string">'production'</span>                    environment name<span class="token punctuation">:</span> <span class="token string">'DEPLOY_TO'</span><span class="token punctuation">,</span> value<span class="token punctuation">:</span> <span class="token string">'staging'</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Deploying'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent none    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example Build'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Hello World'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example Deploy'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            agent <span class="token punctuation">{</span>                label <span class="token string">"some-label"</span>            <span class="token punctuation">}</span>            when <span class="token punctuation">{</span>                beforeAgent <span class="token boolean">true</span>                branch <span class="token string">'production'</span>            <span class="token punctuation">}</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Deploying'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><h3 id="并行"><a href="#并行" class="headerlink" title="并行"></a>并行</h3><p>声明式流水线的阶段可以在他们内部声明多隔嵌套阶段, 它们将并行执行。 注意，一个阶段必须只有一个 <code>steps</code> 或 <code>parallel</code> 的阶段。 嵌套阶段本身不能包含进一步的 <code>parallel</code> 阶段, 但是其他的阶段的行为与任何其他 <code>stage</code> 相同。任何包含 <code>parallel</code> 的阶段不能包含 <code>agent</code> 或 <code>tools</code> 阶段, 因为他们没有相关 <code>steps</code>。</p><p>另外, 通过添加 <code>failFast true</code> 到包含 <code>parallel</code>的 <code>stage</code> 中， 当其中一个进程失败时，你可以强制所有的 <code>parallel</code> 阶段都被终止。</p><h4 id="示例-6"><a href="#示例-6" class="headerlink" title="示例"></a>示例</h4><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Non-Parallel Stage'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'This stage will be executed first.'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Parallel Stage'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            when <span class="token punctuation">{</span>                branch <span class="token string">'master'</span>            <span class="token punctuation">}</span>            failFast <span class="token boolean">true</span>            parallel <span class="token punctuation">{</span>                <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Branch A'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                    agent <span class="token punctuation">{</span>                        label <span class="token string">"for-branch-a"</span>                    <span class="token punctuation">}</span>                    steps <span class="token punctuation">{</span>                        echo <span class="token string">"On Branch A"</span>                    <span class="token punctuation">}</span>                <span class="token punctuation">}</span>                <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Branch B'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                    agent <span class="token punctuation">{</span>                        label <span class="token string">"for-branch-b"</span>                    <span class="token punctuation">}</span>                    steps <span class="token punctuation">{</span>                        echo <span class="token string">"On Branch B"</span>                    <span class="token punctuation">}</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><p>声明式流水线可能使用在 <a href="https://www.jenkins.io/doc/pipeline/steps" target="_blank" rel="noopener">流水线步骤引用</a>中记录的所有可用的步骤, 它包含一个完整的步骤列表, 其中添加了下面列出的步骤，这些步骤只在声明式流水线中 <strong>only supported</strong> 。</p><h4 id="脚本"><a href="#脚本" class="headerlink" title="脚本"></a>脚本</h4><p><code>script</code> 步骤需要 <a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#scripted-pipeline" target="_blank" rel="noopener">[scripted-pipeline]</a>块并在声明式流水线中执行。 对于大多数用例来说,应该声明式流水线中的“脚本”步骤是不必要的， 但是它可以提供一个有用的”逃生出口”。 非平凡的规模和/或复杂性的 <code>script</code> 块应该被转移到 <a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#shared-libraries#" target="_blank" rel="noopener">共享库</a> 。</p><h5 id="示例-7"><a href="#示例-7" class="headerlink" title="示例"></a>示例</h5><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Hello World'</span>                script <span class="token punctuation">{</span>                    <span class="token keyword">def</span> browsers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'chrome'</span><span class="token punctuation">,</span> <span class="token string">'firefox'</span><span class="token punctuation">]</span>                    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> browsers<span class="token operator">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">{</span>                        echo <span class="token string">"Testing the ${browsers[i]} browser"</span>                    <span class="token punctuation">}</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><h2 id="脚本化流水线"><a href="#脚本化流水线" class="headerlink" title="脚本化流水线"></a>脚本化流水线</h2><p>脚本化流水线, 与<a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#declarative-pipeline" target="_blank" rel="noopener">[declarative-pipeline]</a>一样的是, 是建立在底层流水线的子系统上的。与声明式不同的是, 脚本化流水线实际上是由 <a href="http://groovy-lang.org/syntax.html" target="_blank" rel="noopener">Groovy</a>构建的通用 DSL [<a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#_footnotedef_2" target="_blank" rel="noopener">2</a>]。 Groovy 语言提供的大部分功能都可以用于脚本化流水线的用户。这意味着它是一个非常有表现力和灵活的工具，可以通过它编写持续交付流水线。</p><h3 id="流控制"><a href="#流控制" class="headerlink" title="流控制"></a>流控制</h3><p>脚本化流水线从 <code>Jenkinsfile</code> 的顶部开始向下串行执行, 就像 Groovy 或其他语言中的大多数传统脚本一样。 因此，提供流控制取决于 Groovy 表达式, 比如 <code>if/else</code> 条件, 例如:</p><p>Jenkinsfile (Scripted Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">node <span class="token punctuation">{</span>    <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>env<span class="token operator">.</span>BRANCH_NAME <span class="token operator">==</span> <span class="token string">'master'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            echo <span class="token string">'I only execute on the master branch'</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            echo <span class="token string">'I execute elsewhere'</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>另一种方法是使用Groovy的异常处理支持来管理脚本化流水线流控制。当 <a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#scripted-steps" target="_blank" rel="noopener">步骤</a> 失败 ，无论什么原因，它们都会抛出一个异常。处理错误的行为必须使用Groovy中的 <code>try/catch/finally</code> 块 , 例如:</p><p>Jenkinsfile (Scripted Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">node <span class="token punctuation">{</span>    <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">try</span> <span class="token punctuation">{</span>            sh <span class="token string">'exit 1'</span>        <span class="token punctuation">}</span>        <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">exc</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            echo <span class="token string">'Something failed, I should sound the klaxons!'</span>            <span class="token keyword">throw</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><h3 id="步骤-1"><a href="#步骤-1" class="headerlink" title="步骤"></a>步骤</h3><p>正如 <a href="https://www.jenkins.io/zh/doc/book/pipeline/" target="_blank" rel="noopener">本章开始</a>所讨论的, 流水线最基础的部分是”步骤”。从根本上说, 步骤告诉 Jenkins要做 <em>what</em> ，并作为声明式和脚本化流水线已发的基本构建块。</p><p>脚本化流水线 <strong>not</strong> 不引入任何特定于其语法的步骤; <a href="https://www.jenkins.io/doc/pipeline/steps" target="_blank" rel="noopener">流水线步骤引用</a> 包括流水线和插件提供的步骤的完整列表。</p><h3 id="区别普通-Groovy"><a href="#区别普通-Groovy" class="headerlink" title="区别普通 Groovy"></a>区别普通 Groovy</h3><p>为了提供 <em>durability</em>, 这意味着运行流水线可以在Jenkins <a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#../glossary#master" target="_blank" rel="noopener">master</a> 重启后继续运行，脚本化的流水线序列化数据到主服务器。由于这个设计需求, 一些Groovy 习惯用语，比如 <code>collection.each { item -&gt; /* perform operation */ }</code> 都不完全支持。详情参见 <a href="https://issues.jenkins-ci.org/browse/JENKINS-27421" target="_blank" rel="noopener">JENKINS-27421</a> 和 <a href="https://issues.jenkins-ci.org/browse/JENKINS-26481" target="_blank" rel="noopener">JENKINS-26481</a>。</p><h2 id="语法比较"><a href="#语法比较" class="headerlink" title="语法比较"></a>语法比较</h2><p>当Jenkins 流水线第一次构建时, Groovy 被选为基础。 Jenkins长期使用嵌入式 Groovy引擎来为管理员和用户提供 高级脚本功能。另外, Jenkins流水线的实现者发现 Groovy是 构建现在成为 “脚本化流水线” DSL的坚实基础 [<a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#_footnotedef_2" target="_blank" rel="noopener">2</a>]。</p><p>由于它是一个功能齐全的编程环境, 脚本化流水线为Jenkins用户提供了 大量的灵活性性和可扩展性。 Groovy学习曲线通常不适合给定团队的所有成员, 因此创造了声明式流水线来为编写Jenkins流水线提供一种更简单、更有主见的语法。</p><p>两者本质上是相同的流水线子系统。 underneath. 他们都是 “流水线即代码” 的持久实现。它们都能够使用构建到流水线中或插件提供的步骤。它们都能够使用 <a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#shared-libraries#" target="_blank" rel="noopener">共享库</a></p><p>但是它们的区别在于语法和灵活性。 声明式限制了用户使用更严格和预定义的结构， 使其成为更简单的持续交付流水线的理想选择。 脚本化提供了很少的限制, 以至于对脚本和语法的唯一限制往往是由Groovy子集本身定义的，而不是任何特定于流水线的系统, 这使他成为权利用户和那些有更复杂需求的人的理想选择。 顾名思义, 声明式流水线鼓励 声明式编程模型。 [<a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#_footnotedef_3" target="_blank" rel="noopener">3</a>] 而脚本化流水线遵循一个更命令式的编程模型 [<a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#_footnotedef_4" target="_blank" rel="noopener">4</a>]</p>]]></content>
      
      
      <categories>
          
          <category> DevOps </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins_流水线语法_001</title>
      <link href="2020/05/28/devops/jenkins-liu-shui-xian-yu-fa-001/"/>
      <url>2020/05/28/devops/jenkins-liu-shui-xian-yu-fa-001/</url>
      
        <content type="html"><![CDATA[<h4 id="流水线语法"><a href="#流水线语法" class="headerlink" title="流水线语法"></a>流水线语法</h4><p>本节是建立在 <a href="https://www.jenkins.io/zh/doc/book/pipeline/getting-started" target="_blank" rel="noopener">流水线入门</a>内容的基础上，而且，应当被当作一个参考。 对于在实际示例中如何使用流水线语法的更多信息, 请参阅本章在流水线插件的2.5版本中的 <a href="https://www.jenkins.io/zh/doc/book/pipeline/jenkinsfile" target="_blank" rel="noopener">使用 Jenkinsfile</a>部分, 流水线支持两种离散的语法，具体如下对于每种的优缺点, 参见<a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#compare" target="_blank" rel="noopener">语法比较</a>。</p><p>正如 <a href="https://www.jenkins.io/zh/doc/book/pipeline/" target="_blank" rel="noopener">本章开始</a>讨论的, 流水线最基础的部分是 “步骤”。基本上, 步骤告诉 Jenkins 要做什么，以及作为声明式和脚本化流水线语法的基本构建块。</p><p>对于可用步骤的概述, 请参考 <a href="https://www.jenkins.io/doc/pipeline/steps" target="_blank" rel="noopener">流水线步骤引用</a>，它包含了一个构建到流水线的步骤和 插件提供的步骤的全面的列表。</p><h4 id="声明式流水线"><a href="#声明式流水线" class="headerlink" title="声明式流水线"></a>声明式流水线</h4><p>声明式流水线是最近添加到 Jenkins 流水线的 [<a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#_footnotedef_1" target="_blank" rel="noopener">1</a>]，它在流水线子系统之上提供了一种更简单，更有主见的语法。</p><p>所有有效的声明式流水线必须包含在一个 <code>pipeline</code> 块中, 比如:</p><pre><code>pipeline {    /* insert Declarative Pipeline here */}</code></pre><p>在声明式流水线中有效的基本语句和表达式遵循与 <a href="http://groovy-lang.org/syntax.html" target="_blank" rel="noopener">Groovy的语法</a>同样的规则， 有以下例外:</p><ul><li>流水线顶层必须是一个 <em>block</em>, 特别地: <code>pipeline { }</code></li><li>没有分号作为语句分隔符，，每条语句都必须在自己的行上。</li><li>块只能由 <a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#declarative-sections" target="_blank" rel="noopener">节段</a>, <a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#declarative-directives" target="_blank" rel="noopener">指令</a>, <a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#declarative-steps" target="_blank" rel="noopener">步骤</a>, 或赋值语句组成。 *属性引用语句被视为无参方法调用。 例如, input被视为 input()</li></ul><h3 id="节段"><a href="#节段" class="headerlink" title="节段"></a>节段</h3><p>声明式流水线中的节段通常包含一个或多个 <a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#declarative-directives" target="_blank" rel="noopener">指令</a> 或 <a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#declarative-steps" target="_blank" rel="noopener">步骤</a>。</p><h4 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h4><p><code>agent</code> 部分指定了整个流水线或特定的部分, 将会在Jenkins环境中执行的位置，这取决于 <code>agent</code> 区域的位置。该部分必须在 <code>pipeline</code> 块的顶层被定义, 但是 stage 级别的使用是可选的。</p><table><thead><tr><th align="left">Required</th><th>Yes</th></tr></thead><tbody><tr><td align="left">Parameters</td><td><a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#agent-parameters" target="_blank" rel="noopener">Described below</a></td></tr><tr><td align="left">Allowed</td><td>In the top-level <code>pipeline</code> block and each <code>stage</code> block.</td></tr></tbody></table><h5 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h5><p>为了支持作者可能有的各种各样的用例流水线, <code>agent</code> 部分支持一些不同类型的参数。这些参数应用在<code>pipeline</code>块的顶层, 或 <code>stage</code> 指令内部。</p><ul><li><p>any</p><p>在任何可用的代理上执行流水线或阶段。例如: <code>agent any</code></p></li><li><p>none</p><p>当在 <code>pipeline</code> 块的顶部没有全局代理， 该参数将会被分配到整个流水线的运行中并且每个 <code>stage</code> 部分都需要包含他自己的 <code>agent</code> 部分。比如: <code>agent none</code></p></li><li><p>label</p><p>在提供了标签的 Jenkins 环境中可用的代理上执行流水线或阶段。 例如: <code>agent { label &#39;my-defined-label&#39; }</code></p></li><li><p>node</p><p><code>agent { node { label &#39;labelName&#39; } }</code> 和 <code>agent { label &#39;labelName&#39; }</code> 一样, 但是 <code>node</code> 允许额外的选项 (比如 <code>customWorkspace</code> )。</p></li><li><p>docker</p><p>使用给定的容器执行流水线或阶段。该容器将在预置的 <a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#../glossary#node" target="_blank" rel="noopener">node</a>上，或在匹配可选定义的<code>label</code> 参数上，动态的供应来接受基于Docker的流水线。 <code>docker</code> 也可以选择的接受 <code>args</code> 参数，该参数可能包含直接传递到 <code>docker run</code> 调用的参数, 以及 <code>alwaysPull</code> 选项, 该选项强制 <code>docker pull</code> ，即使镜像名称已经存在。 比如: </p><pre><code>agent {    docker {        image &#39;maven:3-alpine&#39;        label &#39;my-defined-label&#39;        args  &#39;-v /tmp:/tmp&#39;    }}</code></pre></li><li><p>dockerfile</p><p>执行流水线或阶段, 使用从源代码库包含的 <code>Dockerfile</code> 构建的容器。为了使用该选项， <code>Jenkinsfile</code> 必须从多个分支流水线中加载, 或者加载 “Pipeline from SCM.” 通常，这是源代码仓库的根目录下的 <code>Dockerfile</code> : <code>agent { dockerfile true }</code>. 如果在另一个目录下构建 <code>Dockerfile</code> , 使用 <code>dir</code> 选项: <code>agent { dockerfile {dir &#39;someSubDir&#39; } }</code>。如果 <code>Dockerfile</code> 有另一个名称, 你可以使用 <code>filename</code> 选项指定该文件名。你可以传递额外的参数到 <code>docker build ...</code> 使用 <code>additionalBuildArgs</code> 选项提交, 比如 <code>agent { dockerfile {additionalBuildArgs &#39;--build-arg foo=bar&#39; } }</code>。 例如, 一个带有 <code>build/Dockerfile.build</code> 的仓库,期望一个构建参数 <code>version</code>:</p><pre><code>agent {    // Equivalent to &quot;docker build -f Dockerfile.build --build-arg version=1.0.2 ./build/    dockerfile {        filename &#39;Dockerfile.build&#39;        dir &#39;build&#39;        label &#39;my-defined-label&#39;        additionalBuildArgs  &#39;--build-arg version=1.0.2&#39;    }}</code></pre></li></ul><h5 id="常见选项"><a href="#常见选项" class="headerlink" title="常见选项"></a>常见选项</h5><p>有一些应用于两个或更多 <code>agent</code> 的实现的选项。他们不被要求，除非特别规定。</p><ul><li><p>label</p><p>一个字符串。该标签用于运行流水线或个别的 <code>stage</code>。该选项对 <code>node</code>, <code>docker</code> 和 <code>dockerfile</code> 可用, <code>node</code>要求必须选择该选项。</p></li><li><p>customWorkspace</p><p>一个字符串。在自定义工作区运行应用了 <code>agent</code> 的流水线或个别的 <code>stage</code>, 而不是默认值。 它既可以是一个相对路径, 在这种情况下，自定义工作区会存在于节点工作区根目录下, 或者一个绝对路径。比如:</p><pre><code>agent {    node {        label &#39;my-defined-label&#39;        customWorkspace &#39;/some/other/path&#39;    }}</code></pre><p>该选项对 <code>node</code>, <code>docker</code> 和 <code>dockerfile</code> 有用 。</p></li><li><p>reuseNode</p><p>一个布尔值, 默认为false。 如果是true, 则在流水线的顶层指定的节点上运行该容器, 在同样的工作区, 而不是在一个全新的节点上。这个选项对 <code>docker</code> 和 <code>dockerfile</code> 有用, 并且只有当 使用在个别的 <code>stage</code> 的 <code>agent</code> 上才会有效。</p></li></ul><h5 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h5><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent <span class="token punctuation">{</span> docker <span class="token string">'maven:3-alpine'</span> <span class="token punctuation">}</span>     stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example Build'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            steps <span class="token punctuation">{</span>                sh <span class="token string">'mvn -B clean verify'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><table><thead><tr><th></th><th>在一个给定名称和标签(<code>maven:3-alpine</code>)的新建的容器上执行定义在流水线中的所有步骤 。</th></tr></thead><tbody><tr><td></td><td></td></tr></tbody></table><h6 id="阶段级别的-agent-部分"><a href="#阶段级别的-agent-部分" class="headerlink" title="阶段级别的 agent 部分"></a>阶段级别的 <code>agent</code> 部分</h6><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent none     stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example Build'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            agent <span class="token punctuation">{</span> docker <span class="token string">'maven:3-alpine'</span> <span class="token punctuation">}</span>             steps <span class="token punctuation">{</span>                echo <span class="token string">'Hello, Maven'</span>                sh <span class="token string">'mvn --version'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example Test'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            agent <span class="token punctuation">{</span> docker <span class="token string">'openjdk:8-jre'</span> <span class="token punctuation">}</span>             steps <span class="token punctuation">{</span>                echo <span class="token string">'Hello, JDK'</span>                sh <span class="token string">'java -version'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><table><thead><tr><th></th><th>在流水线顶层定义 <code>agent none</code> 确保 <a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#../glossary#executor" target="_blank" rel="noopener">an Executor</a> 没有被分配。 使用 <code>agent none</code> 也会强制 <code>stage</code> 部分包含他自己的 <code>agent</code> 部分。</th></tr></thead><tbody><tr><td></td><td>使用镜像在一个新建的容器中执行该阶段的该步骤。</td></tr><tr><td></td><td>使用一个与之前阶段不同的镜像在一个新建的容器中执行该阶段的该步骤。</td></tr></tbody></table><h4 id="post"><a href="#post" class="headerlink" title="post"></a>post</h4><p><code>post</code> 部分定义一个或多个<a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#declarative-steps" target="_blank" rel="noopener">steps</a> ，这些阶段根据流水线或阶段的完成情况而 运行(取决于流水线中 <code>post</code> 部分的位置). <code>post</code> 支持以下 <a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#post-conditions" target="_blank" rel="noopener">post-condition</a> 块中的其中之一: <code>always</code>, <code>changed</code>, <code>failure</code>, <code>success</code>, <code>unstable</code>, 和 <code>aborted</code>。这些条件块允许在 <code>post</code> 部分的步骤的执行取决于流水线或阶段的完成状态。</p><table><thead><tr><th align="left">Required</th><th>No</th></tr></thead><tbody><tr><td align="left">Parameters</td><td><em>None</em></td></tr><tr><td align="left">Allowed</td><td>In the top-level <code>pipeline</code> block and each <code>stage</code> block.</td></tr></tbody></table><h5 id="Conditions"><a href="#Conditions" class="headerlink" title="Conditions"></a>Conditions</h5><ul><li><p><code>always</code></p><p>无论流水线或阶段的完成状态如何，都允许在 <code>post</code> 部分运行该步骤。</p></li><li><p><code>changed</code></p><p>只有当前流水线或阶段的完成状态与它之前的运行不同时，才允许在 <code>post</code> 部分运行该步骤。</p></li><li><p><code>failure</code></p><p>只有当前流水线或阶段的完成状态为”failure”，才允许在 <code>post</code> 部分运行该步骤, 通常web UI是红色。</p></li><li><p><code>success</code></p><p>只有当前流水线或阶段的完成状态为”success”，才允许在 <code>post</code> 部分运行该步骤, 通常web UI是蓝色或绿色。</p></li><li><p><code>unstable</code></p><p>只有当前流水线或阶段的完成状态为”unstable”，才允许在 <code>post</code> 部分运行该步骤, 通常由于测试失败,代码违规等造成。通常web UI是黄色。</p></li><li><p><code>aborted</code></p><p>只有当前流水线或阶段的完成状态为”aborted”，才允许在 <code>post</code> 部分运行该步骤, 通常由于流水线被手动的aborted。通常web UI是灰色。</p></li></ul><h5 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h5><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Hello World'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    post <span class="token punctuation">{</span>         always <span class="token punctuation">{</span>             echo <span class="token string">'I will always say Hello again!'</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><table><thead><tr><th></th><th>按照惯例, <code>post</code> 部分应该放在流水线的底部。</th></tr></thead><tbody><tr><td></td><td><a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#post-conditions" target="_blank" rel="noopener">Post-condition</a> 块包含与 <a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#steps" target="_blank" rel="noopener">steps</a> 部分相同的<a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#declarative-steps" target="_blank" rel="noopener">steps</a>。</td></tr></tbody></table><h4 id="stages"><a href="#stages" class="headerlink" title="stages"></a>stages</h4><p>包含一系列一个或多个 <a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#stage" target="_blank" rel="noopener">stage</a> 指令, <code>stages</code> 部分是流水线描述的大部分”work” 的位置。 建议 <code>stages</code> 至少包含一个 <a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#stage" target="_blank" rel="noopener">stage</a> 指令用于连续交付过程的每个离散部分,比如构建, 测试, 和部署。</p><table><thead><tr><th align="left">Required</th><th>Yes</th></tr></thead><tbody><tr><td align="left">Parameters</td><td><em>None</em></td></tr><tr><td align="left">Allowed</td><td>Only once, inside the <code>pipeline</code> block.</td></tr></tbody></table><h5 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h5><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    stages <span class="token punctuation">{</span>         <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Hello World'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><table><thead><tr><th></th><th><code>stages</code> 部分通常会遵循诸如 <code>agent</code>, <code>options</code> 等的指令。</th></tr></thead><tbody><tr><td></td><td></td></tr></tbody></table><h4 id="steps"><a href="#steps" class="headerlink" title="steps"></a>steps</h4><p><code>steps</code> 部分在给定的 <code>stage</code> 指令中执行的定义了一系列的一个或多个<a href="https://www.jenkins.io/zh/doc/book/pipeline/syntax/#declarative-steps" target="_blank" rel="noopener">steps</a>。</p><table><thead><tr><th align="left">Required</th><th>Yes</th></tr></thead><tbody><tr><td align="left">Parameters</td><td><em>None</em></td></tr><tr><td align="left">Allowed</td><td>Inside each <code>stage</code> block.</td></tr></tbody></table><h5 id="示例-3"><a href="#示例-3" class="headerlink" title="示例"></a>示例</h5><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            steps <span class="token punctuation">{</span>                 echo <span class="token string">'Hello World'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p><code>steps</code> 部分必须包含一个或多个步骤。</p><h3 id="指令"><a href="#指令" class="headerlink" title="指令"></a>指令</h3><h4 id="environment"><a href="#environment" class="headerlink" title="environment"></a>environment</h4><p><code>environment</code> 指令制定一个 键-值对序列，该序列将被定义为所有步骤的环境变量，或者是特定于阶段的步骤， 这取决于 <code>environment</code> 指令在流水线内的位置。</p><p>该指令支持一个特殊的助手方法 <code>credentials()</code> ，该方法可用于在Jenkins环境中通过标识符访问预定义的凭证。对于类型为 “Secret Text”的凭证, <code>credentials()</code> 将确保指定的环境变量包含秘密文本内容。对于类型为 “SStandard username and password”的凭证, 指定的环境变量指定为 <code>username:password</code> ，并且两个额外的环境变量将被自动定义 :分别为 <code>MYVARNAME_USR</code> 和 <code>MYVARNAME_PSW</code> 。</p><table><thead><tr><th align="left">Required</th><th>No</th></tr></thead><tbody><tr><td align="left">Parameters</td><td><em>None</em></td></tr><tr><td align="left">Allowed</td><td>Inside the <code>pipeline</code> block, or within <code>stage</code> directives.</td></tr></tbody></table><h5 id="示例-4"><a href="#示例-4" class="headerlink" title="示例"></a>示例</h5><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    environment <span class="token punctuation">{</span>         CC <span class="token operator">=</span> <span class="token string">'clang'</span>    <span class="token punctuation">}</span>    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            environment <span class="token punctuation">{</span>                 AN_ACCESS_KEY <span class="token operator">=</span> <span class="token function">credentials</span><span class="token punctuation">(</span><span class="token string">'my-prefined-secret-text'</span><span class="token punctuation">)</span>             <span class="token punctuation">}</span>            steps <span class="token punctuation">{</span>                sh <span class="token string">'printenv'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><table><thead><tr><th></th><th>顶层流水线块中使用的 <code>environment</code> 指令将适用于流水线中的所有步骤。</th></tr></thead><tbody><tr><td></td><td>在一个 <code>stage</code> 中定义的 <code>environment</code> 指令只会将给定的环境变量应用于 <code>stage</code> 中的步骤。</td></tr><tr><td></td><td><code>environment</code> 块有一个 助手方法 <code>credentials()</code> 定义，该方法可以在 Jenkins 环境中用于通过标识符访问预定义的凭证。</td></tr></tbody></table><h4 id="options"><a href="#options" class="headerlink" title="options"></a>options</h4><p><code>options</code> 指令允许从流水线内部配置特定于流水线的选项。 流水线提供了许多这样的选项, 比如 <code>buildDiscarder</code>,但也可以由插件提供, 比如 <code>timestamps</code>.</p><table><thead><tr><th align="left">Required</th><th>No</th></tr></thead><tbody><tr><td align="left">Parameters</td><td><em>None</em></td></tr><tr><td align="left">Allowed</td><td>Only once, inside the <code>pipeline</code> block.</td></tr></tbody></table><h5 id="可用选项"><a href="#可用选项" class="headerlink" title="可用选项"></a>可用选项</h5><ul><li><p>buildDiscarder</p><p>为最近的流水线运行的特定数量保存组件和控制台输出。例如: <code>options { buildDiscarder(logRotator(numToKeepStr: &#39;1&#39;)) }</code></p></li><li><p>disableConcurrentBuilds</p><p>不允许同时执行流水线。 可被用来防止同时访问共享资源等。 例如: <code>options { disableConcurrentBuilds() }</code></p></li><li><p>overrideIndexTriggers</p><p>允许覆盖分支索引触发器的默认处理。 如果分支索引触发器在多分支或组织标签中禁用, <code>options { overrideIndexTriggers(true) }</code> 将只允许它们用于促工作。否则, <code>options { overrideIndexTriggers(false) }</code> 只会禁用改作业的分支索引触发器。</p></li><li><p>skipDefaultCheckout</p><p>在<code>agent</code> 指令中，跳过从源代码控制中检出代码的默认情况。例如: <code>options { skipDefaultCheckout() }</code></p></li><li><p>skipStagesAfterUnstable</p><p>一旦构建状态变得UNSTABLE，跳过该阶段。例如: <code>options { skipStagesAfterUnstable() }</code></p></li><li><p>checkoutToSubdirectory</p><p>在工作空间的子目录中自动地执行源代码控制检出。例如: <code>options { checkoutToSubdirectory(&#39;foo&#39;) }</code></p></li><li><p>timeout</p><p>设置流水线运行的超时时间, 在此之后，Jenkins将中止流水线。例如: <code>options { timeout(time: 1, unit: &#39;HOURS&#39;) }</code></p></li><li><p>retry</p><p>在失败时, 重新尝试整个流水线的指定次数。 For example: <code>options { retry(3) }</code></p></li><li><p>timestamps</p><p>预谋所有由流水线生成的控制台输出，与该流水线发出的时间一致。 例如: <code>options { timestamps() }</code></p></li></ul><h5 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h5><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    options <span class="token punctuation">{</span>        <span class="token function">timeout</span><span class="token punctuation">(</span>time<span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> unit<span class="token punctuation">:</span> <span class="token string">'HOURS'</span><span class="token punctuation">)</span>     <span class="token punctuation">}</span>    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Hello World'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><table><thead><tr><th></th><th>指定一个小时的全局执行超时, 在此之后，Jenkins 将中止流水线运行。</th></tr></thead><tbody><tr><td></td><td></td></tr></tbody></table><table><thead><tr><th></th><th>一个完整的可用选项列表正在等待完成第 <a href="https://issues.jenkins-ci.org/browse/INFRA-1053" target="_blank" rel="noopener">INFRA-1503</a>次。</th></tr></thead><tbody><tr><td></td><td></td></tr></tbody></table><h5 id="阶段选项"><a href="#阶段选项" class="headerlink" title="阶段选项"></a>阶段选项</h5><p><code>stage</code> 的 <code>options</code> 指令类似于流水线根目录上的 <code>options</code> 指令。然而， <code>stage</code> -级别 <code>options</code> 只能包括 <code>retry</code>, <code>timeout</code>, 或 <code>timestamps</code> 等步骤, 或与 <code>stage</code> 相关的声明式选项，如 <code>skipDefaultCheckout</code>。</p><p>在<code>stage</code>, <code>options</code> 指令中的步骤在进入 <code>agent</code> 之前被调用或在 <code>when</code> 条件出现时进行检查。</p><h6 id="可选的阶段选项"><a href="#可选的阶段选项" class="headerlink" title="可选的阶段选项"></a>可选的阶段选项</h6><ul><li><p>skipDefaultCheckout</p><p>在 <code>agent</code> 指令中跳过默认的从源代码控制中检出代码。例如: <code>options { skipDefaultCheckout() }</code></p></li><li><p>timeout</p><p>设置此阶段的超时时间, 在此之后， Jenkins 会终止该阶段。 例如: <code>options { timeout(time: 1, unit: &#39;HOURS&#39;) }</code></p></li><li><p>retry</p><p>在失败时, 重试此阶段指定次数。 例如: <code>options { retry(3) }</code></p></li><li><p>timestamps</p><p>预谋此阶段生成的所有控制台输出以及该行发出的时间一致。例如: <code>options { timestamps() }</code></p></li></ul><h6 id="示例-5"><a href="#示例-5" class="headerlink" title="示例"></a>示例</h6><p>Jenkinsfile (Declarative Pipeline)</p><pre class=" language-groovy"><code class="language-groovy">pipeline <span class="token punctuation">{</span>    agent any    stages <span class="token punctuation">{</span>        <span class="token function">stage</span><span class="token punctuation">(</span><span class="token string">'Example'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            options <span class="token punctuation">{</span>                <span class="token function">timeout</span><span class="token punctuation">(</span>time<span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> unit<span class="token punctuation">:</span> <span class="token string">'HOURS'</span><span class="token punctuation">)</span>             <span class="token punctuation">}</span>            steps <span class="token punctuation">{</span>                echo <span class="token string">'Hello World'</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>指定 <code>Example</code> 阶段的执行超时时间, 在此之后，Jenkins 将中止流水线运行。</p>]]></content>
      
      
      <categories>
          
          <category> DevOps </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>系统调优</title>
      <link href="2020/05/26/interview/xi-tong-diao-you/"/>
      <url>2020/05/26/interview/xi-tong-diao-you/</url>
      
        <content type="html"><![CDATA[<p>PS：以下内容，网友提供    欢迎投稿     <a href="mailto:cyylog@aliyun.com">cyylog@aliyun.com</a></p><h3 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h3><p><strong>优化的目的</strong></p><pre><code>1. 提高资源的利用率2. 找到性能瓶颈以及缓解这个瓶颈（CPU，内存，IO调度、网络、使用的应用程序）3. 通过性能管理实现合理的资源分配，以及提升硬件的性价比4. 通常做两种调优：    response time:  响应时间   Web服务器，用户感受度好    throughput:         吞吐量       文件服务器，拷贝的速度</code></pre><p><strong>调优需要掌握的技能：</strong></p><pre><code>系统当前状况如何是不是有瓶颈的1. 必须了解硬件和软件2. 能够把所有的性能、指标量化，用数字说话3. 设置一个正常期待值，比如将响应速度调到1.5秒   （企业版操作系统在出厂时已经调优，适用于普遍的应用，再根据个人的环境进行微调）4. 建议有一定的开发能力5. 想要更好的调优，需要更多的经验的积累，从而有一定洞察力，调节时所给参数才最恰当</code></pre><p><strong>性能调优分层及效率问题：</strong></p><pre><code>- 业务级调优                例如：网站一定要使用Apache吗?    例如：将原有的调度器由LVS换成F5-BigIP？ redware    例如：将原有的调度器由Nginx换成Haproxy？    例如：能不能购买CDN？        内容发布网络    例如：通否增加服务器数量？        例如：将原有的Memcache换成Redis?    例如：将原有的MySQL Proxy换成MyCat?- 应用级调优               NFS，Samba，Apache、Nginx、php-fpm、MySQL、Oracle、KVM、LVS、PHP本身调优                    对于日志的处理rsyslog：可以调整记录的日志等级或延后日志写，从而避免大量的I/O操作    禁用一些不必要的服务如蓝牙、smart card，makewhatis, updatadb    从运维人员角度来说无非就是参数的修改和配置- kernel级调优        操作系统系统层面，即kernel调优具有普遍性：I/O CPU Network Memory，通常在系统初始完成    vm.dirty_expire_centisecs    = 2    net.ipv4.tcp_tw_recycle = 1           net.ipv4.tcp_tw_reuse = 1              net.ipv4.tcp_synack_retries = 5    考虑的是怎么让应用程序在我们系统上运行的更合理规范,或者说在硬件不变动的情况下,对系统优化提高性能和效率  </code></pre><p><strong>优化效果</strong></p><pre><code>    1.当前配置是否适合当前的运行环境和用户需求(如果是memcache 那我们考虑更多的可能是内存的消耗是不是更大些,如果是apache的话我们考虑的话可能就是cpu的消耗,所以所有的优化手段都要根据具体的环境,如果是编译需要的内存和cpu)    2.硬件的提升效果会更好，自上往下，效果越来越不明显</code></pre><p><strong>优化</strong></p><pre><code>＝＝调整系统kernel/应用的性能参数＝＝合理资源分配PAM，Cgroup(Docker)＝＝架构优化，Nginx负载集群、MySQL读写分离/Galera Cluster# man proc         /drop_cache</code></pre><p><strong>Kernel级别的优化:查看内核文档</strong></p><pre><code># yum -y install kernel-doc# ls /usr/share/doc/kernel-doc-3.10.0/Documentation/sysctl/00-INDEX  abi.txt  fs.txt  kernel.txt  net.txt  README  sunrpc.txt  vm.txt# grep  &quot;_reuse&quot; -R /usr/share/doc/kernel-doc-3.10.0/Documentation//usr/share/doc/kernel-doc-3.10.0/Documentation/networking/ipvs-sysctl.txt:conn_reuse_mode - INTEGER/usr/share/doc/kernel-doc-3.10.0/Documentation/networking/ip-sysctl.txt:tcp_tw_reuse - BOOLEAN# # grep &quot;drop_caches&quot; -R /usr/share/doc/kernel-doc-3.10.0/Documentation//usr/share/doc/kernel-doc-3.10.0/Documentation/sysctl/vm.txt:drop_caches</code></pre><h3 id="获取硬件信息"><a href="#获取硬件信息" class="headerlink" title="获取硬件信息"></a>获取硬件信息</h3><p>硬件方面，主要要调优的对象<br>    CPU<br>    Memory<br>    Storage<br>    Networking</p><p><strong>基本知识</strong></p><pre><code>基本知识： 所有存储类的设备    离CPU越近会越快，离CPU越远将越慢    离CPU越近存储的容量越小，离CPU越远存储的容量越大    离CPU最近的是寄存器，寄存器的时钟周期和CPU是一样的    离CPU稍远的存储：     L1，在CPU中，静态内存，工艺复杂    L2，使用的是动态高速内存    L3    L4    Memory    Storage   TB, PB# lscpu                                L1d cache                            一级数据缓存L1i  cache                            一级指令缓存L2                                        二级缓存（L2是否共享?）Thread(s) per core:            线程数为1，不支持超线程Core(s) per socket:            CPU核数Socket(s):                         1               几路NUMA node(s):                  1               不支持NUMA# x86info -c                         查看CPU型号# getconf -a                     显示所有系统配值变量值  </code></pre><p><strong>根据CPU访问内存的方法：</strong></p><pre><code>a. UMA：一致性内存访问，传统架构       MCH:      内存控制芯片，即北桥       ICH：     I/O控制芯片，即南桥，连接外设，硬盘，USB，慢速PCI总线设备b. NUMA：非一致性内存访问（内存分为多片，而不是UMA时的一片内存）       IOH：     I/O HUB，也可以叫北桥       NUMA    架构显著的特色是：内存划分成片，CPU访问本区的内存的时候，速度非常快</code></pre><p><img src="https://i.loli.net/2019/06/01/5cf21eb40842684062.png" alt=""></p><p><img src="https://i.loli.net/2019/06/01/5cf21ec23c19c60544.png" alt=""></p><p><strong>Memory的相关指标</strong></p><pre><code># cat /proc/meminfo# free# top# vmstatMemory size:内存效率重要指标：a. bandwidth:         带宽，使用的是DDR几代；例如PC2100，指2100M/s的吞吐量，即带宽b. latency:              延迟，纳秒级nsc. ECC内存 </code></pre><p>存储的相关指标</p><pre><code>主要的调优对像，对内存而言，特别慢拿16G的内存存数据！拿16G的硬盘存数据！当前两种磁盘类型：机械磁盘：    盘片电子SSD：     固态磁盘机械磁盘：昂贵的寻道时间 Expensive seek time主轴转速：    7200RPM 10000RPM(10k) 15000RPM(15k)缺点：容易坏优点：存储量非常高，价格低Burst speed:      突发速率，最快读写速率，指的是顺序读写 Sequential accessaverage speed: 平均读写速率，生产中不能保证是顺序读写 Random access调优： 进行大量的优化合并SSD：Electronic disk:  电子磁盘，没有机械部件No start-up time，读和写延迟非常低安静，发热量小，不怕震动，而且很轻，用电少价格高：在同等容量下比较            寿命相对短连接的方式：内部存储：        IDE（PATA），SATA，SAS，FC外部存储：        SCSI线连接, SAS线连接，SATA线连接，Fibre Channel, ISCSI，网络带宽，延迟，多路径都会影响到外部存储的速度4k/sector support： 4k对齐，效率更高（默认扇区大小512B）外圈快，内圈慢：磁盘转一圈，外圈读的扇区数多，所以数据写读时外圈快，内圈慢RHEL安装时，默认将/, /boot分区扔到了最快圈，交换区自动选择内圈（它认为swap不需要经常访问）</code></pre><p><strong>Networking Profile</strong></p><pre><code>带宽延迟尽量把不同的网络隔离开，让其处于不同的广播域，划分VLAN使用bonding或Team技术实现多网卡绑定，从而实现HA或LB（提高带宽）高端网卡支持虚拟化SR-IOV高端网卡有自己的处理芯片，网络上的数据到达时，不需要中断CPU</code></pre><p><strong>其它获得硬件性能指标工具</strong></p><pre><code>dmidecode                    直接查BIOS信息dmidecode -t 0            type 0主要是硬件信息powertop                        查看最耗电进程lspci lsusbethtool=================================================================================//检测是否有该设备[root@install ~]# lspci |grep -i eth03:00.0 Ethernet controller: Broadcom Corporation NetXtreme II BCM5708 Gigabit Ethernet (rev 12)05:00.0 Ethernet controller: Broadcom Corporation NetXtreme II BCM5708 Gigabit Ethernet (rev 12)[root@install ~]# lspci |grep -i fib12:02.0 Fibre Channel: Emulex Corporation Thor LightPulse Fibre Channel Host Adapter (rev 01)12:02.1 Fibre Channel: Emulex Corporation Thor LightPulse Fibre Channel Host Adapter (rev 01)# ethtool eth0Settings for eth0:    Supported ports: [ TP MII ]    Supported link modes:   10baseT/Half 10baseT/Full                             100baseT/Half 100baseT/Full                             1000baseT/Half 1000baseT/Full     Supported pause frame use: No    Supports auto-negotiation: Yes    Advertised link modes:  10baseT/Half 10baseT/Full                             100baseT/Half 100baseT/Full                             1000baseT/Half 1000baseT/Full     Advertised pause frame use: Symmetric Receive-only    Advertised auto-negotiation: Yes    Link partner advertised link modes:  10baseT/Half 10baseT/Full                                          100baseT/Half 100baseT/Full                                          1000baseT/Half 1000baseT/Full     Link partner advertised pause frame use: Symmetric    Link partner advertised auto-negotiation: Yes    Speed: 1000Mb/s    Duplex: Full    Port: MII    PHYAD: 0    Transceiver: internal    Auto-negotiation: on    Supports Wake-on: pumbg    Wake-on: g    Current message level: 0x00000033 (51)                   drv probe ifdown ifup    Link detected: yes# ethtool -i eth0driver: r8169version: 2.3LK-NAPIfirmware-version: rtl8168e-3_0.0.4 03/27/12bus-info: 0000:04:00.0supports-statistics: yessupports-test: nosupports-eeprom-access: nosupports-register-dump: yessupports-priv-flags: no# mii-tool eth0eth0: negotiated 100baseTx-FD flow-control, link ok//是否加载相应的驱动[root@install ~]# dmesg  |grep -i  fibEmulex LightPulse Fibre Channel SCSI driver 8.3.39scsi3 : Emulex LP1050 PCI-X Fibre Channel Adapter  on PCI bus 12 device 10 irq 19scsi4 : Emulex LP1050 PCI-X Fibre Channel Adapter  on PCI bus 12 device 11 irq 18查看FC HBA wwn号[root@install ~]#  cat /sys/class/fc_host/host3/port_name 0x10000000c9672e4a[root@install ~]#  cat /sys/class/fc_host/host4/port_name 0x10000000c9672e49</code></pre><p><strong>至强CPU</strong></p><pre><code>Intel E3，E5，E7代表了3个不同档次的至强CPU，至强“E系列”的这种命名方式有些类似桌面上的Core i3，i5，i7；比较通俗易懂的解释就是可以对应我们的豪华汽车生产商宝马3系，5系和7系。分别对应好，更好和最好。其中：至强E3处理器是第一款使用Haswell微架构的至强处理器芯片（目前，英特尔的多数芯片是以Ivy Bridge架构为基础），最多配置4个内核，最高支持32GB内存，耗电量只有13瓦，主要用于工作站和单路服务器；至强E5处理器主要用于中档服务器，最高支持768GB内存，耗电量为60至130瓦，适用入门级双路服务器、高性能双路和四路服务器，也是目前使用最为广泛的主流处理器；至强E7处理器是英特尔性能最高的服务器处理器，芯片包括30GB三级缓存，最高支持4TB内存，耗电量为130瓦。这种处理器可用于8路服务器。至于具体应用可以根据处理器的型号来判定，以英特尔最新发布的E5-2600 V2为例，这里的“2”，也就是连字符后的第一个数字，它代表处理器最多支持的并行路数，有1、2、4、8四种规格，分别代表了单路、双路、四路和八路。我们现在举例的这款E5-2600 至强CPU，连字符后的第一个数字是&quot;2&quot;，就表示这款CPU为双路，只能用于对应的双路芯片组的主板。紧接着，我们来看连字符后的第二个数字，它代表处理器封装接口形式，一共有2，4，6，8四种规格，分别是2对应Socket H2(LGA 1155)、4对应Socket B2(LGA 1356)、6对应Socket R(LGA 2011)、8对应Socket LS(LGA 1567)。我们举例的这款E5-2600，连字符后的第二个数字是&quot;6&quot;，对应Socket R(LGA 2011)然后，连字符后第三和第四位代表编号序列，一般是数字越大产品性能越高，价格也更贵。最后，看连字符后第四位数字后面的代表什么。紧跟第四位数字后的&quot;L&quot;代表是低功耗版，留空的话就代表是标准版。连字符后面最后的数字代表修订版本，比如v2、v3、v4等等，这次新发布的E5-2600 V2就是第二次升级版。注：LGA 1155：表示不同的封装技术</code></pre><h3 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h3><p>cpu的相关指标</p><p># cat /proc/cpuinfo    </p><p>​     物理的(多少路)，核心的，超线程        </p><pre><code>多路服务器：    双路四核，是指服务器/工作站有两个CPU，每个CPU都是四核处理器。    多路服务器/工作站的关键部件是多路主板，可安装多个处理器，双路主板举一示例如图：    一个CPU，配一套内存，双路就是双CPU加双套内存</code></pre><p><img src="https://i.loli.net/2019/06/01/5cf22857981f842559.png" alt=""></p><p><strong>CPU调度</strong></p><pre><code>cpu调度：3个进程    a  b  c 都是R cpu处理谁? 这样就要依靠调度程序?    a----b-----c 批处理操作系统同样3个进程    a  b  c  每个运行1秒 好像是cpu独占  分时操作系统哪种系统操作完消耗的时间少?批处理操作系统   OS从cpu的调度来分:分时                 分时操作系统以&quot;分时&quot;原则,为每个用户服务.将CPU的时间划分成若干个片段，称为时间片。操作系统把每个时间片分，轮流地切换给各终端用户的程序使用。由于时间间隔很短，每个用户的感觉就像他独占计算机一样。分时操作系统的特点是可有效增加资源的使用率。例如UNIX系统就采用剥夺式动态优先的CPU调度，有力地支持分时操作。批处理            批处理(batch processing )就是将作业按照它们的性质分组（或分批），然后再成组（或成批）地提交给计算机系统，由计算机自动完成后再输出结果，从而减少作业建立和结束过程中的时间浪费。        如:打印机就是采用这种操作系统实时            实时操作系统(RealTimeOperatingSystem，RTOS)是指使计算机能及时响应外部事件的请求在规定的严格时间内完成对该事件的处理，并控制所有实时设备和实时任务协调一致地工作的操作系统。实时操作系统要追求的目标是：对外部请求在严格时间范围内做出反应，有高可靠性和完整性。其主要特点是资源的分配和调度首先要考虑实时性然后才是效率。此外，实时操作系统应有较强的容错能力。区别:            批处理系统(batch processing system)中，一个作业可以长时间地占用cpu。而分时系统中，一个作业只能在一个时间片（Time Slice，一般取100ms）的时间内使用cpu。        批处理系统的目的：提高系统吞吐量和资源的利用率。        分时系统的目的：   对用户的请求及时响应，并在可能条件下尽量提高系统资源的利用率。进程与调度：进程：    程序是一个文件,而process是一个执行中的程序实例。    linux系统中创建新进程使用fork()系统调用。    利用分时技术，在linux操作系统上同时可以运行多个进程，当进程的时间片用完时，kernel就利用调度程序切换到另一个进程去运行。内核中的调度程序：    用于选择系统中下一个要运行的进程。你可以将调度程序看做在所有处于运行状态的进程之间分配CPU运行时间的管理代码。为了让进程有效的使用系统资源，又能让进程有较快的响应时间，就需要对进程的切换调度采用一定的调度策略。</code></pre><p><strong>时钟频率</strong></p><pre><code>CPU timer   固定频率给CPU发中断,CPU可停下来通过调度器处理下一个任务    #grep  HZ  /boot/config-x.x.x    #grep HZ /boot/config-2.6.32-358.el6.x86_64        CONFIG_NO_HZ=y        # CONFIG_HZ_100 is not set        # CONFIG_HZ_250 is not set        # CONFIG_HZ_300 is not set        CONFIG_HZ_1000=y ---------------------------1秒1000次        CONFIG_HZ=1000        CONFIG_MACHZ_WDT=m所有的linux操作系统都是基于中断驱动的：    当我们在键盘上按下一个按键时，键盘就会对CPU说，一个键已经被按下。在这种情况下，键盘的IRQ线路中的电压就会发生一次变化，而这种电压的变化就是来自设备的请求，就相当于说这个设备有一个请求需要处理。    [root@mail ~]#watch -n 1 cat /proc/interrupts    //包含有关于哪些中断正在使用和每个处理器各被中断了多少次的信息。               CPU0             0:        174   IO-APIC-edge      timer      1:         70   IO-APIC-edge      i8042      3:          1   IO-APIC-edge          4:          1   IO-APIC-edge          7:          0   IO-APIC-edge      parport0      8:          0   IO-APIC-edge      rtc0      9:          0   IO-APIC-fasteoi   acpi     12:       1397   IO-APIC-edge      i8042     14:          0   IO-APIC-edge      ata_piix     15:       4180   IO-APIC-edge      ata_piix     16:        945   IO-APIC-fasteoi   Ensoniq AudioPCI     17:     778014   IO-APIC-fasteoi   ehci_hcd:usb1, ioc0     18:          0   IO-APIC-fasteoi   uhci_hcd:usb2     19:        487   IO-APIC-fasteoi   eth0     第一列表示IRQ号,IRQ号决定了需要被CPU处理的优先级。IRQ号越小意味着优先级越高。     第二、三、四列表示相应的CPU核心被中断的次数。IO-APIC-edge表示终端接口，timer表示中断名称（为系统时钟）。174表示CPU0被中断了174次。i8042表示控制键盘和鼠标的键盘控制器。对于像rtc（real time clock）这样的中断，CPU是不会被中断的。因为RTC存在于电子设备中，是用于追踪时间的。NMI和LOC是系统所使用的驱动，用户无法访问和配置。     例如，如果CPU同时接收了来自键盘和系统时钟的中断，那么CPU首先会服务于系统时钟，因为他的IRQ号是 0 。     IRQ0 ：系统时钟（不能改变）     IRQ1 ：键盘控制器（不能改变）     IRQ3 ：串口2的串口控制器（如有串口4，则其也使用这个中断）     IRQ4 ：串口1的串口控制器（如有串口3，则其也使用这个中断）     IRQ5 ：并口2和3 或 声卡     IRQ6 ：软盘控制器     IRQ7 : 并口1。它被用于打印机或若是没有打印机，可以用于任何的并口。调整：每接收到一个时钟中断就要处理另一个任务.调度器----根据调度算法       频率高   响应速度高  吞吐量低       频率低   响应速度底  吞吐量高    桌面推荐高频率,服务器推荐低频率    对于应用程序的运行，最好的办法是纵向升级（提升CPU频率）而不是横向升级（增加CPU数量）。这取决于你的应用程序是否能使用到多个处理器。例如一个单线程应用程序的升级方式最好是更换成更快的CPU而不是增加为多个CPU</code></pre><p><strong>PS命令</strong></p><pre><code>ps命令：    ps -o user,pid,%cpu -p 3288    ps -eo  user,pid,%cpu  --sort %cpu     //升序 -%cpu 降序top命令#top -d 1    top - 10:18:15 up  1:45,  4 users,  load average: 2.44, 2.42, 1.82    Tasks: 225 total,   3 running, 222 sleeping,   0 stopped,   0 zombie    Cpu(s): 79.2%us, 17.6%sy,  0.0%ni,  0.3%id,  0.0%wa,  0.0%hi,  2.8%si,  0.0%st    Mem:   4019424k total,  2419520k used,  1599904k free,   248248k buffers    Swap:  8191992k total,        0k used,  8191992k free,   525780k cached----------------------------------------------------------快捷键：    P 按cpu排序    M 按内存排序    f  添加删除字段，带*的是默认显示  大写的是当前显示  小写的是现在没有显示的 可以关掉指定的列，开启需要的列，按对应的字母就可以    1 可以展开cpu，也就是如果有多个cpu可以这样查看 ，没有展开之前是平均值        top后按1，然后按W，会将此次的显示配置保存到 ~/.toprc 文件中,下次再top的时候就会直接显示多CPU使用率。可以在脚本中直接使用top的Batch模式    #top -bn1</code></pre><p><strong>一台服务器是否稳定</strong></p><pre><code>up后面的时间可以作为判断标准之一load average: 1 5 151分钟，5分钟，15分钟之前到现在的cpu平均负载(等待cpu处理的进程队列平均长度)负载：    正在运行的进程    进入到IO等待位置的进程我是cpu 你们是程序 没人跟我说话  我现在是没有负载的有一个人问问题 我有负载吗？    没有     如果再有一个人问问题，如果之前同学的问题处理完了或者他俩的问题很简单，我一次就解决完了，这时候是没有负载的    如果第一个问的问题很困难，我一时解决不完，这时候再有人问问题的时候我就产生负载了1分钟之内举例：    0   10  20    30  40  50  60  CPU     A   只用了10秒，这时候cpu的负载是1/6    B   用了20秒，  这时候负载是1/2    C   用30秒，    这时候负载是1最好的单核CPU负载是1加上cpu核数，最好的负载是跟核数相等，核数的2倍以内没什么大问题，2倍以上说明负载过高8核负载 25 15 3 ，这样的负载是没什么问题的但是一定要判断到25那个地方发生了什么事情，能不能把那个峰值化解掉，不然如果峰值越来越高，那么服务器可能承受不住比如邮件服务器的收发高峰和邮件备份产生的负载高峰，我们可以把他们两个操作分开成两个小高峰，这样最好-----------------------------------------------------------running 两个含义1.正在运行 2.可运行的      //也就是此程序必须在调用cpu之前要准备好运行sleeping 可以叫睡眠，等待或者阻塞stoped表示挂起(暂停)------------------------------------------------------------%us     用户态程序占用cpu百分比%sy     内核态程序占用cpu百分比%ni     调整过nice值的程序占用cpu百分比%id     cpu空闲百分比%wa    io等待消耗cpu的百分比（cpu空转）%hi     硬件中断占用cpu的百分比%si     软中断%st     cpu被偷走的百分比    ……………………………………………………    内核态和用户态        当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。即此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。这与处于内核态的进程的状态有些类似。     例：        #cat /etc/passwd        在用户级别执行cat     //这些开销就是用户的开销        要用cat查看文件，必须得去硬盘上找文件，那么需要有硬盘驱动，这样就会需要内核，所以就会用到系统调用，因为有了系统调用才能跟内核对话  //这些开销就是内核态的开销        在内存里就会有一个cat命令的进程 把cat命令所需要的Lib库准备好    常用的系统调用    open()    read()    write()    close()    us &gt; sy    用户的开销一般大于系统开销    us一般不会超过%70，如果大于%70，那看看是不是运行的程序是否过多或者一个类似死循环的程序    sy一般不会超过%30，如果大于%30，那看看是不是运行了大量的内核态程序，比如iptables和lvs都是内核态程序    ……………………………………………………    ni  nice值的调整可能两种情况:系统自动去调整或者人工调整  那么这里的百分比是指人工调整    id  空闲太高不好，浪费资源，那么在20-30之间最好        如果%idle 的值高但系统响应慢时，有可能是 CPU 等待分配内存，此时应加大内存容量        如果%idle 的值持续低于1，则系统的 CPU 处理能力相对较低，表明系统中最需要解决的资源是 CPU 。    wa        a在运行过程当中要产生10G数据，现在先产生了2G，cpu说你先停，你先把这2G写到硬盘上，但是现在硬盘慢，cpu要等，所以他可以去找b去运行，现在b程序发生了和a一样的情况，也在往硬盘写数据，那么cpu现在干什么？在等，这时候的等待状态我们称他为空转状态，所以通过这个数值可以判断硬盘慢不慢        如果%iowait 的值过高，表示硬盘存在I/O瓶颈    hi          中断：对cpu当前操作的一个打断        硬中断，也就是硬件产生的中断（比如键盘，鼠标，网卡）在实际工作当作，网卡产生的中断最多，    si  软件中断，比如说计划任务        硬中断优先级比软中断优先级高    st    这个数值是针对虚拟机的  他的值我们看不到        vm1        vm2          //虚拟机        vcpu     vcpu            //虚拟cpu        cpu                        //真实cpu        假如现在vm1正在使用vcpu，那么他实际上用的是cpu，那么这时候如果vm2要使用cpu的话，不能用，因为现在cpu正被vm1偷走了-------------------------------------------------------------buffers cached    cached这个是属于mem那一行的，说是这里放不下了所以才放到了下面    两者都是RAM中的数据。简单来说，buffer是即将要被写入磁盘的，cache是被从磁盘中读出来的。        buffer是由各种进程分配的，被用在如输入队列等方面，索引缓存，存inode信息。一个简单的例子如某个进程要求有多个字段读入，在所有字段被读入完整之前，进程把先前读入的字段放在buffer中保存。        cache经常被用在磁盘的I/O请求上，存block信息，如果有多个进程都要访问某个文件，于是该文件便被做成cache以方便下次被访问，这样可提高系统性能。    手动释放buffers和cached:    #echo 3 &gt; /proc/sys/vm/drop_caches  =======================优先级    作用：        1、优先级高会被优先调度。        2、时间片会不同。    范围：        早先优先级范围     nice范围        0                              -20        20                          0        39                         19        0~39                    -20~19        现在：        0-139  linux优先级的整个范围，其中0号为优先级最高，139为最低            0-99        RT实时进程(静态)优先级范围 ， 0号保留，设置时使用1-99            100-139  非实时进程(动态)的优先级别范围 (由nice值映射过来)         分类：            动态优先级和静态优先级                top里面显示的PR是动态优先级，数值越小有限级越高                SYSV又加了60个优先级  ，那60个优先级就是静态优先级                现在Linux在之前40个优先级的基础上加了100个静态优先级，RT        实时优先级肯定大于非实时优先级        实际优先级范围是99优先级最大，0最小，在往后，从RT的角度来看全是0，但是实际是0-39            0--------------------99 100-----------139          整个优先级范围           -99---FIFO RR---------0--------------0    从RT的角度看后面优先级都是0                                          0--------------39   后面部分实际优先级    查看实时进程优先级：        # chrt -p 5752        //pid为5752的进程在top内显示PR为20,但是在从RT的角度来看是0             pid 5752&#39;s current scheduling policy: SCHED_OTHER        pid 5752&#39;s current scheduling priority: 0                          优先级一样的时候先执行谁？        早期：单cpu,单用户，单任务            在运行一个应用程序的时候，使用内存，会有空闲内存，cpu空闲，硬盘空闲            但是当时的硬件配置相当低(比如4k的内存)，而且执行很快(汇编写的程序)，所以也不会出现资源浪费，那么现在随着硬件的性能提高就会出现资源浪费现象        现在：多cpu,多用户，多任务            假如有一个应用程序占用CPU时间太长，那么后面的程序会无法执行            所以内核会对同优先级的程序进程判断是cpu消耗型还是IO消耗型，IO消耗型的程序并不是不使用cpu，只是用的时间很短，所以我们让他们两个都可以运行，但是在io消耗型程序使用cpu的时候临时给他调整一下优先级            内核可以让cpu消耗型在+5范围内优先级进程偏移，io消耗型在-5范围内优先级进程偏移，所以这里的优先级是动态优先级，            程序分为几种:1.cpu消耗型（计算） 2.IO消耗型（通常如果不是恶意程序，基本上就是IO消耗型，比如QQ，只有在收发信息的一瞬间才会消耗cpu。听歌消耗的是硬盘和声卡也是IO消耗型）        cpu消耗型的 pri值为80~85 85标准cpu消耗型，如：死循环            io消耗型的    pri值为75~80  75标准io消耗型，往往是和用户交互的程序，如：bash,vi，下载    本身占CPU并不多，但I/0消耗多    调整优先级：        可以通过renice命令调整nice值,pri值调整不了,系统自已评估.        我们设置优先级别，设置的是nice 值，实际系统看的是pri值。用户调整nice值，系统会干预pri值        系统要考虑在两种进程的nice值一样的情况下,i/o消耗型的进程应该优先级别更高一些(也就是pri值更小)             ps -l              pri  ni              77   0   ps             75   0   bash        bash  典型的I/0消耗型,pri值大概为75        pri是系统以nice值为基数的调整            pri 浮动范围    85 &lt;---- 80 -----&gt; 75                                CPU                      I/O       进程队列中如果有实时进程除非它释放资源,才执行非实时进程.当然实时进程也有优先级别高的,先执行完高优先级的才执行一下个进程.</code></pre><p><strong>调度策略</strong></p><pre><code>       查看所有调度策略：        #chrt -m              SCHED_OTHER min/max priority    : 0/0            SCHED_FIFO min/max priority    : 1/99            SCHED_RR min/max priority    : 1/99            SCHED_BATCH min/max priority    : 0/0            SCHED_IDLE min/max priority    : 0/0            1/99是实时进程使用的调度策略            0/0非实时进程使用的调度策略            FIFO     先进先出，谁先来，处理谁            RR       分时算法，程序被分配时间片，每个程序使用一会儿            OTHER 跟RR一样论询，如果没有特殊情况跟RR一样            BATCH  批处理，来5个人处理一次            IDLE             FIFO 和 RR 属于实时进程（也叫静态优先级进程）的调度策略。优先级高于非实时进程（动态优先级进程） BATCH和OTHER ，如果一个实时进程准备运行，调度器总是试图先调度实时进程。            BATCH是2.6内核新加入的策略，这种类型额进程一般都是后台处理进程，总是倾向于跑完自己的时间片，没有交互性，对于这样的调度策略，调度器一般给的优先级比较低。如果有一个程序设置成BATCH，cpu会尽量给这个程序使用，但是一旦有OTHER，那么先给OTHER策略的程序 ，也就是OTHER优先级高            IDLE是只要有其他程序运行，我就不运行，也就是只有在cpu空闲的时候就把这个程序设置成IDLE            OTHER&gt;BATCH&gt;IDLE            IDLE的nice值比19还要低，rhel6新出的，rhel5没有        修改调度策略：                #chrt  调度中实时进程的优先级可以让一个非实时进程以实时进程的方式运行，也相当与提高了这个进程的优先级                #cat     执行一个cat命令                #ps -e | grep cat  查看PID                6183                #chrt -p 6183   查看默认策略                #chrt -p 10 6183   优先级改成10，默认策略变成RR                 #chrt -f 20 cat    在开始运行cat命令的时候制定优先级，策略为FIFO         top 中有RT字样的是实时进程：                例如：                    2 root      RT  -5     0    0    0 S  0.0  0.0   0:00.00 migration/0                  # ps -el  //结果中NI值为-的是实时进程                 只要实时进程处于r状态 那么非实时进程就没有时间片了                pid 10以内的进程为内核进程 是内核的一部分</code></pre><h4 id="cpu亲和力"><a href="#cpu亲和力" class="headerlink" title="cpu亲和力"></a>cpu亲和力</h4><pre><code>cpu亲和力（也就是cpu绑定）系统资源不够用，一台机子上跑了几个比较重要的服务，每天我们还要在上面进行个备份压缩等处理，网络长时间传输，这就很影响本就不够用的系统资源；这个时候我们就可以把一些不太重要的比如copy/备份/同步等工作限定在一颗cpu上，或者是多核的cpu的一颗核心上进行处理，虽然这不一定是最有效的方法，但可以最大程度上利用了有效资源，降低那些不太重要的进程占用cpu资源；cpu绑定：      把一个程序绑定到一个cpu上去执行    好处：        1.多核cpu使用的时候，内核会优先使用0，1号cpu，假如有4核，2，3号可能会利用率比较低，那么我们可以把不同的程序绑定到2，3号cpu上以提高cpu使用率        2.可以提高缓存命中率    安装软件：        util-linux-ng-2.17.2-12.9.el6.x86_64    查看cpu绑定:        # taskset -p 1         pid 1&#39;s current affinity mask: 3        affinity //cpu亲和力(也就是cpu绑定)        假如4核cpu：3 2 1 0   cpu编号从0开始        2^3+2^2+2^1+2^0=和 再把和换算成16进制就是mask后面的值，可以利用这个算式和值找到我们正在使用哪个cpu    绑定cpu:        #taskset -c 1，2 cat         把cat程序绑定到1号和2号cpu上执行    修改已经启动进程的cpu绑定：        # taskset -pc 0 11358        让进程11358运行在0号cpu上=======================================多并发：    多核情况下以线程方式运行效果更好一些,单核的话区别就不大了    进程和线程 有本质的区别        线程模式      创建和撤销开销小  资源竞争问题        进程模式         创建和撤销开销大  没有资源竞争问题    如apache 线程和进程模式 多核每秒处理并发访问量 达到1000 ，这时线程表现较好测试：#ab -n 1000 -c 1000 http://localhost当2000时 apache 挂了  ab命令最多支持2个万测试    测试nginx    单进程和多进程    加大页面内容    cps 每秒的并发连接数(TCP)    qps 每秒的并发请求数 GET/HEAD/DELETE/PUT--------------------------------------平衡cpu中断:        上下文切换:        cpu读取数据的时候会从L1,L2,L3等一级二级三级缓存里面读，先去L1找，L1没有，去L2里找，L2没有，去L3找，L3没有找内存，内存没有找硬盘。        如果A被处理要把A放到L1里面，那么现在B需要处理，所以需要把B放到L1里，那么原来L1里的A清除掉，这就是上下文切换    当产生中断的时候就会产生一次上下文切换    a还没有运行完的时候，出现一个中断信号，cpu会处理这个中断，处理完成再回来处理a    那么打断多了好还是少了好?不一定，多有多的好处，少有少的好处        打断少了会增加吞吐量，但是响应就会变慢        所以在中断的时候要考虑是要吞吐量还是要响应能力    假如我是4核cpu：        我们发现大部分中断都集中在一个cpu上，所以我们可以平衡中断，把中断平分到其他cpu上去            #cat /proc/interrupts   显示系统内已经注册的中断            第1列注册了的中断编号   第2，3，4，5列 每个cpu处理了多少次中断        自动平衡，rhel6直接启动这个命令就可以            #/etc/init.d/irqbalance start              rhel5里面没有自动平衡，只能手工平衡            rhel6如果想手工平衡的话，需要关闭上面的irqbalance服务            手工平衡实验：                确定想调整谁，就记住他的中断编号，然后去/proc/irq/里面找到相应的编号，比如23  /proc/irq/23                #cat /proc/irq/23/smp_affinity  这个文件里的值就是亲和力，算法一样跟之前一样                实验：                #watch -n 1 cat /proc/interrupts   1秒钟监控一次后面的程序                然后拿另一台机器一直ping这台监控机器，我们发现网卡中断在cpu0上，那么现在要求把网卡中断交给cpu1处理                28:   25202611    1428501   PCI-MSI-edge      eth0                #echo 2 &gt; /proc/irq/28/smp_affinity                发现中断会跑到第2块儿cpu上</code></pre><h4 id="cpu监控"><a href="#cpu监控" class="headerlink" title="cpu监控"></a>cpu监控</h4><pre><code>相关监测命令系统负载 uptime                 举例：             处理器 1            1分钟的负载值     &lt;=3CPU使用率TOP工具：   第三排信息值Cpu(s): 消耗CPU处理时间的百分比  （iostat 看更全的单词）95.8%us,        用户态     1.1%sy,          内核态 2.6%ni,          优先级切换0.0%id,          CPU空闲                ＊＊＊0.0%wa,      等待，IO输入输出等待0.0%hi,          硬中断                           什么叫中断呢？  每个硬件都有会中断地址/proc/interrupts0.5%si,          软中断0.0%st        CPU偷窃时间    ，与xen虚拟化有关系[root@xen ~]# iostat Linux 2.6.18-194.el5xen (xen.pg.com)    2011年01月18日avg-cpu:  %user   %nice %system %iowait  %steal   %idle               2.75     0.75      1.31        1.89       0.01       93.29Device:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtnsda               7.46       152.21        82.99    1240948     676550sda1              1.05        11.99         0.03      97781        256sda2              0.00         0.00         0.00          6          0sda5              0.12         5.22         0.00      42549          0sda6              0.05         1.30         0.00      10621         16sda7              0.01         0.22         0.00       1818         38sda8              0.01         0.16         0.00       1315          0sda9              6.22       133.26        82.95    1086402     676240观测占用CPU时间top    (这个命令本身就挺消耗CPU时间的)找出 R 状态的进程。    临时:    使用renice 调整进程的优先级。    治本：    要明确这个进程的功能了。            如果有问题的，结束，修改程序。            如果没有问题，是正常的进程。花钱买CPU。举例：    WEB服务器（PHP）    CPU负载跟CPU使用率都很高，而且CPU不能扩充。    怎么办？        “集群“进程列表:    ps    只对具体进程进行观测 #ps -eo &quot;pid,comm,rss,pcpu&quot; --sort pcpu  升序#ps -eo &quot;pid,comm,rss,pcpu&quot; --sort -pcpu  降序#ps -eo &quot;pid,comm,rss,pcpu,rtprio,ni,pri,stat&quot; --sort -pcpu   实时进程优先级   如果显示为空，说明不是实时进程man psAIX FORMAT DESCRIPTORSThis ps supports AIX format descriptors, which work somewhat like the formatting codes ofprintf(1) and printf(3). For example, the normal default output can be produced with this:ps -eo &quot;%p %y %x %c&quot;. The NORMAL codes are described in the next section.CODE   NORMAL   HEADER%C     pcpu     %CPU%G     group    GROUP%P     ppid     PPID%U     user     USER%a     args     COMMAND%c     comm     COMMAND%g     rgroup   RGROUP%n     nice     NI%p     pid      PID%r     pgid     PGID%t     etime    ELAPSED%u     ruser    RUSER%x     time     TIME    %y     tty      TTY%z     vsz      VSZ多核心监测mpstat工具：    mpstat是Multiprocessor  Statistics的缩写，是实时系统监控工具。其报告与CPU的一些统计信息，这些信息存放在/proc/stat文件中。在多CPUs系统里，其不 但能查看所有CPU的平均状况信息，而且能够查看特定CPU的信息。mpstat最大的特点是：可以查看多核心cpu中每个计算核心的统计数据；而类似工 具vmstat只能查看系统整体cpu情况    #mpstat -P ALL 1 1000    #mpstat [-P {|ALL}] [internal [count]]    参数 解释    -P {|ALL} 表示监控哪个CPU， cpu在[0,cpu个数-1]中取值    internal 相邻的两次采样的间隔时间、    count 采样的次数，count只能和delay一起使用    当没有参数时，mpstat则显示系统启动以后所有信息的平均值。有interval时，第一行的信息自系统启动以来的平均信息。从第二行开始，输出为前一个interval时间段的平均信息。    [root@xen ~]# mpstat     Linux 2.6.18-194.el5xen (xen.pg.com)    2011年01月18日    12时16分20秒  CPU   %user   %nice    %sys %iowait    %irq   %soft  %steal   %idle    intr/s    12时16分20秒  all    2.70    0.62    1.19    1.64    0.00    0.00    0.03   93.82    212.95    [root@xen ~]# mpstat -P ALL    Linux 2.6.18-194.el5xen (xen.pg.com)    2011年01月18日    12时16分29秒  CPU   %user   %nice    %sys %iowait    %irq   %soft  %steal   %idle    intr/s    12时16分29秒  all    2.70    0.62    1.19    1.64    0.00    0.00    0.03   93.82    213.14    12时16分29秒    0    3.10    0.63    1.39    2.71    0.00    0.00    0.04   92.14    121.29    12时16分29秒    1    2.31    0.61    0.98    0.58    0.00    0.00    0.02   95.50     91.85[root@xen ~]# mpstat -P 0 1 10 每隔一秒取一次，取10次高级系统检查sar -u    使用率sar -q    系统平均负载立刻采集显示 &lt;interval&gt;  &lt;count&gt; sar -q 1 10sar -u 1 10 即时性的报告获取CPU各个核心信息sar -u -P ALL 1[root@xen sa]# sar -I ALL 1获取每个进程CPU使用率，注意默认这个数据不记录在数据库。sar -x ALL 1 3  *指定文件读取sar -u -f /var/log/sa/sa28输出SAR格式数据sar -u 1 10 -o /tmp/ooo根据时间过滤数据sar -u -s 13:00:00 -e 13:05:01[root@xen sa]# sar -u -f /var/log/sa/sa18  -s 09:50:01 -e 12:40:01Linux 2.6.18-194.el5xen (xen.pg.com)    2019年01月18日09时50分01秒       CPU     %user     %nice   %system   %iowait    %steal     %idle10时00分01秒       all      2.08      0.00      0.32      0.15      0.01     97.4410时10分01秒       all      1.74      0.00      0.36      0.21      0.01     97.6810时20分01秒       all      3.04      0.00      0.33      0.02      0.01     96.6010时30分01秒       all      6.22      0.00      1.16      0.15      0.01     92.4510时40分01秒       all      2.79      0.17      0.75      0.16      0.01     96.1310时50分01秒       all      5.55      9.29      9.93     15.51      0.03     59.6811时00分01秒       all      4.32      0.50      1.28      0.49      0.01     93.4011时10分01秒       all      0.03      0.00      0.02      0.00      0.01     99.9411时20分01秒       all      0.03      0.00      0.03      0.06      0.01     99.8711时30分01秒       all      0.04      0.00      0.01      0.03      0.01     99.9111时40分01秒       all      0.04      0.08      0.04      0.04      0.01     99.7911时50分01秒       all      3.06      0.00      0.67      0.03      0.01     96.2312时00分01秒       all      2.72      0.00      0.70      1.17      0.23     95.1712时10分01秒       all      0.64      0.00      0.28      0.04      0.05     98.9912时20分01秒       all      3.52      0.00      0.66      0.04      0.07     95.7012时30分01秒       all      4.52      0.00      1.05      0.04      0.08     94.3112时40分01秒       all      4.31      0.08      1.22      0.05      0.08     94.27Average:          all      2.63      0.60      1.11      1.07      0.04     94.56===============================================    通过上面那些工具可以搜集一段时间的数据，通过数据可以分析系统状态比如在公司写服务器运行报告的时候，怎么写，可以写这些工具搜集的信息实际上搜集那些信息不用我们自己去做，如果安装了sysstat工具，那么就会有下面的计划任务    # ls /etc/cron.d/sysstat     /etc/cron.d/sysstat  这个计划任务会给我生成下面的记录文件，这些记录文件记录了cpu，mem和net，io等等所有的信息    # cd  /var/log/sa/        sa01 sa07  这些文件后面的数字是日志，比如01就是1号    # sar -f sa01 查看那些记录文件[root@xen sa]# sar  -f /var/log/sa/sa18 Linux 2.6.18-194.el5xen (xen.pg.com)    2019年01月18日09时50分01秒       CPU     %user     %nice   %system   %iowait    %steal     %idle10时00分01秒       all      2.08      0.00      0.32      0.15      0.01     97.4410时10分01秒       all      1.74      0.00      0.36      0.21      0.01     97.6810时20分01秒       all      3.04      0.00      0.33      0.02      0.01     96.6010时30分01秒       all      6.22      0.00      1.16      0.15      0.01     92.4510时40分01秒       all      2.79      0.17      0.75      0.16      0.01     96.1310时50分01秒       all      5.55      9.29      9.93     15.51      0.03     59.6811时00分01秒       all      4.32      0.50      1.28      0.49      0.01     93.4011时10分01秒       all      0.03      0.00      0.02      0.00      0.01     99.9411时20分01秒       all      0.03      0.00      0.03      0.06      0.01     99.8711时30分01秒       all      0.04      0.00      0.01      0.03      0.01     99.9111时40分01秒       all      0.04      0.08      0.04      0.04      0.01     99.7911时50分01秒       all      3.06      0.00      0.67      0.03      0.01     96.2312时00分01秒       all      2.72      0.00      0.70      1.17      0.23     95.1712时10分01秒       all      0.64      0.00      0.28      0.04      0.05     98.9912时20分01秒       all      3.52      0.00      0.66      0.04      0.07     95.7012时30分01秒       all      4.52      0.00      1.05      0.04      0.08     94.3112时40分01秒       all      4.31      0.08      1.22      0.05      0.08     94.27Average:          all      2.63      0.60      1.11      1.07      0.04     94.56[root@xen sa]# sar -u -f /var/log/sa/sa18 Linux 2.6.18-194.el5xen (xen.pg.com)    2019年01月18日09时50分01秒       CPU     %user     %nice   %system   %iowait    %steal     %idle10时00分01秒       all      2.08      0.00      0.32      0.15      0.01     97.4410时10分01秒       all      1.74      0.00      0.36      0.21      0.01     97.6810时20分01秒       all      3.04      0.00      0.33      0.02      0.01     96.6010时30分01秒       all      6.22      0.00      1.16      0.15      0.01     92.4510时40分01秒       all      2.79      0.17      0.75      0.16      0.01     96.1310时50分01秒       all      5.55      9.29      9.93     15.51      0.03     59.6811时00分01秒       all      4.32      0.50      1.28      0.49      0.01     93.4011时10分01秒       all      0.03      0.00      0.02      0.00      0.01     99.9411时20分01秒       all      0.03      0.00      0.03      0.06      0.01     99.8711时30分01秒       all      0.04      0.00      0.01      0.03      0.01     99.9111时40分01秒       all      0.04      0.08      0.04      0.04      0.01     99.7911时50分01秒       all      3.06      0.00      0.67      0.03      0.01     96.2312时00分01秒       all      2.72      0.00      0.70      1.17      0.23     95.1712时10分01秒       all      0.64      0.00      0.28      0.04      0.05     98.9912时20分01秒       all      3.52      0.00      0.66      0.04      0.07     95.7012时30分01秒       all      4.52      0.00      1.05      0.04      0.08     94.3112时40分01秒       all      4.31      0.08      1.22      0.05      0.08     94.27Average:          all      2.63      0.60      1.11      1.07      0.04     94.56[root@xen sa]# sar -q -f /var/log/sa/sa18 Linux 2.6.18-194.el5xen (xen.pg.com)    2019年01月18日09时50分01秒   runq-sz  plist-sz   ldavg-1   ldavg-5  ldavg-1510时00分01秒         0       220      0.03      0.12      0.1710时10分01秒         0       220      0.25      0.10      0.1010时20分01秒         0       220      0.02      0.07      0.0810时30分01秒         0       220      0.16      0.19      0.1210时40分01秒         0       225      0.32      0.22      0.1310时50分01秒         4       227      1.65      1.28      0.6911时00分01秒         0       220      0.00      0.24      0.4011时10分01秒         0       220      0.00      0.02      0.1911时20分01秒         0       221      0.00      0.00      0.0811时30分01秒         0       221      0.00      0.00      0.0211时40分01秒         0       221      0.08      0.02      0.0111时50分01秒         2       221      0.42      0.22      0.0812时00分01秒         0       229      0.17      0.13      0.0812时10分01秒         0       232      0.00      0.01      0.0312时20分01秒         2       228      0.30      0.16      0.0912时30分01秒         1       228      0.33      0.18      0.1112时40分01秒         1       228      0.31      0.20      0.11Average:            1       224      0.24      0.19      0.15===============================================</code></pre><h3 id="mem"><a href="#mem" class="headerlink" title="mem"></a>mem</h3><pre><code>    内存的特点:    速度快,所存数据不会保存,内存的最大消耗来源于进程测试内存速度：安装软件:memtest86+-4.10-2.el6.x86_64.rpm执行 memtest-setup命令 多出一个操作系统内存存储的数据有那些?    程序代码,程序定义的变量(初始化和未初始化),继承父进程的环境变量,进程读取的文件,程序需要的库文件.还有程序本身动态申请的内存存放自己的数据    除了进程以外还有内核也要占用,还有buffer和cache,还有共享内存(如共享库)    我们使用管道符| 进程之间通讯也要使用到内存,socket文件那我们可以优化哪部分程序?    内核内存不能省    buffer/cache不能省    进程通讯不省系统支持的内存大小：    2的32次方 32位系统支持的内存  windows受到约束  linux只要换个pae(物理地址扩展)内核 可以支持2的36次方     2的64次方 查看系统内存信息    [root@localhost ~]# free -m                total           used     free     shared     buffers     cached    Mem:     1010         981         29         0         145         649    -/+ buffers/cache:     186         824    Swap:     2047         0             2047    share 在6之前包括6，这个地方永远都是0，已经被废弃了，rhel7里面已经可以正常显示    # cat /proc/meminfo | grep -i shm   share就是这个值,free和vmstat都是从/proc/meminfo文件里面搜集的信息    Shmem:             26620 kB    used包括buffers和cached，是已使用的内存+buffers+cached ，剩下的是free    -/+ buffers/cache:        186       824    186是减去buffers和cached之后的物理内存，824是总内存减去186之后的值    buffers  索引缓存 存inode信息    cached 页缓存    存block信息            catched实验:                # watch -n 0.5 free -m  监控内存信息                在另外一个窗口dd一个1G的文件，观察buffer和cache                # dd if=/dev/zero of=abc bs=1000M count=1                从/dev/zero里面读了1G数据到cache里面                dd之前:                             total         used       free     shared    buffers     cached                Mem:     3724    619        3105          0         59        242                dd之后:                             total         used       free     shared    buffers   cached                Mem:     3724    1652       2071          0         59       1246            buffers实验:                #find /      把/下所有文件都列出来  会读到directory block，通过inode找到文件名，有多少个文件就会读多少次目录块，所以我们现在的查找实际上是块操作，所以使用的是buffer                find之后:                             total         used       free     shared    buffers     cached                Mem:     3724    1713       2010          0         95       1246    [root@localhost ~]# vmstatprocs -----------memory----------           ---swap--   -----io----     --system-- -----cpu------r b     swpd   free   buff       cache         si     so         bi     bo     in      cs            us sy id wa st0 0     0         48584 118300 663564       0      0              12 23     60  240        3  2   95 0  0procs:    r   正在运行或可运行的进程数，如果长期大于cpu个数，说明cpu不足，需要增加cpu    b  block  但是这个是阻塞，表示在等待资源的进程数，比如正在等待I/O、或者内存交换等。  由于硬盘速度特别慢而导致内存同步的时候没成功，那么现在告诉程序，说你先不要产生数据，这就是阻塞！！！！！ ---&gt;  b越大证明硬盘压力很大memory    swpd 切换到内存交换区的内存数量(k表示)。如果swpd的值不为0，或者比较大，比如超过了100m，只要si、so的值长期为0，系统性能还是正常    free 当前的空闲页面列表中内存数量(k表示)    buff 作为buffer cache的内存数量    cache: 作为page cache的内存数量swap    si swapin    把swap分区的数据放到内存    so swapout  把内存数据放到磁盘    通过上面两个可以分析内存的使用情况，如果swap有数据是不是内存不够用了？不一定，因为系统会把一些用不到的进程放到swap里面，把腾出来的空间做缓存，如果发现si,so里面有数据，说明内存可能不够用了    IO    bi blockin 这个是块进来  ，把块儿从硬盘搬进来，也就是说bi是读    bo blockout  把块儿从内存搬到硬盘，也就是说bo是写        实验:        # vmstat -1         # dd if=/dev/zero  of=/aa bs=1G count=1   //这条命令之后查看bo的数值，发现bo产生数据         记录了1+0 的读入         记录了1+0 的写出         1073741824字节(1.1 GB)已复制，4.90872 秒，219 MB/秒        #find /        //这条命令之后查看bi，发现bi产生数据        如果 一直开着vmstat发现bo 5秒钟一个数，这就是因为脏数据5秒钟一次        如果要拿这个数据做图，bo的第一个数据一定要剔除到，这个数字是上一次重启到敲vmstat这条命令之间的平均值，所以这个数字没用system 显示采集间隔内发生的中断数    in 列表示在某一时间间隔中观测到的每秒设备中断数。    cs列表示每秒产生的上下文切换次数cpu：    剩下的就是cpu的各种使用百分比以上解释都可以查看man手册:#man vmstat    ========================================buffer/cache根据时间和数据大小同步  主要用于写缓存内核里面的一套系统：伙伴系统，负责把内存里面的数据往硬盘上搬    rhel5：        kswapd pdflush        kswapd负责说什么时候搬数据        pdflush负责干活儿,他会一直开启着    rhel6:        kswapd负责说什么时候搬数据，但是干活儿的不是pdflush了        有需要搬的数据的时候，才产生一个进程---&gt; flush 主设备号:从设备号 负责搬数据已经同步到硬盘的数据就是干净数据# cat /proc/sys/vm/dirty_    查看的是脏数据（缓存内还没来得急同步到硬盘的数据）dirty_background_bytes     dirty_expire_centisecsdirty_background_ratio     dirty_ratiodirty_bytes                dirty_writeback_centisecs[root@localhost ~]# cat /proc/sys/vm/dirty_expire_centisecs   //想知道这里面是什么可以使用下面的man或者kernel-doc查看2999        //单位百分之一秒，这里也就是30秒，30秒之后标记为脏数据，意味着用户写的数据在30秒之后才有可能被刷入磁盘，在这期间断电可能会丢数据[root@localhost ~]# cat /proc/sys/vm/dirty_writeback_centisecs499         //  5秒钟往硬盘同步一次数据5秒同步一次脏数据（在缓存中的）假如我内存1G1秒  100M2秒  300M3秒  400M4秒  400M还没到5秒，但是内存使用已经超过1G了，这时候怎么办？下面的文件来解决[root@localhost ~]# cat /proc/sys/vm/dirty_ratio40          //如果单个进程占用的buffer/cache达到内存总量的40%,立刻同步。假如我内存1G，一个进程1秒  1M2秒  3M3秒  4M4秒  40M那要是1000个进程呢？这时候怎么办？下面的文件来解决[root@localhost ~]# cat /proc/sys/vm/dirty_background_ratio10          //所有进程占用的buffer/cache使得剩余内存低于内存总量的10%，立刻同步# cat /proc/sys/vm/dirty_background_bytes //上面的ratio文件用百分比，这个用字节限制，但是百分比存在的时候，字节不生效0如果服务器是一个数据服务器，比如NAS，dirty_writeback和dirty_ratio里面的数值可以适当改大一点,存储需要频繁读数据的时候，可以直接从内存里面读，而且在同步数据的时候会使用更大的连续的块儿。=============================================释放buffer/cache    [root@localhost ~]# cat /proc/sys/vm/drop_caches    0    1 释放buffer    2 释放cache    3 buffer/cache都释放    需要编译安装一个程序，在make的时候报错内存不足，这时候就可以释放一下缓存，一般情况下不要用    # watch -n 0.5 free -m    # echo 3 &gt; /proc/sys/vm/drop_caches=============================内存如果真耗尽了，后果无法预测OOM进程  OOM killer out      当内存耗尽的时候，系统会出现一个OOM killer进程在系统内随机杀进程    每个运行的程序都会有一个score(分)，这个是不良得分，所以谁分高，就杀谁    如果还不行的话，他会自杀，也就是杀kernel，就会出现内核恐慌(panic),所以会死机    实验：        #cat         # ps -el | grep cat        0 S     0  9566  2975  0  80   0 - 25232 n_tty_ pts/1    00:00:00 cat        # cat /proc/9566/oom_score        1        # cat /proc/9566/oom_adj        0 可以用这个值干预上面oom得分        -17 15     -17免杀，15是先干掉        # echo 15 &gt; /proc/9566/oom_adj        # echo f &gt; /proc/sysrq-trigger   //启动OOM_KILLER 必杀一个        # cat    //因为上面已经把9566的adj改成了15，所以这次启动杀死了cat进程          已杀死 swap     那么到底怎么解决内存耗尽的问题？swap    假如a，b，c已经把内存占满了，那么来了个d，内核先看看abc谁不忙，就把谁的数据先放到swap里面去，比如a不用，把a的数据放到swap里面去，释放出来的空间给d    swap分区分多大？现在内存很大比如256G，那么就没必要2倍了。。。    什么样的数据才能往swap里面放？        # cat /proc/meminfo | grep -i active         Active:           233836 kB         Inactive:        1280348 kB         Active(anon):     138780 kB         Inactive(anon):    26740 kB         Active(file):      95056 kB         Inactive(file):  1253608 kB        active活跃数据，inactive非活跃数据，又分为匿名数据和文件数据        匿名数据不能往swap里面放        文件形式的active不能往swap里放，只有文件的inactive才能往swap放               所以并不是有了swap，内存就解决了    什么时候放进去？根据swap_tendency（swap趋势）        swap_tendency = mapped_ratio/2 + distress + vm_swappiness          这就是swap趋势，如果这个值到达100，就往交换分区里面放，如果小于100，尽量不往里面放，但是就算到100，也只能说内核倾向与要往swap里面放，但也不一定放        系统就只开放第三个给用户设置         # cat /proc/sys/vm/swappiness  swap的喜好程度，范围0-100          60=============================使用内存文件系统    #df -h    tmpfs                 1.9G  224K  1.9G   1% /dev/shm  （共享内存）    tmpfs   内存里面的临时文件系统  系统会承诺拿出50%（这里是2G）的空间来做SHM，只是承诺，实际用多少给多少，如果内存比较富裕的情况下，我们可以拿内存当硬盘使用    #mount  -t tmpfs -o size=1000M tmpfs /mnt   //挂内存    #dd if=/dev/zero of=/mnt/file1 bs=1M count=800     记录了800+0 的读入    记录了800+0 的写出    838860800字节(839 MB)已复制，0.310507 秒，2.7 GB/秒    //这里用的是内存的速度    # dd if=/dev/zero of=/tmp/file1 bs=1M count=800 oflag=direct     记录了800+0 的读入     记录了800+0 的写出     838860800字节(839 MB)已复制，8.77251 秒，95.6 MB/秒   //这里用的是硬盘的速度    如果临时对某一个目录有较高的io需求，可以使用上面的方法使用内存    ----------------------------------------------------------------------------------------------    # mount -t tmpfs -o size=20000M tmpfs /mnt    //发现这样也可以，为什么，这只是承诺给20G，并没有实际给20G    #dd if=/dev/zero of=/mnt/file1   //不指定多大，把swap关闭（如果不关会等半天），这样就会把内存耗尽，========================虚拟内存和物理内存    查看：        #top        VIRT RES SHR    虚拟内存：        应用程序没办法直接使用物理内存，每个程序都有一个被内核分配给自己的虚拟内存    虚拟内存申请：        32位CPU,2^32也就是4G        64位cpu,2^64        每个程序都最多能申请4G的虚拟内存，但是现在这4G内存还和物理内存没关系呢，a说我先用100M，然后内核就会把100M映射给物理内存        VIRT就是程序运行的时候说申请的虚拟内存，RES就是映射的内存    为什么要有虚拟内存？            跟开发有关系，内存是有地址空间的，开发者在调用内存的时候如果直接调用物理内存，开发者不知道哪块儿地址被占用了，所以在中间内核站出来给开发者分配，开发者只需要提出需要多大内存，由内核来解决你的内存就可以了                ------------                程序1 程序2                4G     4G                -----------                kernel                -----------                物理内存                -----------            以上3层，第一层就是程序可以使用的虚拟内存，程序可以跟内核申请需要多少内存，内核就分配相应大小的物理内存给程序就可以了========================映射表：概念：    内存是分页的，1个page是4k(默认值),在硬盘上分块，硬盘数据和内存数据是一一对应问题：    条目非常多，查询特别慢解决：    固有方法：        硬件TLB ，在cpu里面，用来解决查询映射表慢的问题，第一次查询过之后把结果缓存到TLB里面，以后再查的时候就可以直接从TLB里面提取            # yum install x86info            # x86info  -a  可以查询TLB信息    自定义方法：        如果page变大，条目就会变少，这样就会提高查询速度        大于4k的分页称为hugepage 巨页 ，但是这个需要程序支持        那我们现在的操作系统是否支持巨页            # cat /proc/meminfo | grep -i hugepage            AnonHugePages:     26624 kB            HugePages_Total:       0      我现在没有巨页            HugePages_Free:        0            HugePages_Rsvd:        0            HugePages_Surp:        0            Hugepagesize:       2048 kB    说明现在我的系统支持2M的巨页        假如一个程序需要200M的巨页，那么就要把total改成100            #echo 100 &gt; /proc/sys/vm/nr_hugepages  //修改巨页total数目            #mkdir dir1            #mount -t hugetlbfs none /dir1    那么现在程序使用/dir1就可以了外翻：    TLB(Translation Lookaside Buffer)传输后备缓冲器是一个内存管理单元用于改进虚拟地址到物理地址转换速度的缓存。TLB是一个小的，虚拟寻址的缓存，其中每一行都保存着一个由单个PTE组成的块。如果没有TLB，则每次取数据都需要两次访问内存，即查页表获得物理地址和取数据========================进程间通信(IPC)种类：        进程间通信的方式有5种:    1.管道(pipe)      本地进程间通信，用来连接不同进程之间的数据流    2.socket    网络进程间通信，套接字(Socket)是由Berkeley在BSD系统中引入的一种基于连接的IPC，是对网络接口(硬件)和网络协议(软件)的抽象。它既解决了无名管道只能在相关进程间单向通信的问题，又解决了网络上不同主机之间无法通信的问题。    以上两种unix遗留下来的    3.消息队列(Message Queues)  消息队列保存在内核中，是一个由消息组成的链表。    4.共享内存段(Shared Memory)  共享内存允许两个或多个进程共享一定的存储区，因为不需要拷贝数据，所以这是最快的一种IPC。    5.信号量集(Semaphore Arrays)        System V的信号量集表示的是一个或多个信号量的集合。查看：    ipc 进程间通信    #ipcs   //这条命令可以看到后3种,前两种可以通过文件类型查看含义：    管道        a | b        在内存打开一个缓冲区，a把结果存到缓冲区，b去缓冲区里面拿数据        管道通信的时候 独木桥：特点--&gt;只能一个人 单向  先进先出        3个人过桥，一个一个的过，那如果100个人过，速度会很慢，所以管道传输的数据有限    socket           IE浏览器  访问网站 通过端口 端口在系统内实际不存在是个伪概念，只是一个标识，        a会打开一个buffer  b会打开一个buffer  ，这两个buffer用来接受数据包，并且重组，交给apache的socket，apache就会去socket接受数据    消息队列        跟管道基本一样  也是独木桥，也是单向，先进先出，但是他会对消息进程排队，谁着急谁先走，那么过河的人多了之后，同样也是数据传输较慢    共享内存段        开辟一块内存，a把数据全都丢到共享内存里面，b去共享内存拿数据，而且b可以按需选择拿哪些数据        共享内存段在oracle里面肯定要使用    信号量             在a和b之间传递信号，a把一个文件锁住给b发一个信号，说这个文件我正在使用            信号所携带的数据量非常有限，只能指定信号是干什么用的==============================================查看内存使用情况[root@localhost ~]# sar -r 1 101时31分38秒   kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit01时31分39秒   6045368     1917916        24.08        67236       649020     2435764     17.73kbcommit：保证当前系统所需要的内存,即为了确保不溢出而需要的内存(RAM+swap).%commit：这个值是kbcommit与内存总量(包括swap)的一个百分比.</code></pre><h3 id="I-O"><a href="#I-O" class="headerlink" title="I/O"></a>I/O</h3><pre><code>I/O这块是影响系统性能比较大的地方查看速度：    #hdparm -t /dev/sda影响I/O性能的因素1.mount2.文件系统：日志文件系统和非日志文件系统3.I/O调度算法4.RAID，LVM（条带化） 网络附加存储（cpu的iowait转移到存储服务器）</code></pre><h5 id="mount"><a href="#mount" class="headerlink" title="mount"></a>mount</h5><p>​    rw    ro</p><hr><p>​    atime noatime</p><hr><p>​    Update inode access time for each access. This is the default.<br>​    atime是这里影响性能的一个重要因素，可以用noatime关掉</p><p>​    async、sync</p><hr><p>​    [root@node1 ~]# mount /dev/sdb1 /mnt/<br>​    [root@node1 ~]# mount -o remount,sync /dev/sdb1 /mnt/</p><p>​    数据传输3种:<br>​        sync   应用程序产生数据也是写到缓存，但是会等到缓存内的脏数据同步到硬盘之后才会产生新的数据<br>​        async  应用程序把数据写到缓存，操作系统通过伙伴程序kswapd把脏数据写到硬盘，而且会一直产生脏数据，不会等<br>​        directIO直接IO  不会经过缓存，直接往硬盘上写</p><p>​    练习：<br>​    使用dd命令测试sync async directIO三种方式谁快谁慢</p><p>​    那么上面3种方式，对应用程序来说，async最快，其次是直接IO，最慢的是同步</p><p>问题：<br>    虽然异步对应用程序快了，但是会产生问题，比如脏数据还没来得及全部同步到硬盘，突然断电了，这时候我们称硬盘上的不完整数据被损坏，或者数据不一致</p><pre><code>解决：    断电我们阻止不了，但是我们可以重新写数据，但是现在他怎么知道哪个数据坏了？开机启动的时候使用fsck检测坏块儿</code></pre><p>问题：<br>    但是fsck在数据量比较大的时候会非常慢，那怎么解决这个问题？</p><pre><code>解决：    通过Journal日志</code></pre><p>​    在数据写到内存之前先记录一下日志，如果断电重启之后发现哪个写操作没有完成，就通过日志恢复哪个就可以了</p><p>​    有日志以后的数据存储过程:<br>​        写日志<br>​        写数据<br>​        删除日志</p><p>ext4可以关掉日志，但是只有在格式化的时候才能关</p><p>有日志的话，会变慢，那这个问题如何解决？<br>    创建2个分区，分别格式化为ext2、ext3，dd文件测试速度差异</p><pre><code>记录日志的方法：    #man mount    Mount options for ext3    data={journal|ordered|writeback}</code></pre><p>​        journal最好，但是这种开销最大<br>​        journal 把信息写到缓存，记录日志，记录inode和数据到日志，然后写到硬盘<br>​        ordered 这是默认的模式把信息写到缓存，记录日志，只记录inode，然后写到硬盘<br>​        writeback首先在缓存内把所有的写排好序,然后记录inode，最后写到硬盘<br>​<br>​        性能上ordered和writeback差不多<br>​<br>​    解决记录日志慢问题：<br>​        之所以日志慢：硬盘是一个一个的磁盘片，硬盘效率最高的时候是磁头在某一个磁道不换位置，如果数据不连续也就意味着磁头要来回在日志数据所在的磁道和数据所在的磁道跳换，如果能解决这个问题就OK了。我们可以采用日志分离的方式</p><p>​        日志分离:<br>​            两块硬盘，一块存日志，一块存数据，必须是两块磁盘，两个分区是不可以的<br>​            #mke2fs -O journal_dev /dev/sdb5   //把这个设备格式化成专门记录日志的设备<br>​            #mkfs.ext3 -J device=/dev/sdb5 /dev/sdb1  //在格式化sdb1的时候声明日志记录在sdb5上，因为是做实验，这里用的是分区<br>​            #mount -o data=journal /dev/sdb1 /mnt/<br>​            在工作当中一般不用日志分离，因为一般我们的服务器上都是raid，所以速度不会慢到哪去，如果不用raid的设备就可能要用到日志分离</p><hr><p>各种日志文件系统:<br>ext3<br>ext4<br>jfs IBM的 恢复相当快<br>xfs 处理大文件性能特别好<br>reiserfs suse用的文件系统<br>btresfs 处理小文件速度特别快</p><p>zfs z是26个英文字母的最后一个，寓意在他之后不会再有其他文件系统</p><p>rhel7已经放弃ext4了，使用xfs</p><h5 id="I-O调度算法"><a href="#I-O调度算法" class="headerlink" title="I/O调度算法"></a>I/O调度算法</h5><pre><code>查看调度算法[root@localhost ~]# cat /sys/block/sda/queue/schedulernoop anticipatory deadline [cfq]      //这里是所有的算法，被中括号扩起来的cfq就是默认的调度算法    CFQ (Completely Fair Queuing 完全公平的排队)(elevator=cfq)：        这是默认算法，对于通用服务器来说通常是最好的选择。它试图均匀地分布对I/O带宽的访问。在多媒体应用, 总能保证audio、video及时从磁盘读取数据。但对于其他各类应用表现也很好。每个进程一个queue，每个queue按照上述规则进行merge 和sort。进程之间round robin调度，每次执行一个进程的4个请求。    Deadline (elevator=deadline)：        这个算法试图把每次请求的延迟降至最低。该算法重排了请求的顺序来提高性能。    NOOP (elevator=noop):        这个算法实现了一个简单FIFO队列。他假定I/O请求由驱动程序或者设备做了优化或者重排了顺序(就像一个智能控制器完成的工作那样)。在有些SAN环境下，这个选择可能是最好选择。适用于随机存取设备, no seek cost，非机械可随机寻址的磁盘。    Anticipatory (elevator=as):        这个算法推迟I/O请求，希望能对它们进行排序，获得最高的效率。同deadline不同之处在于每次处理完读请求之后, 不是立即返回, 而是等待几个微妙在这段时间内, 任何来自临近区域的请求都被立即执行. 超时以后, 继续原来的处理.基于下面的假设: 几个微妙内, 程序有很大机会提交另一次请求.调度器跟踪每个进程的io读写统计信息, 以获得最佳预期.-------------------------------------    APP    app发出请求到下层    buffer cache    io调度器    硬盘cfq 完全公平队列    a，b，c三个app发出请求， cfq会为每个app准备一个队列，cfg会在每个队列里面一次取4个请求，如果还有剩余请求，继续再取，总之是4个4个的取，他的好处就是每个app都会得到响应    每个app自己的请求可能都是连续的，但是app和app之间他们可能就不会在同一个磁道上，这样就会增加磁头的寻址    所以cfg适用于多媒体或者说桌面级系统deadline    deadline会把a,b,c的所有请求放到同一个队列，然后对他们进行排序，然后在把统一类型的请求比如读的请求放到fifo里面(fifo就是先进先出)    比如：    a 11 12 13 47    b 31 32 38 39    c 27 28 41 42    deadline    11    12    13    27    28    31    32    38    39    41    42    47    先处理11，然后12，13，。。。。直到最后的47    但是deadline会使a进入饿死状态(比如47)，怎样解决 我们会给每一个请求规定一个时间（过了这个时间就饿死了），如果发现某一个请求到时间了，那么停止现在其他所有的操作去处理到达规定时间的那个请求    11    12    13    27    28    31    32    38    39    41    42    47    anticipatory跟deadline差不多,3.0的内核里面已经砍掉了，但是跟deadline不一样的地方是处理11，12，13完事儿之后先等一下，看还有没有14，15如果没有的话再继续    noop直接fifo，谁先来，先处理谁  ssd的硬盘会使用  san存储也会用到--------------------------------------------------------------------对IO调度使用的建议Deadline I/O scheduler 使用轮询的调度器,简洁小巧,提供了最小的读取延迟和尚佳的吞吐量,特别适合于读取较多的环境(比如数据库,Oracle 10G 之类).Anticipatory I/O scheduler 假设一个块设备只有一个物理查找磁头(例如一个单独的SATA硬盘),将多个随机的小写入流合并成一个大写入流,用写入延时换取最大的写入吞吐量.适用于大多数环境,特别是写入较多的环境(比如文件服务器)Web,App等应用我们可以采纳as调度.CFQ I/O scheduler使用QoS策略为所有任务分配等量的带宽,避免进程被饿死并实现了较低的延迟,可以认为是上述两种调度器的折中.适用于有大量进程的多用户系统设置调度方法：    linux启动时设置默认IO调度,让系统启动时就使用默认的IO方法,只需在grub.conf文件中加入类似如下行    kernel /vmlinuz-2.6.24 ro root=/dev/sda1 elevator=deadline</code></pre><h5 id="查看I-O状态"><a href="#查看I-O状态" class="headerlink" title="查看I/O状态"></a>查看I/O状态</h5><pre><code>[root@localhost ~]# sar -d 1 100Linux 2.6.32-358.el6.x86_64 (mail.robin.com)     2013年11月21日     _x86_64_    (1 CPU)22时25分22秒       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util22时25分23秒   dev11-0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.0022时25分23秒    dev8-0    844.58      0.00  10987.95     13.01      0.54      0.65      0.48     40.84时间    设备主从号  每秒读写请求次数 每秒读多少个扇区  每秒写的扇区个数 平均请求大小 平均队列长度 等待时间tps 每秒请求数rd_sec/s 每秒读的扇区数wr_sec/s 每秒写的扇区数avgrq-sz  平均每个请求的大小(读写)avgqu-sz 平均队列长度  队列越长io性能越低await  io请求消耗的平均时间(毫秒)   所有时间(包括等待时间和服务时间)       await-svctm=io的等待时间 差值越大  io越繁忙         等待时间：假如现在有块硬盘，处理速度每秒能处理10个请求，那么我现在给他发15个，处理不过来怎么办？排队 await就是从进队列一直到处理完一共用了多长时间svctm：调度器处理这个排队的请求用了多长时间，比如你排队看医生，医生给你看病花了多长时间%util io处理io请求所消耗的cpu百分比[root@localhost ~]# iostat -kDevice:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtnscd0              0.00         0.02         0.00        216          0sda             653.44        28.39      4613.55     365863   59445489[root@localhost ~]# iostat -x 1Device:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await  svctm  %utilscd0              0.00     0.00    0.00    0.00     0.03     0.00     6.86     0.00    2.76   2.76   0.00sda               2.46   500.26    0.82  651.74    56.41  9215.99    14.21     0.69    1.06   0.73  47.67rrqm/s 每秒合并的读请求次数wrqm/s 每秒合并的写请求次数a对某一个块发出一个读请求，但是现在因为硬盘速度慢，还没来得及处理，结果a又对这个块发出一个读请求，这样我们就可以把这两个读请求合并到一起a对某一个块发出一个写请求，比如把某一块数据改成123，但是没来得及处理，a又对这个块儿发出一个写请求要把数据改成789，那么这个最后的结果是789，所以我们可以把这两个写请求合并</code></pre><h6 id="filesystem（了解）"><a href="#filesystem（了解）" class="headerlink" title="filesystem（了解）"></a>filesystem（了解）</h6><pre><code>需要一些编译工具，安装“开发工具” “开发库”[root@localhost ~]# yum groupinstall &quot;Development Libraries&quot; &quot;Development Tools&quot;安装与现有内核版本相对应的src.rpm[root@localhost ~]# uname -r2.6.18-308.el5xen[root@localhost ~]# rpm -ivh /tmp/kernel-2.6.18-308.el5.src.rpmrhel5会将src .rpm释放到/usr/src/redhat/中（rhel6会释放到当前用户家目录下的rpmbuild）[root@localhost ~]# cd /usr/src/redhat/[root@localhost redhat]# lsBUILD  RPMS  SOURCES  SPECS  SRPMSBUILD         操作源码过程中产生的数据RPMS         存放制作好的rpmSOURCES     存放程序的源代码和相关文件SPECS         存放制作rpm所使用的spec脚本SRPMS         存放src.rpm[root@localhost redhat]# cd SPECS/[root@localhost SPECS]# ls -l 总计 820-rw-r--r-- 1 root root 834836 2010-03-17 kernel-2.6.spec[root@localhost SPECS]# rpmbuild  -bp --target=$(uname -m)  kernel-2.6.spec [root@localhost ~]# cd /usr/src/redhat/BUILD/kernel-2.6.18/linux-2.6.18.i686[root@localhost linux-2.6.18.i686]# cp /boot/config-2.6.18-308.el5xen  .config编辑Makefile，EXTRAVERSION = -308.el5xen 与当前内核版本相对应[root@localhost linux-2.6.18.i686]# vim Makefile    EXTRAVERSION = -308.el5xen        #第四行[root@localhost linux-2.6.18.i686]# make oldconfig在编译模块的过程中需要 .tmp_versions临时目录[root@localhost linux-2.6.18.i686]# mkdir .tmp_versions在字符菜单中找到文件系统文件系统，在其中找到Reiserfs、JFS、XFS，使用M选中（ext4默认就已经有了）[root@localhost linux-2.6.18.i686]# make menuconfig File systems  ---&gt;       &lt;M&gt; Reiserfs support      &lt;M&gt; JFS filesystem support      &lt;M&gt; XFS filesystem support单独编译3个文件系统模块[root@localhost linux-2.6.18.i686]# make fs/xfs/xfs.ko[root@localhost linux-2.6.18.i686]# make fs/jfs/jfs.ko[root@localhost linux-2.6.18.i686]# make fs/reiserfs/reiserfs.ko在系统内核模块目录中，创建3个文件系统的对应目录，并将编译好的模块拷贝到对应的目录中[root@localhost linux-2.6.18.i686]# mkdir  /lib/modules/2.6.18-308.el5xen/kernel/fs/jfs[root@localhost linux-2.6.18.i686]# mkdir  /lib/modules/2.6.18-308.el5xen/kernel/fs/reiserfs[root@localhost linux-2.6.18.i686]# mkdir  /lib/modules/2.6.18-308.el5xen/kernel/fs/xfs[root@localhost linux-2.6.18.i686]# cp  fs/jfs/jfs.ko  /lib/modules/2.6.18-308.el5xen/kernel/fs/jfs[root@localhost linux-2.6.18.i686]# cp  fs/reiserfs/reiserfs.ko  /lib/modules/2.6.18-308.el5xen/kernel/fs/reiserfs[root@localhost linux-2.6.18.i686]# cp  fs/xfs/xfs.ko  /lib/modules/2.6.18-308.el5xen/kernel/fs/xfsext4的模块rhel5u8中默认就有，放在以下位置 [root@localhost linux-2.6.18.i686]# ls /lib/modules/2.6.18-194.el5/kernel/fs/ext4/ext4.ko /lib/modules/2.6.18-194.el5/kernel/fs/ext4/ext4.ko检查模块依赖性并加载模块[root@lcoalhost linux-2.6.18.i686]# depmod -a[root@lcoalhost linux-2.6.18.i686]# modprobe  xfs[root@localhost linux-2.6.18.i686]# modprobe  jfs[root@localhost linux-2.6.18.i686]# modprobe  reiserfs[root@localhost linux-2.6.18.i686]# modprobe  ext4安装创建文件系统的工具ext4：    [root@localhost tmp]# yum install e4fsprogsJFS:    [root@localhost tmp]# tar xf jfsutils-1.1.14.tar.gz      ./configure &amp;&amp; make &amp;&amp; make installXFS:    [root@localhost tmp]# tar xf xfsprogs_2.9.8-1.tar.bz2      ./configure &amp;&amp; make &amp;&amp; make installREISERFS:    [root@localhost tmp]# tar xf reiserfsprogs-3.6.21.tar.bz2      ./configure &amp;&amp; make &amp;&amp; make install创建4个分区每个2G，分别给4个分区创建4种文件系统，并挂载到对应名称的目录[root@localhost tmp]# mkfs.xfs /dev/sda13[root@localhost tmp]# mkfs.jfs /dev/sda12[root@localhost tmp]# mkreiserfs /dev/sda11[root@localhost tmp]# mkfs.ext4 /dev/sda10[root@localhost tmp]# mkdir /xfs[root@localhost tmp]# mkdir /jfs[root@localhost tmp]# mkdir /reiserfs[root@localhost tmp]# mkdir /ext4[root@localhost tmp]# mount -t xfs /dev/sda13 /xfs[root@localhost tmp]# mount -t reiserfs /dev/sda11 /reiserfs/[root@localhost tmp]# mount -t jfs  /dev/sda12  /jfs/[root@localhost tmp]# mount -t ext4 /dev/sda10  /ext4[root@apache xfsprogs-2.9.8]# df -T文件系统          类型         1K-块           已用         可用         已用%     挂载点/dev/sda13       xfs         1949656          4256       1945400       1%         /xfs/dev/sda11       reiserfs     1959808         32840       1926968       2%         /reiserfs/dev/sda12      jfs         1951440           372         1951068       1%         /jfs/dev/sda10      ext4         1929068         35648       1795428       2%         /ext4</code></pre><h6 id="xfs（了解）"><a href="#xfs（了解）" class="headerlink" title="xfs（了解）"></a>xfs（了解）</h6><pre><code>XFS 最初是由 Silicon Graphics，Inc. 开发的。支持最大文件系统到16EB，最大文件8EB，那数以千万计的目录结构条目。XFS文件系统支持metadata 日志，更快的崩溃恢复，在线整理碎片，在线增长，使用实用工具（xfsdump和xfsrestore）备份与恢复。xfs在处理特大文件上有很好的表现，在多线程并行I/O的工作模式下处理小文件也有很好的表现xfs也支持以下特征基于Extent的分配方式XFS文件系统中的文件用到的块由变长Extent管理，每一个Extent描述了一个或多个连续的块。相比将每个文件用到的所有的块存储为列表的文件系统，这种策略大幅缩短了列表的长度。有些文件系统用一个或多个面向块的栅格管理空间分配在XFS中这种结构被由一对B+树组成的、面向Extent的结构替代了；每个文件系统分配组(AG)包含这样的一个结构。其中，一个B+树用于索引未被使用的Extent的长度，另一个索引这些Extent的起始块。这种双索引策略使得文件系统在定位剩余空间中的Extent时十分高效。条带化分配在条带化RAID阵列上创建XFS文件系统时，可以指定一个“条带化数据单元”。这可以保证数据分配、inode分配、以及内部日志被对齐到该条带单元上，以此最大化吞吐量。延迟分配XFS在文件分配上使用了惰性计算技术。当一个文件被写入缓存时，XFS简单地在内存中对该文件保留合适数量的块，而不是立即对数据分配Extent。实际的块分配仅在这段数据被冲刷到磁盘时才发生。这一机制提高了将这一文件写入一组连续的块中的机会，减少碎片的同时提升了性能。扩展属性XFS通过实现扩展文件属性给文件提供了多个数据流，使文件可以被附加多个名/值对。文件名是一个最大长度为256字节的、以NULL字符结尾的可打印字符串，其它的关联值则可包含多达 64KB 的二进制数据。这些数据被进一步分入两个名字空间中，root和user。保存在root名字空间中的扩展属性只能被超级用户修改，user名字空间中的可以被任何对该文件拥有写权限的用户修改。扩展属性可以被添加到任意一种XFS inode上，包括符号链接、设备节点、目录，等等。可以使用 attr 这个命令行程序操作这些扩展属性。xfsdump 和 xfsrestore 工具在进行备份和恢复时会一同操作扩展属性，而其它的大多数备份系统则会忽略扩展属性。XFS 支援 disk quota。 xfs局限性1.XFS是一个单节点文件系统，如果需要多节点同时访问需要考虑使用GFS2文件系统2.XFS支持16EB文件系统，而redhat仅支持100TB文件系统3.XFS较少的适用在单线程元数据密集的工作负荷，在单线程创建删除巨大数量的小文件的工作负荷下，其他文件系统（ext4）表现的会更好一些4.xfs文件在操作元数据时可能会使用2倍的ext4CPU资源，在CPU资源有限制的情况下可以研究使用不同文件系统5.xfs更多适用的特大文件的系统快速存储，ext4在小文件的系统或系统存储带宽有限的情况下表现的更好[root@node6 ~]# yum install xfsprogs -y[root@node6 ~]# mkfs.xfs /dev/vdb1meta-data=/dev/vdb1           isize=256        agcount=4, agsize=6016 blks              =                           sectsz=512       attr=2, projid32bit=0data          =                           bsize=4096       blocks=24064, imaxpct=25              =                           sunit=0          swidth=0 blksnaming    =version 2              bsize=4096       ascii-ci=0log          =internal log           bsize=4096       blocks=1200, version=2             =                           sectsz=512       sunit=0 blks, lazy-count=1realtime  =none                    extsz=4096       blocks=0, rtextents=0[root@node6 ~]# mkfs.xfs -l logdev=/dev/vdb2 /dev/vdb1 -fmeta-data=/dev/vdb1       isize=256        agcount=4, agsize=6016 blks              =                           sectsz=512       attr=2, projid32bit=0data         =                           bsize=4096       blocks=24064, imaxpct=25             =                           sunit=0          swidth=0 blksnaming     =version 2           bsize=4096       ascii-ci=0log           =/dev/vdb2          bsize=4096       blocks=24576, version=2              =                           sectsz=512       sunit=0 blks, lazy-count=1realtime     =none                      extsz=4096       blocks=0, rtextents=0[root@node6 ~]# mount -o logdev=/dev/vdb2 /dev/vdb1 /xfs/[root@node6 ~]# pvcreate /dev/vdb1 /dev/vdb2 [root@node6 ~]# vgcreate vgxfs /dev/vdb2 /dev/vdb1[root@node6 ~]# lvcreate -l 25 -n lvxfs vgxfs  Logical volume &quot;lvxfs&quot; created[root@node6 ~]# mkfs.xfs /dev/vgxfs/lvxfs meta-data=/dev/vgxfs/lvxfs           isize=256        agcount=4, agsize=6400 blks              =                               sectsz=512       attr=2, projid32bit=0data          =                               bsize=4096       blocks=25600, imaxpct=25              =                               sunit=0          swidth=0 blksnaming     =version 2                  bsize=4096       ascii-ci=0log           =internal log               bsize=4096       blocks=1200, version=2              =                               sectsz=512       sunit=0 blks, lazy-count=1realtime =none                           extsz=4096       blocks=0, rtextents=0[root@node6 ~]# mount /dev/vgxfs/lvxfs /xfs/[root@node6 ~]# lvextend -l +100%FREE /dev/vgxfs/lvxfs [root@node6 ~]# xfs_growfs /xfs/meta-data=/dev/mapper/vgxfs-lvxfs     isize=256        agcount=4, agsize=6400 blks              =                                   sectsz=512       attr=2, projid32bit=0data          =                                   bsize=4096       blocks=25600, imaxpct=25                 =                                   sunit=0          swidth=0 blksnaming      =version 2                      bsize=4096       ascii-ci=0log          =internal                       bsize=4096      blocks=1200, version=2                =                                   sectsz=512       sunit=0 blks, lazy-count=1realtime     =none                               extsz=4096       blocks=0, rtextents=0data blocks changed from 25600 to 47104[root@node6 ~]# umount /xfs[root@node6 ~]# xfs_repair /dev/vgxfs/lvxfs [root@node6 ~]# mkfs.xfs -l logdev=/dev/vdb2 /dev/vdb1[root@node6 ~]# mount -o logdev=/dev/vdb2 /dev/vdb1 /xfs[root@node6 ~]# for FILE in file{0..3} ; do dd if=/dev/zero of=/xfs/${FILE} bs=4M count=100 &amp; done[root@node6 ~]# filefrag /xfs/file*[root@node6 ~]# xfs_fsr -v[root@node6 ~]# umount /xfs[root@node6 ~]# xfs_repair -n -l /dev/vdb2 /dev/vdb1 Phase 1 - find and verify superblock...Phase 2 - using external log on /dev/vdb2        - scan filesystem freespace and inode maps...        - found root inode chunkPhase 3 - for each AG...        - scan (but don&#39;t clear) agi unlinked lists...        - process known inodes and perform inode discovery...        - agno = 0        - agno = 1        - agno = 2        - agno = 3        - process newly discovered inodes...Phase 4 - check for duplicate blocks...        - setting up duplicate extent list...        - check for inodes claiming duplicate blocks...        - agno = 0        - agno = 1        - agno = 2        - agno = 3No modify flag set, skipping phase 5Phase 6 - check inode connectivity...        - traversing filesystem ...        - traversal finished ...        - moving disconnected inodes to lost+found ...Phase 7 - verify link counts...No modify flag set, skipping filesystem flush and exiting.[root@node6 ~]# [root@node6 ~]# xfs_repair -l /dev/vdb2 /dev/vdb1 Phase 1 - find and verify superblock...Phase 2 - using external log on /dev/vdb2        - zero log...        - scan filesystem freespace and inode maps...        - found root inode chunkPhase 3 - for each AG...        - scan and clear agi unlinked lists...        - process known inodes and perform inode discovery...        - agno = 0        - agno = 1        - agno = 2        - agno = 3        - process newly discovered inodes...Phase 4 - check for duplicate blocks...        - setting up duplicate extent list...        - check for inodes claiming duplicate blocks...        - agno = 0        - agno = 1        - agno = 2        - agno = 3Phase 5 - rebuild AG headers and trees...        - reset superblock...Phase 6 - check inode connectivity...        - resetting contents of realtime bitmap and summary inodes        - traversing filesystem ...        - traversal finished ...        - moving disconnected inodes to lost+found ...Phase 7 - verify and correct link counts...done[root@node6 ~]# mount -o logdev=/dev/vdb2 /dev/vdb1 /xfs[root@node6 ~]# yum install xfsdump[root@node6 ~]# xfsdump -L full -M dumpfile -l 0 - /xfs | xz &gt; /tmp/xfs.$(date +%Y%m%d).0.xzxfsdump: using file dump (drive_simple) strategyxfsdump: version 3.0.4 (dump format 3.0) - Running single-threadedxfsdump: level 0 dump of node6.uplooking.com:/xfsxfsdump: dump date: Sat Sep 14 17:39:47 2013xfsdump: session id: 75f91e6b-c0bc-4ad1-978b-e2ee5deb01d4xfsdump: session label: &quot;full&quot;xfsdump: ino map phase 1: constructing initial dump listxfsdump: ino map phase 2: skipping (no pruning necessary)xfsdump: ino map phase 3: skipping (only one dump stream)xfsdump: ino map construction completexfsdump: estimated dump size: 1677743680 bytesxfsdump: /var/lib/xfsdump/inventory createdxfsdump: creating dump session media file 0 (media 0, file 0)xfsdump: dumping ino mapxfsdump: dumping directoriesxfsdump: dumping non-directory filesxfsdump: ending media filexfsdump: media file size 1678152296 bytesxfsdump: dump size (non-dir files) : 1678101072 bytesxfsdump: dump complete: 152 seconds elapsedxfsdump: Dump Status: SUCCESS[root@node6 ~]# [root@node6 ~]# xfsdump -Ifile system 0:    fs id:        467c218c-22b5-45bc-9b0e-cd5782be6e2e    session 0:        mount point:    node6.uplooking.com:/xfs        device:        node6.uplooking.com:/dev/vdb1        time:        Sat Sep 14 17:39:47 2013        session label:    &quot;full&quot;        session id:    75f91e6b-c0bc-4ad1-978b-e2ee5deb01d4        level:        0        resumed:    NO        subtree:    NO        streams:    1        stream 0:            pathname:    stdio            start:        ino 131 offset 0            end:        ino 135 offset 0            interrupted:    NO            media files:    1            media file 0:                mfile index:    0                mfile type:    data                mfile size:    1678152296                mfile start:    ino 131 offset 0                mfile end:    ino 135 offset 0                media label:    &quot;dumpfile&quot;                media id:    de67b2b5-db72-4555-9804-a050829b2179xfsdump: Dump Status: SUCCESS[root@node6 ~]# rm -rf /xfs/*[root@node6 ~]# xzcat /tmp/xfs.20130914.0.xz | xfsrestore - /xfsxfsrestore: using file dump (drive_simple) strategyxfsrestore: version 3.0.4 (dump format 3.0) - Running single-threadedxfsrestore: searching media for dumpxfsrestore: examining media file 0xfsrestore: dump description: xfsrestore: hostname: node6.uplooking.comxfsrestore: mount point: /xfsxfsrestore: volume: /dev/vdb1xfsrestore: session time: Sat Sep 14 17:39:47 2013xfsrestore: level: 0xfsrestore: session label: &quot;full&quot;xfsrestore: media label: &quot;dumpfile&quot;xfsrestore: file system id: 467c218c-22b5-45bc-9b0e-cd5782be6e2exfsrestore: session id: 75f91e6b-c0bc-4ad1-978b-e2ee5deb01d4xfsrestore: media id: de67b2b5-db72-4555-9804-a050829b2179xfsrestore: searching media for directory dumpxfsrestore: reading directoriesxfsrestore: 1 directories and 4 entries processedxfsrestore: directory post-processingxfsrestore: restoring non-directory filesxfsrestore: restore complete: 33 seconds elapsedxfsrestore: Restore Status: SUCCESS[root@node6 ~]# ls /xfsfile0  file1  file2  file3</code></pre><h3 id="net"><a href="#net" class="headerlink" title="net"></a>net</h3><pre><code>一台服务器CPU和内存资源额定有限的情况下，如何提高服务器的性能是作为系统运维的重要工作。要提高Linux系统下的负载能力，当网站发展起来之后，web连接数过多的问题就会日益明显。在节省成本的情况下，可以考虑修改Linux 的内核TCP/IP参数来部分实现；Linux系统下，TCP/IP连接断开后，会以TIME_WAIT状态保留一定的时间，然后才会释放端口。当并发请求过多的时候，就会产生大量的 TIME_WAIT状态的连接，无法及时断开的话，会占用大量的端口资源和服务器资源(因为关闭后进程才会退出)。这个时候我们可以考虑优化TCP/IP 的内核参数，来及时将TIME_WAIT状态的端口清理掉。写在/etc/sysctl.conf里.开路由的也在这里.net.ipv4.tcp_syncookies = 1     表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；net.ipv4.tcp_tw_reuse = 1     表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；net.ipv4.tcp_tw_recycle = 1     表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭；net.ipv4.tcp_fin_timeout = 5  修改系统默认的 TIMEOUT 时间。net.ipv4.tcp_timestamps = 1 以一种比重发超时更精确的方法（参阅 RFC 1323）来启用对 RTT 的计算；为了实现更好的性能应该启用这个选项net.ipv4.tcp_keepalive_time = 1200     表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟。net.ipv4.ip_local_port_range = 10000     65000 表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为10000到65000。(注意：这里不要将最低值设的太低，否则可能会占用掉正常的端口！)net.ipv4.tcp_max_syn_backlog = 8192 表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。net.ipv4.tcp_max_tw_buckets = 5000 表示系统同时保持TIME_WAIT的最大数量，如果超过这个数字，TIME_WAIT将立刻被清除并打印警告信息。默认为180000，改为5000。对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量。</code></pre><h5 id="网卡绑定"><a href="#网卡绑定" class="headerlink" title="网卡绑定"></a>网卡绑定</h5><pre><code>网卡绑定网卡绑定的分类 模式 7中Ethernet Channel Bonding    Linux双网卡绑定的实现是使用两块网卡虚拟成为一块网卡，这个聚合起来的设备看起来是一个单独的以太网接口设备，通俗点讲就是两块网卡具有相同的IP地址而并行链接聚合成一个逻辑链路工作。其实这项技术在Sun和Cisco中早已存在，被称为Trunking和Etherchannel技术，在Linux的2.4.x以上内核中也采用这这种技术，被称为bonding。bonding技术的最早应用是在集群，为了提高集群节点间的数据传输而设计的。bonding的配置方式文档    [root@localhost ~]# rpm -q kernel-doc    /usr/share/doc/kernel-doc-2.6.18/Documentation/networking/bonding.txt系统是否支持bonding    # modinfo bonding    如果没有返回消息，说明不支持需要重新编译内核检查ifenslave     #which ifenslave     /sbin/ifenslave    分别修改2个网卡配置文件，声明自己为slave，master是bond0    [root@localhost ~]# vim /etc/sysconfig/network-scripts/ifcfg-eth0    －－－    DEVICE=eth0    USERCTL=no    ONBOOT=yes    BOOTPROTO=none    MASTER=bond0    SLAVE=yes－－－生成master设备的配置文件    [root@localhost ~]# vim /etc/sysconfig/network-scripts/ifcfg-bond0    -----------    DEVICE=bond0    IPADDR=192.168.122.254    NETMASK=255.255.255.0    ONBOOT=yes    BOOTPROTO=none    USERCTL=no-----------bond0是什么设备？实际我们做的网卡绑定，是通过bonding模块来实现的，所以要bonding模块设置一个别名，指向我们创建的bond0[root@localhost ~]# vim /etc/modprobe.conf  －－－alias bond0 bondingoptions bonding miimon=100 mode=balance-rroptions bond0 miimon=100 mode=1 primary=eth0   //模式为1的时候使用这行配置RHEL6下不再有modprobe.conf这个文件    在/etc/modprobe.d/里建立bond0.conf    # cat /etc/modprobe.d/bond0.conf       alias bond0 bonding－－－miimon是用来进行链路监测的。 比如:miimon=100，那么系统每100ms监测一次链路连接状态，如果有一条线路不通就转入另一条线路；mode的值表示工作模式，他共有0，1,2,3四种模式，常用的为0,1两种。    mode=0表示load balancing (round-robin)为负载均衡方式，两块网卡都工作。    mode=1表示fault-tolerance (active-backup)提供冗余功能，工作方式是主备的工作方式,也就是说默认情况下只有一块网卡工作,另一块做备份.重启服务，如果不生效需要重启系统：    [root@localhost ~]# service network restart验证bond0是否成功：    [root@localhost ~]# cat /proc/net/bonding/bond0===================================rhel6    DEVICE=bond0    IPADDR=192.168.0.253    NETMASK=255.255.255.0    ONBOOT=yes    NM_CONTROLLED=no    BOOTPROTO=none    USERCTL=no    BONDING_OPTS=&quot;miimon=50 mode=0&quot;    建立bonding.conf      #cat  /etc/modprobe.d/bond.conf       alias bond0 bonding       在/etc/rc.local文件末尾加入如下内容     #vi /etc/rc.local      ifenslave bond0 eth0 eth2</code></pre><h3 id="资源控制"><a href="#资源控制" class="headerlink" title="资源控制"></a>资源控制</h3><h5 id="ulimit"><a href="#ulimit" class="headerlink" title="ulimit"></a>ulimit</h5><pre><code>系统性能一直是一个受关注的话题，如何通过最简单的设置来实现最有效的性能调优，如何在有限资源的条件下保证程序的运作，ulimit 是我们在处理这些问题时，经常使用的一种简单手段。ulimit 是一种 linux 系统的内键功能，它具有一套参数集，用于为由它生成的 shell 进程及其子进程的资源使用设置限制。ulimit 功能简述假设有这样一种情况，当一台 Linux 主机上同时登陆了 10 个人，在系统资源无限制的情况下，这 10 个用户同时打开了 500 个文档，而假设每个文档的大小有 10M，这时系统的内存资源就会受到巨大的挑战。而实际应用的环境要比这种假设复杂的多，例如在一个嵌入式开发环境中,各方面的资源都是非常紧缺的，对于开启文件描述符的数量，分配堆栈的大小，CPU 时间，虚拟内存大小，等等，都有非常严格的要求。资源的合理限制和分配，不仅仅是保证系统可用性的必要条件，也与系统上软件运行的性能有着密不可分的联系。这时，ulimit 可以起到很大的作用，它是一种简单并且有效的实现资源限制的方式。ulimit 用于限制 shell 启动进程所占用的资源，支持以下各种类型的限制：所创建的内核文件的大小、进程数据块的大小、Shell 进程创建文件的大小、内存锁住的大小、常驻内存集的大小、打开文件描述符的数量、分配堆栈的最大大小、CPU 时间、单个用户的最大线程数、Shell 进程所能使用的最大虚拟内存。同时，它支持硬资源和软资源的限制。作为临时限制，ulimit 可以作用于通过使用其命令登录的 shell 会话，在会话终止时便结束限制，并不影响于其他 shell 会话。而对于长期的固定限制，ulimit 命令语句又可以被添加到由登录 shell 读取的文件中，作用于特定的 shell 用户。[root@localhost Desktop]# ulimit  -acore file size                  (blocks, -c)     0            #最大的 core 文件的大小， 以 blocks 为单位core文件的简单介绍在一个程序崩溃时，它一般会在指定目录下生成一个core文件。core文件仅仅是一个内存映象(同时加上调试信息)，主要是用来调试的。 data seg size               (kbytes, -d)     unlimited    #进程最大的数据段的大小，以 Kbytes 为单位。scheduling priority            (-e)             0file size                       (blocks, -f)     unlimited    #进程可以创建文件的最大值，以 blocks 为单位。pending signals                 (-i)             59335        max locked memory        (kbytes, -l)     64            #最大可加锁内存大小，以 Kbytes 为单位。max memory size             (kbytes, -m)     unlimited    #最大内存大小，以 Kbytes 为单位open files                          (-n)             1024        #可以打开最大文件描述符的数量。pipe size                    (512 bytes, -p) 8            #管道缓冲区的大小，以 512byte/个 为单位。POSIX message queues    (bytes, -q)     819200        real-time priority               (-r)             0stack size                      (kbytes, -s)     10240        #堆栈大小，以 Kbytes 为单位。cpu time                       (seconds, -t)     unlimited    #最大的 CPU 占用时间，以秒为单位。max user processes         (-u)             59335        #用户最大可用的进程数。virtual memory              (kbytes, -v)     unlimited    #进程最大可用的虚拟内存，以 Kbytes 为单位。file locks                          (-x)             unlimited-a     显示当前所有的 limit 信息。-H     设置硬资源限制，一旦设置不能增加。     ulimit  Hs 64；限制硬资源，线程栈大小为 64K。-S     设置软资源限制，设置后可以增加，但是不能超过硬资源设置。     ulimit  Sn 32；限制软资源，32 个文件描述符。限制使用CPU时间[root@localhost ~]# vim /tmp/a.sh #!/bin/bashwhile  truedo    :done[root@localhost ~]# ulimit -t 20[root@localhost ~]# ulimit -a | grep &quot;cpu time&quot;cpu time               (seconds, -t) 20[root@localhost ~]# /tmp/a.sh Killed限制用户使用的虚拟内存[root@localhost ~]# ulimit -v 0[root@localhost ~]# lsKilled[root@localhost ~]# df Killed[root@localhost ~]# psKilled[root@localhost ~]# cd /etc[root@localhost etc]# echo 111111[root@localhost etc]# type cdcd is a shell builtin[root@localhost etc]# type echoecho is a shell builtin限制创建文件大小[root@node5 ~]# ulimit -f 1000[root@node5 ~]# dd if=/dev/zero of=file1 bs=1024 count=1001File size limit exceeded (core dumped)[root@node5 ~]# dd if=/dev/zero of=file1 bs=1024 count=900900+0 records in900+0 records out921600 bytes (922 kB) copied, 0.0031932 s, 289 MB/s系统性能一直是一个受关注的话题，如何通过最简单的设置来实现最有效的性能调优，如何在有限资源的条件下保证程序的运作，ulimit 是我们在处理这些问题时，经常使用的一种简单手段。ulimit 是一种 linux 系统的内键功能，它具有一套参数集，用于为由它生成的 shell 进程及其子进程的资源使用设置限制。ulimit 功能简述假设有这样一种情况，当一台 Linux 主机上同时登陆了 10 个人，在系统资源无限制的情况下，这 10 个用户同时打开了 500 个文档，而假设每个文档的大小有 10M，这时系统的内存资源就会受到巨大的挑战。而实际应用的环境要比这种假设复杂的多，例如在一个嵌入式开发环境中,各方面的资源都是非常紧缺的，对于开启文件描述符的数量，分配堆栈的大小，CPU 时间，虚拟内存大小，等等，都有非常严格的要求。资源的合理限制和分配，不仅仅是保证系统可用性的必要条件，也与系统上软件运行的性能有着密不可分的联系。这时，ulimit 可以起到很大的作用，它是一种简单并且有效的实现资源限制的方式。ulimit 用于限制 shell 启动进程所占用的资源，支持以下各种类型的限制：所创建的内核文件的大小、进程数据块的大小、Shell 进程创建文件的大小、内存锁住的大小、常驻内存集的大小、打开文件描述符的数量、分配堆栈的最大大小、CPU 时间、单个用户的最大线程数、Shell 进程所能使用的最大虚拟内存。同时，它支持硬资源和软资源的限制。作为临时限制，ulimit 可以作用于通过使用其命令登录的 shell 会话，在会话终止时便结束限制，并不影响于其他 shell 会话。而对于长期的固定限制，ulimit 命令语句又可以被添加到由登录 shell 读取的文件中，作用于特定的 shell 用户。[root@localhost Desktop]# ulimit  -acore file size                  (blocks, -c)     0            #最大的 core 文件的大小， 以 blocks 为单位core文件的简单介绍在一个程序崩溃时，它一般会在指定目录下生成一个core文件。core文件仅仅是一个内存映象(同时加上调试信息)，主要是用来调试的。 data seg size               (kbytes, -d)     unlimited    #进程最大的数据段的大小，以 Kbytes 为单位。scheduling priority            (-e)             0file size                       (blocks, -f)     unlimited    #进程可以创建文件的最大值，以 blocks 为单位。pending signals                 (-i)             59335        max locked memory        (kbytes, -l)     64            #最大可加锁内存大小，以 Kbytes 为单位。max memory size             (kbytes, -m)     unlimited    #最大内存大小，以 Kbytes 为单位open files                          (-n)             1024        #可以打开最大文件描述符的数量。pipe size                    (512 bytes, -p) 8            #管道缓冲区的大小，以 512byte/个 为单位。POSIX message queues    (bytes, -q)     819200        real-time priority               (-r)             0stack size                      (kbytes, -s)     10240        #堆栈大小，以 Kbytes 为单位。cpu time                       (seconds, -t)     unlimited    #最大的 CPU 占用时间，以秒为单位。max user processes         (-u)             59335        #用户最大可用的进程数。virtual memory              (kbytes, -v)     unlimited    #进程最大可用的虚拟内存，以 Kbytes 为单位。file locks                          (-x)             unlimited-a     显示当前所有的 limit 信息。-H     设置硬资源限制，一旦设置不能增加。     ulimit  Hs 64；限制硬资源，线程栈大小为 64K。-S     设置软资源限制，设置后可以增加，但是不能超过硬资源设置。     ulimit  Sn 32；限制软资源，32 个文件描述符。限制使用CPU时间[root@localhost ~]# vim /tmp/a.sh #!/bin/bashwhile  truedo    :done[root@localhost ~]# ulimit -t 20[root@localhost ~]# ulimit -a | grep &quot;cpu time&quot;cpu time               (seconds, -t) 20[root@localhost ~]# /tmp/a.sh Killed限制用户使用的虚拟内存[root@localhost ~]# ulimit -v 0[root@localhost ~]# lsKilled[root@localhost ~]# df Killed[root@localhost ~]# psKilled[root@localhost ~]# cd /etc[root@localhost etc]# echo 111111[root@localhost etc]# type cdcd is a shell builtin[root@localhost etc]# type echoecho is a shell builtin限制创建文件大小[root@node5 ~]# ulimit -f 1000[root@node5 ~]# dd if=/dev/zero of=file1 bs=1024 count=1001File size limit exceeded (core dumped)[root@node5 ~]# dd if=/dev/zero of=file1 bs=1024 count=900900+0 records in900+0 records out921600 bytes (922 kB) copied, 0.0031932 s, 289 MB/s</code></pre><h5 id="pam-limit-so"><a href="#pam-limit-so" class="headerlink" title="pam_limit.so"></a>pam_limit.so</h5><pre><code>pam_limits 资源限制模块（提供的管理组:session）pam 插入式验证模块为使用此模块, 系统管理员必须首先建立一个 root只读 的文件(默认是 /etc/security/limits.conf). 这文件描述了superuser想强迫用户和用户组的资源限制. uid=0的帐号不会受限制.以下参数可以用来改变此模块的行为:    * debug - 往syslog(3)写入冗长的记录.    * conf=/path/to/file.conf - 指定一个替换的limits设定档.设定档的每一行描述了一个用户的限制,以下面的格式:&lt;domain&gt; &lt;type&gt; &lt;item&gt; &lt;value&gt;上面列出的栏位可以填下面的值:...&lt;domain&gt; 可以是:    * 一个用户名    * 一个组名,语法是@group    * 通配符*, 定义默认条目&lt;type&gt; 可以有一下两个值:    * hard 为施行硬 资源限制. 这些限制由superuser设定,由Linux内核施行. 用户不能提升他对资源的需求到大于此值.    * soft 为施行软 资源限制. 用户的限制能在软硬限制之间上下浮动. 这种限制在普通用法下可以看成是默认值.&lt;item&gt; 可以是以下之一:    * core - 限制core文件的大小(KB)    * data - 最大的资料大小 (KB)    * fsize - 最大的文件尺寸 (KB)    * memlock - 最大能锁定的内存空间(KB)    * nofile - 最多能打开的文件    * rss - 最大的驻留程序大小(KB)    * stack - 最大的堆栈尺寸(KB)    * cpu - 最大的CPU 时间(分钟)    * nproc - 最多的进程数    * as - 地址空间的限制    * maxlogins - 用户的最多登录数    * priority - 用户进程执行时的优先级要完全不限制用户(或组), 可以用一个(-)(例如: ``bin -&#39;&#39;, ``@admin -&#39;&#39;). 注意,个体的限制比组限制的优先级高, 所以如果你设定admin组不受限制, 但是组中的某个成员被设定档中某行限制, 那么此用户就会依据这样被限制.还应该注意, 所有的限制设定只是每个登录的设定. 他们既不是全局的,也不是永久的 ; 之存在于会话期间.pam_limits 模块会通过syslog(3)报告它从设定档中找到的问题.下面配置文件实例:# EXAMPLE /etc/security/limits.conf file:# =======================================# &lt;domain&gt; &lt;type&gt; &lt;item&gt; &lt;value&gt;    *         soft     core     0    *         hard     rss         10000   @student     hard     nproc    20   @faculty     soft     nproc     20   @faculty     hard     nproc     50      ftp         hard     nproc     0注意, 对同一个资源的软限制和硬限制 - 这建立了用户可以从指定服务会话中得到的默认和最大允许的资源数.限制用户登录次数/etc/security/limits.conf[root@localhost ~]# vim /etc/pam.d/loginsession required pam_limits.so[root@localhost ~]# vim /etc/security/limits.confhulk hard maxlogins 2限制用户打开进程数[root@localhost ~]# vim /etc/security/limits.conf hulk        hard     nproc     3[root@localhost ~]# useradd hulk[root@localhost ~]# echo &quot;123456&quot; | passwd --stdin hulk[root@localhost ~]# su - hulk[hulk@localhost ~]$ sleep 3000 &amp;[1] 4650[hulk@localhost ~]$ sleep 3000 &amp;[2] 4651[hulk@localhost ~]$ sleep 3000 &amp;-bash: fork: retry: Resource temporarily unavailable限制用户使用CPU时间[root@localhost ~]# vim /etc/security/limits.conf hulk     hard   cpu     1[hulk@localhost ~]$ ./a.sh    脚本执行1分钟后 Killed限制用户创建文件大小[root@localhost ~]# vim /etc/security/limits.conf hulk    hard   fsize    500[root@localhost ~]# su - hulk[hulk@localhost ~]$ dd if=/dev/zero of=file1 bs=1M count=1File size limit exceeded (core dumped)</code></pre><h5 id="cgroup"><a href="#cgroup" class="headerlink" title="cgroup"></a>cgroup</h5><pre><code>Cgroups是什么？Cgroups是control groups的缩写，是Linux内核提供的一种可以限制、记录、隔离进程组（process groups）所使用的物理资源（如：cpu,memory,IO等等）的机制。最初由google的工程师提出，后来被整合进Linux内核。Cgroups也是LXC为实现虚拟化所使用的资源管理手段，可以说没有cgroups就没有LXC。 概述LXC为LinuxContainer的简写。LinuxContainer容器是一种内核虚拟化技术，可以提供轻量级的虚拟化Cgroups可以做什么？Cgroups最初的目标是为资源管理提供的一个统一的框架，既整合现有的cpuset等子系统，也为未来开发新的子系统提供接口。现在的cgroups适用于多种应用场景，从单个进程的资源控制，到实现操作系统层次的虚拟化（OS Level Virtualization）。Cgroups提供了一下功能：1.限制进程组可以使用的资源数量（Resource limiting ）。比如：memory子系统可以为进程组设定一个memory使用上限，一旦进程组使用的内存达到限额再申请内存，就会出发OOM（out of memory）。2.进程组的优先级控制（Prioritization ）。比如：可以使用cpu子系统为某个进程组分配特定cpu share。3.记录进程组使用的资源数量（Accounting ）。比如：可以使用cpuacct子系统记录某个进程组使用的cpu时间4.进程组隔离（Isolation）。比如：使用ns子系统可以使不同的进程组使用不同的namespace，以达到隔离的目的，不同的进程组有各自的进程、网络、文件系统挂载空间。5.进程组控制（Control）。比如：使用freezer子系统可以将进程组挂起和恢复。Cgroups相关概念及其关系相关概念1.任务（task）。在cgroups中，任务就是系统的一个进程。2.控制族群（control group）。控制族群就是一组按照某种标准划分的进程。Cgroups中的资源控制都是以控制族群为单位实现。一个进程可以加入到某个控制族群，也从一个进程组迁移到另一个控制族群。一个进程组的进程可以使用cgroups以控制族群为单位分配的资源，同时受到cgroups以控制族群为单位设定的限制。3.层级（hierarchy）。控制族群可以组织成hierarchical的形式，既一颗控制族群树。控制族群树上的子节点控制族群是父节点控制族群的孩子，继承父控制族群的特定的属性。4.子系统（subsytem）。一个子系统就是一个资源控制器，比如cpu子系统就是控制cpu时间分配的一个控制器。子系统必须附加（attach）到一个层级上才能起作用，一个子系统附加到某个层级以后，这个层级上的所有控制族群都受到这个子系统的控制。相互关系1.每次在系统中创建新层级时，该系统中的所有任务都是那个层级的默认 cgroup（我们称之为 root cgroup ，此cgroup在创建层级时自动创建，后面在该层级中创建的cgroup都是此cgroup的后代）的初始成员。2.一个子系统最多只能附加到一个层级。3.一个层级可以附加多个子系统4.一个任务可以是多个cgroup的成员，但是这些cgroup必须在不同的层级。5.系统中的进程（任务）创建子进程（任务）时，该子任务自动成为其父进程所在 cgroup 的成员。然后可根据需要将该子任务移动到不同的 cgroup 中，但开始时它总是继承其父任务的cgroup。Cgroups子系统介绍blkio      这个子系统为块设备设定输入/输出限制，比如物理设备（磁盘，固态硬盘，USB 等等）。cpu         这个子系统使用调度程序提供对 CPU 的 cgroup 任务访问。cpuacct     这个子系统自动生成 cgroup 中任务所使用的 CPU 报告。cpuset     这个子系统为 cgroup 中的任务分配独立 CPU（在多核系统）和内存节点。devices     这个子系统可允许或者拒绝 cgroup 中的任务访问设备。freezer     这个子系统挂起或者恢复 cgroup 中的任务。memory     这个子系统设定 cgroup 中任务使用的内存限制，并自动生成由那些任务使用的内存资源报告。net_cls     这个子系统使用等级识别符（classid）标记网络数据包，可允许 Linux 流量控制程序（tc）识别从具体 cgroup 中生成的数据包。ns         名称空间子系统。安装kernel-doc查看帮助[root@localhost ~]# ls /usr/share/doc/kernel-doc-2.6.32/Documentation/cgroups/00-INDEX                  cpuacct.txt      freezer-subsystem.txt      net_prio.txtblkio-controller.txt  cpusets.txt      memcg_test.txt             resource_counter.txtcgroups.txt               devices.txt      memory.txt</code></pre>]]></content>
      
      
      <categories>
          
          <category> Interview </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Prometheus-入门</title>
      <link href="2020/05/26/monitor/prometheus-ru-men/"/>
      <url>2020/05/26/monitor/prometheus-ru-men/</url>
      
        <content type="html"><![CDATA[<h1 id="Prometheus搭建简单的监控告警系统"><a href="#Prometheus搭建简单的监控告警系统" class="headerlink" title="Prometheus搭建简单的监控告警系统"></a>Prometheus搭建简单的监控告警系统</h1><h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><blockquote><p>使用的操作系统为CentOS 7.6.1810，其他系统请自己根据差异做对应调整</p><p>仅用于记录部署过程</p><p>告警通知对接了邮件和钉钉机器人</p></blockquote><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><blockquote><p>在监控告警系统主机上安装prometheus、alertmanager和grafana</p><p>被监控的主机安装各种各样的exporter，每个exporter只监控自身的服务状态</p></blockquote><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><pre><code># 创建prometheus配置目录mkdir -p /etc/prometheus /etc/prometheus/rules.d# 创建prometheus用户useradd prometheus# 修改属主属组chown -R prometheus:prometheus /etc/prometheus</code></pre><h2 id="软件包"><a href="#软件包" class="headerlink" title="软件包"></a>软件包</h2><h3 id="prometheus"><a href="#prometheus" class="headerlink" title="prometheus"></a>prometheus</h3><p><a href="https://github.com/prometheus/prometheus/releases/download/v2.9.2/prometheus-2.9.2.linux-amd64.tar.gz" target="_blank" rel="noopener">prometheus-v2.9.2</a></p><pre><code># 下载解压wget -O - https://github.com/prometheus/prometheus/releases/download/v2.9.2/prometheus-2.9.2.linux-amd64.tar.gz | tar xz# 创建数据目录mkdir -p /var/lib/prometheuschwon -R prometheus:prometheus /var/lib/prometheus# 拷贝文件到对应位置cd prometheus-2.9.2.linux-amd64chown -R prometheus:prometheus prometheus promtool console_libraries consoles prometheus.ymlmv prometheus promtool /usr/local/bin/mv console_libraries consoles prometheus.yml /etc/prometheus/</code></pre><h3 id="alertmanager"><a href="#alertmanager" class="headerlink" title="alertmanager"></a>alertmanager</h3><p><a href="https://github.com/prometheus/alertmanager/releases/download/v0.17.0/alertmanager-0.17.0.linux-amd64.tar.gz" target="_blank" rel="noopener">alertmanager-v0.17.0</a></p><pre><code># 下载解压wget -O - https://github.com/prometheus/alertmanager/releases/download/v0.17.0/alertmanager-0.17.0.linux-amd64.tar.gz | tar xz# 创建数据目录mkdir -p /var/lib/prometheuschwon -R prometheus:prometheus /var/lib/prometheus# 拷贝文件cd alertmanager-0.17.0.linux-amd64chown -R prometheus:prometheus alertmanager alertmanager.yml amtoolmv alertmanager amtool /usr/local/bin/mv alertmanager.yml /etc/prometheus</code></pre><h3 id="node-exporter"><a href="#node-exporter" class="headerlink" title="node_exporter"></a>node_exporter</h3><p><a href="https://github.com/prometheus/node_exporter/releases/download/v0.18.0/node_exporter-0.18.0.linux-amd64.tar.gz" target="_blank" rel="noopener">node_exporter-v0.18.0</a></p><pre><code># 下载解压wget -O - https://github.com/prometheus/node_exporter/releases/download/v0.18.0/node_exporter-0.18.0.linux-amd64.tar.gz | tar xzcd node_exporter-0.18.0.linux-amd64chown prometheus:prometheus node_exporter# 拷贝文件mv node_exporter /usr/local/bin/</code></pre><h3 id="mysqld-exporter"><a href="#mysqld-exporter" class="headerlink" title="mysqld_exporter"></a>mysqld_exporter</h3><p><a href="https://github.com/prometheus/mysqld_exporter/releases/download/v0.11.0/mysqld_exporter-0.11.0.linux-amd64.tar.gz" target="_blank" rel="noopener">mysqld_exporter-v0.11.0</a></p><pre><code># 下载解压wget -O - https://github.com/prometheus/mysqld_exporter/releases/download/v0.11.0/mysqld_exporter-0.11.0.linux-amd64.tar.gz | tar xzcd mysqld_exporter-0.11.0.linux-amd64chown prometheus:prometheus mysqld_exporter# 拷贝文件mv mysqld_exporter /usr/local/bin/</code></pre><h3 id="postgresql-exporter"><a href="#postgresql-exporter" class="headerlink" title="postgresql_exporter"></a>postgresql_exporter</h3><pre><code># 下载解压wget -O - https://github.com/wrouesnel/postgres_exporter/releases/download/v0.4.7/postgres_exporter_v0.4.7_linux-amd64.tar.gz | tar xzcd postgres_exporter_v0.4.7_linux-amd64chown prometheus:prometheus postgres_exporter# 拷贝文件mv postgres_exporter /usr/local/bin/</code></pre><h3 id="blackbox-exporter"><a href="#blackbox-exporter" class="headerlink" title="blackbox_exporter"></a>blackbox_exporter</h3><p><a href="https://github.com/prometheus/blackbox_exporter/releases/download/v0.14.0/blackbox_exporter-0.14.0.linux-amd64.tar.gz" target="_blank" rel="noopener">blackbox_exporter-v0.14.0</a></p><pre><code># 下载解压wget -O - https://github.com/prometheus/blackbox_exporter/releases/download/v0.14.0/blackbox_exporter-0.14.0.linux-amd64.tar.gz | tar xzcd blackbox_exporter-0.14.0.linux-amd64chown prometheus:prometheus blackbox_exporter blackbox.yml# 拷贝文件mv blackbox_exporter /usr/local/bin/mv blackbox.yml /etc/prometheus/</code></pre><h3 id="grafana"><a href="#grafana" class="headerlink" title="grafana"></a>grafana</h3><p><a href="https://dl.grafana.com/oss/release/grafana-6.1.6-1.x86_64.rpm" target="_blank" rel="noopener">grafana-v6.1.6</a></p><pre><code># 下载wget https://dl.grafana.com/oss/release/grafana-6.1.6-1.x86_64.rpmyum localinstall grafana-6.1.6-1.x86_64.rpm</code></pre><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="Prometheus"><a href="#Prometheus" class="headerlink" title="Prometheus"></a>Prometheus</h3><p>/etc/prometheus/prometheus.yml</p><pre><code>global:  scrape_interval: 15s  scrape_timeout: 10s  evaluation_interval: 15salerting:  alertmanagers:  - static_configs:    - targets:      - localhost:9093    scheme: http    timeout: 10srule_files:- /etc/prometheus/rules.d/*.rulesscrape_configs:- job_name: prometheus  honor_timestamps: true  scrape_interval: 5s  scrape_timeout: 5s  metrics_path: /metrics  scheme: http  static_configs:  - targets:    - localhost:9090- job_name: node-exporter  honor_timestamps: true  scrape_interval: 5s  scrape_timeout: 5s  metrics_path: /metrics  scheme: http  static_configs:  - targets:    - localhost:9100- job_name: mysqld-exporter  honor_timestamps: true  scrape_interval: 5s  scrape_timeout: 5s  metrics_path: /metrics  scheme: http  static_configs:  - targets:    - localhost:9104- job_name: postgresql-exporter  honor_timestamps: true  scrape_interval: 5s  scrape_timeout: 5s  metrics_path: /metrics  scheme: http  static_configs:  - targets:    - localhost:9187</code></pre><p>/etc/prometheus/rules.d/host-status.rules</p><pre><code>groups:  - name: host-status-rule    rules:    - alert: NodeFilesystemSpaceUsage      expr: ( 1 - (node_filesystem_avail_bytes{fstype=~&quot;ext[234]|btrfs|xfs|zfs&quot;} / node_filesystem_size_bytes{fstype=~&quot;ext[234]|btrfs|xfs|zfs&quot;}) ) * 100 &gt; 85      for: 1m      labels:        team: node      annotations:        summary: &quot;{{$labels.instance}}: 文件系统空间使用率过高&quot;        description: &quot;{{$labels.instance}}: 文件系统空间使用率超过 85% (当前使用率: {{ $value }})&quot;    - alert: NodeFilesystemInodeUsage      expr: ( 1 - (node_filesystem_files_free{fstype=~&quot;ext[234]|btrfs|xfs|zfs&quot;} / node_filesystem_files{fstype=~&quot;ext[234]|btrfs|xfs|zfs&quot;}) ) * 100 &gt; 80      for: 1m      labels:        team: node      annotations:        summary: &quot;{{$labels.instance}}: 文件系统inode使用率过高&quot;        description: &quot;{{$labels.instance}}: 文件系统inode使用率超过 80% (当前使用率: {{ $value }})&quot;    - alert: NodeFilesystemReadOnly      expr: node_filesystem_readonly{job=&quot;node-exporter&quot;,device!~&#39;rootfs&#39;} == 1      for: 1m      labels:        team: node      annotations:        summary: &quot;{{$labels.instance}}: 文件系统只读状态&quot;        description: &quot;{{$labels.instance}}: 文件系统只读状态&quot;    - alert: NodeMemoryUsage      expr: (node_memory_MemTotal - (node_memory_MemFree+node_memory_Buffers+node_memory_Cached )) / node_memory_MemTotal * 100 &gt; 80      for: 1m      labels:        team: node      annotations:        summary: &quot;{{$labels.instance}}: 内存使用率过高&quot;        description: &quot;{{$labels.instance}}: 内存使用率过高超过80% (当前使用率: {{ $value }})&quot;    - alert: NodeCPUUsage      expr: (100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=&#39;idle&#39;,job=&quot;node-exporter&quot;}[1m])) * 100)) &gt; 80      for: 1m      labels:        team: node      annotations:        summary: &quot;{{$labels.instance}}: CPU使用率过高&quot;        description: &quot;{{$labels.instance}}: CPU使用率超过80% (当前使用率: {{ $value }})&quot;</code></pre><p>/etc/prometheus/rules.d/mysql-status.rules</p><pre><code>groups:  - name: MySQLStatsAlert    rules:    - alert: MySQL is down      expr: mysql_up == 0      for: 1m      labels:        severity: critical      annotations:        summary: &quot;Instance {{ $labels.instance }} MySQL is down&quot;        description: &quot;MySQL database is down. This requires immediate action!&quot;    - alert: open files high      expr: mysql_global_status_innodb_num_open_files &gt; (mysql_global_variables_open_files_limit) * 0.75      for: 1m      labels:        severity: warning      annotations:        summary: &quot;Instance {{ $labels.instance }} open files high&quot;        description: &quot;Open files is high. Please consider increasing open_files_limit.&quot;    - alert: Read buffer size is bigger than max. allowed packet size      expr: mysql_global_variables_read_buffer_size &gt; mysql_global_variables_slave_max_allowed_packet       for: 1m      labels:        severity: warning      annotations:        summary: &quot;Instance {{ $labels.instance }} Read buffer size is bigger than max. allowed packet size&quot;        description: &quot;Read buffer size (read_buffer_size) is bigger than max. allowed packet size (max_allowed_packet).This can break your replication.&quot;    - alert: Sort buffer possibly missconfigured      expr: mysql_global_variables_innodb_sort_buffer_size &lt;256*1024 or mysql_global_variables_read_buffer_size &gt; 4*1024*1024       for: 1m      labels:        severity: warning      annotations:        summary: &quot;Instance {{ $labels.instance }} Sort buffer possibly missconfigured&quot;        description: &quot;Sort buffer size is either too big or too small. A good value for sort_buffer_size is between 256k and 4M.&quot;    - alert: Thread stack size is too small      expr: mysql_global_variables_thread_stack &lt;196608      for: 1m      labels:        severity: warning      annotations:        summary: &quot;Instance {{ $labels.instance }} Thread stack size is too small&quot;        description: &quot;Thread stack size is too small. This can cause problems when you use Stored Language constructs for example. A typical is 256k for thread_stack_size.&quot;    - alert: Used more than 80% of max connections limited       expr: mysql_global_status_max_used_connections &gt; mysql_global_variables_max_connections * 0.8      for: 1m      labels:        severity: warning      annotations:        summary: &quot;Instance {{ $labels.instance }} Used more than 80% of max connections limited&quot;        description: &quot;Used more than 80% of max connections limited&quot;    - alert: InnoDB Force Recovery is enabled      expr: mysql_global_variables_innodb_force_recovery != 0       for: 1m      labels:        severity: warning      annotations:        summary: &quot;Instance {{ $labels.instance }} InnoDB Force Recovery is enabled&quot;        description: &quot;InnoDB Force Recovery is enabled. This mode should be used for data recovery purposes only. It prohibits writing to the data.&quot;    - alert: InnoDB Log File size is too small      expr: mysql_global_variables_innodb_log_file_size &lt; 16777216       for: 1m      labels:        severity: warning      annotations:        summary: &quot;Instance {{ $labels.instance }} InnoDB Log File size is too small&quot;        description: &quot;The InnoDB Log File size is possibly too small. Choosing a small InnoDB Log File size can have significant performance impacts.&quot;    - alert: InnoDB Flush Log at Transaction Commit      expr: mysql_global_variables_innodb_flush_log_at_trx_commit != 1      for: 1m      labels:        severity: warning      annotations:        summary: &quot;Instance {{ $labels.instance }} InnoDB Flush Log at Transaction Commit&quot;        description: &quot;InnoDB Flush Log at Transaction Commit is set to a values != 1. This can lead to a loss of commited transactions in case of a power failure.&quot;    - alert: Table definition cache too small      expr: mysql_global_status_open_table_definitions &gt; mysql_global_variables_table_definition_cache      for: 1m      labels:        severity: page      annotations:        summary: &quot;Instance {{ $labels.instance }} Table definition cache too small&quot;        description: &quot;Your Table Definition Cache is possibly too small. If it is much too small this can have significant performance impacts!&quot;    - alert: Table open cache too small      expr: mysql_global_status_open_tables &gt;mysql_global_variables_table_open_cache * 99/100      for: 1m      labels:        severity: page      annotations:        summary: &quot;Instance {{ $labels.instance }} Table open cache too small&quot;        description: &quot;Your Table Open Cache is possibly too small (old name Table Cache). If it is much too small this can have significant performance impacts!&quot;    - alert: Thread stack size is possibly too small      expr: mysql_global_variables_thread_stack &lt; 262144      for: 1m      labels:        severity: page      annotations:        summary: &quot;Instance {{ $labels.instance }} Thread stack size is possibly too small&quot;        description: &quot;Thread stack size is possibly too small. This can cause problems when you use Stored Language constructs for example. A typical is 256k for thread_stack_size.&quot;    - alert: InnoDB Plugin is enabled      expr: mysql_global_variables_ignore_builtin_innodb == 1      for: 1m      labels:        severity: page      annotations:        summary: &quot;Instance {{ $labels.instance }} InnoDB Plugin is enabled&quot;        description: &quot;InnoDB Plugin is enabled&quot;    - alert: Binary Log is disabled      expr: mysql_global_variables_log_bin != 1      for: 1m      labels:        severity: warning      annotations:        summary: &quot;Instance {{ $labels.instance }} Binary Log is disabled&quot;        description: &quot;Binary Log is disabled. This prohibits you to do Point in Time Recovery (PiTR).&quot;    - alert: Binlog Cache size too small      expr: mysql_global_variables_binlog_cache_size &lt; 1048576      for: 1m      labels:        severity: page      annotations:        summary: &quot;Instance {{ $labels.instance }} Binlog Cache size too small&quot;        description: &quot;Binlog Cache size is possibly to small. A value of 1 Mbyte or higher is OK.&quot;    - alert: Binlog Transaction Cache size too small      expr: mysql_global_variables_binlog_cache_size  &lt; 1048576      for: 1m      labels:        severity: page      annotations:        summary: &quot;Instance {{ $labels.instance }} Binlog Transaction Cache size too small&quot;        description: &quot;Binlog Transaction Cache size is possibly to small. A value of 1 Mbyte or higher is typically OK.&quot;</code></pre><p>/etc/prometheus/rules.d/postgresql-status.rules</p><pre><code>groups:- name: PostgreSQL-Status-Alert  rules:########## EXPORTER RULES ##########  - alert: PGExporterScrapeError    expr: pg_exporter_last_scrape_error &gt; 0    for: 60s    labels:      service: postgresql      severity: critical      severity_num: 300    annotations:      summary: &#39;Postgres Exporter running on {{ $labels.job }} (instance: {{ $labels.instance }}) is encountering scrape errors processing queries. Error count: ( {{ $value }} )&#39;  - alert: NodeExporterScrapeError    expr: node_textfile_scrape_error &gt; 0    for: 60s    labels:      service: system       severity: critical      severity_num: 300    annotations:      summary: &#39;Node Exporter running on {{ $labels.job }} (instance: {{ $labels.instance }}) is encountering scrape errors processing custom metrics.  Error count: ( {{ $value }} )&#39;########## POSTGRESQL RULES ##########  - alert: PGIsUp    expr: pg_up &lt; 1    for: 60s    labels:      service: postgresql      severity: critical      severity_num: 300    annotations:      summary: &#39;postgres_exporter running on {{ $labels.job }} is unable to communicate with the configured database&#39;# Whether a system switches from primary to replica or vice versa must be configured per named job.# No way to tell what value a system is supposed to be without a rule expression for that specific system# 2 to 1 means it changed from primary to replica. 1 to 2 means it changed from replica to primary# Set this alert for each system that you want to monitor a recovery status change# Below is an example for a target job called &quot;Replica&quot; and watches for the value to change above 1 which means it&#39;s no longer a replica##  - alert: PGRecoveryStatusSwitch_Replica #    expr: ccp_is_in_recovery_status{job=&quot;Replica&quot;} &gt; 1 #    for: 60s#    labels:#      service: postgresql#      severity: critical#      severity_num: 300#    annotations:#      summary: &#39;{{ $labels.job }} has changed from replica to primary&#39;# Absence alerts must be configured per named job, otherwise there&#39;s no way to know which job is down# Below is an example for a target job called &quot;Prod&quot;#  - alert: PGConnectionAbsent#    expr: absent(ccp_connection_stats_max_connections{job=&quot;Prod&quot;})#    for: 10s#    labels:#      service: postgresql#      severity: critical#      severity_num: 300#    annotations:#      description: &#39;Connection metric is absent from target (Prod). Check that postgres_exporter can connect to PostgreSQL.&#39;  - alert: PGIdleTxn    expr: ccp_connection_stats_max_idle_in_txn_time &gt; 300    for: 60s    labels:      service: postgresql      severity: warning      severity_num: 200    annotations:      description: &#39;{{ $labels.job }} has at least one session idle in transaction for over 5 minutes.&#39;      summary: &#39;PGSQL Instance idle transactions&#39;  - alert: PGIdleTxn    expr: ccp_connection_stats_max_idle_in_txn_time &gt; 900    for: 60s    labels:      service: postgresql      severity: critical      severity_num: 300    annotations:      description: &#39;{{ $labels.job }} has at least one session idle in transaction for over 15 minutes.&#39;      summary: &#39;PGSQL Instance idle transactions&#39;  - alert: PGQueryTime    expr: ccp_connection_stats_max_query_time &gt; 43200    for: 60s    labels:      service: postgresql      severity: warning       severity_num: 200    annotations:      description: &#39;{{ $labels.job }} has at least one query running for over 12 hours.&#39;      summary: &#39;PGSQL Max Query Runtime&#39;  - alert: PGQueryTime    expr: ccp_connection_stats_max_query_time &gt; 86400     for: 60s    labels:      service: postgresql      severity: critical      severity_num: 300    annotations:      description: &#39;{{ $labels.job }} has at least one query running for over 1 day.&#39;      summary: &#39;PGSQL Max Query Runtime&#39;  - alert: PGConnPerc    expr: 100 * (ccp_connection_stats_total / ccp_connection_stats_max_connections) &gt; 75    for: 60s    labels:      service: postgresql      severity: warning      severity_num: 200    annotations:      description: &#39;{{ $labels.job }} is using 75% or more of available connections ({{ $value }}%)&#39;      summary: &#39;PGSQL Instance connections&#39;  - alert: PGConnPerc    expr: 100 * (ccp_connection_stats_total / ccp_connection_stats_max_connections) &gt; 90     for: 60s    labels:      service: postgresql      severity: critical      severity_num: 300    annotations:      description: &#39;{{ $labels.job }} is using 90% or more of available connections ({{ $value }}%)&#39;      summary: &#39;PGSQL Instance connections&#39;  - alert: PGDBSize    expr: ccp_database_size &gt; 1.073741824e+11    for: 60s    labels:      service: postgresql      severity: warning      severity_num: 200    annotations:      description: &#39;PGSQL Instance {{ $labels.job }} over 100GB in size: {{ $value }} bytes&#39;      summary: &#39;PGSQL Instance size warning&#39;  - alert: PGDBSize    expr: ccp_database_size &gt; 2.68435456e+11    for: 60s    labels:      service: postgresql      severity: critical      severity_num: 300    annotations:      description: &#39;PGSQL Instance {{ $labels.job }} over 250GB in size: {{ $value }} bytes&#39;      summary: &#39;PGSQL Instance size critical&#39;  - alert: PGReplicationByteLag    expr: ccp_replication_status_byte_lag &gt; 5.24288e+07    for: 60s    labels:      service: postgresql      severity: warning      severity_num: 200    annotations:      description: &#39;PGSQL Instance {{ $labels.job }} has at least one replica lagging over 50MB behind.&#39;      summary: &#39;PGSQL Instance replica lag warning&#39;  - alert: PGReplicationByteLag    expr: ccp_replication_status_byte_lag &gt; 1.048576e+08    for: 60s    labels:      service: postgresql      severity: critical      severity_num: 300    annotations:      description: &#39;PGSQL Instance {{ $labels.job }} has at least one replica lagging over 100MB behind.&#39;      summary: &#39;PGSQL Instance replica lag warning&#39;  - alert: PGReplicationSlotsInactive    expr: ccp_replication_slots_active == 0    for: 60s    labels:      service: postgresql      severity: critical      severity_num: 300    annotations:      description: &#39;PGSQL Instance {{ $labels.job }} has one or more inactive replication slots&#39;      summary: &#39;PGSQL Instance inactive replication slot&#39;  - alert: PGXIDWraparound    expr: ccp_transaction_wraparound_percent_towards_wraparound &gt; 50    for: 60s    labels:      service: postgresql      severity: warning      severity_num: 200    annotations:      description: &#39;PGSQL Instance {{ $labels.job }} is over 50% towards transaction id wraparound.&#39;      summary: &#39;PGSQL Instance {{ $labels.job }} transaction id wraparound imminent&#39;  - alert: PGXIDWraparound    expr: ccp_transaction_wraparound_percent_towards_wraparound &gt; 75    for: 60s    labels:      service: postgresql      severity: critical      severity_num: 300    annotations:      description: &#39;PGSQL Instance {{ $labels.job }} is over 75% towards transaction id wraparound.&#39;      summary: &#39;PGSQL Instance transaction id wraparound imminent&#39;  - alert: PGEmergencyVacuum    expr: ccp_transaction_wraparound_percent_towards_emergency_autovac &gt; 75    for: 60s    labels:      service: postgresql      severity: warning      severity_num: 200    annotations:      description: &#39;PGSQL Instance {{ $labels.job }} is over 75% towards emergency autovacuum processes beginning&#39;      summary: &#39;PGSQL Instance emergency vacuum imminent&#39;  - alert: PGEmergencyVacuum    expr: ccp_transaction_wraparound_percent_towards_emergency_autovac &gt; 90    for: 60s    labels:      service: postgresql      severity: critical      severity_num: 300    annotations:      description: &#39;PGSQL Instance {{ $labels.job }} is over 90% towards emergency autovacuum processes beginning&#39;      summary: &#39;PGSQL Instance emergency vacuum imminent&#39;  - alert: PGArchiveCommandStatus    expr: ccp_archive_command_status_seconds_since_last_fail &gt; 300    for: 60s    labels:        service: postgresql        severity: critical        severity_num: 300    annotations:        description: &#39;PGSQL Instance {{ $labels.job }} has a recent failing archive command&#39;        summary: &#39;Seconds since the last recorded failure of the archive_command&#39;  - alert: PGSequenceExhaustion    expr: ccp_sequence_exhaustion_count &gt; 0    for: 60s    labels:        service: postgresql        severity: critical        severity_num: 300    annotations:        description: &#39;Count of sequences on instance {{ $labels.job }} at over 75% usage: {{ $value }}. Run following query to see full sequence status: SELECT * FROM monitor.sequence_status() WHERE percent &gt;= 75&#39;########## SYSTEM RULES ##########  - alert: ExporterDown    expr: avg_over_time(up[5m]) &lt; 0.9     for: 10s     labels:      service: system      severity: critical      severity_num: 300    annotations:      description: &#39;Metrics exporter service for {{ $labels.job }} running on {{ $labels.instance }} has been down at least 50% of the time for the last 5 minutes. Service may be flapping or down.&#39;      summary: &#39;Prometheus Exporter Service Down&#39;  - alert: DiskUsagePerc    expr: (100 - 100 * sum(node_filesystem_avail_bytes{device!~&quot;tmpfs|by-uuid&quot;,fstype=~&quot;xfs|ext&quot;} / node_filesystem_size_bytes{device!~&quot;tmpfs|by-uuid&quot;,fstype=~&quot;xfs|ext&quot;}) BY (job,device)) &gt; 70    for: 2m    labels:      service: system      severity: warning      severity_num: 200    annotations:      description: &#39;Disk usage on target {{ $labels.job }} at {{ $value }}%&#39;  - alert: DiskUsagePerc    expr: (100 - 100 * sum(node_filesystem_avail_bytes{device!~&quot;tmpfs|by-uuid&quot;,fstype=~&quot;xfs|ext&quot;} / node_filesystem_size_bytes{device!~&quot;tmpfs|by-uuid&quot;,fstype=~&quot;xfs|ext&quot;}) BY (job,device)) &gt; 85    for: 2m    labels:      service: system      severity: critical      severity_num: 300    annotations:      description: &#39;Disk usage on target {{ $labels.job }} at {{ $value }}%&#39;  - alert: DiskFillPredict    expr: predict_linear(node_filesystem_free_bytes{device!~&quot;tmpfs|by-uuid&quot;,fstype=~&quot;xfs|ext&quot;}[1h], 4 * 3600) &lt; 0    for: 5m    labels:      service: system      severity: warning      severity_num: 200    annotations:      description: &#39;(EXPERIMENTAL) Disk {{ $labels.device }} on target {{ $labels.job }} is predicted to fill in 4 hrs based on current usage&#39;  - alert: SystemLoad5m    expr: node_load5 &gt; 5    for: 10m    labels:      service: system      severity: warning      severity_num: 200    annotations:      description: &#39;System load for target {{ $labels.job }} is high ({{ $value }})&#39;  - alert: SystemLoad5m    expr: node_load5 &gt; 10    for: 10m    labels:      service: system      severity: critical      severity_num: 300    annotations:      description: &#39;System load for target {{ $labels.job }} is high ({{ $value }})&#39;  - alert: MemoryAvailable    expr: (100 * (node_memory_Available_bytes) / node_memory_MemTotal_bytes) &lt; 25    for: 1m    labels:      service: system      severity: warning      severity_num: 200    annotations:      description: &#39;Memory available for target {{ $labels.job }} is at {{ $value }}%&#39;  - alert: MemoryAvailable    expr: (100 * (node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes) &lt; 10    for: 1m    labels:      service: system      severity: critical      severity_num: 300    annotations:      description: &#39;Memory available for target {{ $labels.job }} is at {{ $value }}%&#39;  - alert: SwapUsage    expr: (100 - (100 * (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes))) &gt; 60    for: 1m    labels:      service: system      severity: warning      severity_num: 200    annotations:      description: &#39;Swap usage for target {{ $labels.job }} is at {{ $value }}%&#39;  - alert: SwapUsage    expr: (100 - (100 * (node_memory_SwapFree_byte / node_memory_SwapTotal_bytes))) &gt; 80    for: 1m    labels:      service: system      severity: critical      severity_num: 300    annotations:      description: &#39;Swap usage for target {{ $labels.job }} is at {{ $value }}%&#39;########## PGBACKREST RULES ############ Uncomment and customize one or more of these rules to monitor your pgbackrest backups. # Full backups are considered the equivalent of both differentials and incrementals since both are based on the last full#   And differentials are considered incrementals since incrementals will be based off the last diff if one exists#   This avoid false alerts, for example when you don&#39;t run diff/incr backups on the days that you run a full# Stanza should also be set if different intervals are expected for each stanza. #   Otherwise rule will be applied to all stanzas returned on target system if not set.# Otherwise, all backups returned by the pgbackrest info command run from where the database exists will be checked## Relevant metric names are: #   ccp_backrest_last_full_time_since_completion_seconds#   ccp_backrest_last_incr_time_since_completion_seconds#   ccp_backrest_last_diff_time_since_completion_seconds##  - alert: PGBackRestLastCompletedFull_main#    expr: ccp_backrest_last_full_backup_time_since_completion_seconds{stanza=&quot;main&quot;} &gt; 604800#    for: 60s#    labels:#       service: postgresql#       severity: critical#       severity_num: 300#    annotations:#       summary: &#39;Full backup for stanza [main] on system {{ $labels.job }} has not completed in the last week.&#39;##  - alert: PGBackRestLastCompletedIncr_main#    expr: ccp_backrest_last_incr_backup_time_since_completion_seconds{stanza=&quot;main&quot;} &gt; 86400#    for: 60s#    labels:#       service: postgresql#       severity: critical#       severity_num: 300#    annotations:#       summary: &#39;Incremental backup for stanza [main] on system {{ $labels.job }} has not completed in the last 24 hours.&#39;### Runtime monitoring is handled with a single metric:##   ccp_backrest_last_runtime_backup_runtime_seconds## Runtime monitoring should have the &quot;backup_type&quot; label set. #   Otherwise the rule will apply to the last run of all backup types returned (full, diff, incr)# Stanza should also be set if runtimes per stanza have different expected times##  - alert: PGBackRestLastRuntimeFull_main#    expr: ccp_backrest_last_runtime_backup_runtime_seconds{backup_type=&quot;full&quot;, stanza=&quot;main&quot;} &gt; 14400#    for: 60s#    labels:#       service: postgresql#       severity: critical#       severity_num: 300#    annotations:#       summary: &#39;Expected runtime of full backup for stanza [main] has exceeded 4 hours&#39;##  - alert: PGBackRestLastRuntimeDiff_main#    expr: ccp_backrest_last_runtime_backup_runtime_seconds{backup_type=&quot;diff&quot;, stanza=&quot;main&quot;} &gt; 3600#    for: 60s#    labels:#       service: postgresql#       severity: critical#       severity_num: 300#    annotations:#       summary: &#39;Expected runtime of diff backup for stanza [main] has exceeded 1 hour&#39;##### If the pgbackrest command fails to run, the metric disappears from the exporter output and the alert never fires. ## An absence alert must be configured explicitly for each target (job) that backups are being monitored.## Checking for absence of just the full backup type should be sufficient (no need for diff/incr).## Note that while the backrest check command failing will likely also cause a scrape error alert, the addition of this ## check gives a clearer answer as to what is causing it and that something is wrong with the backups.##  - alert: PGBackrestAbsentFull_Prod#    expr: absent(ccp_backrest_last_full_backup_time_since_completion_seconds{job=&quot;Prod&quot;})#    for: 10s#    labels:#      service: postgresql#      severity: critical#      severity_num: 300#    annotations:#      description: &#39;Backup Full status missing for Prod. Check that pgbackrest info command is working on target system.&#39;</code></pre><h3 id="Alertmanager"><a href="#Alertmanager" class="headerlink" title="Alertmanager"></a>Alertmanager</h3><p>/etc/prometheus/alertmanager.yml</p><pre><code>global:  resolve_timeout: 5m  http_config: {}  smtp_from: monitor@example.com  smtp_hello: localhost  smtp_smarthost: smtp.example.com:465  smtp_auth_username: monitor@example.com  smtp_auth_password: &#39;这里写密码&#39;  smtp_require_tls: false  pagerduty_url: https://events.pagerduty.com/v2/enqueue  hipchat_api_url: https://api.hipchat.com/  opsgenie_api_url: https://api.opsgenie.com/  wechat_api_url: https://qyapi.weixin.qq.com/cgi-bin/  victorops_api_url: https://alert.victorops.com/integrations/generic/20131114/alert/route:  # 这里配置默认路由到&#39;default-receiver&#39;  receiver: default-receiver  group_by:  - alertname  - cluster  group_wait: 10s  group_interval: 10s  repeat_interval: 1hinhibit_rules:- source_match:    severity: critical  target_match:    severity: warning  equal:  - alertname  - dev  - instancereceivers:- name: default-receiver  email_configs:  - send_resolved: false    to: monitor@example.com    from: monitor@example.com    hello: localhost    smarthost: smtp.example.com:465    auth_username: monitor@example.com    auth_password: &#39;这里写密码&#39;    headers:      From: monitor@example.com      Subject: &#39;{{ template "email.default.subject" . }}&#39;      To: monitor@example.com    html: &#39;{{ template "email.default.html" . }}&#39;    require_tls: false  # 配置钉钉机器人  webhook_configs:  - send_resolved: false    url: http://localhost:8060/dingtalk/webhook001/send# 配置钉钉机器人- name: dingtalk002  webhook_configs:  - send_resolved: false    url: http://localhost:8060/dingtalk/webhook002/sendtemplates: []</code></pre><p>配置dingtalk webhook程序</p><pre><code># 这里偷懒用docker跑钉钉的webhookdocker run -d \           --restart=always \           --name prometheus-webhook-dingtalk \           -p 8060:8060 \           -v /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime:ro \           timonwong/prometheus-webhook-dingtalk \           --ding.profile=&quot;webhook001=https://oapi.dingtalk.com/robot/send?access_token=xxxxxxxxxxxx&quot; \           --ding.profile=&quot;webhook002=https://oapi.dingtalk.com/robot/send?access_token=yyyyyyyyyyy&quot;</code></pre><h3 id="blackbox-exporter-1"><a href="#blackbox-exporter-1" class="headerlink" title="blackbox_exporter"></a>blackbox_exporter</h3><p>/etc/prometheus/backbox_exporter.yml</p><pre><code>没空搞，占个位</code></pre><h3 id="mysqld-exporter-1"><a href="#mysqld-exporter-1" class="headerlink" title="mysqld_exporter"></a>mysqld_exporter</h3><p>需要创建用于监控的数据库用户</p><pre><code>CREATE USER &#39;prometheus&#39;@&#39;127.0.0.1&#39; IDENTIFIED BY &#39;prometheus_password&#39; WITH MAX_USER_CONNECTIONS 3;GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO &#39;prometheus&#39;@&#39;127.0.0.1&#39;;flush privileges;</code></pre><h3 id="postgresql-exporter-1"><a href="#postgresql-exporter-1" class="headerlink" title="postgresql_exporter"></a>postgresql_exporter</h3><p>根据需求决定是否使用superuser作为postgresql_exporter的数据库用户</p><p>如果要创建专用用户可以参照下面的方式创建用户</p><pre><code># 创建postgresql_exporter专用用户CREATE USER postgres_exporter PASSWORD &#39;password&#39;;ALTER USER postgres_exporter SET SEARCH_PATH TO postgres_exporter,pg_catalog;# 创建schemaCREATE SCHEMA postgres_exporter;# 授权schemaGRANT USAGE ON SCHEMA postgres_exporter TO postgres_exporter;# 创建函数CREATE FUNCTION get_pg_stat_activity() RETURNS SETOF pg_stat_activity AS$$ SELECT * FROM pg_catalog.pg_stat_activity; $$LANGUAGE sqlVOLATILESECURITY DEFINER;# 创建视图CREATE VIEW postgres_exporter.pg_stat_activityAS  SELECT * from get_pg_stat_activity();# 视图授权GRANT SELECT ON postgres_exporter.pg_stat_activity TO postgres_exporter;# 创建函数CREATE FUNCTION get_pg_stat_replication() RETURNS SETOF pg_stat_replication AS$$ SELECT * FROM pg_catalog.pg_stat_replication; $$LANGUAGE sqlVOLATILESECURITY DEFINER;# 创建视图CREATE VIEW postgres_exporter.pg_stat_replicationAS  SELECT * FROM get_pg_stat_replication();# 视图授权GRANT SELECT ON postgres_exporter.pg_stat_replication TO postgres_exporter;</code></pre><h3 id="grafana-1"><a href="#grafana-1" class="headerlink" title="grafana"></a>grafana</h3><p>/etc/grafana/grafana.ini</p><pre><code>app_mode = production[paths]data = /var/lib/grafanatemp_data_lifetime = 24hlogs = /var/log/grafanaplugins = /var/lib/grafana/plugins[server]protocol = httphttp_port = 3000domain = gkhtroot_url = http://localhost:3000enable_gzip = true[database]log_queries =[remote_cache][session]provider = file[dataproxy][analytics]reporting_enabled = falsecheck_for_updates = false[security]admin_user = adminadmin_password = adminsecret_key = SW2YcwTIb9zpOOhoPsMm[snapshots][dashboards]versions_to_keep = 10[users]default_theme = dark[auth][auth.anonymous]enabled = trueorg_role = Viewer[auth.github][auth.google][auth.generic_oauth][auth.grafana_com][auth.proxy][auth.basic][auth.ldap][smtp][emails][log]mode = console filelevel = info[log.console][log.file]log_rotate = truedaily_rotate = truemax_days = 7[log.syslog][alerting]enabled = trueexecute_alerts = true[explore][metrics]enabled           = trueinterval_seconds  = 10[metrics.graphite][tracing.jaeger][grafana_com]url = https://grafana.com[external_image_storage][external_image_storage.s3][external_image_storage.webdav][external_image_storage.gcs][external_image_storage.azure_blob][external_image_storage.local][rendering][enterprise][panels]</code></pre><h2 id="systemd服务"><a href="#systemd服务" class="headerlink" title="systemd服务"></a>systemd服务</h2><h3 id="prometheus-service"><a href="#prometheus-service" class="headerlink" title="prometheus.service"></a>prometheus.service</h3><p>/usr/lib/systemd/system/prometheus.service</p><pre><code>[Unit]Description=prometheusAfter=network.target[Service]Type=simpleUser=prometheusExecStart=/usr/local/bin/prometheus \          --config.file=/etc/prometheus/prometheus.yml \          --storage.tsdb.path=/var/lib/prometheus \          --storage.tsdb.retention.time=15d \          --storage.tsdb.retention.size=40GB \          --web.console.templates=/etc/prometheus/consoles \          --web.console.libraries=/etc/prometheus/console_librariesExecReload=/bin/kill -HUP $MAINPIDRestart=on-failureRestartSec=60s[Install]WantedBy=multi-user.target</code></pre><h3 id="alertmanager-servicce"><a href="#alertmanager-servicce" class="headerlink" title="alertmanager.servicce"></a>alertmanager.servicce</h3><p>/usr/lib/systemd/system/alertmanager.service</p><pre><code>[Unit]Description=alertmanagerAfter=network.target[Service]Type=simpleUser=prometheusExecStart=/usr/local/bin/alertmanager \          --config.file=/etc/prometheus/alertmanager.yml \          --storage.path=/var/lib/alertmanager \          --data.retention=120hRestart=on-failureRestartSec=60s[Install]WantedBy=multi-user.target</code></pre><h3 id="node-exporter-service"><a href="#node-exporter-service" class="headerlink" title="node_exporter.service"></a>node_exporter.service</h3><p>/usr/lib/systemd/system/node_exporter.service</p><pre><code>[Unit]Description=node_exporterAfter=network.target[Service]Type=simpleUser=prometheusExecStart=/usr/local/bin/node_exporterRestart=on-failureRestartSec=60s[Install]WantedBy=multi-user.target</code></pre><h3 id="blackbox-exporter-service"><a href="#blackbox-exporter-service" class="headerlink" title="blackbox_exporter.service"></a>blackbox_exporter.service</h3><p>/usr/lib/systemd/system/balckbox_exporter.service</p><pre><code>[Unit]Description=blackbox_exporterAfter=network.target[Service]Type=simpleUser=prometheusExecStart=/usr/local/bin/blackbox_exporter \          --config.file=/etc/prometheus/blackbox.yml \          --web.listen-address=:9115 \          --log.level=info          Restart=on-failureRestartSec=60s[Install]WantedBy=multi-user.target</code></pre><h3 id="mysqld-exporter-service"><a href="#mysqld-exporter-service" class="headerlink" title="mysqld_exporter.service"></a>mysqld_exporter.service</h3><p>/usr/lib/systemd/system/mysqld_exporter.service</p><pre><code>[Unit]Description=mysqld_exporterAfter=network.target[Service]Type=simpleUser=prometheusEnvironment=&#39;DATA_SOURCE_NAME=prometheus:prometheus_password@tcp(127.0.0.1:3306)&#39;ExecStart=/usr/local/bin/mysqld_exporter \          --collect.engine_innodb_status \          --collect.info_schema.innodb_metrics \          --collect.info_schema.userstats \          --collect.perf_schema.eventsstatements \          --collect.perf_schema.indexiowaits \          --collect.perf_schema.tableiowaits \          --collect.slave_status \          --log.level=info \          --web.listen-address=:9104 \          --web.telemetry-path=/metricsRestart=on-failureRestartSec=60s[Install]WantedBy=multi-user.target</code></pre><h3 id="postgresql-exporter-service"><a href="#postgresql-exporter-service" class="headerlink" title="postgresql_exporter.service"></a>postgresql_exporter.service</h3><p>/usr/lib/systemd/system/postgresql_exporter.service</p><pre><code>[Unit]Description=postgresql_exporterAfter=network.target[Service]Type=simpleUser=prometheusEnvironment=DATA_SOURCE_NAME=postgresql://postgres_exporter:password@localhost:5432/postgres?sslmode=disableExecStart=/usr/local/bin/postgresql_exporter \          --web.listen-address=:9187 \          --web.telemetry-path=/metrics \          --log.level=info \          --log.format=logger:stderrRestart=on-failureRestartSec=60s[Install]WantedBy=multi-user.target</code></pre><h2 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h2><p>修改了systemd脚本之后需要reload一下</p><pre><code>systemctl daemon-reload</code></pre><h3 id="prometheus-1"><a href="#prometheus-1" class="headerlink" title="prometheus"></a>prometheus</h3><pre><code>systemctl enable --now prometheus.service</code></pre><h3 id="alertmanager-1"><a href="#alertmanager-1" class="headerlink" title="alertmanager"></a>alertmanager</h3><pre><code>systemctl enable --now alertmanager.service</code></pre><h3 id="node-exporter-1"><a href="#node-exporter-1" class="headerlink" title="node_exporter"></a>node_exporter</h3><pre><code>systemctl enable --now node_exporter.service</code></pre><h3 id="grafana-2"><a href="#grafana-2" class="headerlink" title="grafana"></a>grafana</h3><pre><code>systemctl enable --now grafana.service</code></pre><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><blockquote><p>其他服务同理，择需启动对应的服务即可</p></blockquote><h2 id="验证服务"><a href="#验证服务" class="headerlink" title="验证服务"></a>验证服务</h2><h3 id="prometheus-2"><a href="#prometheus-2" class="headerlink" title="prometheus"></a>prometheus</h3><p>浏览器访问<code>http://prometheus_server_ip:9090</code></p><h3 id="alertmanager-2"><a href="#alertmanager-2" class="headerlink" title="alertmanager"></a>alertmanager</h3><p>浏览器访问<code>http://prometheus_server_ip:9093</code></p><h3 id="node-exporter-2"><a href="#node-exporter-2" class="headerlink" title="node_exporter"></a>node_exporter</h3><p>浏览器访问<code>http://prometheus_server_ip:9100</code></p><h3 id="grafana-3"><a href="#grafana-3" class="headerlink" title="grafana"></a>grafana</h3><p>浏览器访问<code>http://prometheus_server_ip:3000</code></p><p>默认用户密码<code>admin</code>/<code>admin</code>，初次登录需要改密码</p><h1 id="配置grafana监控面板"><a href="#配置grafana监控面板" class="headerlink" title="配置grafana监控面板"></a>配置grafana监控面板</h1><p><a href="https://grafana.com/dashboards" target="_blank" rel="noopener">这里</a>很多作业可以抄，这里简单列举几个我用到的面板</p><h2 id="node-exporter面板"><a href="#node-exporter面板" class="headerlink" title="node_exporter面板"></a>node_exporter面板</h2><p><a href="https://grafana.com/dashboards/8919" target="_blank" rel="noopener">1 Node Exporter 0.16–0.18 for Prometheus 监控展示看板</a></p><p><img src="https://cdn.nlark.com/yuque/0/2019/jpeg/293789/1558407617091-d0ca215d-674c-49cf-b10e-9d157894413b.jpeg" alt="img"></p><h2 id="mysqld-exporter面板"><a href="#mysqld-exporter面板" class="headerlink" title="mysqld_exporter面板"></a>mysqld_exporter面板</h2><p><a href="https://github.com/percona/grafana-dashboards" target="_blank" rel="noopener">Percona出品的dashboard</a></p><p><img src="https://cdn.nlark.com/yuque/0/2019/png/293789/1558407620385-f6d98cbe-73b0-46fc-81e6-e68f535538f5.png" alt="img"></p><p><a href="https://grafana.com/dashboards/6239" target="_blank" rel="noopener">第三方人员提供的dashboard</a></p><p><img src="https://cdn.nlark.com/yuque/0/2019/png/293789/1558407617454-4f3f9655-0509-4ed6-a9c1-24cecec00993.png?x-oss-process=image/resize,w_2222" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> monitor </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络解析与抓包工具</title>
      <link href="2020/05/21/network/wang-luo-jie-xi-yu-zhua-bao-gong-ju/"/>
      <url>2020/05/21/network/wang-luo-jie-xi-yu-zhua-bao-gong-ju/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="网络解析与抓包–简介"><a href="#网络解析与抓包–简介" class="headerlink" title="网络解析与抓包–简介"></a>网络解析与抓包–简介</h3><p>本文简述一下内容：</p><p>TCP三次握手和四次挥手</p><p>网络分析工具tcpdump抓包</p><h5 id="No-1-tcp三次握手和四次挥手"><a href="#No-1-tcp三次握手和四次挥手" class="headerlink" title="No.1 tcp三次握手和四次挥手"></a><strong>No.1 tcp三次握手和四次挥手</strong></h5><p>—确认ACK, 仅当ACK=1时, 确认号字段才有效. TCP规定在连接建立后所有报文的传输都必须把ACK置1</p><p>—同步SYN, 在连接建立时用来同步序号. 当SYN=1 ACK=0 表明是连接请求报文, 若同意连接则响应报文中应该使SYN=1 ACK=1</p><p>—终止FIN, 用来释放连接. 当FIN=1表明此报文的发送方的数据已经发送完毕并且要求释放</p><h6 id="三次握手-建立连接"><a href="#三次握手-建立连接" class="headerlink" title="三次握手_建立连接"></a>三次握手_建立连接</h6><ul><li>第一次握手:Client将标志位SYN置为1, 随机产生一个值seq=x, 并将该数据包发送给Server, Client进入SYN_SENT状态, 等待Server确认</li><li>第二次握手:Server收到数据包后由标志位SYN=1知道Client请求建立连接, Server将标志位SYN和ACK都置为1, ack=x+1, 随机产生一个值seq=y, 并将该数据包发送给Client以确认连接请求, Server进入SYN_RCVD状态</li><li>第三次握手: Client收到确认后, 检查ack是否为x+1, ACK是否为1, 如果正确则将标志位ACK置为1, ack=y+1并将该数据包发送给Server, Server检查ack是否为y+1, ACK是否为1, 如果正确则连接建立成功, Client和Server进入ESTABLISHED状态, 完成三次握手, 随后Client与Server之间可以开始传输数据了</li></ul><p><img src="http://pb3.pstatp.com/large/pgc-image/b58d300a5a7c45e7ae396651edf473a7" alt="img"></p><h6 id="四次挥手-断开连接"><a href="#四次挥手-断开连接" class="headerlink" title="四次挥手_断开连接"></a>四次挥手_断开连接</h6><ul><li>第一次挥手：Client发送一个FIN, 用来关闭Client到Server的数据传送, Client进入FIN_WAIT_1状态</li><li>第二次挥手：Server收到FIN后, 发送一个ACK给Client, 确认序号为收到序号+1, Server进入CLOSE_WAIT状</li><li>第三次挥手：Server发送一个FIN, 用来关闭Server到Client的数据传送, Server进入LAST_ACK状态</li><li>第四次挥手：Client收到FIN后, Client进入TIME_WAIT状态, 接着发送一个ACK给Server, 确认序号为收到序号+1, Server进入CLOSED状态, 完成四次挥手</li></ul><p><img src="http://pb3.pstatp.com/large/pgc-image/5ab36dab139a42e6be52ff4976cc84ea" alt="img"></p><h5 id="No-2-网络分析工具tcpdump抓包"><a href="#No-2-网络分析工具tcpdump抓包" class="headerlink" title="No.2 网络分析工具tcpdump抓包"></a><strong>No.2 网络分析工具tcpdump抓包</strong></h5><p>抓取tcp的三次握手</p><p>tcpdump -S host 192.168.0.108 and 151.101.100.133</p><p><img src="http://pb3.pstatp.com/large/pgc-image/cde15b7285c641cd9ce597ecebf0599e" alt="img"></p><h6 id="抓取tcp的四次挥手"><a href="#抓取tcp的四次挥手" class="headerlink" title="抓取tcp的四次挥手"></a>抓取tcp的四次挥手</h6><p>（算了，懒得写了）在上方的基础上断开连接即可</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tomcat__05_JVM_排障工具</title>
      <link href="2020/04/02/linux/tomcat-05/"/>
      <url>2020/04/02/linux/tomcat-05/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="JVM-运维实用排障工具"><a href="#JVM-运维实用排障工具" class="headerlink" title="JVM 运维实用排障工具"></a>JVM 运维实用排障工具</h3><h4 id="1、jps"><a href="#1、jps" class="headerlink" title="1、jps"></a>1、jps</h4><pre><code>用来查看Java进程的具体状态, 包括进程ID，进程启动的路径及启动参数等等，与unix上的ps类似，只不过jps是用来显示java进程，可以把jps理解为ps的一个子集。常用参数如下:-q：忽略输出的类名、Jar名以及传递给main方法的参数，只输出pid-m：输出传递给main方法的参数，如果是内嵌的JVM则输出为null-l：输出完全的包名，应用主类名，jar的完全路径名-v：输出传给jvm的参数注意: 使用jps 时的运行账户要和JVM 虚拟机启动的账户一致。若启动JVM虚拟机是运行的账户为www，那使用jps指令时，也要使用www 用户去指定。 sudo -u www jps</code></pre><p>Example</p><pre class=" language-shell"><code class="language-shell">// 查看已经运行的JVM 进程的实际启动参数[root@mouse03 bin]# jps  -v38372 Jps -Dapplication.home=/usr/local/jdk -Xms8m38360 Bootstrap -Djava.util.logging.config.file=/data0/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Xms4096m -Xmx4096m -XX:PermSize=1024m -XX:MaxPermSize=2048m -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dignore.endorsed.dirs= -Dcatalina.base=/data0/tomcat -Dcatalina.home=/data0/tomcat -Djava.io.tmpdir=/data0/tomcat/temp</code></pre><h4 id="2、jstack"><a href="#2、jstack" class="headerlink" title="2、jstack"></a>2、jstack</h4><pre><code>jstack用于打印出给定的java进程ID或core file或远程调试服务的Java堆栈信息。如果现在运行的java程序呈现hung的状态，jstack是非常有用的。此信息通常在运维的过程中被保存起来(保存故障现场)，以供RD们去分析故障。常用参数如下:jstack &lt;pid&gt;jstack [-l] &lt;pid&gt; //长列表. 打印关于锁的附加信息jstack [-F] &lt;pid&gt; //当’jstack [-l] pid’没有响应的时候强制打印栈信息</code></pre><p>Example</p><pre class=" language-shell"><code class="language-shell">// 打印JVM 的堆栈信息，以供问题排查[root@mouse03 ~]# jstack -F 38360 > /tmp/jstack.log</code></pre><h4 id="3、jinfo"><a href="#3、jinfo" class="headerlink" title="3、jinfo"></a>3、jinfo</h4><pre><code>可以查看或修改运行时的JVM进程的参数。常用参数:jinfo [option] pidwhere &lt;option&gt; is one of:    -flag &lt;name&gt;         to print the value of the named VM flag    -flag [+|-]&lt;name&gt;    to enable or disable the named VM flag    -flag &lt;name&gt;=&lt;value&gt; to set the named VM flag to the given value    -flags               to print VM flags</code></pre><p>Example</p><pre class=" language-shell"><code class="language-shell">// 根据 PID 查看目前分配的最大堆栈[root@mouse03 ~]# jinfo -flag MaxHeapSize 38360-XX:MaxHeapSize=4294967296// 动态更改 JVM 的最大堆栈值[root@mouse03 ~]# jinfo -flag MaxHeapSize=4294967296  38360Exception in thread "main" com.sun.tools.attach.AttachOperationFailedException: flag 'MaxHeapSize' cannot be changed    at sun.tools.attach.LinuxVirtualMachine.execute(LinuxVirtualMachine.java:229)    at sun.tools.attach.HotSpotVirtualMachine.executeCommand(HotSpotVirtualMachine.java:261)    at sun.tools.attach.HotSpotVirtualMachine.setFlag(HotSpotVirtualMachine.java:234)    at sun.tools.jinfo.JInfo.flag(JInfo.java:134)    at sun.tools.jinfo.JInfo.main(JInfo.java:81)// jinfo 并不能动态的改变所有的JVM 参数。 那到底有哪些参数能够被动态的改变呢?// java -XX:+PrintFlagsFinal -version 答应JVM 的所有参数// java -XX:+PrintFlagsFinal -version | grep manageable[root@mouse03 ~]# java -XX:+PrintFlagsFinal -version | grep manageable     intx CMSAbortablePrecleanWaitMillis            = 100                                 {manageable}     intx CMSTriggerInterval                        = -1                                  {manageable}     intx CMSWaitDuration                           = 2000                                {manageable}     bool HeapDumpAfterFullGC                       = false                               {manageable}     bool HeapDumpBeforeFullGC                      = false                               {manageable}     bool HeapDumpOnOutOfMemoryError                = false                               {manageable}    ccstr HeapDumpPath                              =                                     {manageable}    uintx MaxHeapFreeRatio                          = 70                                  {manageable}    uintx MinHeapFreeRatio                          = 40                                  {manageable}     bool PrintClassHistogram                       = false                               {manageable}     bool PrintClassHistogramAfterFullGC            = false                               {manageable}     bool PrintClassHistogramBeforeFullGC           = false                               {manageable}     bool PrintConcurrentLocks                      = false                               {manageable}     bool PrintGC                                   = false                               {manageable}     bool PrintGCDateStamps                         = false                               {manageable}     bool PrintGCDetails                            = false                               {manageable}     bool PrintGCID                                 = false                               {manageable}     bool PrintGCTimeStamps                         = false                               {manageable}// 也只有以上这些值才能够动态的被改变[root@mouse03 ~]# jinfo -flag CMSWaitDuration=1900  38360# 查看， jinfo -flags 查看 JVM 的 flags [root@mouse03 ~]# jinfo -flags 38360Attaching to process ID 38360, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.91-b14Non-default VM flags: -XX:CICompilerCount=2 -XX:CMSWaitDuration=1900 -XX:InitialHeapSize=4294967296 -XX:MaxHeapSize=4294967296 -XX:MaxNewSize=1431633920 -XX:MinHeapDeltaBytes=196608 -XX:NewSize=1431633920 -XX:OldSize=2863333376 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStampsCommand line:  -Djava.util.logging.config.file=/data0/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Xms4096m -Xmx4096m -XX:PermSize=1024m -XX:MaxPermSize=2048m -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dignore.endorsed.dirs= -Dcatalina.base=/data0/tomcat -Dcatalina.home=/data0/tomcat -Djava.io.tmpdir=/data0/tomcat/temp</code></pre><h4 id="4、jstat"><a href="#4、jstat" class="headerlink" title="4、jstat"></a>4、jstat</h4><pre class=" language-shell"><code class="language-shell">// 监控JVM 的状态，常用指令:# jstat -gc 113059 1000 10 // 打印PID 为 113059 JVM 状态，一共打印10次，每次间隔时间为1s(1000ms)// 注 jstat 的用法超级强大， 我们这里只是列举出列其中一个简单的应用。</code></pre><p>Example</p><pre class=" language-shell"><code class="language-shell"># jstat -gc 113059 1000 10 S0C    S1C    S0U    S1U      EC       EU        OC         OU       PC     PU    YGC     YGCT    FGC    FGCT     GCT195904.0 195904.0  0.0   21610.3 1567680.0 1516721.9 8526272.0  3557507.8  1048576.0 163148.4   2577   92.033   0      0.000   92.033195904.0 195904.0 23600.9  0.0   1567680.0 142541.6 8526272.0  3558435.8  1048576.0 163148.4   2578   92.060   0      0.000   92.060195904.0 195904.0 23600.9  0.0   1567680.0 266338.1 8526272.0  3558435.8  1048576.0 163148.4   2578   92.060   0      0.000   92.060195904.0 195904.0 23600.9  0.0   1567680.0 413941.8 8526272.0  3558435.8  1048576.0 163148.4   2578   92.060   0      0.000   92.060195904.0 195904.0 23600.9  0.0   1567680.0 642390.6 8526272.0  3558435.8  1048576.0 163148.4   2578   92.060   0      0.000   92.060195904.0 195904.0 23600.9  0.0   1567680.0 813957.3 8526272.0  3558435.8  1048576.0 163148.4   2578   92.060   0      0.000   92.060195904.0 195904.0 23600.9  0.0   1567680.0 984223.2 8526272.0  3558435.8  1048576.0 163148.4   2578   92.060   0      0.000   92.060195904.0 195904.0 23600.9  0.0   1567680.0 1155472.7 8526272.0  3558435.8  1048576.0 163148.4   2578   92.060   0      0.000   92.060195904.0 195904.0 23600.9  0.0   1567680.0 1399228.5 8526272.0  3558435.8  1048576.0 163148.4   2578   92.060   0      0.000   92.060195904.0 195904.0  0.0   23866.6 1567680.0 38005.6  8526272.0  3559196.7  1048576.0 163148.4   2579   92.092   0      0.000   92.092</code></pre><p><strong>字段意义如下</strong></p><table><thead><tr><th>列名</th><th>说明</th></tr></thead><tbody><tr><td>S0C</td><td>新生代中Survivor space中S0当前容量的大小（KB）</td></tr><tr><td>S1C</td><td>新生代中Survivor space中S1当前容量的大小（KB）</td></tr><tr><td>S0U</td><td>新生代中Survivor space中S0容量使用的大小（KB）</td></tr><tr><td>S1U</td><td>新生代中Survivor space中S1容量使用的大小（KB）</td></tr><tr><td>EC</td><td>Eden space当前容量的大小（KB）</td></tr><tr><td>EU</td><td>Eden space容量使用的大小（KB）</td></tr><tr><td>OC</td><td>Old space当前容量的大小（KB）</td></tr><tr><td>OU</td><td>Old space使用容量的大小（KB）</td></tr><tr><td>PC</td><td>Permanent space当前容量的大小（KB）</td></tr><tr><td>PU</td><td>Permanent space使用容量的大小（KB）</td></tr><tr><td>YGC</td><td>从应用程序启动到采样时发生 Young GC 的次数</td></tr><tr><td>YGCT</td><td>从应用程序启动到采样时 Young GC 所用的时间(秒)</td></tr><tr><td>FGC</td><td>从应用程序启动到采样时发生 Full GC 的次数</td></tr><tr><td>FGCT</td><td>从应用程序启动到采样时 Full GC 所用的时间(秒)</td></tr><tr><td>GCT</td><td>T从应用程序启动到采样时用于垃圾回收的总时间(单位秒)，它的值等于YGC+FGC</td></tr></tbody></table><h4 id="5、jvmtop"><a href="#5、jvmtop" class="headerlink" title="5、jvmtop"></a>5、jvmtop</h4><pre><code>以上介绍的jps、jstack、jinfo等都是安装JDK 时自带的系统分析工具，而jvmtop是一款开源的JVM工具。它的下载地址如下: https://github.com/patric-r/jvmtop顾名思义，它是一个只针对JVM的工具，展示的方式和unix的top命令相似.jvmtop 提供了两个视图，一个是概览视图，可以展示出当前机器的所有的 JVM 的情况. 还有一个视图是详情视图，展示一个 JVM 的详细情况.</code></pre><p><strong>概览视图</strong></p><pre><code>jvmtop.sh</code></pre><p><img src="https://s1.ax1x.com/2020/05/21/YHC9BV.png" alt="YHC9BV.png"></p><pre><code>其中，各个字段的意义分别如下：PID：进程 IDMAIN-CLASS：main 类的名字HPCUR：当前被使用的 heap 的大小HPMAX：最大可用的 heap 的大小NHCUR：当前被使用的非 heap 大小（比如：perm gen）NHMAX：最大可用的非 heap 大小CPU：CPU 的使用情况GC：消耗在 GC 上的时间比例VM：JVM 的提供者，大版本号，小版本号，图中的意思是 Apple 提供的 JDK 6U51 版本。USERNAME：当前的用户名#T：线程数量DL：是否有现成发生死锁</code></pre><p><strong>详情视图</strong></p><pre><code>jvmtop.sh &lt;pid&gt;</code></pre><p><img src="https://s1.ax1x.com/2020/05/21/YHCiAU.png" alt="YHCiAU.png"></p><pre><code>其中，各个字段的意义如下：TID：线程 IDNAME：线程名STATE：线程状态CPU：线程当前的 CPU 占用情况TOTALCPU：从线程被创建开始总体的 CPU 占用情况BLOCKBY：阻塞这个线程的线程 ID</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes-Namespace-配置默认的内存请求和限制</title>
      <link href="2020/04/01/container/kubernetes-ru-men-wei-ming-ming-kong-jian-pei-zhi-mo-ren-de-nei-cun-qing-qiu-he-xian-zhi/"/>
      <url>2020/04/01/container/kubernetes-ru-men-wei-ming-ming-kong-jian-pei-zhi-mo-ren-de-nei-cun-qing-qiu-he-xian-zhi/</url>
      
        <content type="html"><![CDATA[<h4 id="为命名空间配置默认的内存请求和限制"><a href="#为命名空间配置默认的内存请求和限制" class="headerlink" title="为命名空间配置默认的内存请求和限制"></a>为命名空间配置默认的内存请求和限制</h4><blockquote><p>本文介绍怎样给命名空间配置默认的内存请求和限制。 如果在一个有默认内存限制的命名空间创建容器，该容器没有声明自己的内存限制时， 将会被指定默认内存限制。 Kubernetes 还为某些情况指定了默认的内存请求，本章后面会进行介绍。</p></blockquote><h5 id="环境要求："><a href="#环境要求：" class="headerlink" title="环境要求："></a>环境要求：</h5><blockquote><p>集群中的每个节点必须至少有 2 GiB 的内存。</p></blockquote><h5 id="创建命名空间"><a href="#创建命名空间" class="headerlink" title="创建命名空间"></a>创建命名空间</h5><pre class=" language-shell"><code class="language-shell">kubectl create namespace default-mem-example</code></pre><h5 id="创建-LimitRange-和-Pod"><a href="#创建-LimitRange-和-Pod" class="headerlink" title="创建 LimitRange 和 Pod"></a>创建 LimitRange 和 Pod</h5><p>配置默认的内存请求和默认的内存限制。</p><p><code>vi memory-defaults.yaml</code></p><pre class=" language-shell"><code class="language-shell">apiVersion: v1kind: LimitRangemetadata:  name: mem-limit-rangespec:  limits:  - default:      memory: 512Mi    defaultRequest:      memory: 256Mi    type: Container</code></pre><p>在 <code>default-mem-example</code> 命名空间创建限制范围：</p><pre class=" language-shell"><code class="language-shell">kubectl apply -f memory-defaults.yaml --namespace=default-mem-example</code></pre><p>现在，如果在 <code>default-mem-example</code> 命名空间创建容器，并且该容器没有声明自己的内存请求和限制值， 它将被指定默认的内存请求 256 MiB 和默认的内存限制 512 MiB。</p><p>下面是具有一个容器的 Pod 的配置文件。 容器未指定内存请求和限制。</p><pre class=" language-shell"><code class="language-shell">$ vi memory-defaults-pod.yamlapiVersion: v1kind: Podmetadata:  name: default-mem-demospec:  containers:  - name: default-mem-demo-ctr    image: nginx$ kubectl apply -f memory-defaults-pod.yaml --namespace=default-mem-example</code></pre><p>查看 Pod 的详情：</p><pre class=" language-shell"><code class="language-shell">kubectl get pod default-mem-demo --output=yaml --namespace=default-mem-example</code></pre><p>输出内容显示该 Pod 的容器有 256 MiB 的内存请求和 512 MiB 的内存限制。 这些都是 LimitRange 设置的默认值。</p><pre class=" language-shell"><code class="language-shell">containers:- image: nginx  imagePullPolicy: Always  name: default-mem-demo-ctr  resources:    limits:      memory: 512Mi    requests:      memory: 256Mi</code></pre><p>删除 Pod：</p><pre class=" language-shell"><code class="language-shell">kubectl delete pod default-mem-demo --namespace=default-mem-example</code></pre><h6 id="配置内存限制，没配置内存请求示例："><a href="#配置内存限制，没配置内存请求示例：" class="headerlink" title="配置内存限制，没配置内存请求示例："></a>配置内存限制，没配置内存请求示例：</h6><pre class=" language-shell"><code class="language-shell">$ vi memory-defaults-pod-2.yamlapiVersion: v1kind: Podmetadata:  name: default-mem-demo-2spec:  containers:  - name: default-mem-demo-2-ctr    image: nginx    resources:      limits:        memory: "1Gi"### 创建 Pod：kubectl apply -f memory-defaults-pod-2.yaml --namespace=default-mem-example### 查看 Pod 的详情：kubectl get pod default-mem-demo-2 --output=yaml --namespace=default-mem-example输出结果显示容器的内存请求被设置为它的内存限制相同的值。注意该容器没有被指定默认的内存请求值 256MiB。resources:  limits:    memory: 1Gi  requests:    memory: 1Gi</code></pre><h6 id="配置内存请求限制，没配置内存示例："><a href="#配置内存请求限制，没配置内存示例：" class="headerlink" title="配置内存请求限制，没配置内存示例："></a>配置内存请求限制，没配置内存示例：</h6><pre class=" language-shell"><code class="language-shell">$ vi memory-defaults-pod-3.yamlapiVersion: v1kind: Podmetadata:  name: default-mem-demo-3spec:  containers:  - name: default-mem-demo-3-ctr    image: nginx    resources:      requests:        memory: "128Mi"### 创建 Pod：kubectl apply -f memory-defaults-pod-3.yaml --namespace=default-mem-example### 查看 Pod 声明：kubectl get pod default-mem-demo-3 --output=yaml --namespace=default-mem-example### 输出结果显示该容器的内存请求被设置为了容器配置文件中声明的数值。 容器的内存限制被设置为 512MiB，即命名空间的默认内存限制。resources:  limits:    memory: 512Mi  requests:    memory: 128Mi</code></pre><h5 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h5><blockquote><p>如果你的命名空间有资源配额，那么默认内存限制是很有帮助的。 下面是一个例子，通过资源配额为命名空间设置两项约束：</p><ul><li>运行在命名空间中的每个容器必须有自己的内存限制。</li><li>命名空间中所有容器的内存使用量之和不能超过声明的限制值。</li></ul><p>如果一个容器没有声明自己的内存限制，会被指定默认限制，然后它才会被允许在限定了配额的命名空间中运行。</p></blockquote><h5 id="Clean-up"><a href="#Clean-up" class="headerlink" title="Clean up"></a>Clean up</h5><pre class=" language-shell"><code class="language-shell">kubectl delete namespace default-mem-example</code></pre>]]></content>
      
      
      <categories>
          
          <category> container </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tomcat_04_安全优化</title>
      <link href="2020/03/30/linux/tomcat-04/"/>
      <url>2020/03/30/linux/tomcat-04/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h4 id="10、Tomcat安全优化"><a href="#10、Tomcat安全优化" class="headerlink" title="10、Tomcat安全优化"></a>10、Tomcat安全优化</h4><h5 id="1、telnet管理端口保护（强制）"><a href="#1、telnet管理端口保护（强制）" class="headerlink" title="1、telnet管理端口保护（强制）"></a>1、telnet管理端口保护（强制）</h5><table><thead><tr><th><strong>类别</strong></th><th><strong>配置内容及说明</strong></th><th><strong>标准配置</strong></th><th><strong>备注</strong></th></tr></thead><tbody><tr><td>telnet管理端口保护</td><td>1.修改默认的8005管理端口为不易猜测的端口（大于1024）；2.修改SHUTDOWN指令为其他字符串；</td><td><Server port="**8527**" shutdown="**dangerous**"></td><td>1.以上配置项的配置内容只是建议配置，可以按照服务实际情况进行合理配置，但要求端口配置在<strong>8000~8999</strong>之间；</td></tr></tbody></table><h5 id="2、-ajp连接端口保护（推荐）"><a href="#2、-ajp连接端口保护（推荐）" class="headerlink" title="2、 ajp连接端口保护（推荐）"></a>2、 ajp连接端口保护（推荐）</h5><table><thead><tr><th><strong>类别</strong></th><th><strong>配置内容及说明</strong></th><th><strong>标准配置</strong></th><th><strong>备注</strong></th></tr></thead><tbody><tr><td>Ajp 连接端口保护</td><td>1.修改默认的ajp 8009端口为不易冲突的大于1024端口；2.通过iptables规则限制ajp端口访问的权限仅为线上机器；</td><td>&lt;Connector port=”<strong>8528</strong>“protocol=”AJP/1.3” /&gt;</td><td>以上配置项的配置内容仅为建议配置，请按照服务实际情况进行合理配置，但要求端口配置在<strong>8000~8999</strong>之间；；保护此端口的目的在于防止线下的测试流量被mod_jk转发至线上tomcat服务器；</td></tr></tbody></table><h5 id="3、禁用管理端（强制）"><a href="#3、禁用管理端（强制）" class="headerlink" title="3、禁用管理端（强制）"></a>3、禁用管理端（强制）</h5><table><thead><tr><th><strong>类别</strong></th><th><strong>配置内容及说明</strong></th><th><strong>标准配置</strong></th><th><strong>备注</strong></th></tr></thead><tbody><tr><td>禁用管理端</td><td>1. 删除默认的{Tomcat安装目录}/conf/tomcat-users.xml文件，重启tomcat后将会自动生成新的文件；2. 删除{Tomcat安装目录}/webapps下默认的所有目录和文件；3.将tomcat 应用根目录配置为tomcat安装目录以外的目录；</td><td>&lt;Context path=”” docBase=”<strong>/home/work/local/tomcat**</strong>_webapps**”debug=”0”reloadable=”false”crossContext=”true”/&gt;</td><td>对于前段web模块，Tomcat管理端属于tomcat的高危安全隐患，一旦被攻破，黑客通过上传web shell的方式将会直接取得服务器的控制权，后果极其严重；</td></tr></tbody></table><h5 id="4、降权启动（强制）"><a href="#4、降权启动（强制）" class="headerlink" title="4、降权启动（强制）"></a>4、降权启动（强制）</h5><table><thead><tr><th><strong>类别</strong></th><th><strong>配置内容及说明</strong></th><th><strong>标准配置</strong></th><th><strong>备注</strong></th></tr></thead><tbody><tr><td>降权启动</td><td>1.tomcat启动用户权限必须为非root权限，尽量降低tomcat启动用户的目录访问权限；2.如需直接对外使用80端口，可通过普通账号启动后，配置iptables规则进行转发；</td><td></td><td>避免一旦tomcat 服务被入侵，黑客直接获取高级用户权限危害整个server的安全；</td></tr></tbody></table><pre><code>[root@web03 ~]# useradd tomcat[root@web03 ~]# cp -a /application/tools/tomcat8_1 /home/tomcat/[root@web03 ~]# chown -R tomcat.tomcat /home/tomcat/tomcat8_1/[root@web03 ~]# su -c &#39;/home/tomcat/tomcat8_1/bin/startup.sh&#39; tomcatUsing CATALINA_BASE:   /home/tomcat/tomcat8_1Using CATALINA_HOME:   /home/tomcat/tomcat8_1Using CATALINA_TMPDIR: /home/tomcat/tomcat8_1/tempUsing JRE_HOME:        /application/jdkUsing CLASSPATH:       /home/tomcat/tomcat8_1/bin/bootstrap.jar:/home/tomcat/tomcat8_1/bin/tomcat-juli.jarTomcat started.[root@web03 ~]# ps -ef|grep tomcat</code></pre><h5 id="5、文件列表访问控制（强制）"><a href="#5、文件列表访问控制（强制）" class="headerlink" title="5、文件列表访问控制（强制）"></a>5、文件列表访问控制（强制）</h5><table><thead><tr><th><strong>类别</strong></th><th><strong>配置内容及说明</strong></th><th><strong>标准配置</strong></th><th><strong>备注</strong></th></tr></thead><tbody><tr><td>文件列表访问控制</td><td>1.conf/web.xml文件中default部分listings的配置必须为false；</td><td><init-param><param-name><strong>listings</strong></param-name><param-value><strong>false</strong></param-value></init-param></td><td>false为不列出目录文件，true为允许列出，默认为false；</td></tr></tbody></table><h5 id="6、版本信息隐藏（强制）"><a href="#6、版本信息隐藏（强制）" class="headerlink" title="6、版本信息隐藏（强制）"></a>6、版本信息隐藏（强制）</h5><table><thead><tr><th><strong>类别</strong></th><th><strong>配置内容及说明</strong></th><th><strong>标准配置</strong></th><th><strong>备注</strong></th></tr></thead><tbody><tr><td>版本信息隐藏</td><td>1.修改conf/web.xml，重定向403、404以及500等错误到指定的错误页面；2.也可以通过修改应用程序目录下的WEB-INF/web.xml下的配置进行错误页面的重定向；</td><td><error-page><error-code><strong>403</strong></error-code><location><strong>/forbidden.jsp</strong></location></error-page><error-page><error-code><strong>404</strong></error-code><location><strong>/notfound.jsp</strong></location></error-page><error-page><error-code><strong>500</strong></error-code><location><strong>/systembusy.jsp</strong></location></error-page></td><td>在配置中对一些常见错误进行重定向，避免当出现错误时tomcat默认显示的错误页面暴露服务器和版本信息；必须确保程序根目录下的错误页面已经存在；</td></tr></tbody></table><h5 id="7、Server-header重写（推荐）"><a href="#7、Server-header重写（推荐）" class="headerlink" title="7、Server header重写（推荐）"></a>7、Server header重写（推荐）</h5><table><thead><tr><th><strong>类别</strong></th><th><strong>配置内容及说明</strong></th><th><strong>标准配置</strong></th><th><strong>备注</strong></th></tr></thead><tbody><tr><td>Server header重写</td><td>在HTTP Connector配置中加入server的配置；</td><td>server=”<strong>webserver</strong>“</td><td>当tomcat HTTP端口直接提供web服务时此配置生效，加入此配置，将会替换http 响应Server header部分的默认配置，默认是<code>Apache-Coyote/1.1</code></td></tr></tbody></table><h5 id="8、访问限制（可选）"><a href="#8、访问限制（可选）" class="headerlink" title="8、访问限制（可选）"></a>8、访问限制（可选）</h5><table><thead><tr><th><strong>类别</strong></th><th><strong>配置内容及说明</strong></th><th><strong>标准配置或操作</strong></th><th><strong>备注</strong></th></tr></thead><tbody><tr><td>访问限制</td><td>通过配置，限定访问的ip来源</td><td><Context path="" docBase="/home/work/tomcat" debug="0" reloadable="false" crossContext="true">&lt;Valve className=”org.apache.catalina.valves.RemoteAddrValve” <strong>allow=”61.148.18.138,61.135.165.*“ deny=”*.*.*.*“</strong>/&gt;</Context></td><td>通过配置信任ip的白名单，拒绝非白名单ip的访问，此配置主要是针对高保密级别的系统，一般产品线不需要；</td></tr></tbody></table><h5 id="9、起停脚本权限回收（推荐）"><a href="#9、起停脚本权限回收（推荐）" class="headerlink" title="9、起停脚本权限回收（推荐）"></a>9、起停脚本权限回收（推荐）</h5><table><thead><tr><th><strong>类别</strong></th><th><strong>配置内容及说明</strong></th><th><strong>标准配置或操作</strong></th><th><strong>备注</strong></th></tr></thead><tbody><tr><td>起停脚本权限回收</td><td>去除其他用户对Tomcat的bin目录下shutdown.sh、startup.sh、catalina.sh的可执行权限；</td><td>chmod -R 744 tomcat/bin/*</td><td>防止其他用户有起停线上Tomcat的权限；</td></tr></tbody></table><h5 id="10、-访问日志格式规范（推荐）"><a href="#10、-访问日志格式规范（推荐）" class="headerlink" title="10、 访问日志格式规范（推荐）"></a>10、 访问日志格式规范（推荐）</h5><table><thead><tr><th><strong>类别</strong></th><th><strong>配置内容及说明</strong></th><th><strong>标准配置或操作</strong></th><th><strong>备注</strong></th></tr></thead><tbody><tr><td>访问日志格式规范</td><td>开启Tomcat默认访问日志中的Referer和User-Agent记录</td><td><Valve className="org.apache.catalina.valves.AccessLogValve"                 directory="logs"  prefix="localhost_access_log." suffix=".txt"                 pattern="%h %l %u %t %r %s %b %{Referer}i %{User-Agent}i %D" resolveHosts="false"/></td><td>开启Referer和User-Agent是为了一旦出现安全问题能够更好的根据日志进行问题排查；</td></tr></tbody></table><h5 id="11、-附录：建议配置及标准执行方案"><a href="#11、-附录：建议配置及标准执行方案" class="headerlink" title="11、 附录：建议配置及标准执行方案"></a>11、 附录：建议配置及标准执行方案</h5><p><strong>1.</strong>       <strong>配置部分（**</strong>${ CATALINA_HOME }conf/server.xml<strong>**）</strong></p><pre><code>&lt;Server port=&quot;8527&quot; shutdown=&quot; dangerous&quot;&gt;&lt;!-- Define a non-SSL HTTP/1.1 Connector on port 8080 --&gt;&lt;Connector port=&quot;8080&quot; server=&quot;webserver&quot;/&gt; &lt;!-- Define an AJP 1.3 Connector on port 8528 --&gt;&lt;!--Define an accesslog --&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot;                 directory=&quot;logs&quot;  prefix=&quot;localhost_access_log.&quot; suffix=&quot;.txt&quot;                 pattern=&quot;%h %l %u %t %r %s %b %{Referer}i %{User-Agent}i %D&quot; resolveHosts=&quot;false&quot;/&gt;    &lt;Connector port=&quot;8528&quot; protocol=&quot;AJP/1.3&quot; /&gt;&lt;Context path=&quot;&quot; docBase=&quot;/home/work/local/tomcat_webapps&quot; debug=&quot;0&quot; reloadable=&quot;false&quot; crossContext=&quot;true&quot;/&gt;</code></pre><p><strong>2.</strong>       <strong>配置部分（**</strong>${ CATALINA_HOME }conf/web.xml<strong><strong>或者</strong></strong>WEB-INF/web.xml<strong>**）</strong></p><pre><code>&lt;init-param&gt;    &lt;param-name&gt;listings&lt;/param-name&gt;    &lt;param-value&gt;false&lt;/param-value&gt;&lt;/init-param&gt;&lt;error-page&gt;    &lt;error-code&gt;403&lt;/error-code&gt;    &lt;location&gt;/forbidden.jsp&lt;/location&gt;&lt;/error-page&gt;&lt;error-page&gt;    &lt;error-code&gt;404&lt;/error-code&gt;    &lt;location&gt;/notfound.jsp&lt;/location&gt;&lt;/error-page&gt;&lt;error-page&gt;    &lt;error-code&gt;500&lt;/error-code&gt;    &lt;location&gt;/systembusy.jsp&lt;/location&gt;&lt;/error-page&gt;</code></pre><p><strong>3.</strong>       <strong>删除如下**</strong>tomcat<strong>**的默认目录和默认文件</strong></p><pre><code>tomcat/webapps/*tomcat/conf/tomcat-user.xml</code></pre><p><strong>4.</strong>       <strong>去除其他用户对**</strong>tomcat** <strong>起停脚本的执行权限</strong></p><pre><code>chmod 744 –R tomcat/bin/*</code></pre><h4 id="11、Tomcat性能优化"><a href="#11、Tomcat性能优化" class="headerlink" title="11、Tomcat性能优化"></a>11、Tomcat性能优化</h4><p>tomcat性能取决于 内存大小</p><p><strong>上策：优化代码</strong></p><p>   该项需要开发经验足够丰富，对开发人员要求较高</p><p><strong>中策：jvm**</strong>优化机制** <strong>垃圾回收机制</strong> <strong>把不需要的内存回收</strong></p><p>​                  优化jvm–优化垃圾回收策略</p><p>优化catalina.sh配置文件。在catalina.sh配置文件中添加以下代码</p><pre><code># tomcat分配1G内存模板JAVA_OPTS=&quot;-Djava.awt.headless=true -Dfile.encoding=UTF-8 -server -Xms1024m -Xmx1024m -XX:NewSize=512m -XX:MaxNewSize=512m -XX:PermSize=512m -XX:MaxPermSize=512m&quot;        JAVA_OPTS=&quot;-Djava.awt.headless=true -Dfile.encoding=UTF-8 -server -Xms800m -Xmx800m -XX:NewSize=400m -XX:MaxNewSize=400m -XX:PermSize=400m -XX:MaxPermSize=400m&quot;    # 重启服务su -c &#39;/home/tomcat/tomcat8_1/bin/shutdown.sh&#39; tomcatsu -c &#39;/home/tomcat/tomcat8_1/bin/startup.sh&#39; tomcat</code></pre><p>​         <strong>修改之前</strong></p><p><img src="https://s1.ax1x.com/2020/05/21/YHitTf.png" alt="YHitTf.png"></p><p>​         <strong>修改之后</strong></p><p><img src="https://s1.ax1x.com/2020/05/21/YHiUk8.png" alt="YHiUk8.png"></p><p><strong>下策：加足够大的内存</strong></p><p>该项的资金投入较大</p><p><strong>下下策：每天0**</strong>点定时重启tomcat**</p><p>使用较为广泛</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes常用命令</title>
      <link href="2020/03/29/container/kubernetes-chang-yong-ming-ling/"/>
      <url>2020/03/29/container/kubernetes-chang-yong-ming-ling/</url>
      
        <content type="html"><![CDATA[<p>常用kubectl命令介绍:</p><h6 id="1-help"><a href="#1-help" class="headerlink" title="1.help"></a>1.help</h6><blockquote><p>​    类似于所有的命令行工具工具，kubectl也可以直接执行<kubectl>或<kubectl help> | &lt;kubectl –help&gt;可获得命令的帮助信息</p></blockquote><pre class=" language-shell"><code class="language-shell"># kubectl --help  查看kubectl帮助信息# kubectl command --help   查看具体命令的帮助信息</code></pre><h6 id="2-get"><a href="#2-get" class="headerlink" title="2.get"></a>2.get</h6><blockquote><p>get命令用于获取集群的resource信息,如node(no),namespace(ns),pod(po),service(svc)等,使用–help可以获取帮助信息</p></blockquote><pre class=" language-shell"><code class="language-shell"># kubectl get node                               #查看node# kubectl get namespace                      #查看namespace# kubectl get po --all-namespaces         #查看所有的pod# kubectl get po -n kube-system           #查看指定namespace中的所有pod# kubectl get svc  -o yaml                    #查看service并以yaml的格式输出.-o 选项还有wide,json等,详见帮助</code></pre><h6 id="3-describe"><a href="#3-describe" class="headerlink" title="3.describe"></a>3.describe</h6><blockquote><p>类似于get,不同的是describe将攻取某一具体资源的更详细信息</p></blockquote><pre class=" language-shell"><code class="language-shell"># kubectl describe no NodeName                               #获取某个节点的详细信息# kubectl describe pod PodName -n NameSpace          #获取某个pod的详细信息</code></pre><h6 id="4-create"><a href="#4-create" class="headerlink" title="4.create"></a>4.create</h6><blockquote><p>​    根据文件或输入创建集群resource</p></blockquote><pre class=" language-shell"><code class="language-shell"># kubectl create -f rc-nginx.yaml</code></pre><h6 id="5-replace"><a href="#5-replace" class="headerlink" title="5.replace"></a>5.replace</h6><blockquote><p>​    replace命令用于对已有资源进行更新、替换. 如前面create中创建的nginx，当我们需要更新resource的一些属性的时候，<br>​    如果修改副本数量，增加、修改label，更改image版本，修改端口等。都可以直接修改原yaml文件，然后执行replace命令.</p></blockquote><pre class=" language-shell"><code class="language-shell"># kubectl replace -f rc-nginx.yaml注：名字不能被更新。另外，如果是更新label，原有标签的pod将会与更新label后的rc断开联系，有新label的rc将会创建指定副本数的新的pod，但是默认并不会删除原来的pod。所以此时如果使用get po将会发现pod数翻倍，进一步check会发现原来的pod已经不会被新rc控制</code></pre><h6 id="6-patch"><a href="#6-patch" class="headerlink" title="6.patch"></a>6.patch</h6><blockquote><p>如果一个容器已经在运行，这时需要对一些容器属性进行修改，又不想删除容器，或不方便通过replace的方式进行更新。<br>kubernetes还提供了一种在容器运行时，直接对容器进行修改的方式，就是patch命令。 </p></blockquote><pre class=" language-shell"><code class="language-shell">如前面创建pod的label是app=nginx-2，如果在运行过程中，需要把其label改为app=nginx-3，这patch命令如下：# kubectl patch pod rc-nginx-2-kpiqt -p '{"metadata":{"labels":{"app":"nginx-3"}}}'</code></pre><h6 id="7-delete"><a href="#7-delete" class="headerlink" title="7.delete"></a>7.delete</h6><blockquote><p>根据resource名,文件或label删除resource</p></blockquote><pre class=" language-shell"><code class="language-shell"># kubectl delete -f rc-nginx.yaml                    #通过yaml文件删除# kubectl delete po rc-nginx-btv4j                  #通过pod名称删除# kubectl delete po -l app=nginx-2                #通过label删除</code></pre><h6 id="8-logs"><a href="#8-logs" class="headerlink" title="8.logs"></a>8.logs</h6><blockquote><p>logs命令用于显示pod运行中，容器内程序输出到标准输出的内容。跟docker的logs命令类似。如果要获得tail -f 的方式，也可以使用-f选项</p></blockquote><pre class=" language-shell"><code class="language-shell"># kubectl logs rc-nginx-2-kpiqt </code></pre><h6 id="9-rolling-update"><a href="#9-rolling-update" class="headerlink" title="9.rolling-update"></a>9.rolling-update</h6><blockquote><p>rolling-update是一个非常重要的命令，对于已经部署并且正在运行的业务，rolling-update提供了不中断业务的更新方式。<br>rolling-update每次起一个新的pod，等新pod完全起来后删除一个旧的pod，然后再起一个新的pod替换旧的pod，直到替换掉所有的pod。 </p></blockquote><pre class=" language-shell"><code class="language-shell">rolling-update需要确保新的版本有不同的name，Version和label，否则会报错# kubectl rolling-update rc-nginx-2 -f rc-nginx.yaml     #升级如果在升级过程中，发现有问题还可以中途停止update，并回滚到前面版本# kubectl rolling-update rc-nginx-2 --rollback              #回滚</code></pre><blockquote><h6 id="10-scale"><a href="#10-scale" class="headerlink" title="10.scale"></a>10.scale</h6><p>​    scale用于副本的扩容或缩容，如前面创建的nginx有两个副本，可以轻松的使用scale命令对副本数进行扩展或缩小。</p></blockquote><pre class=" language-shell"><code class="language-shell"> # kubectl scale deployment  rc-nginx-3 --replicas=4       #扩容到4个     # kubectl scale deployment rc-nginx-3 --replicas=2        #缩容至2个</code></pre>]]></content>
      
      
      <categories>
          
          <category> container </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tomcat_03_监控</title>
      <link href="2020/03/27/linux/tomcat-03/"/>
      <url>2020/03/27/linux/tomcat-03/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h4 id="9、监控tomcat集群状态"><a href="#9、监控tomcat集群状态" class="headerlink" title="9、监控tomcat集群状态"></a>9、监控tomcat集群状态</h4><h5 id="1、方法一：开发java监控页面"><a href="#1、方法一：开发java监控页面" class="headerlink" title="1、方法一：开发java监控页面"></a>1、方法一：开发java监控页面</h5><pre><code>[root@web03 tomcat8_1]# cat /application/tomcat/webapps/memtest/meminfo.jsp &lt;%Runtime rtm = Runtime.getRuntime();long mm = rtm.maxMemory()/1024/1024;long tm = rtm.totalMemory()/1024/1024;long fm = rtm.freeMemory()/1024/1024;out.println(&quot;JVM memory detail info :&lt;br&gt;&quot;);out.println(&quot;Max memory:&quot;+mm+&quot;MB&quot;+&quot;&lt;br&gt;&quot;);out.println(&quot;Total memory:&quot;+tm+&quot;MB&quot;+&quot;&lt;br&gt;&quot;);out.println(&quot;Free memory:&quot;+fm+&quot;MB&quot;+&quot;&lt;br&gt;&quot;);out.println(&quot;Available memory can be used is :&quot;+(mm+fm-tm)+&quot;MB&quot;+&quot;&lt;br&gt;&quot;);%&gt;</code></pre><h5 id="2、方法二：使用jps命令进行监控"><a href="#2、方法二：使用jps命令进行监控" class="headerlink" title="2、方法二：使用jps命令进行监控"></a>2、方法二：使用jps命令进行监控</h5><pre><code>[root@web03 ~]# jps -lvm31906 org.apache.catalina.startup.Bootstrap start -Djava.util.logging.config.file=/application/tomcat8_1/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.endorsed.dirs=/application/tomcat8_1/endorsed -Dcatalina.base=/application/tomcat8_1 -Dcatalina.home=/application/tomcat8_1 -Djava.io.tmpdir=/application/tomcat8_1/temp31812 org.apache.catalina.startup.Bootstrap start -Djava.util.logging.config.file=/application/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.endorsed.dirs=/application/tomcat/endorsed -Dcatalina.base=/application/tomcat -Dcatalina.home=/application/tomcat -Djava.io.tmpdir=/application/tomcat/temp31932 org.apache.catalina.startup.Bootstrap start -Djava.util.logging.config.file=/application/tomcat8_2/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.endorsed.dirs=/application/tomcat8_2/endorsed -Dcatalina.base=/application/tomcat8_2 -Dcatalina.home=/application/tomcat8_2 -Djava.io.tmpdir=/application/tomcat8_2/temp32079 sun.tools.jps.Jps -lvm -Denv.class.path=.:/application/jdk/lib:/application/jdk/jre/lib:/application/jdk/lib/tools.jar -Dapplication.home=/application/jdk1.8.0_60 -Xms8m</code></pre><h5 id="3、Tomcat远程监控功能"><a href="#3、Tomcat远程监控功能" class="headerlink" title="3、Tomcat远程监控功能"></a>3、Tomcat远程监控功能</h5><p>修改配置文件，开启远程监控</p><pre><code>vim /application/tomcat8_1/bin/catalina.sh +97CATALINA_OPTS=&quot;$CATALINA_OPTS-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=12345  -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=10.0.0.17&quot;</code></pre><p>​         重启服务，检查12345端口是否开启</p><pre><code>/application/tomcat8_1/bin/shutdown.sh /application/tomcat8_1/bin/startup.sh netstat -tunlp|grep 12345</code></pre><p>​         检查端口</p><pre><code>[root@web03 ~]# netstat -tunlp|grep 12345tcp6       0      0 :::12345           :::*          LISTEN      33158/java  </code></pre><p><strong>在windows**</strong>上监控tomcat**</p><p><strong>注意：windwos**</strong>需要安装jdk<strong>**环境！</strong></p><p>查考：<a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="noopener">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a></p><h5 id="4、zabbix监控tomcat程序"><a href="#4、zabbix监控tomcat程序" class="headerlink" title="4、zabbix监控tomcat程序"></a>4、zabbix监控tomcat程序</h5><p>zabbix搭建详情参考：<em><a href="https://www.toutiao.com/i6808897883299906059/" target="_blank" rel="noopener">https://www.toutiao.com/i6808897883299906059/</a></em></p><p>若是有问题，请移步官网 ： <em><a href="https://www.zabbix.com/documentation/4.0/zh/manual/installation" target="_blank" rel="noopener">https://www.zabbix.com/documentation/4.0/zh/manual/installation</a></em></p><p><strong>服务端安装配置java**</strong>监控服务**</p><pre><code>[root@m01 ~]# yum install zabbix-java-gateway -y</code></pre><p><strong>查看配置文件</strong></p><pre><code>配置文件路径：/etc/zabbix/zabbix_java_gateway.confsed -i -e &#39;220a JavaGateway=127.0.0.1&#39; -e &#39;236a StartJavaPollers=5&#39;  /etc/zabbix/zabbix_server.conf</code></pre><p>启动zabbix-java-gateway服务，与zabbix服务</p><pre><code>systemctl start zabbix-java-gateway.servicesystemctl restart zabbix-server.service</code></pre><p>检查java端口是否开启</p><pre><code>[root@m01 ~]# netstat -lntup |grep javatcp6       0      0 :::10052   :::*    LISTEN      72971/java  </code></pre><p>​         检查java进程是否存在</p><pre><code>[root@m01 ~]# ps -ef |grep [j]avazabbix    72971      1  0 11:29 ?        00:00:00 java -server -Dlogback.configurationFile=/etc/zabbix/zabbix_java_gateway_logback.xml -classpath lib:lib/android-json-4.3_r3.1.jar:lib/logback-classic-0.9.27.jar:lib/logback-core-0.9.27.jar:lib/slf4j-api-1.6.1.jar:bin/zabbix-java-gateway-3.0.13.jar -Dzabbix.pidFile=/var/run/zabbix/zabbix_java.pid -Dzabbix.timeout=3 -Dsun.rmi.transport.tcp.responseTimeout=3000 com.zabbix.gateway.JavaGatewayzabbix    73255  73226  0 11:35 ?        00:00:00 /usr/sbin/zabbix_server: java poller #1 [got 0 values in 0.000002 sec, idle 5 sec]zabbix    73256  73226  0 11:35 ?        00:00:00 /usr/sbin/zabbix_server: java poller #2 [got 0 values in 0.000002 sec, idle 5 sec]zabbix    73257  73226  0 11:35 ?        00:00:00 /usr/sbin/zabbix_server: java poller #3 [got 0 values in 0.000002 sec, idle 5 sec]zabbix    73258  73226  0 11:35 ?        00:00:00 /usr/sbin/zabbix_server: java poller #4 [got 0 values in 0.000002 sec, idle 5 sec]zabbix    73259  73226  0 11:35 ?        00:00:00 /usr/sbin/zabbix_server: java poller #5 [got 0 values in 0.000004 sec, idle 5 sec]</code></pre><p><strong>web**</strong>界面添加**</p><p>​         添加主机</p><p><img src="https://s1.ax1x.com/2020/05/21/YHilSH.png" alt="YHilSH.png"> </p><p>​         主机管理模板，注意是JMX模板</p><p><img src="https://s1.ax1x.com/2020/05/21/YHi36A.png" alt="YHi36A.png">         监控完成</p><p><img src="https://s1.ax1x.com/2020/05/21/YHi8OI.png" alt="YHi8OI.png"> </p><h5 id="5、排除tomcat故障步骤"><a href="#5、排除tomcat故障步骤" class="headerlink" title="5、排除tomcat故障步骤"></a>5、排除tomcat故障步骤</h5><p>a. 查看catalina.out</p><p>b. 使用sh show-busy-java-threads.sh脚本进行检测</p><p>脚本下载地址</p><p><em><a href="https://files.cnblogs.com/files/clsn/show-busy-java-threads.sh" target="_blank" rel="noopener">https://files.cnblogs.com/files/clsn/show-busy-java-threads.sh</a></em></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tomcat_02_应用部署</title>
      <link href="2020/03/25/linux/tomcat-02/"/>
      <url>2020/03/25/linux/tomcat-02/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h4 id="6、WEB站点部署"><a href="#6、WEB站点部署" class="headerlink" title="6、WEB站点部署"></a>6、WEB站点部署</h4><p>上线的代码有两种方式：</p><p>第一种方式是直接将程序目录放在webapps目录下面，这种方式大家已经明白了，就不多说了。</p><p>第二种方式是使用开发工具将程序打包成war包，然后上传到webapps目录下面。</p><h5 id="1、使用war包部署web站点"><a href="#1、使用war包部署web站点" class="headerlink" title="1、使用war包部署web站点"></a>1、使用war包部署web站点</h5><pre><code>[root@web03 webapps]# pwd/application/tomcat/webapps[root@web03 webapps]# wget http://10.0.0.1/apache/tomcat/memtest.war</code></pre><p>站点主动解压部署</p><pre><code>[root@web03 webapps]# lsdocs  examples  host-manager  logs  manager  memtest  memtest.war  ROOT</code></pre><p>浏览器访问：</p><p><em><a href="http://10.0.0.17:8080//memtest/meminfo.jsp" target="_blank" rel="noopener">http://10.0.0.17:8080//memtest/meminfo.jsp</a></em></p><p><img src="https://s1.ax1x.com/2020/05/21/YHPrdK.png" alt="YHPrdK.png"></p><h5 id="2、自定义默认网站目录"><a href="#2、自定义默认网站目录" class="headerlink" title="2、自定义默认网站目录"></a>2、自定义默认网站目录</h5><p>上面访问的网址为 <em><a href="http://10.0.0.3:8080/memtest/meminfo.jsp" target="_blank" rel="noopener">http://10.0.0.3:8080/memtest/meminfo.jsp</a></em></p><p>现在想访问格式为<em><a href="http://10.0.0.3:8080/meminfo.jsp" target="_blank" rel="noopener">http://10.0.0.3:8080/meminfo.jsp</a></em></p><p><strong>方法一</strong></p><p>将meminfo.jsp或其他程序放在tomcat/webapps/ROOT目录下即可。因为默认网站根目录为tomcat/webapps/ROOT</p><p><strong>方法二</strong></p><pre><code>[root@web03 ~]# vim /application/tomcat/conf/server.xml +125…… #添加上这两行        &lt;Context path=&quot;&quot; docBase=&quot;/application/tomcat/webapps/memtest&quot; debug=&quot;0&quot; reloadable=&quot;false&quot; crossContext=&quot;true&quot;/&gt;        &lt;Context path=&quot;/40team&quot; docBase=&quot;/application/tomcat/webapps/memtest&quot; debug=&quot;0&quot; reloadable=&quot;false&quot; crossContext=&quot;true&quot;/&gt;……</code></pre><p>修改配置文件后，要重启服务</p><pre><code>[root@web03 ~]# /application/tomcat/bin/shutdown.sh [root@web03 ~]# /application/tomcat/bin/startup.sh  </code></pre><h5 id="3、部署开源站点（jpress）"><a href="#3、部署开源站点（jpress）" class="headerlink" title="3、部署开源站点（jpress）"></a>3、部署开源站点（jpress）</h5><p>jpress官网：<a href="http://jpress.io" target="_blank" rel="noopener">http://jpress.io</a></p><p>下载地址：<a href="https://github.com/JpressProjects/jpress" target="_blank" rel="noopener">https://github.com/JpressProjects/jpress</a></p><p>​         第一个里程碑：安装配置数据库</p><pre><code>yum -y install mariadb-serversystemctl start mariadb.service</code></pre><p>​         #配置数据库</p><pre><code>mysqlcreate database jpress DEFAULT CHARACTER SET utf8;grant all on jpress.* to jpress@&#39;localhost&#39; identified by &#39;123456&#39;;exit</code></pre><p>​         第二个里程碑：jpress站点上线</p><pre><code>[root@web03 webapps]# pwd/application/tomcat/webapps[root@web03 webapps]# wget http://10.0.0.1/apache/tomcat/jpress-web-newest.war</code></pre><p>​         第三个里程碑：浏览器访问</p><p>浏览器访问： <a href="http://10.0.0.17:8080/jpress-web-newest/install" target="_blank" rel="noopener">http://10.0.0.17:8080/jpress-web-newest/install</a></p><p><img src="https://s1.ax1x.com/2020/05/21/YHPsIO.png" alt="YHPsIO.png"></p><p>填写数据库信息</p><p><img src="https://s1.ax1x.com/2020/05/21/YHPWQA.png" alt="YHPWQA.png"></p><p>设置站点名称等</p><p><img src="https://s1.ax1x.com/2020/05/21/YHPIdf.png" alt="YHPIdf.png"></p><p>安装完成</p><p><img src="https://s1.ax1x.com/2020/05/21/YHP7FS.png" alt="YHP7FS.png"></p><p>重启tomcat服务</p><pre><code>[root@web03 ~]# /application/tomcat/bin/shutdown.sh [root@web03 ~]# /application/tomcat/bin/startup.sh  </code></pre><h4 id="7、Tomcat多实例配置"><a href="#7、Tomcat多实例配置" class="headerlink" title="7、Tomcat多实例配置"></a>7、Tomcat多实例配置</h4><p><strong>多虚拟主机</strong>：nginx 多个Server标签（域名，ip，端口） 进程数量固定 master+worker</p><p><strong>多实例（多进程）</strong>：同一个程序启动多次，分为两种情况:</p><p>第一种：一台机器跑多个站点； </p><p>第二种：一个机器跑一个站点多个实例，配合负载均衡</p><h5 id="1、复制程序文件"><a href="#1、复制程序文件" class="headerlink" title="1、复制程序文件"></a>1、复制程序文件</h5><pre><code>    cd /application/tools/    tar xf apache-tomcat-8.0.27.tar.gz    cp -a apache-tomqcat-8.0.27 tomcat8_1    cp -a apache-tomcat-8.0.27 tomcat8_2</code></pre><p>修改端口，以启动多实例。多实例之间端口不能一致</p><pre><code>sed -i &#39;s#8005#8011#;s#8080#8081#&#39; tomcat8_1/conf/server.xmlsed -i &#39;s#8005#8012#;s#8080#8082#&#39; tomcat8_2/conf/server.xml[root@web03 application]# diff tomcat8_1/conf/server.xml tomcat8_2/conf/server.xml22c22&lt; &lt;Server port=&quot;8011&quot; shutdown=&quot;SHUTDOWN&quot;&gt;---&gt; &lt;Server port=&quot;8012&quot; shutdown=&quot;SHUTDOWN&quot;&gt;67c67&lt;          Define a non-SSL/TLS HTTP/1.1 Connector on port 8081---&gt;          Define a non-SSL/TLS HTTP/1.1 Connector on port 808269c69&lt;     &lt;Connector port=&quot;8081&quot; protocol=&quot;HTTP/1.1&quot;---&gt;     &lt;Connector port=&quot;8082&quot; protocol=&quot;HTTP/1.1&quot;75c75&lt;                port=&quot;8081&quot; protocol=&quot;HTTP/1.1&quot;---&gt;                port=&quot;8082&quot; protocol=&quot;HTTP/1.1&quot;</code></pre><p>　　 将配置好的tomcat程序打包，以备之后使用</p><pre><code>tar zcf muti_tomcat8.tar.gz ./tomcat8_1 ./tomcat8_2</code></pre><p>启动tomcat多实例</p><pre><code> /application/tomcat8_1/bin/startup.sh  /application/tomcat8_2/bin/startup.sh</code></pre><p>检查端口是否启动</p><pre><code>[root@web03 tomcat8_1]# netstat -lntup |grep javatcp6   0   0 127.0.0.1:8011    :::*    LISTEN   31906/javatcp6   0   0 127.0.0.1:8012    :::*    LISTEN   31932/javatcp6   0   0 :::8080           :::*    LISTEN   31812/javatcp6   0   0 :::8081           :::*    LISTEN   31906/javatcp6   0   0 :::8082           :::*    LISTEN   31932/javatcp6   0   0 127.0.0.1:8005    :::*    LISTEN   31812/javatcp6   0   0 :::8009           :::*    LISTEN   31812/java</code></pre><p>将每个实例的网页进行区分</p><pre><code>echo 8081 &gt;&gt;/application/tomcat8_1/webapps/ROOT/index.jsp echo 8082 &gt;&gt;/application/tomcat8_2/webapps/ROOT/index.jsp</code></pre><h5 id="2、在浏览器访问，进行测试"><a href="#2、在浏览器访问，进行测试" class="headerlink" title="2、在浏览器访问，进行测试"></a>2、在浏览器访问，进行测试</h5><p>检查多实例的启动</p><p>​                  <a href="http://10.0.0.17:8082" target="_blank" rel="noopener">http://10.0.0.17:8082</a></p><p><img src="https://s1.ax1x.com/2020/05/21/YHPbWQ.png" alt="YHPbWQ.png"></p><p><a href="http://10.0.0.17:8081" target="_blank" rel="noopener">http://10.0.0.17:8081</a></p><p><img src="https://s1.ax1x.com/2020/05/21/YHPXyn.png" alt="YHPXyn.png"></p><h4 id="8、tomcat反向代理集群"><a href="#8、tomcat反向代理集群" class="headerlink" title="8、tomcat反向代理集群"></a>8、tomcat反向代理集群</h4><h5 id="1、负载均衡器说明"><a href="#1、负载均衡器说明" class="headerlink" title="1、负载均衡器说明"></a>1、负载均衡器说明</h5><pre><code>[root@lb01 ~]# cat /etc/redhat-release CentOS release 6.9 (Final)[root@lb01 ~]# uname -aLinux lb01 2.6.32-696.el6.x86_64 #1 SMP Tue Mar 21 19:29:05 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux[root@lb01 ~]# getenforce Disabled[root@lb01 ~]# /etc/init.d/iptables statusiptables: Firewall is not running.</code></pre><p>负载均衡软件使用nginx，详情参照</p><p><a href="http://www.cnblogs.com/clsn/p/7750615.html" target="_blank" rel="noopener">http://www.cnblogs.com/clsn/p/7750615.html</a></p><h5 id="2、配置负载均衡器"><a href="#2、配置负载均衡器" class="headerlink" title="2、配置负载均衡器"></a>2、配置负载均衡器</h5><p>备份原配置文件</p><pre><code>mv  /application/nginx/conf/nginx.conf{,.20171127}    egrep -v &#39;#|^$&#39; /application/nginx/conf/nginx.conf.default  &gt; /application/nginx/conf/nginx.conf</code></pre><p>​         配置文件内容</p><pre><code>[root@lb01 ~]# cat /application/nginx/conf/nginx.confworker_processes  1;events {    worker_connections  1024;}http {    include       mime.types;    default_type  application/octet-stream;    sendfile        on;    keepalive_timeout  65;    upstream web_pools {        server 10.0.0.17:8081;        server 10.0.0.17:8082;    }    server {        listen       80;        server_name  localhost;        location / {            root   html;            index  index.jsp index.htm;        proxy_pass http://web_pools;        }        error_page   500 502 503 504  /50x.html;        location = /50x.html {            root   html;        }    }}</code></pre><p>​         配置完成后重启nginx服务</p><pre><code>/application/nginx/sbin/nginx  -s stop /application/nginx/sbin/nginx</code></pre><h5 id="3、使用命令进行访问测试"><a href="#3、使用命令进行访问测试" class="headerlink" title="3、使用命令进行访问测试"></a>3、使用命令进行访问测试</h5><p>使用curl 命令进行测试，tail进行关键字提取</p><pre><code>[root@lb01 ~]# curl -s 10.0.0.5|tail -18081[root@lb01 ~]# curl -s 10.0.0.5|tail -18082</code></pre><p>使用curl 命令进行测试，awk进行关键字提取</p><pre><code>[root@lb01 ~]# curl -s 10.0.0.5|awk &#39;END{print}&#39;8082[root@lb01 ~]# curl -s 10.0.0.5|awk &#39;END{print}&#39;8081</code></pre><p> 使用curl 命令进行测试，sed进行关键字提取</p><pre><code>[root@lb01 ~]# curl -s 10.0.0.5|sed -n &#39;$p&#39;8082[root@lb01 ~]# curl -s 10.0.0.5|sed -n &#39;$p&#39;8081</code></pre><h5 id="4、在浏览器上进行访问测试"><a href="#4、在浏览器上进行访问测试" class="headerlink" title="4、在浏览器上进行访问测试"></a>4、在浏览器上进行访问测试</h5><p><img src="https://s1.ax1x.com/2020/05/21/YHPjLq.png" alt="YHPjLq.png"></p><p><img src="https://s1.ax1x.com/2020/05/21/YHPxe0.png" alt="YHPxe0.png"></p><p>​         建议使用google浏览器chrome 的隐身模式进行访问，使用ctrl+f5 进行强制刷新</p><h4 id=""><a href="#" class="headerlink" title=""></a></h4>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tomcat_01_简介</title>
      <link href="2020/03/21/linux/tomcat-01/"/>
      <url>2020/03/21/linux/tomcat-01/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h4 id="1、Tomcat-简介"><a href="#1、Tomcat-简介" class="headerlink" title="1、Tomcat 简介"></a><strong>1、Tomcat 简介</strong></h4><p>Tomcat是Apache软件基金会（Apache Software Foundation）的Jakarta 项目中的一个核心项目，由Apache、Sun和其他一些公司及个人共同开发而成。</p><p>Tomcat服务器是一个免费的开放源代码的Web应用服务器，属于轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试JSP程序的首选。</p><p>Tomcat和Nginx、Apache(httpd)、lighttpd等Web服务器一样，具有处理HTML页面的功能，另外它还是一个Servlet和JSP容器，独立的Servlet容器是Tomcat的默认模式。不过，Tomcat处理静态HTML的能力不如Nginx/Apache服务器。</p><p>目前Tomcat最新版本为9.0。Java容器还有resin、weblogic等。</p><p><strong>Tomcat**</strong>官网：** <a href="http://tomcat.apache.org/" target="_blank" rel="noopener">http://tomcat.apache.org</a></p><h5 id="1、Tomcat好帮手—JDK"><a href="#1、Tomcat好帮手—JDK" class="headerlink" title="1、Tomcat好帮手—JDK"></a>1、Tomcat好帮手—JDK</h5><p>JDK是 Java 语言的软件开发工具包，主要用于移动设备、嵌入式设备上的java应用程序。JDK是整个java开发的核心，它包含了JAVA的运行环境（JVM+Java系统类库）和JAVA工具。</p><p><strong>JDK**</strong>包含了一批用于Java<strong>**开发的组件，其中包括：</strong></p><pre><code>javac：编译器，将后缀名为.java的源代码编译成后缀名为“.class”的字节码java：运行工具，运行.class的字节码jar：打包工具，将相关的类文件打包成一个文件javadoc：文档生成器，从源码注释中提取文档，注释需匹配规范jdb debugger：调试工具jps：显示当前java程序运行的进程状态javap：反编译程序appletviewer：运行和调试applet程序的工具，不需要使用浏览器javah：从Java类生成C头文件和C源文件。这些文件提供了连接胶合，使Java和C代码可进行交互。javaws：运行JNLP程序extcheck：一个检测jar包冲突的工具apt：注释处理工具 jhat：java堆分析工具jstack：栈跟踪程序jstat：JVM检测统计工具jstatd：jstat守护进程jinfo：获取正在运行或崩溃的java程序配置信息jmap：获取java进程内存映射信息idlj：IDL-to-Java编译器。将IDL语言转化为java文件 policytool：一个GUI的策略文件创建和管理工具jrunscript：命令行脚本运行</code></pre><p>JDK中还包括完整的JRE（Java Runtime Environment），Java运行环境，也被称为private runtime。包括了用于产品环境的各种库类，如基础类库rt.jar，以及给开发人员使用的补充库，如国际化与本地化的类库、IDL库等等。</p><p>JDK中还包括各种样例程序，用以展示Java API中的各部分。</p><p><strong>JDK**</strong>下载面页：</p><p>**<a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="noopener">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a> **</p><h5 id="2、安装Tomcat-amp-JDK"><a href="#2、安装Tomcat-amp-JDK" class="headerlink" title="2、安装Tomcat &amp; JDK"></a>2、安装Tomcat &amp; JDK</h5><p>安装时候选择tomcat软件版本要与程序开发使用的版本一致。jdk版本要进行与tomcat保持一致。</p><h6 id="1、系统环境说明"><a href="#1、系统环境说明" class="headerlink" title="1、系统环境说明"></a>1、系统环境说明</h6><pre><code>[root@web03 ~]# cat /etc/redhat-release CentOS Linux release 7.4.1708 (Core) [root@web03 ~]# uname -a Linux web03 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux[root@web03 ~]# getenforce Disabled[root@web03 ~]# systemctl status firewalld.service● firewalld.service - firewalld - dynamic firewall daemon   Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled)   Active: inactive (dead)     Docs: man:firewalld(1)</code></pre><h6 id="2-、安装JDK"><a href="#2-、安装JDK" class="headerlink" title="2 、安装JDK"></a>2 、安装JDK</h6><p>命令集：</p><pre><code>tar xf jdk-8u60-linux-x64.tar.gz -C /application/ln -s /application/jdk1.8.0_60 /application/jdk# 设置环境变量sed -i.ori &#39;$a export JAVA_HOME=/application/jdk\nexport PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH\nexport CLASSPATH=.:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar&#39; /etc/profilesource /etc/profile</code></pre><p>测试jdk是否安装成功↓</p><pre><code>[root@web03 ~]# java -versionjava version &quot;1.8.0_60&quot;Java(TM) SE Runtime Environment (build 1.8.0_60-b27)Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode)</code></pre><h6 id="3、安装Tomcat"><a href="#3、安装Tomcat" class="headerlink" title="3、安装Tomcat"></a>3、安装Tomcat</h6><p>命令集：</p><pre><code>tar xf apache-tomcat-8.0.27.tar.gz -C /application/ln -s /application/apache-tomcat-8.0.27 /application/tomcat# 设置环境变量echo &#39;export TOMCAT_HOME=/application/tomcat&#39;&gt;&gt;/etc/profilesource /etc/profile# 注意授权，统一权限chown -R root.root /application/jdk/ /application/tomcat/</code></pre><p>检查tomcat是否安装成功</p><pre><code>[root@web03 ~]# /application/tomcat/bin/version.shUsing CATALINA_BASE:   /application/tomcatUsing CATALINA_HOME:   /application/tomcatUsing CATALINA_TMPDIR: /application/tomcat/tempUsing JRE_HOME:        /application/jdkUsing CLASSPATH:       /application/tomcat/bin/bootstrap.jar:/application/tomcat/bin/tomcat-juli.jarServer version: Apache Tomcat/8.0.27Server built:   Sep 28 2015 08:17:25 UTCServer number:  8.0.27.0OS Name:        LinuxOS Version:     3.10.0-693.el7.x86_64Architecture:   amd64JVM Version:    1.8.0_60-b27JVM Vendor:     Oracle Corporation</code></pre><h4 id="2、Tomcat目录介绍"><a href="#2、Tomcat目录介绍" class="headerlink" title="2、Tomcat目录介绍"></a>2、Tomcat目录介绍</h4><h5 id="1、tomcat主目录介绍"><a href="#1、tomcat主目录介绍" class="headerlink" title="1、tomcat主目录介绍"></a>1、tomcat主目录介绍</h5><pre><code>[root@web03 ~]# cd /application/tomcat/[root@web03 tomcat]# tree -L 1.├── bin              #存放tomcat管理脚本├── conf             # tomcat 配置文件存放目录├── lib              # web应用调用的jar包存放路径├── LICENSE├── logs             # tomcat 日志存放目录，catalina.out 为主要输出日志├── NOTICE├── RELEASE-NOTES├── RUNNING.txt├── temp             # 存放临时文件├── webapps         # web程序存放目录└── work             # 存放编译产生的.java 与 .class文件7 directories, 4 files</code></pre><h5 id="2、webapps目录介绍"><a href="#2、webapps目录介绍" class="headerlink" title="2、webapps目录介绍"></a>2、webapps目录介绍</h5><pre><code>[root@web03 tomcat]# cd webapps/[root@web03 webapps]# tree -L 1.├── docs            # tomcat 帮助文档├── examples       # web应用实例├── host-manager  # 主机管理├── manager         # 管理└── ROOT             # 默认站点根目录5 directories, 0 files</code></pre><h5 id="3、Tomcat配置文件目录介绍（conf）"><a href="#3、Tomcat配置文件目录介绍（conf）" class="headerlink" title="3、Tomcat配置文件目录介绍（conf）"></a>3、Tomcat配置文件目录介绍（conf）</h5><pre><code>[root@web03 conf]# tree -L 1.├── Catalina├── catalina.policy├── catalina.properties├── context.xml├── logging.properties├── logs├── server.xml           # tomcat 主配置文件├── server.xml.bak├── server.xml.bak2├── tomcat-users.xml    # tomcat 管理用户配置文件├── tomcat-users.xsd└── web.xml2 directories, 10 files</code></pre><h5 id="4、Tomcat的管理"><a href="#4、Tomcat的管理" class="headerlink" title="4、Tomcat的管理"></a>4、Tomcat的管理</h5><pre><code>#  启动程序/application/tomcat/bin/startup.sh#  关闭程序/application/tomcat/bin/shutdown.sh</code></pre><p>启动停止</p><pre><code>[root@web03 ~]# /application/tomcat/bin/shutdown.sh Using CATALINA_BASE:   /application/tomcatUsing CATALINA_HOME:   /application/tomcatUsing CATALINA_TMPDIR: /application/tomcat/tempUsing JRE_HOME:        /application/jdkUsing CLASSPATH:       /application/tomcat/bin/bootstrap.jar:/application/tomcat/bin/tomcat-juli.jar[root@web03 ~]# /application/tomcat/bin/startup.sh Using CATALINA_BASE:   /application/tomcatUsing CATALINA_HOME:   /application/tomcatUsing CATALINA_TMPDIR: /application/tomcat/tempUsing JRE_HOME:        /application/jdkUsing CLASSPATH:       /application/tomcat/bin/bootstrap.jar:/application/tomcat/bin/tomcat-juli.jarTomcat started.</code></pre><p>​         注意：tomcat未启动的情况下使用shutdown脚本，会有大量的输出信息。</p><p>检查tomcat是否启动正常</p><pre><code>[root@web03 ~]# netstat -lntup  |grep javatcp6       0      0 :::8080         :::*                   LISTEN      30560/java          tcp6       0      0 127.0.0.1:8005          :::*          LISTEN      30560/java          tcp6       0      0 :::8009                 :::*           LISTEN      30560/java      </code></pre><p><strong>说明：</strong>所有与java相关的，服务启动都是java命名的进程</p><p>启动完成浏览器进行访问</p><p><a href="http://10.0.0.17:8080/" target="_blank" rel="noopener">http://10.0.0.17:8080/</a></p><p><img src="https://s1.ax1x.com/2020/05/21/YHPn2j.png" alt="YHPn2j.png"></p><h4 id="3、Tomcat日志说明"><a href="#3、Tomcat日志说明" class="headerlink" title="3、Tomcat日志说明"></a>3、Tomcat日志说明</h4><h5 id="1、查看日志"><a href="#1、查看日志" class="headerlink" title="1、查看日志"></a>1、查看日志</h5><pre><code>[root@web03 ~]# tailf /application/tomcat/logs/catalina.out24-Nov-2017 15:09:51.654 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;http-nio-8080&quot;]24-Nov-2017 15:09:51.665 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [&quot;ajp-nio-8009&quot;]24-Nov-2017 15:09:51.670 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 60037 ms</code></pre><p>​         发现启动时间较长，其中有一项的启动时间占据了绝大多数</p><pre><code>24-Nov-2017 15:09:50.629 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployWAR Deployment of web application archive /application/apache-tomcat-8.0.27/webapps/memtest.war has finished in 58,892 ms</code></pre><p>​         发现耗时在这里：是session引起的随机数问题导致的。Tocmat的Session ID是通过SHA1算法计算得到的，计算Session ID的时候必须有一个密钥。为了提高安全性Tomcat在启动的时候会通过随机生成一个密钥。</p><h5 id="2、解决Tomcat启动慢的方法"><a href="#2、解决Tomcat启动慢的方法" class="headerlink" title="2、解决Tomcat启动慢的方法"></a>2、解决Tomcat启动慢的方法</h5><p>Tomcat启动慢主要原因是生成随机数的时候卡住了,导致tomcat启动不了。</p><p>是否有足够的熵来用于产生随机数，可以通过如下命令来查看</p><pre><code>[root@web03 ~]# cat /proc/sys/kernel/random/entropy_avail6</code></pre><p>为了加速/dev/random提供随机数的速度，你可以通过操作设备的外设，让其产生大量的中断，网络传输数据，按键，移动鼠标，在命令行敲几个不同的命令，俗称聚气。</p><p>cat /dev/random 会消耗能量</p><p><strong>方法1**</strong>：**</p><pre><code>vim $JAVA_HOME/jre/lib/security/java.securitysecurerandom.source=file:/dev/random</code></pre><p>改为</p><pre><code>securerandom.source=file:/dev/urandom</code></pre><p><strong>方法2**</strong>：**</p><pre><code>vim $TOMCAT_HOME/bin/catalina.shif [[ &quot;$JAVA_OPTS&quot; != *-Djava.security.egd=* ]]; then    JAVA_OPTS=&quot;$JAVA_OPTS -Djava.security.egd=file:/dev/urandom&quot;fi</code></pre><p>这个系统属性egd表示熵收集守护进程(entropy gathering daemon)</p><p><strong>方法3**</strong>：（推荐）**</p><pre><code>yum install rng-tools # 安装rngd服务（熵服务，增大熵池）systemctl start rngd  # 启动服务</code></pre><h4 id="4、Tomcat管理功能使用"><a href="#4、Tomcat管理功能使用" class="headerlink" title="4、Tomcat管理功能使用"></a>4、Tomcat管理功能使用</h4><p><strong>注意：测试功能，生产环境不要用</strong></p><p>Tomcat管理功能用于对Tomcat自身以及部署在Tomcat上的应用进行管理的web应用。在默认情况下是处于禁用状态的。如果需要开启这个功能，就需要配置管理用户，即配置tomcat-users.xml 文件。</p><pre><code>[root@web03 ~]# vim /application/tomcat/conf/tomcat-users.xml……39 &lt;role rolename=&quot;manager-gui&quot;/&gt; 40 &lt;role rolename=&quot;admin-gui&quot;/&gt; 41 &lt;user username=&quot;tomcat&quot; password=&quot;tomcat&quot; roles=&quot;manager-gui,admin-gui&quot;/&gt; 42 &lt;/tomcat-users&gt;   # 在此行前加入上面三行</code></pre><p><strong>未修改文件前进行访问</strong></p><p><img src="https://s1.ax1x.com/2020/05/21/YHPuxs.png" alt="YHPuxs.png"></p><pre><code>&lt;role rolename=&quot;manager-gui&quot;/&gt;&lt;user username=&quot;tomcat&quot; password=&quot;s3cret&quot; roles=&quot;manager-gui&quot;/&gt;</code></pre><p><img src="https://s1.ax1x.com/2020/05/21/YHPMMn.png" alt="YHPMMn.png"></p><pre><code>&lt;role rolename=&quot;admin-gui&quot;/&gt;&lt;user username=&quot;tomcat&quot; password=&quot;s3cret&quot; roles=&quot;admin-gui&quot;/&gt;</code></pre><p>​         从而得出上面的配置文件信息。</p><h5 id="1、在web界面访问管理界面"><a href="#1、在web界面访问管理界面" class="headerlink" title="1、在web界面访问管理界面"></a>1、在web界面访问管理界面</h5><p><img src="https://s1.ax1x.com/2020/05/21/YHP3ZV.png" alt="YHP3ZV.png"></p><p>​         输入之前配置的账户与密码即可</p><p><img src="https://s1.ax1x.com/2020/05/21/YHPGIU.png" alt="YHPGIU.png"></p><p><img src="https://s1.ax1x.com/2020/05/21/YHPtG4.png" alt="YHPtG4.png"></p><h4 id="5、Tomcat主配置文件详解"><a href="#5、Tomcat主配置文件详解" class="headerlink" title="5、Tomcat主配置文件详解"></a>5、Tomcat主配置文件详解</h4><h5 id="1、server-xml组件类别"><a href="#1、server-xml组件类别" class="headerlink" title="1、server.xml组件类别"></a>1、server.xml组件类别</h5><p>顶级组件：位于整个配置的顶层，如server。</p><p>容器类组件：可以包含其它组件的组件，如service、engine、host、context。</p><p>连接器组件：连接用户请求至tomcat，如connector。</p><p>被嵌套类组件：位于一个容器当中，不能包含其他组件，如Valve、logger。</p><pre><code>&lt;server&gt;     &lt;service&gt;     &lt;connector /&gt;     &lt;engine&gt;     &lt;host&gt;     &lt;context&gt;&lt;/context&gt;     &lt;/host&gt;     &lt;host&gt;     &lt;context&gt;&lt;/context&gt;     &lt;/host&gt;     &lt;/engine&gt;     &lt;/service&gt;&lt;/server&gt;</code></pre><h5 id="2、组件介绍"><a href="#2、组件介绍" class="headerlink" title="2、组件介绍"></a>2、组件介绍</h5><table><thead><tr><th><strong>组件名称</strong></th><th><strong>功能介绍</strong></th></tr></thead><tbody><tr><td><strong>engine</strong></td><td>核心容器组件，catalina引擎，负责通过connector接收用户请求，并处理请求，将请求转至对应的虚拟主机host。</td></tr><tr><td><strong>host</strong></td><td>类似于httpd中的虚拟主机，一般而言支持基于FQDN的虚拟主机。</td></tr><tr><td><strong>context</strong></td><td>定义一个应用程序，是一个最内层的容器类组件（不能再嵌套）。配置context的主要目的指定对应对的webapp的根目录，类似于httpd的alias，其还能为webapp指定额外的属性，如部署方式等。</td></tr><tr><td><strong>connector</strong></td><td>接收用户请求，类似于httpd的listen配置监听端口的。</td></tr><tr><td><strong>service**</strong>（服务）**</td><td>将connector关联至engine，因此一个service内部可以有多个connector，但只能有一个引擎engine。service内部有两个connector，一个engine。因此，一般情况下一个server内部只有一个service，一个service内部只有一个engine，但一个service内部可以有多个connector。</td></tr><tr><td><strong>server</strong></td><td>表示一个运行于JVM中的tomcat实例。</td></tr><tr><td><strong>Valve</strong></td><td>阀门，拦截请求并在将其转至对应的webapp前进行某种处理操作，可以用于任何容器中，比如记录日志(access log valve)、基于IP做访问控制(remote address filter valve)。</td></tr><tr><td><strong>logger</strong></td><td>日志记录器，用于记录组件内部的状态信息，可以用于除context外的任何容器中。</td></tr><tr><td><strong>realm</strong></td><td>可以用于任意容器类的组件中，关联一个用户认证库，实现认证和授权。可以关联的认证库有两种：UserDatabaseRealm、MemoryRealm和JDBCRealm。</td></tr><tr><td><strong>UserDatabaseRealm</strong></td><td>使用JNDI自定义的用户认证库。</td></tr><tr><td><strong>MemoryRealm</strong></td><td>认证信息定义在tomcat-users.xml中。</td></tr><tr><td><strong>JDBCRealm</strong></td><td>认证信息定义在数据库中，并通过JDBC连接至数据库中查找认证用户。</td></tr></tbody></table><h5 id="3、server-xml配置文件注释"><a href="#3、server-xml配置文件注释" class="headerlink" title="3、server.xml配置文件注释"></a>3、server.xml配置文件注释</h5><pre><code>&lt;?xml version=&#39;1.0&#39; encoding=&#39;utf-8&#39;?&gt;&lt;!--&lt;Server&gt;元素代表整个容器,是Tomcat实例的顶层元素.由org.apache.catalina.Server接口来定义.它包含一个&lt;Service&gt;元素.并且它不能做为任何元素的子元素.    port指定Tomcat监听shutdown命令端口.终止服务器运行时,必须在Tomcat服务器所在的机器上发出shutdown命令.该属性是必须的.    shutdown指定终止Tomcat服务器运行时,发给Tomcat服务器的shutdown监听端口的字符串.该属性必须设置--&gt;&lt;Server port=&quot;8005&quot; shutdown=&quot;SHUTDOWN&quot;&gt;  &lt;Listener className=&quot;org.apache.catalina.startup.VersionLoggerListener&quot; /&gt;  &lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine=&quot;on&quot; /&gt;  &lt;Listener className=&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot; /&gt;  &lt;Listener className=&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot; /&gt;  &lt;Listener className=&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot; /&gt;  &lt;GlobalNamingResources&gt;    &lt;Resource name=&quot;UserDatabase&quot; auth=&quot;Container&quot;              type=&quot;org.apache.catalina.UserDatabase&quot;              description=&quot;User database that can be updated and saved&quot;              factory=&quot;org.apache.catalina.users.MemoryUserDatabaseFactory&quot;              pathname=&quot;conf/tomcat-users.xml&quot; /&gt;  &lt;/GlobalNamingResources&gt;  &lt;!--service服务组件--&gt;  &lt;Service name=&quot;Catalina&quot;&gt;    &lt;!-- Connector主要参数说明（见下表） --&gt;    &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;               connectionTimeout=&quot;20000&quot;               redirectPort=&quot;8443&quot; /&gt;    &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt;    &lt;!--engine,核心容器组件,catalina引擎,负责通过connector接收用户请求,并处理请求,将请求转至对应的虚拟主机host        defaultHost指定缺省的处理请求的主机名，它至少与其中的一个host元素的name属性值是一样的    --&gt;    &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt;      &lt;!--Realm表示存放用户名，密码及role的数据库--&gt;      &lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt;        &lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot;               resourceName=&quot;UserDatabase&quot;/&gt;      &lt;/Realm&gt;      &lt;!-- 详情常见下表（host参数详解）--&gt;      &lt;Host name=&quot;localhost&quot;  appBase=&quot;webapps&quot;            unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;        &lt;!-- 详情常见下表（Context参数说明 ）--&gt;        &lt;Context path=&quot;&quot; docBase=&quot;&quot; debug=&quot;&quot;/&gt;        &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot;               prefix=&quot;localhost_access_log&quot; suffix=&quot;.txt&quot;               pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt;      &lt;/Host&gt;    &lt;/Engine&gt;  &lt;/Service&gt;&lt;/Server&gt;</code></pre><h5 id="4、Connector主要参数说明"><a href="#4、Connector主要参数说明" class="headerlink" title="4、Connector主要参数说明"></a>4、Connector主要参数说明</h5><table><thead><tr><th><strong>参数</strong></th><th><strong>参数说明</strong></th></tr></thead><tbody><tr><td><strong>connector</strong></td><td>接收用户请求，类似于httpd的listen配置监听端口.</td></tr><tr><td><strong>port</strong></td><td>指定服务器端要创建的端口号，并在这个端口监听来自客户端的请求。</td></tr><tr><td><strong>address</strong></td><td>指定连接器监听的地址，默认为所有地址（即0.0.0.0）</td></tr><tr><td><strong>protocol</strong></td><td>连接器使用的协议，支持HTTP和AJP。AJP（Apache Jserv Protocol）专用于tomcat与apache建立通信的， 在httpd反向代理用户请求至tomcat时使用（可见Nginx反向代理时不可用AJP协议）。</td></tr><tr><td><strong>minProcessors</strong></td><td>服务器启动时创建的处理请求的线程数</td></tr><tr><td><strong>maxProcessors</strong></td><td>最大可以创建的处理请求的线程数</td></tr><tr><td><strong>enableLookups</strong></td><td>如果为true，则可以通过调用request.getRemoteHost()进行DNS查询来得到远程客户端的实际主机名，若为false则不进行DNS查询，而是返回其ip地址</td></tr><tr><td><strong>redirectPort</strong></td><td>指定服务器正在处理http请求时收到了一个SSL传输请求后重定向的端口号</td></tr><tr><td><strong>acceptCount</strong></td><td>指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理</td></tr><tr><td><strong>connectionTimeout</strong></td><td>指定超时的时间数(以毫秒为单位)</td></tr></tbody></table><h5 id="5、host参数详解"><a href="#5、host参数详解" class="headerlink" title="5、host参数详解"></a>5、host参数详解</h5><table><thead><tr><th><strong>参数</strong></th><th><strong>参数说明</strong></th></tr></thead><tbody><tr><td><strong>host</strong></td><td>表示一个虚拟主机</td></tr><tr><td><strong>name</strong></td><td>指定主机名</td></tr><tr><td><strong>appBase</strong></td><td>应用程序基本目录，即存放应用程序的目录.一般为appBase=”webapps”，相对于CATALINA_HOME而言的，也可以写绝对路径。</td></tr><tr><td><strong>unpackWARs</strong></td><td>如果为true，则tomcat会自动将WAR文件解压，否则不解压，直接从WAR文件中运行应用程序</td></tr><tr><td><strong>autoDeploy</strong></td><td>在tomcat启动时，是否自动部署。</td></tr><tr><td><strong>xmlValidation</strong></td><td>是否启动xml的校验功能，一般xmlValidation=”false”。</td></tr><tr><td><strong>xmlNamespaceAware</strong></td><td>检测名称空间，一般xmlNamespaceAware=”false”。</td></tr></tbody></table><h5 id="6、Context参数说明"><a href="#6、Context参数说明" class="headerlink" title="6、Context参数说明"></a>6、Context参数说明</h5><table><thead><tr><th><strong>参数</strong></th><th><strong>参数说明</strong></th></tr></thead><tbody><tr><td><strong>Context</strong></td><td>表示一个web应用程序，通常为WAR文件</td></tr><tr><td><strong>docBase</strong></td><td>应用程序的路径或者是WAR文件存放的路径,也可以使用相对路径，起始路径为此Context所属Host中appBase定义的路径。</td></tr><tr><td><strong>path</strong></td><td>表示此web应用程序的url的前缀，这样请求的url为<a href="http://localhost:8080/path/" target="_blank" rel="noopener">http://localhost:8080/path/</a>****</td></tr><tr><td><strong>reloadable</strong></td><td>这个属性非常重要，如果为true，则tomcat会自动检测应用程序的/WEB-INF/lib和/WEB-INF/classes目录的变化，自动装载新的应用程序，可以在不重启tomcat的情况下改变应用程序</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>xshell 配置</title>
      <link href="2020/03/21/xshell-tu-chu-xian-shi-ji/"/>
      <url>2020/03/21/xshell-tu-chu-xian-shi-ji/</url>
      
        <content type="html"><![CDATA[<h3 id="xshell配色方案"><a href="#xshell配色方案" class="headerlink" title="[xshell配色方案]"></a>[xshell配色方案]</h3><pre><code>[cyylog]text=00ff80cyan(bold)=00fffftext(bold)=e9e9e9magenta=c000c0green=80ff00green(bold)=3c5a38background=042028cyan=00c0c0red(bold)=ff0000yellow=c0c000magenta(bold)=ff00ffyellow(bold)=ffff00red=ff4500white=c0c0c0blue(bold)=1e90ffwhite(bold)=fdf6e3black=000000blue=00bfffblack(bold)=808080[Names]name0=cyylogcount=1</code></pre><h5 id="！！！-请自行创建-xcs-后缀的文件"><a href="#！！！-请自行创建-xcs-后缀的文件" class="headerlink" title="！！！ 请自行创建 xcs 后缀的文件"></a>！！！ 请自行创建 <code>xcs</code> 后缀的文件</h5><h3 id="xshell突出显示集"><a href="#xshell突出显示集" class="headerlink" title="[xshell突出显示集]"></a>[xshell突出显示集]</h3><h3 id="xshell突出显示集（参考mobaxterm，直接拷贝过来不行，应该是xshell对正则表达式的支持不够好）"><a href="#xshell突出显示集（参考mobaxterm，直接拷贝过来不行，应该是xshell对正则表达式的支持不够好）" class="headerlink" title="xshell突出显示集（参考mobaxterm，直接拷贝过来不行，应该是xshell对正则表达式的支持不够好）:"></a>xshell突出显示集（参考mobaxterm，直接拷贝过来不行，应该是xshell对正则表达式的支持不够好）:</h3><p>Underline:</p><pre class=" language-shell"><code class="language-shell">\b(http(s)?://[A-Za-z0-9_./&?=%~#{}()@+-]+)\b</code></pre><p>Red:</p><pre class=" language-shell"><code class="language-shell">(\b((bad|wrong|incorrect|improper|invalid|unsupported|bad)( file| memory)? (descriptor|alloc(ation)?|addr(ess)?|owner(ship)?|arg(ument)?|param(eter)?|setting|length|filename)|not properly|improperly|(operation |connection |authentication |access |permission )?(false|no|ko|denied|disallowed|not allowed|refused|problem|failed|failure|not permitted)|no [A-Za-z]+( [A-Za-z]+)? found|invalid|unsupported|not supported|seg(mentation )?fault|corruption|corrupted|corrupt|overflow|underrun|not ok|unimplemented|unsuccessfull|not implemented|permerrors?|fehlers?|errore|errors?|erreurs?|fejl|virhe|greška|erro|fel|\(ee\)|\(ni\))\b)</code></pre><p>Green:</p><pre class=" language-shell"><code class="language-shell">(\b(true|yes|ok|accepted|allowed|enabled|connected|erfolgreich|exitoso|successo|sucedido|framgångsrik|successfully|successful|succeeded|success)\b)</code></pre><p>Yellow:</p><pre><code>(\b(\[\-w[A-Za-z-]+\]|caught signal [0-9]+|cannot|(connection (to (remote host|[a-z0-9.]+) )?)?(closed|terminated|stopped|not responding)|exited|no more [A-Za-z] available|unexpected|(command |binary |file )?not found|(o)+ps|out of (space|memory)|low (memory|disk)|unknown|disabled|disconnected|deprecated|refused|disconnect(ion)?|advertencia|avvertimento|attention|warnings?|achtung|exclamation|alerts?|warnungs?|advarsel|pedwarn|aviso|varoitus|upozorenje|peringatan|uyari|varning|avertissement|\(ww\)|\(\?\?\)|could not|unable to)\b)</code></pre><p>shellMagenta:</p><pre class=" language-shell"><code class="language-shell">(\b(localhost|([1-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-4])\.[0-9]+\.[0-9]+\.[0-9]+|null|none)\b)</code></pre><p>Cyan:</p><pre class=" language-shell"><code class="language-shell">(\b(last (failed )?login:|launching|checking|loading|creating|building|important|booting|starting|notice|informational|informationen|informazioni|informação|oplysninger|informations?|info|información|informasi|note|\(ii\)|\(\!\!\))\b)</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kubeadm快速部署kubernetes集群</title>
      <link href="2020/03/17/container/kubeadm-kuai-su-bu-shu-kubernetes-ji-qun/"/>
      <url>2020/03/17/container/kubeadm-kuai-su-bu-shu-kubernetes-ji-qun/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p>kubeadm是官方社区推出的一个用于快速部署kubernetes集群的工具。</p><p>这个工具能通过两条指令完成一个kubernetes集群的部署：</p><pre><code># 创建一个 Master 节点$ kubeadm init# 将一个 Node 节点加入到当前集群中$ kubeadm join &lt;Master节点的IP和端口 &gt;</code></pre><h2 id="1-安装要求"><a href="#1-安装要求" class="headerlink" title="1. 安装要求"></a>1. 安装要求</h2><p>在开始之前，部署Kubernetes集群机器需要满足以下几个条件：</p><ul><li>一台或多台机器，操作系统 CentOS7.x-86_x64</li><li>硬件配置：2GB或更多RAM，2个CPU或更多CPU，硬盘30GB或更多</li><li>集群中所有机器之间网络互通</li><li>可以访问外网，需要拉取镜像</li><li>禁止swap分区</li></ul><h2 id="2-学习目标"><a href="#2-学习目标" class="headerlink" title="2. 学习目标"></a>2. 学习目标</h2><ol><li>在所有节点上安装Docker和kubeadm</li><li>部署Kubernetes Master</li><li>部署容器网络插件</li><li>部署 Kubernetes Node，将节点加入Kubernetes集群中</li><li>部署Dashboard Web页面，可视化查看Kubernetes资源</li></ol><h2 id="3-准备环境"><a href="#3-准备环境" class="headerlink" title="3. 准备环境"></a>3. 准备环境</h2><p><img src="http://p9.pstatp.com/large/pgc-image/d244ddcca380403e816a8705da3898c6" alt="kubeadm快速部署kubernetes集群"></p><p>Kubernetes 架构图</p><p><img src="http://p3.pstatp.com/large/pgc-image/8f8781176b8d4670b94214caa934d880" alt="kubeadm快速部署kubernetes集群"></p><p>Kubernetes 架构图</p><pre><code>关闭防火墙：$ systemctl stop firewalld$ systemctl disable firewalld关闭selinux：$ sed -i &#39;s/enforcing/disabled/&#39; /etc/selinux/config $ setenforce 0关闭swap：$ swapoff -a  $ 临时$ vim /etc/fstab  $ 永久添加主机名与IP对应关系（记得设置主机名）：$ cat /etc/hosts192.168.31.63 k8s-master192.168.31.65 k8s-node1192.168.31.66 k8s-node2将桥接的IPv4流量传递到iptables的链：$ cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOF$ sysctl --system</code></pre><h2 id="4-所有节点安装Docker-kubeadm-kubelet"><a href="#4-所有节点安装Docker-kubeadm-kubelet" class="headerlink" title="4. 所有节点安装Docker/kubeadm/kubelet"></a>4. 所有节点安装Docker/kubeadm/kubelet</h2><p>Kubernetes默认CRI（容器运行时）为Docker，因此先安装Docker。</p><h3 id="4-1-安装Docker"><a href="#4-1-安装Docker" class="headerlink" title="4.1 安装Docker"></a>4.1 安装Docker</h3><pre><code>$ wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo$ yum -y install docker-ce-18.06.1.ce-3.el7$ systemctl enable docker &amp;&amp; systemctl start docker$ docker --versionDocker version 18.06.1-ce, build e68fc7a</code></pre><h3 id="4-2-添加阿里云YUM软件源"><a href="#4-2-添加阿里云YUM软件源" class="headerlink" title="4.2 添加阿里云YUM软件源"></a>4.2 添加阿里云YUM软件源</h3><pre><code>$ cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF</code></pre><h3 id="4-3-安装kubeadm，kubelet和kubectl"><a href="#4-3-安装kubeadm，kubelet和kubectl" class="headerlink" title="4.3 安装kubeadm，kubelet和kubectl"></a>4.3 安装kubeadm，kubelet和kubectl</h3><p>由于版本更新频繁，这里指定版本号部署：</p><pre><code>$ yum install -y kubelet-1.14.0 kubeadm-1.14.0 kubectl-1.14.0$ systemctl enable kubelet</code></pre><h2 id="5-部署Kubernetes-Master"><a href="#5-部署Kubernetes-Master" class="headerlink" title="5. 部署Kubernetes Master"></a>5. 部署Kubernetes Master</h2><p>在192.168.31.63（Master）执行。</p><pre><code>$ kubeadm init \  --apiserver-advertise-address=192.168.31.63 \  --image-repository registry.aliyuncs.com/google_containers \  --kubernetes-version v1.14.0 \  --service-cidr=10.1.0.0/16 \  --pod-network-cidr=10.244.0.0/16</code></pre><p>由于默认拉取镜像地址k8s.gcr.io国内无法访问，这里指定阿里云镜像仓库地址。</p><p>使用kubectl工具：</p><pre><code>mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config$ kubectl get nodes</code></pre><h2 id="6-安装Pod网络插件（CNI）"><a href="#6-安装Pod网络插件（CNI）" class="headerlink" title="6. 安装Pod网络插件（CNI）"></a>6. 安装Pod网络插件（CNI）</h2><pre><code>$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/a70459be0084506e4ec919aa1c114638878db11b/Documentation/kube-flannel.yml</code></pre><p>确保能够访问到quay.io这个registery。 master执行</p><p># kubectl get pods -n kube-system</p><h2 id="7-加入Kubernetes-Node"><a href="#7-加入Kubernetes-Node" class="headerlink" title="7. 加入Kubernetes Node"></a>7. 加入Kubernetes Node</h2><p>在192.168.31.65/66（Node）执行。</p><p>向集群添加新节点，执行在kubeadm init输出的kubeadm join命令：</p><pre><code>$  kubeadm join 192.168.31.63:6443 --token l79g5t.6ov4jkddwqki1dxe --discovery-token-ca-cert-hash sha256:4f07f9068c543130461c9db368d62b4aabc22105451057f887defa35f47fa076</code></pre><h2 id="8-测试kubernetes集群"><a href="#8-测试kubernetes集群" class="headerlink" title="8. 测试kubernetes集群"></a>8. 测试kubernetes集群</h2><p>在Kubernetes集群中创建一个pod，验证是否正常运行：</p><pre><code>$ kubectl create deployment nginx --image=nginx$ kubectl expose deployment nginx --port=80 --type=NodePort$ kubectl get pod,svc$ kubectl get pod,svc -o wide</code></pre><p>访问地址：<a href="http://NodeIP:Port">http://NodeIP:Port</a></p><h2 id="9-部署-Dashboard"><a href="#9-部署-Dashboard" class="headerlink" title="9. 部署 Dashboard"></a>9. 部署 Dashboard</h2><pre><code>$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml镜像下载因为网络的原因：镜像难以下载，需要修改以下两个地方        image: tigerfive/kubernetes-dashboard-amd64:v1.10.1spec:  type: NodePort  ports:    - port: 443      targetPort: 8443</code></pre><p>默认Dashboard只能集群内部访问，修改Service为NodePort类型，暴露到外部：</p><pre><code>kind: ServiceapiVersion: v1metadata:  labels:    k8s-app: kubernetes-dashboard  name: kubernetes-dashboard  namespace: kube-systemspec:  type: NodePort  ports:    - port: 443      targetPort: 8443      nodePort: 30001  selector:    k8s-app: kubernetes-dashboard$ kubectl apply -f kubernetes-dashboard.yaml</code></pre><p>访问地址：<a href="http://NodeIP:30001" target="_blank" rel="noopener">http://NodeIP:30001</a></p><p>创建service account并绑定默认cluster-admin管理员集群角色：</p><pre><code>$ kubectl create serviceaccount dashboard-admin -n kube-system$ kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin$ kubectl describe secrets -n kube-system $(kubectl -n kube-system get secret | awk &#39;/dashboard-admin/{print $1}&#39;)</code></pre><p>使用输出的token登录Dashboard。</p>]]></content>
      
      
      <categories>
          
          <category> container </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes-入门</title>
      <link href="2020/03/14/container/kubernetes-ru-men/"/>
      <url>2020/03/14/container/kubernetes-ru-men/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="Kubernetes功能"><a href="#Kubernetes功能" class="headerlink" title="Kubernetes功能"></a>Kubernetes功能</h2><p>​        官方定义k8s能够对容器化软件进行部署管理，在不停机的前提下提供简单快速的发布和更新方式。换句话说，如果项目需要多机器节点的微服务架构，并且采用Docker image（镜像）进行容器化部署，那么k8s可以帮助我们屏蔽掉集群的复杂性，自动选择最优资源分配方式进行部署。在此基础上，k8s还提供简单的多实例部署及更新方案，仅需几个操作命令就可以轻松实现。</p><h2 id="k8s集群简单介绍"><a href="#k8s集群简单介绍" class="headerlink" title="k8s集群简单介绍"></a>k8s集群简单介绍</h2><p><img src="https://s1.ax1x.com/2020/05/04/YCTTYR.png" alt="YCTTYR.png"></p><p><strong>Master 负责管理集群</strong> 负责协调集群中的所有活动，例如调度应用程序，维护应用程序的状态，扩展和更新应用程序。</p><p><strong>Worker节点(即图中的Node)是VM(虚拟机)或物理计算机，充当k8s集群中的工作计算机。</strong> 每个Worker节点都有一个Kubelet，它管理该Worker节点并负责与Master节点通信。该Worker节点还应具有用于处理容器操作的工具，例如Docker。</p><h1 id="1-部署一个应用程序"><a href="#1-部署一个应用程序" class="headerlink" title="1.部署一个应用程序"></a>1.部署一个应用程序</h1><h3 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h3><p>已经</p><ul><li>完成 Kubernetes 集群的安装，请参考文档 <a href="https://www.kuboard.cn/install/install-k8s.html" target="_blank" rel="noopener">安装 Kubernetes 单Master节点</a></li></ul><h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><ul><li>使用 kubectl 在 k8s 上部署第一个应用程序。</li></ul><p>TIP</p><ul><li>kubectl 是 k8s 的客户端工具，可以使用命令行管理集群。</li><li>如果参考文档 <a href="https://www.kuboard.cn/install/install-k8s.html" target="_blank" rel="noopener">安装 Kubernetes 单Master节点</a>，您可以在 master 节点的 root 用户使用 kubectl 操作您的集群</li><li>您也可以尝试 <a href="https://www.kuboard.cn/install/install-kubectl.html" target="_blank" rel="noopener">从客户端电脑远程管理 Kubernetes</a></li></ul><h3 id="Kubernetes-部署"><a href="#Kubernetes-部署" class="headerlink" title="Kubernetes 部署"></a>Kubernetes 部署</h3><p>在 k8s 上进行部署前，首先需要了解一个基本概念 <strong>Deployment</strong></p><p><strong>Deployment</strong> 译名为 <strong>部署</strong>。在k8s中，通过发布 Deployment，可以创建应用程序 (docker image) 的实例 (docker container)，这个实例会被包含在称为 <strong>Pod</strong> 的概念中，<strong>Pod</strong> 是 k8s 中最小可管理单元。</p><p>在 k8s 集群中发布 Deployment 后，Deployment 将指示 k8s 如何创建和更新应用程序的实例，master 节点将应用程序实例调度到集群中的具体的节点上。</p><p>创建应用程序实例后，Kubernetes Deployment Controller 会持续监控这些实例。如果运行实例的 worker 节点关机或被删除，则 Kubernetes Deployment Controller 将在群集中资源最优的另一个 worker 节点上重新创建一个新的实例。<strong>这提供了一种自我修复机制来解决机器故障或维护问题。</strong></p><p>在容器编排之前的时代，各种安装脚本通常用于启动应用程序，但是不能够使应用程序从机器故障中恢复。通过创建应用程序实例并确保它们在集群节点中的运行实例个数，Kubernetes Deployment 提供了一种完全不同的方式来管理应用程序。</p><h2 id="在-Kubernetes-上部署第一个应用程序"><a href="#在-Kubernetes-上部署第一个应用程序" class="headerlink" title="在 Kubernetes 上部署第一个应用程序"></a>在 Kubernetes 上部署第一个应用程序</h2><p><img src="https://s1.ax1x.com/2020/05/04/YCLxJJ.png" alt="YCLxJJ.png"></p><p>​        Deployment 处于 master 节点上，通过发布 Deployment，master 节点会选择合适的 worker 节点创建 Container（即图中的正方体），Container 会被包含在 Pod （即蓝色圆圈）里。</p><h2 id="部署-nginx-Deployment"><a href="#部署-nginx-Deployment" class="headerlink" title="部署 nginx Deployment"></a>部署 nginx Deployment</h2><p><strong>创建 YAML 文件</strong></p><p>创建文件 nginx-deployment.yaml，内容如下：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1    <span class="token comment" spellcheck="true">#与k8s集群版本有关，使用 kubectl api-versions 即可查看当前集群支持的版本</span><span class="token key atrule">kind</span><span class="token punctuation">:</span> Deployment    <span class="token comment" spellcheck="true">#该配置的类型，我们使用的是 Deployment</span><span class="token key atrule">metadata</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true">#译名为元数据，即 Deployment 的一些基本属性和信息</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> nginx<span class="token punctuation">-</span>deployment    <span class="token comment" spellcheck="true">#Deployment 的名称</span>  <span class="token key atrule">labels</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#标签，可以灵活定位一个或多个资源，其中key和value均可自定义，可以定义多组，目前不需要理解</span>    <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx    <span class="token comment" spellcheck="true">#为该Deployment设置key为app，value为nginx的标签</span><span class="token key atrule">spec</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true">#这是关于该Deployment的描述，可以理解为你期待该Deployment在k8s中如何使用</span>  <span class="token key atrule">replicas</span><span class="token punctuation">:</span> <span class="token number">1    </span><span class="token comment" spellcheck="true">#使用该Deployment创建一个应用程序实例</span>  <span class="token key atrule">selector</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#标签选择器，与上面的标签共同作用，目前不需要理解</span>    <span class="token key atrule">matchLabels</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true">#选择包含标签app:nginx的资源</span>      <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx  <span class="token key atrule">template</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#这是选择或创建的Pod的模板</span>    <span class="token key atrule">metadata</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#Pod的元数据</span>      <span class="token key atrule">labels</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#Pod的标签，上面的selector即选择包含标签app:nginx的Pod</span>        <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx    <span class="token key atrule">spec</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#期望Pod实现的功能（即在pod中部署）</span>      <span class="token key atrule">containers</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#生成container，与docker中的container是同一种</span>      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> nginx    <span class="token comment" spellcheck="true">#container的名称</span>        <span class="token key atrule">image</span><span class="token punctuation">:</span> nginx<span class="token punctuation">:</span>1.7.9    <span class="token comment" spellcheck="true">#使用镜像nginx:1.7.9创建container，该container默认80端口可访问</span></code></pre><p><strong>应用 YAML 文件</strong></p><pre class=" language-shell"><code class="language-shell">kubectl apply -f nginx-deployment.yaml</code></pre><p><strong>查看部署结果</strong></p><pre><code># 查看 Deploymentkubectl get deployments# 查看 Podkubectl get pods</code></pre><p>可分别查看到一个名为 nginx-deployment 的 Deployment 和一个名为 nginx-deployment-xxxxxxx 的 Pod</p><h1 id="2-查看Pods-Nodes"><a href="#2-查看Pods-Nodes" class="headerlink" title="2.查看Pods/Nodes"></a>2.查看Pods/Nodes</h1><h2 id="Kubernetes-Pods"><a href="#Kubernetes-Pods" class="headerlink" title="Kubernetes Pods"></a>Kubernetes Pods</h2><p>在 <a href="https://www.kuboard.cn/learning/k8s-basics/deploy-app.html" target="_blank" rel="noopener">部署第一个应用程序</a> 中创建 Deployment 后，k8s创建了一个 <strong>Pod（容器组）</strong> 来放置应用程序实例（container 容器）。</p><h2 id="Pods概述"><a href="#Pods概述" class="headerlink" title="Pods概述"></a>Pods概述</h2><p><img src="https://s1.ax1x.com/2020/05/04/YCjWdK.png" alt="YCjWdK.png"></p><p><strong>Pod 容器组</strong> 是一个k8s中一个抽象的概念，用于存放一组 container（可包含一个或多个 container 容器，即图上正方体)，以及这些 container （容器）的一些共享资源。这些资源包括：</p><ul><li>共享存储，称为卷(Volumes)，即图上紫色圆柱</li><li>网络，每个 Pod（容器组）在集群中有个唯一的 IP，pod（容器组）中的 container（容器）共享该IP地址</li><li>container（容器）的基本信息，例如容器的镜像版本，对外暴露的端口等</li></ul><blockquote><p>例如，Pod可能既包含带有Node.js应用程序的 container 容器，也包含另一个非 Node.js 的 container 容器，用于提供 Node.js webserver 要发布的数据。Pod中的容器共享 IP 地址和端口空间（同一 Pod 中的不同 container 端口不能相互冲突），始终位于同一位置并共同调度，并在同一节点上的共享上下文中运行。（同一个Pod内的容器可以使用 localhost + 端口号互相访问）。</p></blockquote><p>Pod（容器组）是 k8s 集群上的最基本的单元。当我们在 k8s 上创建 Deployment 时，会在集群上创建包含容器的 Pod (而不是直接创建容器)。每个Pod都与运行它的 worker 节点（Node）绑定，并保持在那里直到终止或被删除。如果节点（Node）发生故障，则会在群集中的其他可用节点（Node）上运行相同的 Pod（从同样的镜像创建 Container，使用同样的配置，IP 地址不同，Pod 名字</p><p>TIP</p><p>重要：</p><ul><li><p>Pod 是一组容器（可包含一个或多个应用程序容器），以及共享存储（卷 Volumes）、IP 地址和有关如何运行容器的信息。</p></li><li><p>如果多个容器紧密耦合并且需要共享磁盘等资源，则他们应该被部署在同一个Pod（容器组）中。</p></li></ul><h2 id="Node（节点）"><a href="#Node（节点）" class="headerlink" title="Node（节点）"></a>Node（节点）</h2><p>下图显示一个 Node（节点）上含有4个 Pod（容器组）</p><p><img src="https://s1.ax1x.com/2020/05/04/YCxkjA.png" alt="YCxkjA.png"></p><p>Pod（容器组）总是在 <strong>Node（节点）</strong> 上运行。Node（节点）是 kubernetes 集群中的计算机，可以是虚拟机或物理机。每个 Node（节点）都由 master 管理。一个 Node（节点）可以有多个Pod（容器组），kubernetes master 会根据每个 Node（节点）上可用资源的情况，自动调度 Pod（容器组）到最佳的 Node（节点）上。</p><p>每个 Kubernetes Node（节点）至少运行：</p><ul><li><p>Kubelet，负责 master 节点和 worker 节点之间通信的进程；管理 Pod（容器组）和 Pod（容器组）内运行的 Container（容器）。</p></li><li><p>容器运行环境（如Docker）负责下载镜像、创建和运行容器等。</p></li></ul><h2 id="故障排除"><a href="#故障排除" class="headerlink" title="故障排除"></a>故障排除</h2><p>在<a href="https://www.kuboard.cn/learning/k8s-basics/deploy-app.html" target="_blank" rel="noopener">部署第一个应用程序</a> 中，我们使用了 kubectl 命令行界面部署了 nginx 并且查看了 Deployment 和 Pod。kubectl 还有如下四个常用命令，在我们排查问题时可以提供帮助：</p><ul><li><strong>kubectl get</strong> - 显示资源列表</li></ul><pre class=" language-shell"><code class="language-shell"># kubectl get 资源类型#获取类型为Deployment的资源列表kubectl get deployments#获取类型为Pod的资源列表kubectl get pods#获取类型为Node的资源列表kubectl get nodes</code></pre><blockquote><p>名称空间</p><p>在命令后增加 <code>-A</code> 或 <code>--all-namespaces</code> 可查看所有 <a href="https://www.kuboard.cn/learning/k8s-intermediate/obj/namespaces.html" target="_blank" rel="noopener">名称空间中</a> 的对象，使用参数 <code>-n</code> 可查看指定名称空间的对象，例如</p><pre class=" language-shell"><code class="language-shell"># 查看所有名称空间的 Deploymentkubectl get deployments -Akubectl get deployments --all-namespaces# 查看 kube-system 名称空间的 Deploymentkubectl get deployments -n kube-system</code></pre><p>并非所有对象都在名称空间里)</p></blockquote><ul><li><strong>kubectl describe</strong> - 显示有关资源的详细信息</li></ul><pre class=" language-shell"><code class="language-shell"># kubectl describe 资源类型 资源名称#查看名称为nginx-XXXXXX的Pod的信息kubectl describe pod nginx-XXXXXX    #查看名称为nginx的Deployment的信息kubectl describe deployment nginx    </code></pre><ul><li><strong>kubectl logs</strong> - 查看pod中的容器的打印日志（和命令docker logs 类似）</li></ul><pre class=" language-shell"><code class="language-shell"># kubectl logs Pod名称#查看名称为nginx-pod-XXXXXXX的Pod内的容器打印的日志#本案例中的 nginx-pod 没有输出日志，所以您看到的结果是空的kubectl logs -f nginx-pod-XXXXXXX</code></pre><p>尝试在集群中执行一下上述的几个命令，可以了解如何通过 kubectl 操作 kubernetes 集群中的 Node、Pod、Container。</p><blockquote><p>TIP</p><p>Worker节点是k8s中的工作计算机，可能是VM或物理计算机，具体取决于群集。多个Pod可以在一个节点上运行。</p></blockquote><h1 id="3-公布应用程序"><a href="#3-公布应用程序" class="headerlink" title="3.公布应用程序"></a>3.公布应用程序</h1><h2 id="Kubernetes-Service（服务）概述"><a href="#Kubernetes-Service（服务）概述" class="headerlink" title="Kubernetes Service（服务）概述"></a>Kubernetes Service（服务）概述</h2><p>事实上，Pod（容器组）有自己的 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/" target="_blank" rel="noopener">生命周期</a>。当 worker node（节点）故障时，节点上运行的 Pod（容器组）也会消失。然后，<a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/" target="_blank" rel="noopener">Deployment</a> 可以通过创建新的 Pod（容器组）来动态地将群集调整回原来的状态，以使应用程序保持运行。</p><p>举个例子，假设有一个图像处理后端程序，具有 3 个运行时副本。这 3 个副本是可以替换的（无状态应用），即使 Pod（容器组）消失并被重新创建，或者副本数由 3 增加到 5，前端系统也无需关注后端副本的变化。由于 Kubernetes 集群中每个 Pod（容器组）都有一个唯一的 IP 地址（即使是同一个 Node 上的不同 Pod），我们需要一种机制，为前端系统屏蔽后端系统的 Pod（容器组）在销毁、创建过程中所带来的 IP 地址的变化。</p><p>Kubernetes 中的 <strong>Service（服务）</strong> 提供了这样的一个抽象层，它选择具备某些特征的 Pod（容器组）并为它们定义一个访问方式。Service（服务）使 Pod（容器组）之间的相互依赖解耦（原本从一个 Pod 中访问另外一个 Pod，需要知道对方的 IP 地址）。一个 Service（服务）选定哪些 <strong>Pod（容器组）</strong> 通常由 <strong>LabelSelector(标签选择器)</strong> 来决定。</p><p>在创建Service的时候，通过设置配置文件中的 spec.type 字段的值，可以以不同方式向外部暴露应用程序：</p><ul><li><p><strong>ClusterIP</strong>（默认）</p><p>在群集中的内部IP上公布服务，这种方式的 Service（服务）只在集群内部可以访问到</p></li><li><p><strong>NodePort</strong></p><p>使用 NAT 在集群中每个的同一端口上公布服务。这种方式下，可以通过访问集群中任意节点+端口号的方式访问服务 <code>:</code>。此时 ClusterIP 的访问方式仍然可用。</p></li><li><p><strong>LoadBalancer</strong></p><p>在云环境中（需要云供应商可以支持）创建一个集群外部的负载均衡器，并为使用该负载均衡器的 IP 地址作为服务的访问地址。此时 ClusterIP 和 NodePort 的访问方式仍然可用。</p></li></ul><blockquote><p>TIP</p><p>Service是一个抽象层，它通过 LabelSelector 选择了一组 Pod（容器组），把这些 Pod 的指定端口公布到到集群外部，并支持负载均衡和服务发现。</p><ul><li>公布 Pod 的端口以使其可访问</li><li>在多个 Pod 间实现负载均衡</li><li>使用 Label 和 LabelSelector</li></ul></blockquote><h2 id="服务和标签"><a href="#服务和标签" class="headerlink" title="服务和标签"></a>服务和标签</h2><p>下图中有两个服务Service A(黄色虚线)和Service B(蓝色虚线) Service A 将请求转发到 IP 为 10.10.10.1 的Pod上， Service B 将请求转发到 IP 为 10.10.10.2、10.10.10.3、10.10.10.4 的Pod上。</p><p><img src="https://s1.ax1x.com/2020/05/04/YP1c6J.png" alt="YP1c6J.png"></p><p>Service 将外部请求路由到一组 Pod 中，它提供了一个抽象层，使得 Kubernetes 可以在不影响服务调用者的情况下，动态调度容器组（在容器组失效后重新创建容器组，增加或者减少同一个 Deployment 对应容器组的数量等）。</p><p>Service使用 <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels" target="_blank" rel="noopener">Labels、LabelSelector(标签和选择器)</a> 匹配一组 Pod。Labels（标签）是附加到 Kubernetes 对象的键/值对，其用途有多种：</p><ul><li>将 Kubernetes 对象（Node、Deployment、Pod、Service等）指派用于开发环境、测试环境或生产环境</li><li>嵌入版本标签，使用标签区别不同应用软件版本</li><li>使用标签对 Kubernetes 对象进行分类</li></ul><p>下图体现了 Labels（标签）和 LabelSelector（标签选择器）之间的关联关系</p><ul><li>Deployment B 含有 LabelSelector 为 app=B 通过此方式声明含有 app=B 标签的 Pod 与之关联</li><li>通过 Deployment B 创建的 Pod 包含标签为 app=B</li><li>Service B 通过标签选择器 app=B 选择可以路由的 Pod</li></ul><p><img src="https://s1.ax1x.com/2020/05/04/YP1X7t.png" alt="YP1X7t.png"></p><p>abels（标签）可以在创建 Kubernetes 对象时附加上去，也可以在创建之后再附加上去。任何时候都可以修改一个 Kubernetes 对象的 Labels（标签）</p><h2 id="练习：为-nginx-Deployment-创建一个-Service"><a href="#练习：为-nginx-Deployment-创建一个-Service" class="headerlink" title="练习：为 nginx Deployment 创建一个 Service"></a>练习：为 nginx Deployment 创建一个 Service</h2><ul><li><strong>创建nginx的Deployment中定义了Labels，如下：</strong></li></ul><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">metadata</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#译名为元数据，即Deployment的一些基本属性和信息</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> nginx<span class="token punctuation">-</span>deployment    <span class="token comment" spellcheck="true">#Deployment的名称</span>  <span class="token key atrule">labels</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#标签，可以灵活定位一个或多个资源，其中key和value均可自定义，可以定义多组</span>    <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx    <span class="token comment" spellcheck="true">#为该Deployment设置key为app，value为nginx的标签</span></code></pre><ul><li><strong>创建文件 nginx-service.yaml</strong></li></ul><pre class=" language-shell"><code class="language-shell">vim nginx-service.yaml</code></pre><ul><li><strong>文件内容如下：</strong></li></ul><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Service<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> nginx<span class="token punctuation">-</span>service    <span class="token comment" spellcheck="true">#Service 的名称</span>  <span class="token key atrule">labels</span><span class="token punctuation">:</span>         <span class="token comment" spellcheck="true">#Service 自己的标签</span>    <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx    <span class="token comment" spellcheck="true">#为该 Service 设置 key 为 app，value 为 nginx 的标签</span><span class="token key atrule">spec</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#这是关于该 Service 的定义，描述了 Service 如何选择 Pod，如何被访问</span>  <span class="token key atrule">selector</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#标签选择器</span>    <span class="token key atrule">app</span><span class="token punctuation">:</span> nginx    <span class="token comment" spellcheck="true">#选择包含标签 app:nginx 的 Pod</span>  <span class="token key atrule">ports</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> nginx<span class="token punctuation">-</span>port    <span class="token comment" spellcheck="true">#端口的名字</span>    <span class="token key atrule">protocol</span><span class="token punctuation">:</span> TCP        <span class="token comment" spellcheck="true">#协议类型 TCP/UDP</span>    <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">80            </span><span class="token comment" spellcheck="true">#集群内的其他容器组可通过 80 端口访问 Service</span>    <span class="token key atrule">nodePort</span><span class="token punctuation">:</span> <span class="token number">32600   </span><span class="token comment" spellcheck="true">#通过任意节点的 32600 端口访问 Service</span>    <span class="token key atrule">targetPort</span><span class="token punctuation">:</span> <span class="token number">80    </span><span class="token comment" spellcheck="true">#将请求转发到匹配 Pod 的 80 端口</span>  <span class="token key atrule">type</span><span class="token punctuation">:</span> NodePort    <span class="token comment" spellcheck="true">#Serive的类型，ClusterIP/NodePort/LoaderBalancer</span></code></pre><ul><li><strong>执行命令</strong></li></ul><pre><code>kubectl apply -f nginx-service.yaml</code></pre><ul><li><p><strong>检查执行结果</strong></p><pre class=" language-shell"><code class="language-shell">kubectl get services -o wide</code></pre></li><li><p><strong>访问服务</strong></p></li></ul><pre class=" language-shell"><code class="language-shell">curl <任意节点的 IP>:32600</code></pre><h1 id="4-伸缩应用程序"><a href="#4-伸缩应用程序" class="headerlink" title="4.伸缩应用程序"></a>4.伸缩应用程序</h1><h2 id="Scaling（伸缩）应用程序"><a href="#Scaling（伸缩）应用程序" class="headerlink" title="Scaling（伸缩）应用程序"></a>Scaling（伸缩）应用程序</h2><p>在前面，我们创建了一个 <a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/" target="_blank" rel="noopener">Deployment</a>，然后通过 <a href="https://kubernetes.io/docs/concepts/services-networking/service/" target="_blank" rel="noopener">服务</a> 提供访问 Pod 的方式。我们发布的 Deployment 只创建了一个 Pod 来运行我们的应用程序。当流量增加时，我们需要对应用程序进行伸缩操作以满足系统性能需求。</p><p><strong>伸缩</strong> 的实现可以通过更改 nginx-deployment.yaml 文件中部署的 replicas（副本数）来完成</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">replicas</span><span class="token punctuation">:</span> <span class="token number">2    </span><span class="token comment" spellcheck="true">#使用该Deployment创建两个应用程序实例</span></code></pre><h2 id="Scaling（伸缩）概述"><a href="#Scaling（伸缩）概述" class="headerlink" title="Scaling（伸缩）概述"></a>Scaling（伸缩）概述</h2><p>下图中，Service A 只将访问流量转发到 IP 为 10.0.0.5 的Pod上</p><p><img src="https://s1.ax1x.com/2020/05/04/YP8Wi6.png" alt="YP8Wi6.png"></p><p>​        修改了 Deployment 的 replicas 为 4 后，Kubernetes 又为该 Deployment 创建了 3 新的 Pod，这 4 个 Pod 有相同的标签。因此Service A通过标签选择器与新的 Pod建立了对应关系，将访问流量通过负载均衡在 4 个 Pod 之间进行转发。</p><p><img src="https://s1.ax1x.com/2020/05/04/YP84zD.png" alt="YP84zD.png"></p><blockquote><p>TIP</p><p>通过更改部署中的 replicas（副本数）来完成扩展</p></blockquote><h2 id="练习：将-nginx-Deployment-扩容到-4-个副本"><a href="#练习：将-nginx-Deployment-扩容到-4-个副本" class="headerlink" title="练习：将 nginx Deployment 扩容到 4 个副本"></a>练习：将 nginx Deployment 扩容到 4 个副本</h2><blockquote><p><strong>修改 nginx-deployment.yaml 文件</strong></p><p>将 replicas 修改为 4</p></blockquote><p><img src="https://s1.ax1x.com/2020/05/04/YPGpLj.png" alt="YPGpLj.png"></p><ul><li><strong>执行命令</strong></li></ul><pre class=" language-shell"><code class="language-shell">kubectl apply -f nginx-deployment.yaml</code></pre><ul><li><strong>查看结果</strong></li></ul><pre class=" language-shell"><code class="language-shell">watch kubectl get pods -o wide</code></pre><h1 id="5-执行滚动更新"><a href="#5-执行滚动更新" class="headerlink" title="5.执行滚动更新"></a>5.执行滚动更新</h1><h2 id="更新应用程序"><a href="#更新应用程序" class="headerlink" title="更新应用程序"></a>更新应用程序</h2><p>户期望应用程序始终可用，为此开发者/运维者在更新应用程序时要分多次完成。在 Kubernetes 中，这是通过 Rolling Update 滚动更新完成的。<strong>Rolling Update滚动更新</strong> 通过使用新版本的 Pod 逐步替代旧版本的 Pod 来实现 Deployment 的更新，从而实现零停机。新的 Pod 将在具有可用资源的 Node（节点）上进行调度。</p><blockquote><p>Kubernetes 更新多副本的 Deployment 的版本时，会逐步的创建新版本的 Pod，逐步的停止旧版本的 Pod，以便使应用一直处于可用状态。这个过程中，Service 能够监视 Pod 的状态，将流量始终转发到可用的 Pod 上。</p></blockquote><p>在上一个模块中，我们学习了将应用程序 Scale Up（扩容）为多个实例，这是执行更新而不影响应用程序可用性的前提（如果只有 1 个实例那还玩啥）。默认情况下，<strong>Rolling Update 滚动更新</strong> 过程中，Kubernetes 逐个使用新版本 Pod 替换旧版本 Pod（最大不可用 Pod 数为 1、最大新建 Pod 数也为 1）。这两个参数可以配置为数字或百分比。在Kubernetes 中，更新是版本化的，任何部署更新都可以恢复为以前的（稳定）版本。</p><h2 id="滚动更新概述"><a href="#滚动更新概述" class="headerlink" title="滚动更新概述"></a>滚动更新概述</h2><ol><li><p>原本 Service A 将流量负载均衡到 4 个旧版本的 Pod （当中的容器为 绿色）上</p><p><img src="https://s1.ax1x.com/2020/05/04/YPGrff.png" alt="YPGrff.png"></p></li><li><p>更新完 Deployment 部署文件中的镜像版本后，master 节点选择了一个 worker 节点，并根据新的镜像版本创建 Pod（紫色容器）。新 Pod 拥有唯一的新的 IP。同时，master 节点选择一个旧版本的 Pod 将其移除。</p><p>此时，Service A 将新 Pod 纳入到负载均衡中，将旧Pod移除</p><p><img src="https://s1.ax1x.com/2020/05/04/YPGRmj.png" alt="YPGRmj.png"></p></li><li><p>同步骤2，再创建一个新的 Pod 替换一个原有的 Pod</p><p><img src="https://s1.ax1x.com/2020/05/04/YPGIhV.png" alt="YPGIhV.png"></p></li><li><p>如此 Rolling Update 滚动更新，直到所有旧版本 Pod 均移除，新版本 Pod 也达到 Deployment 部署文件中定义的副本数，则滚动更新完成</p></li></ol><p><img src="https://s1.ax1x.com/2020/05/04/YPGLnJ.png" alt="YPGLnJ.png"></p><p>滚动更新允许以下操作：</p><ul><li>将应用程序从准上线环境升级到生产环境（通过更新容器镜像）</li><li>回滚到以前的版本</li><li>持续集成和持续交付应用程序，无需停机</li></ul><h2 id="练习：更新-nginx-Deployment"><a href="#练习：更新-nginx-Deployment" class="headerlink" title="练习：更新 nginx Deployment"></a>练习：更新 nginx Deployment</h2><p><strong>修改 nginx-deployment.yaml 文件</strong></p><p>修改文件中 image 镜像的标签，如下所示</p><p><img src="https://s1.ax1x.com/2020/05/04/YPJe4P.png" alt="YPJe4P.png"></p><ul><li><p><strong>执行命令</strong></p><pre class=" language-shell"><code class="language-shell">kubectl apply -f nginx-deployment.yaml</code></pre></li><li><p><strong>查看过程及结果</strong></p></li></ul><p>执行命令，可观察到 pod 逐个被替换的过程。</p><pre class=" language-shell"><code class="language-shell">watch kubectl get pods -l app=nginx</code></pre><h1 id="Kubernetes核心概念"><a href="#Kubernetes核心概念" class="headerlink" title="Kubernetes核心概念"></a>Kubernetes核心概念</h1><h2 id="什么是Kubernetes？"><a href="#什么是Kubernetes？" class="headerlink" title="什么是Kubernetes？"></a>什么是Kubernetes？</h2><p>Kubernetes（k8s）是自动化容器操作的开源平台，这些操作包括部署，调度和节点集群间扩展。如果你曾经用过Docker容器技术部署容器，那么可以将Docker看成Kubernetes内部使用的低级别组件。Kubernetes不仅仅支持Docker，还支持Rocket，这是另一种容器技术。 使用Kubernetes可以：</p><ul><li>自动化容器的部署和复制</li><li>随时扩展或收缩容器规模</li><li>将容器组织成组，并且提供容器间的负载均衡</li><li>很容易地升级应用程序容器的新版本</li><li>提供容器弹性，如果容器失效就替换它，等等…</li></ul><h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><p>集群是一组节点，这些节点可以是物理服务器或者虚拟机，之上安装了Kubernetes平台。下图展示这样的集群。注意该图为了强调核心概念有所简化。这里可以看到一个典型的Kubernetes架构图。</p><p><img src="https://s1.ax1x.com/2020/05/04/YPJyU1.png" alt="YPJyU1.png"></p><p>上图可以看到如下组件，使用特别的图标表示Service和Label：</p><ul><li>PodContainer（容器）</li><li>Label(<img src="data:image/png;base64,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" alt="label">))（标签）</li><li>Replication Controller（复制控制器）</li><li>Service（<img src="data:image/png;base64,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" alt="enter image description here">）（服务）</li><li>Node（节点）</li><li>Kubernetes Master（Kubernetes主节点）</li></ul><h2 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h2><p><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/" target="_blank" rel="noopener">Pod</a>（上图绿色方框）安排在节点上，包含一组容器和卷。同一个Pod里的容器共享同一个网络命名空间，可以使用localhost互相通信。Pod是短暂的，不是持续性实体。你可能会有这些问题：</p><ul><li>如果Pod是短暂的，那么我怎么才能持久化容器数据使其能够跨重启而存在呢？ 是的，Kubernetes支持 <strong><em>卷</em></strong> 的概念，因此可以使用持久化的卷类型。</li><li>是否手动创建Pod，如果想要创建同一个容器的多份拷贝，需要一个个分别创建出来么？可以手动创建单个Pod，但是也可以使用Replication Controller使用Pod模板创建出多份拷贝，下文会详细介绍。</li><li>如果Pod是短暂的，那么重启时IP地址可能会改变，那么怎么才能从前端容器正确可靠地指向后台容器呢？这时可以使用Service，下文会详细介绍。</li></ul><h2 id="Label"><a href="#Label" class="headerlink" title="Label"></a>Label</h2><p>正如图所示，一些Pod有Label（<img src="data:image/png;base64,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" alt="enter image description here">）。一个Label是attach到Pod的一对键/值对，用来传递用户定义的属性。比如，你可能创建了一个”tier”和“app”标签，通过Label（<strong>tier=frontend, app=myapp</strong>）来标记前端Pod容器，使用Label（<strong>tier=backend, app=myapp</strong>）标记后台Pod。然后可以使用 <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/" target="_blank" rel="noopener">Selectors</a> 选择带有特定Label的Pod，并且将Service或者Replication Controller应用到上面。</p><h2 id="Replication-Controller"><a href="#Replication-Controller" class="headerlink" title="Replication Controller"></a>Replication Controller</h2><p><em>是否手动创建Pod，如果想要创建同一个容器的多份拷贝，需要一个个分别创建出来么，能否将Pods划到逻辑组里？</em></p><p>Replication Controller确保任意时间都有指定数量的Pod“副本”在运行。如果为某个Pod创建了Replication Controller并且指定3个副本，它会创建3个Pod，并且持续监控它们。如果某个Pod不响应，那么Replication Controller会替换它，保持总数为3.如下面的动画所示：</p><p><img src="https://s1.ax1x.com/2020/05/04/YPJoVA.png" alt="YPJoVA.png"></p><p>如果之前不响应的Pod恢复了，现在就有4个Pod了，那么Replication Controller会将其中一个终止保持总数为3。如果在运行中将副本总数改为5，Replication Controller会立刻启动2个新Pod，保证总数为5。还可以按照这样的方式缩小Pod，这个特性在执行滚动 <a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller/#rolling_updates" target="_blank" rel="noopener">升级</a> 时很有用。</p><p>当创建Replication Controller时，需要指定两个东西：</p><ol><li>Pod模板：用来创建Pod副本的模板</li><li>Label：Replication Controller需要监控的Pod的标签。现在已经创建了Pod的一些副本，那么在这些副本上如何均衡负载呢？我们需要的是Service。</li></ol><p>TIP</p><p>最新 Kubernetes 版本里，推荐使用 Deployment</p><h2 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h2><p><em>如果Pods是短暂的，那么重启时IP地址可能会改变，怎么才能从前端容器正确可靠地指向后台容器呢？</em> <a href="https://kubernetes.io/docs/concepts/services-networking/service/" target="_blank" rel="noopener">Service</a> <strong>抽象</strong> 现在，假定有2个后台Pod，并且定义后台Service的名称为‘backend-service’，label选择器为(tier=backend, app=myapp) 的Service会完成如下两件重要的事情：</p><ul><li>会为Service创建一个本地集群的DNS入口，因此前端Pod只需要DNS查找主机名为 ‘backend-service’，就能够解析出前端应用程序可用的IP地址。</li><li>现在前端已经得到了后台服务的IP地址，但是它应该访问2个后台Pod的哪一个呢？Service在这2个后台Pod之间提供透明的负载均衡，会将请求分发给其中的任意一个（如下面的动画所示）。通过每个Node上运行的代理（kube-proxy）完成。</li></ul><p>下述动画展示了Service的功能。注意该图作了很多简化。如果不进入网络配置，那么达到透明的负载均衡目标所涉及的底层网络和路由相对先进。如果有兴趣，有更深入的介绍。</p><p><img src="https://s1.ax1x.com/2020/05/04/YPJOxS.png" alt="YPJOxS.png"></p><p>每个节点都运行如下Kubernetes关键组件：</p><ul><li>Kubelet：是主节点代理。</li><li>Kube-proxy：Service使用其将链接路由到Pod，如上文所述。</li><li>Docker或Rocket：Kubernetes使用的容器技术来创建容器。</li></ul><h3 id="Kubernetes-Master"><a href="#Kubernetes-Master" class="headerlink" title="Kubernetes Master"></a>Kubernetes Master</h3><p>集群拥有一个Kubernetes Master（紫色方框）。Kubernetes Master提供集群的独特视角，并且拥有一系列组件，比如Kubernetes API Server。API Server提供可以用来和集群交互的REST端点。master节点包括用来创建和复制Pod的Replication Controller。</p>]]></content>
      
      
      <categories>
          
          <category> container </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker数据共享与持久化</title>
      <link href="2020/01/19/container/docker-shu-ju-gong-xiang-yu-chi-jiu-hua/"/>
      <url>2020/01/19/container/docker-shu-ju-gong-xiang-yu-chi-jiu-hua/</url>
      
        <content type="html"><![CDATA[<a id="more"></a>本文介绍如何在 Docker 内部以及容器之间管理数据，在容器中管理数据主要有两种方式：<ul><li>数据卷（Data Volumes）</li><li>挂载主机目录 (Bind mounts)</li></ul><h2 id="数据卷"><a href="#数据卷" class="headerlink" title="数据卷"></a>数据卷</h2><p><code>数据卷</code>是一个可供一个或多个容器使用的特殊目录，它绕过<code>UFS</code>，可以提供很多有用的特性：</p><ul><li>数据卷 可以在容器之间共享和重用</li><li>对 数据卷 的修改会立马生效</li><li>对 数据卷 的更新，不会影响镜像</li><li>数据卷 默认会一直存在，即使容器被删除</li></ul><blockquote><p>注意：数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会隐藏掉，能显示看的是挂载的 数据卷。</p></blockquote><p>选择 -v 还是 -–mount 参数： Docker 新用户应该选择<code>--mount</code>参数，经验丰富的 Docker 使用者对<code>-v</code>或者 <code>--volume</code>已经很熟悉了，但是推荐使用<code>--mount</code>参数。</p><p>创建一个数据卷：</p><pre class=" language-shell"><code class="language-shell">$ docker volume create my-vol</code></pre><p>查看所有的 数据卷：</p><pre class=" language-shell"><code class="language-shell">$ docker volume lslocal               my-vol</code></pre><p>在主机里使用以下命令可以查看指定 数据卷 的信息</p><pre class=" language-shell"><code class="language-shell">$ docker volume inspect my-vol[    {        "Driver": "local",        "Labels": {},        "Mountpoint": "/var/lib/docker/volumes/my-vol/_data",        "Name": "my-vol",        "Options": {},        "Scope": "local"    }]</code></pre><p>启动一个挂载数据卷的容器：在用<code>docker run</code>命令的时候，使用<code>--mount</code>标记来将 数据卷 挂载到容器里。在一次<code>docker run</code>中可以挂载多个 数据卷。下面创建一个名为 web 的容器，并加载一个 数据卷 到容器的 /webapp 目录。</p><pre class=" language-shell"><code class="language-shell">$ docker run -d -P \    --name web \    # -v my-vol:/wepapp \    --mount source=my-vol,target=/webapp \    training/webapp \    python app.py</code></pre><p>查看数据卷的具体信息：在主机里使用以下命令可以查看 web 容器的信息</p><pre class=" language-shell"><code class="language-shell">$ docker inspect web..."Mounts": [    {        "Type": "volume",        "Name": "my-vol",        "Source": "/var/lib/docker/volumes/my-vol/_data",        "Destination": "/app",        "Driver": "local",        "Mode": "",        "RW": true,        "Propagation": ""    }],...</code></pre><p>删除数据卷：</p><pre><code>$ docker volume rm my-vol</code></pre><p>数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 数据卷。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用<code>docker rm -v</code>这个命令。 无主的数据卷可能会占据很多空间，要清理请使用以下命令</p><pre><code>$ docker volume prune</code></pre><h2 id="挂载主机目录"><a href="#挂载主机目录" class="headerlink" title="挂载主机目录"></a>挂载主机目录</h2><p>选择 -v 还是 -–mount 参数： Docker 新用户应该选择 –mount 参数，经验丰富的 Docker 使用者对 -v 或者 –volume 已经很熟悉了，但是推荐使用 –mount 参数。</p><p>挂载一个主机目录作为数据卷：使用 <code>--mount</code> 标记可以指定挂载一个本地主机的目录到容器中去。</p><pre class=" language-shell"><code class="language-shell">$ docker run -d -P \    --name web \    # -v /src/webapp:/opt/webapp \    --mount type=bind,source=/src/webapp,target=/opt/webapp \    training/webapp \    python app.py</code></pre><p>上面的命令加载主机的 /src/webapp 目录到容器的 /opt/webapp目录。这个功能在进行测试的时候十分方便，比如用户可以放置一些程序到本地目录中，来查看容器是否正常工作。本地目录的路径必须是绝对路径，以前使用 -v 参数时如果本地目录不存在 Docker 会自动为你创建一个文件夹，现在使用 –mount 参数时如果本地目录不存在，Docker 会报错。</p><p>Docker 挂载主机目录的默认权限是 读写，用户也可以通过增加<code>readonly</code>指定为 只读。</p><pre class=" language-shell"><code class="language-shell">$ docker run -d -P \    --name web \    # -v /src/webapp:/opt/webapp:ro \    --mount type=bind,source=/src/webapp,target=/opt/webapp,readonly \    training/webapp \    python app.py</code></pre><p>加了<code>readonly</code>之后，就挂载为 只读 了。如果你在容器内 /opt/webapp 目录新建文件，会显示如下错误:</p><pre class=" language-shell"><code class="language-shell">/opt/webapp # touch new.txttouch: new.txt: Read-only file system</code></pre><p>查看数据卷的具体信息：在主机里使用以下命令可以查看 web 容器的信息</p><pre class=" language-shell"><code class="language-shell">$ docker inspect web..."Mounts": [    {        "Type": "bind",        "Source": "/src/webapp",        "Destination": "/opt/webapp",        "Mode": "",        "RW": true,        "Propagation": "rprivate"    }],</code></pre><p>挂载一个本地主机文件作为数据卷：<code>--mount</code>标记也可以从主机挂载单个文件到容器中</p><pre class=" language-shell"><code class="language-shell">$ docker run --rm -it \   # -v $HOME/.bash_history:/root/.bash_history \   --mount type=bind,source=$HOME/.bash_history,target=/root/.bash_history \   ubuntu:17.10 \   bashroot@2affd44b4667:/# history1  ls2  diskutil list</code></pre><p>这样就可以记录在容器输入过的命令了。</p>]]></content>
      
      
      <categories>
          
          <category> container </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>zabbix-监控项</title>
      <link href="2020/01/05/monitor/zabbix-jian-kong-xiang/"/>
      <url>2020/01/05/monitor/zabbix-jian-kong-xiang/</url>
      
        <content type="html"><![CDATA[<h4 id="Zabbix监控什么？"><a href="#Zabbix监控什么？" class="headerlink" title="Zabbix监控什么？"></a>Zabbix监控什么？</h4><p><img src="http://p1.pstatp.com/large/pgc-image/1ee9df63b32b4108a8537cc27eb9252b" alt="Zabbix 监控"></p><p>监控项</p><h4 id="Zabbix常用监控项"><a href="#Zabbix常用监控项" class="headerlink" title="Zabbix常用监控项"></a>Zabbix常用监控项</h4><p><strong>zabbix自带的常用监控项</strong></p><pre><code>agent.ping 检测客户端可达性、返回nothing表示不可达。1表示可达system.cpu.load --检测cpu负载。返回浮点数system.cpu.util -- 检测cpu使用率。返回浮点数vfs.dev.read -- 检测硬盘读取数据，返回是sps.ops.bps浮点类型，需要定义1024倍vfs.dev.write -- 检测硬盘写入数据。返回是sps.ops.bps浮点类型，需要定义1024倍net.if.out[br0] --检测网卡流速、流出方向，时间间隔为60Snet-if-in[br0] --检测网卡流速，流入方向（单位：字节） 时间间隔60Sproc.num[]  目前系统中的进程总数，时间间隔60sproc.num[,,run] 目前正在运行的进程总数，时间间隔60S</code></pre><h5 id="处理器信息"><a href="#处理器信息" class="headerlink" title="处理器信息"></a>处理器信息</h5><pre><code>通过zabbix_get 获取负载值合理的控制用户态、系统态、IO等待时间剋保证进程高效率的运行系统态运行时间较高说明进程进行系统调用的次数比较多，一般的程序如果系统态运行时间占用过高就需要优化程序，减少系统调用io等待时间过高则表明硬盘的io性能差，如果是读写文件比较频繁、读写效率要求比较高，可以考虑更换硬盘，或者使用多磁盘做raid的方案system.cpu.swtiches --cpu的进程上下文切换，单位sps，表示每秒采样次数，api中参数history需指定为3system.cpu.intr  --cpu中断数量、api中参数history需指定为3system.cpu.load[percpu,avg1]  --cpu每分钟的负载值，按照核数做平均值(Processor load (1 min average per core))，api中参数history需指定为0system.cpu.load[percpu,avg5]  --cpu每5分钟的负载值，按照核数做平均值(Processor load (5 min average per core))，api中参数history需指定为0system.cpu.load[percpu,avg15]  --cpu每5分钟的负载值，按照核数做平均值(Processor load (15 min average per core))，api中参数history需指定为0</code></pre><h4 id="zabbix的自定义常用项"><a href="#zabbix的自定义常用项" class="headerlink" title="zabbix的自定义常用项"></a>zabbix的自定义常用项</h4><h5 id="内存相关"><a href="#内存相关" class="headerlink" title="内存相关"></a>内存相关</h5><pre><code>vim /usr/local/zabbix/etc/zabbix_agentd.conf.d/catcarm.confUserParameter=ram.info[*],/bin/cat  /proc/meminfo  |awk &#39;/^$1:{print $2}&#39;ram.info[Cached] --检测内存的缓存使用量、返回整数，需要定义1024倍ram.info[MemFree] --检测内存的空余量，返回整数，需要定义1024倍ram.info[Buffers] --检测内存的使用量，返回整数，需要定义1024倍</code></pre><h5 id="TCP相关的自定义项"><a href="#TCP相关的自定义项" class="headerlink" title="TCP相关的自定义项"></a>TCP相关的自定义项</h5><pre><code>vim /usr/local/zabbix/share/zabbix/alertscripts/tcp_connection.sh#!/bin/bashfunction ESTAB { /usr/sbin/ss -ant |awk &#39;{++s[$1]} END {for(k in s) print k,s[k]}&#39; | grep &#39;ESTAB&#39; | awk &#39;{print $2}&#39;}function TIMEWAIT {/usr/sbin/ss -ant | awk &#39;{++s[$1]} END {for(k in s) print k,s[k]}&#39; | grep &#39;TIME-WAIT&#39; | awk &#39;{print $2}&#39;}function LISTEN {/usr/sbin/ss -ant | awk &#39;{++s[$1]} END {for(k in s) print k,s[k]}&#39; | grep &#39;LISTEN&#39; | awk &#39;{print $2}&#39;}$1vim /usr/local/zabbix/etc/zabbix_agentd.conf.d/cattcp.confUserParameter=tcp[*],/usr/local/zabbix/share/zabbix/alertscripts/tcp_connection.sh $1tcp[TIMEWAIT] --检测TCP的驻留数，返回整数tcp[ESTAB]  --检测tcp的连接数、返回整数tcp[LISTEN] --检测TCP的监听数，返回整数</code></pre><h5 id="nginx相关的自定义项"><a href="#nginx相关的自定义项" class="headerlink" title="nginx相关的自定义项"></a>nginx相关的自定义项</h5><pre><code>vim /etc/nginx/conf.d/default.conf    location /nginx-status    {        stub_status on;        access_log off;        allow 127.0.0.1;        deny all;    }vim /usr/local/zabbix/etc/zabbix_agentd.conf.d/nginx.confUserParameter=Nginx.active,/usr/bin/curl -s &quot;http://127.0.0.1:80/nginx-status&quot; | awk &#39;/Active/ {print $NF}&#39;UserParameter=Nginx.read,/usr/bin/curl -s &quot;http://127.0.0.1:80/nginx-status&quot; | grep &#39;Reading&#39; | cut -d&quot; &quot; -f2UserParameter=Nginx.wrie,/usr/bin/curl -s &quot;http://127.0.0.1:80/nginx-status&quot; | grep &#39;Writing&#39; | cut -d&quot; &quot; -f4UserParameter=Nginx.wait,/usr/bin/curl -s &quot;http://127.0.0.1:80/nginx-status&quot; | grep &#39;Waiting&#39; | cut -d&quot; &quot; -f6UserParameter=Nginx.accepted,/usr/bin/curl -s &quot;http://127.0.0.1:80/nginx-status&quot; | awk &#39;/^[ \t]+[0-9]+[ \t]+[0-9]+[ \t]+[0-9]+/ {print $1}&#39;UserParameter=Nginx.handled,/usr/bin/curl -s &quot;http://127.0.0.1:80/nginx-status&quot; | awk &#39;/^[ \t]+[0-9]+[ \t]+[0-9]+[ \t]+[0-9]+/ {print $2}&#39;UserParameter=Nginx.requests,/usr/bin/curl -s &quot;http://127.0.0.1:80/nginx-status&quot; | awk &#39;/^[ \t]+[0-9]+[ \t]+[0-9]+[ \t]+[0-9]+/ {print $3}&#39;PHP.listenqueue --检测PHP队列数，返回整数PHP.idle --检测PHP空闲进程数，返回整数PHP.active --检测PHP活动进程数，返回整数PHP.conn --检测PHP请求数,返回整数PHP.reached --检测PHP达到限制次数，返回整数PHP.requets --检测PHP慢请求书，返回整数</code></pre><h5 id="redis相关的自定义项"><a href="#redis相关的自定义项" class="headerlink" title="redis相关的自定义项"></a>redis相关的自定义项</h5><pre><code>vim /usr/local/zabbix/etc/zabbix_agentd.conf.d/redis.confUserParameter=Redis.Status,/usr/local/redis/bin/redis-cli -h 127.0.0.1 -p 6379 ping |grep -c PONGUserParameter=Redis_conn[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep -w &quot;connected_clients&quot; | awk -F&#39;:&#39; &#39;{print $2}&#39;UserParameter=Redis_rss_mem[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep -w &quot;used_memory_rss&quot; | awk -F&#39;:&#39; &#39;{print $2}&#39;UserParameter=Redis_lua_mem[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep -w &quot;used_memory_lua&quot; | awk -F&#39;:&#39; &#39;{print $2}&#39;UserParameter=Redis_cpu_sys[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep -w &quot;used_cpu_sys&quot; | awk -F&#39;:&#39; &#39;{print $2}&#39;UserParameter=Redis_cpu_user[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep -w &quot;used_cpu_user&quot; | awk -F&#39;:&#39; &#39;{print $2}&#39;UserParameter=Redis_cpu_sys_cline[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep -w &quot;used_cpu_sys_children&quot; | awk -F&#39;:&#39; &#39;{print $2}&#39;UserParameter=Redis_cpu_user_cline[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep -w &quot;used_cpu_user_children&quot; | awk -F&#39;:&#39; &#39;{print $2}&#39;UserParameter=Redis_keys_num[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep -w &quot;$$1&quot; | grep -w &quot;keys&quot; | grep db$3 | awk -F&#39;=&#39; &#39;{print $2}&#39; | awk -F&#39;,&#39; &#39;{print $1}&#39;UserParameter=Redis_loading[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep loading | awk -F&#39;:&#39; &#39;{print $$2}&#39;Redis.Status --检测Redis运行状态， 返回整数Redis_conn  --检测Redis成功连接数，返回整数Redis_rss_mem  --检测Redis系统分配内存，返回整数Redis_lua_mem  --检测Redis引擎消耗内存，返回整数Redis_cpu_sys --检测Redis主程序核心CPU消耗率，返回整数Redis_cpu_user --检测Redis主程序用户CPU消耗率，返回整数Redis_cpu_sys_cline --检测Redis后台核心CPU消耗率，返回整数Redis_cpu_user_cline --检测Redis后台用户CPU消耗率，返回整数Redis_keys_num --检测库键值数，返回整数Redis_loding --检测Redis持久化文件状态，返回整数</code></pre><h5 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL:"></a>MySQL:</h5><pre><code>version:数据库版本key_buffer_size:myisam的索引buffer大小sort_buffer_size:会话的排序空间（每个线程会申请一个）join_buffer_size:这是为链接操作分配的最小缓存大小，这些连接使用普通索引扫描、范围扫描、或者连接不适用索引max_connections:最大允许同时连接的数量max_connect_errors：允许一个主机最多的错误链接次数，如果超过了就会拒绝之后链接（默认100）。可以使用flush hosts命令去解除拒绝open_files_limits:操作系统允许mysql打开的文件数量，可以通过opened_tables状态确定是否需要增大table_open_cache,如果opened_tables比较大且一直还在增大说明需要增大table_open_cachemax-heap_tables_size:建立的内存表的最大大小（默认16M）这个参数和tmp_table_size一起限制内部临时表的最大值(取这两个参数的小的一个），如果超过限制，则表会变为innodb或myisam引擎，（5.7.5之前是默认是myisam，5.7.6开始是innodb，可以通过internal_tmp_disk_storage_engine参数调整）。max_allowed_packet:一个包的最大大小##########GET INNODB INFO#INNODB variablesinnodb_version:innodb_buffer_pool_instances：将innodb缓冲池分为指定的多个（默认为1）innodb_buffer_pool_size:innodb缓冲池大小、5.7.5引入了innodb_buffer_pool_chunk_size,innodb_doublewrite：是否开启doublewrite（默认开启）innodb_read_io_threads:IO读线程的数量innodb_write_io_threads:IO写线程的数量########innodb statusinnodb_buffer_pool_pages_total:innodb缓冲池页的数量、大小等于innodb_buffer_pool_size/(16*1024)innodb_buffer_pool_pages_data:innodb缓冲池中包含数据的页的数量########## GET MYSQL HITRATE1、查询缓存命中率如果Qcache_hits+Com_select&lt;&gt;0则为 Qcache_hits/（Qcache_hits+Com_select），否则为02、线程缓存命中率如果Connections&lt;&gt;0,则为1-Threads_created/Connections，否则为03、myisam键缓存命中率如果Key_read_requests&lt;&gt;0,则为1-Key_reads/Key_read_requests，否则为04、myisam键缓存写命中率如果Key_write_requests&lt;&gt;0,则为1-Key_writes/Key_write_requests，否则为05、键块使用率如果Key_blocks_used+Key_blocks_unused&lt;&gt;0，则Key_blocks_used/（Key_blocks_used+Key_blocks_unused），否则为06、创建磁盘存储的临时表比率如果Created_tmp_disk_tables+Created_tmp_tables&lt;&gt;0,则Created_tmp_disk_tables/（Created_tmp_disk_tables+Created_tmp_tables），否则为07、连接使用率如果max_connections&lt;&gt;0，则threads_connected/max_connections，否则为08、打开文件比率如果open_files_limit&lt;&gt;0，则open_files/open_files_limit，否则为09、表缓存使用率如果table_open_cache&lt;&gt;0，则open_tables/table_open_cache，否则为0</code></pre>]]></content>
      
      
      <categories>
          
          <category> monitor </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zabbix </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Oracle设置开机自启</title>
      <link href="2019/11/27/sql/oracle-she-zhi-kai-ji-zi-qi/"/>
      <url>2019/11/27/sql/oracle-she-zhi-kai-ji-zi-qi/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><strong>步骤：</strong></p><h5 id="1：查看ORACLE-HOME是否设置"><a href="#1：查看ORACLE-HOME是否设置" class="headerlink" title="1：查看ORACLE_HOME是否设置"></a><strong>1：查看ORACLE_HOME是否设置</strong></h5><pre><code>$ echo $ORACLE_HOME/u01/app/oracle/product/11.2.0/db_1</code></pre><h5 id="2：执行dbstart-数据库自带启动脚本"><a href="#2：执行dbstart-数据库自带启动脚本" class="headerlink" title="2：执行dbstart 数据库自带启动脚本"></a><strong>2：执行dbstart 数据库自带启动脚本</strong></h5><pre><code>[oracle@njdzjkdb ~]$ cd $ORACLE_HOME[oracle@njdzjkdb dbhome_1]$ cd bin/[oracle@njdzjkdb bin]$ dbstartORACLE_HOME_LISTNER is not SET, unable to auto-start Oracle Net Listener Usage: /u01/app/oracle/product/11.2.0/db_1/bin/dbstart ORACLE_HOME错误提示：ORACLE_HOME_LISTNER 没有设置[oracle@njdzjkdb bin]$ ll | grep dbs-rwxr-x---. 1 oracle oinstall 6088 1月 1 2000 dbshut-rwxr-x---. 1 oracle oinstall 13892 12月 11 16:01 dbstart编辑 dbstart，将ORACLE_HOME_LISTNER=$1修改成 ORACLE_HOME_LISTNER=$ORACLE_HOME 前提是$ORACLE_HOME环境设置正确[oracle@njdzjkdb bin]$ vi dbstart ORACLE_HOME_LISTNER=/u01/app/oracle/product/11.2.0/db_1</code></pre><h5 id="3：编辑-etc-oratab文件"><a href="#3：编辑-etc-oratab文件" class="headerlink" title="3：编辑/etc/oratab文件"></a><strong>3：编辑/etc/oratab文件</strong></h5><pre><code>dbca建库时都会自动创建/etc/oratab文件将oracle:/u01/app/oracle/product/11.2.0/db_1:N修改成 oracle:/u01/app/oracle/product/11.2.0/db_1:Y</code></pre><h5 id="4：编辑-etc-rc-d-rc-local启动文件，添加数据库启动脚本dbstart"><a href="#4：编辑-etc-rc-d-rc-local启动文件，添加数据库启动脚本dbstart" class="headerlink" title="4：编辑/etc/rc.d/rc.local启动文件，添加数据库启动脚本dbstart"></a><strong>4：编辑/etc/rc.d/rc.local启动文件，添加数据库启动脚本dbstart</strong></h5><pre><code>[root@njdzjkdb ~]# vi /etc/rc.d/rc.local#!/bin/bash# THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES## It is highly advisable to create own systemd services or udev rules# to run scripts during boot instead of using this file.## In contrast to previous versions due to parallel execution during boot# this script will NOT be run after all other services.## Please note that you must run &#39;chmod +x /etc/rc.d/rc.local&#39; to ensure# that this script will be executed during boot.touch /var/lock/subsys/localsu oracle -lc &quot;/u01/app/oracle/product/11.2.0/db_1/bin/lsnrctl start&quot;su oracle -lc /u01/app/oracle/product/11.2.0/db_1/bin/dbstart</code></pre><h5 id="5：重启主机，查看数据库和监听是自启动"><a href="#5：重启主机，查看数据库和监听是自启动" class="headerlink" title="5：重启主机，查看数据库和监听是自启动"></a><strong>5：重启主机，查看数据库和监听是自启动</strong></h5><pre><code>netstat -tunlp | grep 1521</code></pre><h5 id="6：查看数据库是否处于open状态"><a href="#6：查看数据库是否处于open状态" class="headerlink" title="6：查看数据库是否处于open状态"></a><strong>6：查看数据库是否处于open状态</strong></h5><pre><code>select status from v$instance</code></pre>]]></content>
      
      
      <categories>
          
          <category> SQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Oracle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS7静默安装oracle11g</title>
      <link href="2019/11/27/sql/centos7-jing-mo-an-zhuang-oracle11g/"/>
      <url>2019/11/27/sql/centos7-jing-mo-an-zhuang-oracle11g/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h5 id="操作系统："><a href="#操作系统：" class="headerlink" title="操作系统："></a><strong>操作系统：</strong></h5><pre><code>[root@cyylog ~]# uname -mx86_64[root@cyylog ~]# cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core) </code></pre><h1 id="安装前的准备："><a href="#安装前的准备：" class="headerlink" title="安装前的准备："></a><strong>安装前的准备：</strong></h1><h5 id="1-修改主机名"><a href="#1-修改主机名" class="headerlink" title="1. 修改主机名"></a><strong>1. 修改主机名</strong></h5><pre><code>#sed -i &quot;s/HOSTNAME=localhost.localdomain/HOSTNAME=oracledb/&quot; /etc/sysconfig/network</code></pre><h5 id="2-添加主机名与IP对应记录"><a href="#2-添加主机名与IP对应记录" class="headerlink" title="2.添加主机名与IP对应记录"></a><strong>2.添加主机名与IP对应记录</strong></h5><pre><code># vim /etc/hosts 192.168.0.9 oracledb</code></pre><h5 id="3-关闭Selinux"><a href="#3-关闭Selinux" class="headerlink" title="3.关闭Selinux"></a><strong>3.关闭Selinux</strong></h5><pre><code># sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/&quot; /etc/selinux/config # setenforce 0 </code></pre><h5 id="4-检查是否有swap分区"><a href="#4-检查是否有swap分区" class="headerlink" title="4.检查是否有swap分区."></a><strong>4.检查是否有swap分区.</strong></h5><p>(我的机器是没有这个,所有后面有报错) Linux一切皆文件,没有就自己造一个</p><pre><code>1、检查 Swap 空间在设置 Swap 文件之前，有必要先检查一下系统里有没有既存的 Swap 文件。运行以下命令：# swapon -s如果返回的信息概要是空的，则表示 Swap 文件不存在。2、检查文件系统在设置 Swap 文件之前，同样有必要检查一下文件系统，看看是否有足够的硬盘空间来设置 Swap 。运行以下命令：# df -hal3、创建并允许 Swap 文件下面使用 dd 命令来创建 Swap 文件。检查返回的信息，还剩余足够的硬盘空间即可。# dd if=/dev/zero of=/swapfile bs=1024 count=512k参数解读：if=文件名：输入文件名，缺省为标准输入。即指定源文件。&lt; if=input file &gt;of=文件名：输出文件名，缺省为标准输出。即指定目的文件。&lt; of=output file &gt;bs=bytes：同时设置读入/输出的块大小为bytes个字节count=blocks：仅拷贝blocks个块，块大小等于bs指定的字节数。4、格式化并激活 Swap 文件上面已经创建好 Swap 文件，还需要格式化后才能使用。运行命令：# mkswap /swapfile激活 Swap ，运行命令：# swapon /swapfile以上步骤做完，再次运行命令：# swapon -s你会发现返回的信息概要：1 Filename Type Size Used Priority2 /swapfile file 524284 0 -1如果要机器重启的时候自动挂载 Swap ，那么还需要修改 fstab 配置。用 vim 打开 /etc/fstab 文件，在其最后添加如下一行：/swapfile swap swap defaults 0 0最后，赋予 Swap 文件适当的权限：# chown root:root /swapfile # chmod 0600 /swapfile</code></pre><h5 id="5-安装常用工具-配置阿里源"><a href="#5-安装常用工具-配置阿里源" class="headerlink" title="5.安装常用工具,配置阿里源"></a><strong>5.安装常用工具,配置阿里源</strong></h5><p>(个人习惯,在使用的主机上面配置这些常用工具)</p><pre><code># curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo# curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo# yum clean all# yum makecache fast# yum install -y wget ntpdate net-tools vim bash-completion ShellCheck# ntpdate -b ntp1.aliyun.com</code></pre><h4 id="安装软件包"><a href="#安装软件包" class="headerlink" title="安装软件包"></a>安装软件包</h4><p>参考官方：<a href="http://docs.oracle.com/cd/E11882_01/install.112/e24326/toc.htm#BHCCADGD" target="_blank" rel="noopener">http://docs.oracle.com/cd/E11882_01/install.112/e24326/toc.htm#BHCCADGD</a></p><ul><li>The following or later version of packages for Oracle Linux 7, and Red Hat Enterprise Linux 7 must be installed:</li></ul><pre><code>binutils-2.23.52.0.1-12.el7.x86_64 compat-libcap1-1.10-3.el7.x86_64 compat-libstdc++-33-3.2.3-71.el7.i686compat-libstdc++-33-3.2.3-71.el7.x86_64gcc-4.8.2-3.el7.x86_64 gcc-c++-4.8.2-3.el7.x86_64 glibc-2.17-36.el7.i686 glibc-2.17-36.el7.x86_64 glibc-devel-2.17-36.el7.i686 glibc-devel-2.17-36.el7.x86_64 kshlibaio-0.3.109-9.el7.i686 libaio-0.3.109-9.el7.x86_64 libaio-devel-0.3.109-9.el7.i686 libaio-devel-0.3.109-9.el7.x86_64 libgcc-4.8.2-3.el7.i686 libgcc-4.8.2-3.el7.x86_64 libstdc++-4.8.2-3.el7.i686 libstdc++-4.8.2-3.el7.x86_64 libstdc++-devel-4.8.2-3.el7.i686 libstdc++-devel-4.8.2-3.el7.x86_64 libXi-1.7.2-1.el7.i686 libXi-1.7.2-1.el7.x86_64 libXtst-1.2.2-1.el7.i686 libXtst-1.2.2-1.el7.x86_64 make-3.82-19.el7.x86_64 sysstat-10.1.5-1.el7.x86_64unixODBC-2.3.1-6.el7.x86_64 or laterunixODBC-2.3.1-6.el7.i686 or laterunixODBC-devel-2.3.1-6.el7.x86_64 or laterunixODBC-devel-2.3.1-6.el7.i686 or later</code></pre><pre><code>binutils-2.23.52.0.1-12.el7.x86_64 compat-libcap1-1.10-3.el7.x86_64 compat-libstdc++-33-3.2.3-71.el7.i686compat-libstdc++-33-3.2.3-71.el7.x86_64gcc-4.8.2-3.el7.x86_64 gcc-c++-4.8.2-3.el7.x86_64 glibc-2.17-36.el7.i686 glibc-2.17-36.el7.x86_64 glibc-devel-2.17-36.el7.i686 glibc-devel-2.17-36.el7.x86_64 kshlibaio-0.3.109-9.el7.i686 libaio-0.3.109-9.el7.x86_64 libaio-devel-0.3.109-9.el7.i686 libaio-devel-0.3.109-9.el7.x86_64 libgcc-4.8.2-3.el7.i686 libgcc-4.8.2-3.el7.x86_64 libstdc++-4.8.2-3.el7.i686 libstdc++-4.8.2-3.el7.x86_64 libstdc++-devel-4.8.2-3.el7.i686 libstdc++-devel-4.8.2-3.el7.x86_64 libXi-1.7.2-1.el7.i686 libXi-1.7.2-1.el7.x86_64 libXtst-1.2.2-1.el7.i686 libXtst-1.2.2-1.el7.x86_64 make-3.82-19.el7.x86_64 sysstat-10.1.5-1.el7.x86_64unixODBC-2.3.1-6.el7.x86_64 or laterunixODBC-2.3.1-6.el7.i686 or laterunixODBC-devel-2.3.1-6.el7.x86_64 or laterunixODBC-devel-2.3.1-6.el7.i686 or later</code></pre><h5 id="用yum进行安装"><a href="#用yum进行安装" class="headerlink" title="用yum进行安装"></a><strong>用yum进行安装</strong></h5><pre><code>yum -y install binutils compat-libcap1 compat-libstdc++-33 compat-libstdc++-33*i686 compat-libstdc++-33*.devel compat-libstdc++-33 compat-libstdc++-33*.devel gcc gcc-c++ glibc glibc*.i686 glibc-devel glibc-devel*.i686 ksh libaio libaio*.i686 libaio-devel libaio-devel*.devel libgcc libgcc*.i686 libstdc++ libstdc++*.i686 libstdc++-devel libstdc++-devel*.devel libXi libXi*.i686 libXtst libXtst*.i686 make sysstat unixODBC unixODBC*.i686 unixODBC-devel unixODBC-devel*.i686</code></pre><h5 id="检测是否31个包都有安装"><a href="#检测是否31个包都有安装" class="headerlink" title="检测是否31个包都有安装"></a><strong>检测是否31个包都有安装</strong></h5><p>开放源码绿色蓝色按钮样式</p><pre><code>[root@cyylog ~]# rpm -q binutils compat-libcap1 compat-libstdc++-33 gcc gcc-c++ glibc glibc-devel ksh libaio libaio-devel libgcc libstdc++ libstdc++-devel libXi libXtst make sysstat unixODBC unixODBC-develbinutils-2.23.52.0.1-55.el7.x86_64compat-libcap1-1.10-7.el7.x86_64compat-libstdc++-33-3.2.3-72.el7.x86_64compat-libstdc++-33-3.2.3-72.el7.i686gcc-4.8.5-4.el7.x86_64gcc-c++-4.8.5-4.el7.x86_64glibc-2.17-106.el7_2.8.x86_64glibc-2.17-106.el7_2.8.i686glibc-devel-2.17-106.el7_2.8.x86_64glibc-devel-2.17-106.el7_2.8.i686ksh-20120801-22.el7_1.3.x86_64libaio-0.3.109-13.el7.x86_64libaio-0.3.109-13.el7.i686libaio-devel-0.3.109-13.el7.x86_64libaio-devel-0.3.109-13.el7.i686libgcc-4.8.5-4.el7.x86_64libgcc-4.8.5-4.el7.i686libstdc++-4.8.5-4.el7.x86_64libstdc++-4.8.5-4.el7.i686libstdc++-devel-4.8.5-4.el7.x86_64libstdc++-devel-4.8.5-4.el7.i686libXi-1.7.2-2.1.el7.x86_64libXi-1.7.4-2.el7.i686libXtst-1.2.2-2.1.el7.x86_64libXtst-1.2.2-2.1.el7.i686make-3.82-21.el7.x86_64sysstat-10.1.5-7.el7.x86_64unixODBC-2.3.1-11.el7.x86_64unixODBC-2.3.1-11.el7.i686unixODBC-devel-2.3.1-11.el7.x86_64unixODBC-devel-2.3.1-11.el7.i686</code></pre><p>版本号只能大于规定的版本，不能小于。</p><p>创建oinstall和dba组</p><pre><code># groupadd oinstall# groupadd dba</code></pre><p>创建oracle用户</p><pre><code># useradd -g oinstall -G dba oracle</code></pre><p>设置oracle用户密码</p><pre><code># passwd oracle</code></pre><p>验证创建是否正确</p><pre><code>[root@cyylog ~]# id oracleuid=1000(oracle) gid=1000(oinstall) groups=1000(oinstall),1001(dba)</code></pre><h5 id="配置内核参数"><a href="#配置内核参数" class="headerlink" title="配置内核参数"></a>配置内核参数</h5><pre><code>[root@cyylog ~]# vim /etc/sysctl.conf # System default settings live in /usr/lib/sysctl.d/00-system.conf.# To override those settings, enter new settings here, or in an /etc/sysctl.d/&lt;name&gt;.conf file## For more information, see sysctl.conf(5) and sysctl.d(5).fs.aio-max-nr = 1048576fs.file-max = 6815744kernel.shmall = 2097152kernel.shmmax = 536870912 #最低：536870912，最大值：比物理内存小1个字节的值，建议超过物理内存的一半kernel.shmmni = 4096kernel.sem = 250 32000 100 128net.ipv4.ip_local_port_range = 9000 65500net.core.rmem_default = 262144net.core.rmem_max = 4194304net.core.wmem_default = 262144net.core.wmem_max = 1048576</code></pre><p>参数的值不能小于上面的配置，这是oracle官方建议的最小值，生产环境建议调整这些参数，以优化系统性能。</p><p>修改后使之生效</p><pre><code># sysctl -p</code></pre><p>修改用户限制</p><pre><code>vim /etc/security/limits.conf#在末尾添加oracle soft nproc 2047oracle hard nproc 16384oracle soft nofile 1024oracle hard nofile 65536oracle soft stack 10240oracle hard stack 10240</code></pre><p>在/etc/pam.d/login 文件中，使用文本编辑器或vi命令增加或修改以下内容</p><pre><code>session required /lib64/security/pam_limits.sosession required pam_limits.so</code></pre><p>在/etc/profile 文件中，使用文本编辑器或vi命令增加或修改以下内容</p><pre><code>if [ $USER = &quot;oracle&quot; ]; then if [ $SHELL = &quot;/bin/ksh&quot; ]; then ulimit -p 16384 ulimit -n 65536 else ulimit -u 16384 -n 65536 fifi</code></pre><p>使之生效</p><pre><code># source /etc/profile</code></pre><p>创建安装目录</p><pre><code># mkdir -p /u01/app/# chown -R oracle:oinstall /u01/app/# chmod -R 775 /u01/app/</code></pre><p>配置环境变量</p><pre><code>[oracle@cyylog ~]$ vim ~/.bash_profile export ORACLE_BASE=/u01/app/oracleexport ORACLE_SID=dbsrv2</code></pre><p>使之生效</p><pre><code>source ~/.bash_profile</code></pre><p>解压oracle软件</p><pre><code>[root@cyylog src]# unzip linux.x64_11gR2_database_1of2.zip[root@cyylog src]# unzip linux.x64_11gR2_database_2of2.zip</code></pre><p>复制响应文件模板</p><pre><code>[oracle@cyylog ~]$ mkdir etc[oracle@cyylog ~]$ cp /usr/local/src/database/response/* /home/oracle/etc/[oracle@cyylog ~]$ ls etcdbca.rsp db_install.rsp netca.rsp</code></pre><p>设置响应文件权限</p><pre><code>[oracle@cyylog ~]$ su - root[root@cyylog ~]# chmod 700 /home/oracle/etc/*.rsp</code></pre><h1 id="静默安装Oracle软件"><a href="#静默安装Oracle软件" class="headerlink" title="静默安装Oracle软件"></a><strong>静默安装Oracle软件</strong></h1><p>su - oracle</p><p>修改安装Oracle软件的响应文件/home/oracle/etc/db_install.rsp</p><pre><code>oracle.install.option=INSTALL_DB_SWONLY // 安装类型ORACLE_HOSTNAME=oracledb // 主机名称（hostname查询）UNIX_GROUP_NAME=oinstall // 安装组INVENTORY_LOCATION=/u01/app/oraInventory //INVENTORY目录（不填就是默认值）SELECTED_LANGUAGES=en,zh_CN,zh_TW // 选择语言ORACLE_HOME=/u01/app/oracle/product/11.2.0/db_1 //oracle_homeORACLE_BASE=/u01/app/oracle //oracle_baseoracle.install.db.InstallEdition=EE 　　　　// oracle版本oracle.install.db.isCustomInstall=false 　　//自定义安装，否，使用默认组件oracle.install.db.DBA_GROUP=dba /　　/ dba用户组oracle.install.db.OPER_GROUP=oinstall // oper用户组oracle.install.db.config.starterdb.type=GENERAL_PURPOSE //数据库类型oracle.install.db.config.starterdb.globalDBName=orcl //globalDBNameoracle.install.db.config.starterdb.SID=dbsrv2 //SIDoracle.install.db.config.starterdb.memoryLimit=81920 //自动管理内存的内存(M)oracle.install.db.config.starterdb.password.ALL=oracle //设定所有数据库用户使用同一个密码SECURITY_UPDATES_VIA_MYORACLESUPPORT=false //（手动写了false）DECLINE_SECURITY_UPDATES=true 　　//设置安全更新（貌似是有bug，这个一定要选true，否则会无限提醒邮件地址有问题，终止安装。PS：不管地址对不对）</code></pre><pre><code>oracle.install.option=INSTALL_DB_SWONLY // 安装类型ORACLE_HOSTNAME=oracledb // 主机名称（hostname查询）UNIX_GROUP_NAME=oinstall // 安装组INVENTORY_LOCATION=/u01/app/oraInventory //INVENTORY目录（不填就是默认值）SELECTED_LANGUAGES=en,zh_CN,zh_TW // 选择语言ORACLE_HOME=/u01/app/oracle/product/11.2.0/db_1 //oracle_homeORACLE_BASE=/u01/app/oracle //oracle_baseoracle.install.db.InstallEdition=EE 　　　　// oracle版本oracle.install.db.isCustomInstall=false 　　//自定义安装，否，使用默认组件oracle.install.db.DBA_GROUP=dba /　　/ dba用户组oracle.install.db.OPER_GROUP=oinstall // oper用户组oracle.install.db.config.starterdb.type=GENERAL_PURPOSE //数据库类型oracle.install.db.config.starterdb.globalDBName=orcl //globalDBNameoracle.install.db.config.starterdb.SID=dbsrv2 //SIDoracle.install.db.config.starterdb.memoryLimit=81920 //自动管理内存的内存(M)oracle.install.db.config.starterdb.password.ALL=oracle //设定所有数据库用户使用同一个密码SECURITY_UPDATES_VIA_MYORACLESUPPORT=false //（手动写了false）DECLINE_SECURITY_UPDATES=true 　　//设置安全更新（貌似是有bug，这个一定要选true，否则会无限提醒邮件地址有问题，终止安装。PS：不管地址对不对）</code></pre><p>开始静默安装</p><pre><code>[oracle@cyylog database]$ ./runInstaller -silent -responseFile /home/oracle/etc/db_install.rsp</code></pre><p>新开一个终端 查看安装日志</p><pre><code># tail -f /u01/app/oraInventory/logs/installActions2016-08-31_06-56-29PM.log</code></pre><p>出现类似如下提示表示安装完成：</p><p>-———————————————————————–</p><p>The following configuration scripts need to be executed as the “root” user. #!/bin/sh #Root scripts to run</p><p>/u01/app/oraInventory/orainstRoot.sh /u01/app/oracle/product/11.2.0/db_1/root.sh To execute the configuration scripts:</p><ol><li>Open a terminal window</li><li>Log in as “root”</li><li>Run the scripts</li><li>Return to this window and hit “Enter” key to continue</li></ol><p>Successfully Setup Software.</p><p>-—————————————————————————-</p><p>使用root用户执行脚本</p><pre><code>$ su - root# /u01/app/oraInventory/orainstRoot.sh# /u01/app/oracle/product/11.2.0/db_1/root.sh</code></pre><p>增加或修改oracle的环境变量</p><pre><code># su - oracle# vim ~/.bash_profile</code></pre><pre><code>#for oracleexport ORACLE_BASE=/u01/app/oracleexport ORACLE_SID=dbsrv2export ROACLE_PID=ora11g#export NLS_LANG=AMERICAN_AMERICA.AL32UTF8export LD_LIBRARY_PATH=$ORACLE_HOME/lib:/usr/libexport ORACLE_HOME=/u01/app/oracle/product/11.2.0/db_1export PATH=$PATH:$ORACLE_HOME/binexport LANG=&quot;zh_CN.UTF-8&quot;export NLS_LANG=&quot;SIMPLIFIED CHINESE_CHINA.AL32UTF8&quot;export NLS_DATE_FORMAT=&#39;yyyy-mm-dd hh24:mi:ss&#39;刷新环境变量# source ~/.bash_profile</code></pre><p>配置监听程序</p><pre><code>[oracle@cyylog ~]$ netca /silent /responsefile /home/oracle/etc/netca.rspParsing command line arguments:Parameter &quot;silent&quot; = trueParameter &quot;responsefile&quot; = /home/oracle/etc/netca.rspDone parsing command line arguments.Oracle Net Services Configuration:Profile configuration complete.Oracle Net Listener Startup:Running Listener Control: /u01/app/oracle/product/11.2.0/db_1/bin/lsnrctl start LISTENERListener Control complete.Listener started successfully.Listener configuration complete.Oracle Net Services configuration successful. The exit code is 0</code></pre><p>启动监控程序</p><pre><code>[oracle@cyylog ~]$ lsnrctl startLSNRCTL for Linux: Version 11.2.0.1.0 - Production on 01-SEP-2016 11:23:31Copyright (c) 1991, 2009, Oracle. All rights reserved.Starting /u01/app/oracle/product/11.2.0/db_1/bin/tnslsnr: please wait...TNSLSNR for Linux: Version 11.2.0.1.0 - ProductionSystem parameter file is /u01/app/oracle/product/11.2.0/db_1/network/admin/listener.oraLog messages written to /u01/app/oracle/diag/tnslsnr/cyylog/listener/alert/log.xmlListening on: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC1521)))Listening on: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=cyylog)(PORT=1521)))Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521)))STATUS of the LISTENER------------------------Alias LISTENERVersion TNSLSNR for Linux: Version 11.2.0.1.0 - ProductionStart Date 01-SEP-2016 11:23:31Uptime 0 days 0 hr. 0 min. 0 secTrace Level offSecurity ON: Local OS AuthenticationSNMP OFFListener Parameter File /u01/app/oracle/product/11.2.0/db_1/network/admin/listener.oraListener Log File /u01/app/oracle/diag/tnslsnr/cyylog/listener/alert/log.xmlListening Endpoints Summary... (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC1521))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=cyylog)(PORT=1521)))The listener supports no servicesThe command completed successfully</code></pre><p>静默dbca建库</p><p>编辑应答文件</p><pre><code>[oracle@cyylog ~]$ vi etc/dbca.rsp[GENERAL]RESPONSEFILE_VERSION = &quot;11.2.0&quot;OPERATION_TYPE = &quot;createDatabase&quot;[CREATEDATABASE]GDBNAME = &quot;dbsrv2&quot;SID = &quot;dbsrv2&quot;TEMPLATENAME = &quot;General_Purpose.dbc&quot;CHARACTERSET = &quot;AL32UTF8&quot;</code></pre><p><strong><em>建库(我的finashell会闪屏,但是不影响使用，因为这个是因为无图形界面的情况)</em></strong></p><pre><code>[oracle@cyylog ~]$ dbca -silent -responseFile etc/dbca.rspEnter SYS user password: Enter SYSTEM user password: sh: /bin/ksh: No such file or directorysh: /bin/ksh: No such file or directoryCopying database files1% complete3% complete11% complete18% complete26% complete37% completeCreating and starting Oracle instance40% complete45% complete50% complete55% complete56% complete57% complete60% complete62% completeCompleting Database Creation66% complete70% complete73% complete74% complete85% complete96% complete100% completeLook at the log file Look at the log file &quot;/u01/app/oracle/cfgtoollogs/dbca/orcl11g/orcl11g.log&quot; for further details.</code></pre><pre><code>[oracle@cyylog ~]$ dbca -silent -responseFile etc/dbca.rspEnter SYS user password: Enter SYSTEM user password: sh: /bin/ksh: No such file or directorysh: /bin/ksh: No such file or directoryCopying database files1% complete3% complete11% complete18% complete26% complete37% completeCreating and starting Oracle instance40% complete45% complete50% complete55% complete56% complete57% complete60% complete62% completeCompleting Database Creation66% complete70% complete73% complete74% complete85% complete96% complete100% completeLook at the log file Look at the log file &quot;/u01/app/oracle/cfgtoollogs/dbca/orcl11g/orcl11g.log&quot; for further details.</code></pre><p>查看输出日志</p><pre><code>[oracle@cyylog ~]$ tailf /u01/app/oracle/cfgtoollogs/dbca/silent.logCopying database filesDBCA_PROGRESS : 1%DBCA_PROGRESS : 3%DBCA_PROGRESS : 11%DBCA_PROGRESS : 18%DBCA_PROGRESS : 26%DBCA_PROGRESS : 37%Creating and starting Oracle instanceDBCA_PROGRESS : 40%DBCA_PROGRESS : 45%DBCA_PROGRESS : 50%DBCA_PROGRESS : 55%DBCA_PROGRESS : 56%DBCA_PROGRESS : 60%DBCA_PROGRESS : 62%Completing Database CreationDBCA_PROGRESS : 66%DBCA_PROGRESS : 70%DBCA_PROGRESS : 73%DBCA_PROGRESS : 85%DBCA_PROGRESS : 96%DBCA_PROGRESS : 100%Database creation complete. For details check the logfiles at: /u01/app/oracle/cfgtoollogs/dbca/orcl11g.Database Information:Global Database Name:orcl11g.us.oracle.comSystem Identifier(SID):dbsrv2</code></pre><p><strong>至此完成数据库实例的创建。</strong></p><p>-———————————————————————————-</p><p>-———————————————————————————-</p><p><strong>附：</strong></p><p>删除实例：</p><pre><code>[oracle@cyylog ~]$ dbca -silent -deleteDatabase -sourcedb dbsrv2</code></pre><p>文章来源:<a href="https://www.cnblogs.com/zydev/p/5827207.html" target="_blank" rel="noopener">https://www.cnblogs.com/zydev/p/5827207.html</a></p>]]></content>
      
      
      <categories>
          
          <category> SQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Oracle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker_002</title>
      <link href="2019/11/19/container/dockerfilee-002/"/>
      <url>2019/11/19/container/dockerfilee-002/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h4 id="Dockerfile-redis-5-0"><a href="#Dockerfile-redis-5-0" class="headerlink" title="Dockerfile_redis_5.0"></a>Dockerfile_redis_5.0</h4><pre class=" language-dockerfile"><code class="language-dockerfile">FROM debian:buster-slim# add our user and group first to make sure their IDs get assigned consistently, regardless of whatever dependencies get addedRUN groupadd -r -g 999 redis && useradd -r -g redis -u 999 redis# grab gosu for easy step-down from root# https://github.com/tianon/gosu/releasesENV GOSU_VERSION 1.11RUN set -eux; \# save list of currently installed packages for later so we can clean up    savedAptMark="$(apt-mark showmanual)"; \    apt-get update; \    apt-get install -y --no-install-recommends \        ca-certificates \        dirmngr \        gnupg \        wget \    ; \    rm -rf /var/lib/apt/lists/*; \    \    dpkgArch="$(dpkg --print-architecture | awk -F- '{ print $NF }')"; \    wget -O /usr/local/bin/gosu "https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$dpkgArch"; \    wget -O /usr/local/bin/gosu.asc "https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$dpkgArch.asc"; \    \# verify the signature    export GNUPGHOME="$(mktemp -d)"; \    gpg --batch --keyserver hkps://keys.openpgp.org --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4; \    gpg --batch --verify /usr/local/bin/gosu.asc /usr/local/bin/gosu; \    gpgconf --kill all; \    rm -rf "$GNUPGHOME" /usr/local/bin/gosu.asc; \    \# clean up fetch dependencies    apt-mark auto '.*' > /dev/null; \    [ -z "$savedAptMark" ] || apt-mark manual $savedAptMark > /dev/null; \    apt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant=false; \    \    chmod +x /usr/local/bin/gosu; \# verify that the binary works    gosu --version; \    gosu nobody trueENV REDIS_VERSION 5.0.8ENV REDIS_DOWNLOAD_URL http://download.redis.io/releases/redis-5.0.8.tar.gzENV REDIS_DOWNLOAD_SHA f3c7eac42f433326a8d981b50dba0169fdfaf46abb23fcda2f933a7552ee4ed7RUN set -eux; \    \    savedAptMark="$(apt-mark showmanual)"; \    apt-get update; \    apt-get install -y --no-install-recommends \        ca-certificates \        wget \        \        gcc \        libc6-dev \        make \    ; \    rm -rf /var/lib/apt/lists/*; \    \    wget -O redis.tar.gz "$REDIS_DOWNLOAD_URL"; \    echo "$REDIS_DOWNLOAD_SHA *redis.tar.gz" | sha256sum -c -; \    mkdir -p /usr/src/redis; \    tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1; \    rm redis.tar.gz; \    \# disable Redis protected mode [1] as it is unnecessary in context of Docker# (ports are not automatically exposed when running inside Docker, but rather explicitly by specifying -p / -P)# [1]: https://github.com/antirez/redis/commit/edd4d555df57dc84265fdfb4ef59a4678832f6da    grep -q '^#define CONFIG_DEFAULT_PROTECTED_MODE 1$' /usr/src/redis/src/server.h; \    sed -ri 's!^(#define CONFIG_DEFAULT_PROTECTED_MODE) 1$!\1 0!' /usr/src/redis/src/server.h; \    grep -q '^#define CONFIG_DEFAULT_PROTECTED_MODE 0$' /usr/src/redis/src/server.h; \# for future reference, we modify this directly in the source instead of just supplying a default configuration flag because apparently "if you specify any argument to redis-server, [it assumes] you are going to specify everything"# see also https://github.com/docker-library/redis/issues/4#issuecomment-50780840# (more exactly, this makes sure the default behavior of "save on SIGTERM" stays functional by default)    \    make -C /usr/src/redis -j "$(nproc)" all; \    make -C /usr/src/redis install; \    \# TODO https://github.com/antirez/redis/pull/3494 (deduplicate "redis-server" copies)    serverMd5="$(md5sum /usr/local/bin/redis-server | cut -d' ' -f1)"; export serverMd5; \    find /usr/local/bin/redis* -maxdepth 0 \        -type f -not -name redis-server \        -exec sh -eux -c ' \            md5="$(md5sum "$1" | cut -d" " -f1)"; \            test "$md5" = "$serverMd5"; \        ' -- '{}' ';' \        -exec ln -svfT 'redis-server' '{}' ';' \    ; \    \    rm -r /usr/src/redis; \    \    apt-mark auto '.*' > /dev/null; \    [ -z "$savedAptMark" ] || apt-mark manual $savedAptMark > /dev/null; \    find /usr/local -type f -executable -exec ldd '{}' ';' \        | awk '/=>/ { print $(NF-1) }' \        | sort -u \        | xargs -r dpkg-query --search \        | cut -d: -f1 \        | sort -u \        | xargs -r apt-mark manual \    ; \    apt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant=false; \    \    redis-cli --version; \    redis-server --versionRUN mkdir /data && chown redis:redis /dataVOLUME /dataWORKDIR /dataCOPY docker-entrypoint.sh /usr/local/bin/ENTRYPOINT ["docker-entrypoint.sh"]EXPOSE 6379CMD ["redis-server"]</code></pre><h4 id="Dockerfile-alpine-httpd-2-4"><a href="#Dockerfile-alpine-httpd-2-4" class="headerlink" title="Dockerfile_alpine_httpd_2.4"></a>Dockerfile_alpine_httpd_2.4</h4><pre class=" language-dockerfile"><code class="language-dockerfile">FROM alpine:3.11# ensure www-data user existsRUN set -x \    && addgroup -g 82 -S www-data \    && adduser -u 82 -D -S -G www-data www-data# 82 is the standard uid/gid for "www-data" in Alpine# https://git.alpinelinux.org/cgit/aports/tree/main/apache2/apache2.pre-install?h=v3.8.1# https://git.alpinelinux.org/cgit/aports/tree/main/lighttpd/lighttpd.pre-install?h=v3.8.1# https://git.alpinelinux.org/cgit/aports/tree/main/nginx/nginx.pre-install?h=v3.8.1ENV HTTPD_PREFIX /usr/local/apache2ENV PATH $HTTPD_PREFIX/bin:$PATHRUN mkdir -p "$HTTPD_PREFIX" \    && chown www-data:www-data "$HTTPD_PREFIX"WORKDIR $HTTPD_PREFIXENV HTTPD_VERSION 2.4.43ENV HTTPD_SHA256 a497652ab3fc81318cdc2a203090a999150d86461acff97c1065dc910fe10f43# https://httpd.apache.org/security/vulnerabilities_24.htmlENV HTTPD_PATCHES=""# see https://httpd.apache.org/docs/2.4/install.html#requirementsRUN set -eux; \    \    runDeps=' \        apr-dev \        apr-util-dbm_db \        apr-util-dev \        apr-util-ldap \        perl \    '; \    apk add --no-cache --virtual .build-deps \        $runDeps \        ca-certificates \        coreutils \        dpkg-dev dpkg \        gcc \        gnupg \        libc-dev \        # mod_md        curl-dev \        jansson-dev \        # mod_proxy_html mod_xml2enc        libxml2-dev \        # mod_lua        lua-dev \        make \        # mod_http2        nghttp2-dev \        # mod_session_crypto        openssl \        openssl-dev \        pcre-dev \        tar \        # mod_deflate        zlib-dev \        # mod_brotli        brotli-dev \    ; \    \    ddist() { \        local f="$1"; shift; \        local distFile="$1"; shift; \        local success=; \        local distUrl=; \        for distUrl in \# https://issues.apache.org/jira/browse/INFRA-8753?focusedCommentId=14735394#comment-14735394            'https://www.apache.org/dyn/closer.cgi?action=download&filename=' \# if the version is outdated (or we're grabbing the .asc file), we might have to pull from the dist/archive :/            https://www-us.apache.org/dist/ \            https://www.apache.org/dist/ \            https://archive.apache.org/dist/ \        ; do \            if wget -O "$f" "$distUrl$distFile" && [ -s "$f" ]; then \                success=1; \                break; \            fi; \        done; \        [ -n "$success" ]; \    }; \    \    ddist 'httpd.tar.bz2' "httpd/httpd-$HTTPD_VERSION.tar.bz2"; \    echo "$HTTPD_SHA256 *httpd.tar.bz2" | sha256sum -c -; \    \# see https://httpd.apache.org/download.cgi#verify    ddist 'httpd.tar.bz2.asc' "httpd/httpd-$HTTPD_VERSION.tar.bz2.asc"; \    export GNUPGHOME="$(mktemp -d)"; \    for key in \# gpg: key 791485A8: public key "Jim Jagielski (Release Signing Key) <jim@apache.org>" imported        A93D62ECC3C8EA12DB220EC934EA76E6791485A8 \# gpg: key 995E35221AD84DFF: public key "Daniel Ruggeri (https://home.apache.org/~druggeri/) <druggeri@apache.org>" imported        B9E8213AEFB861AF35A41F2C995E35221AD84DFF \    ; do \        gpg --batch --keyserver ha.pool.sks-keyservers.net --recv-keys "$key"; \    done; \    gpg --batch --verify httpd.tar.bz2.asc httpd.tar.bz2; \    command -v gpgconf && gpgconf --kill all || :; \    rm -rf "$GNUPGHOME" httpd.tar.bz2.asc; \    \    mkdir -p src; \    tar -xf httpd.tar.bz2 -C src --strip-components=1; \    rm httpd.tar.bz2; \    cd src; \    \    patches() { \        while [ "$#" -gt 0 ]; do \            local patchFile="$1"; shift; \            local patchSha256="$1"; shift; \            ddist "$patchFile" "httpd/patches/apply_to_$HTTPD_VERSION/$patchFile"; \            echo "$patchSha256 *$patchFile" | sha256sum -c -; \            patch -p0 < "$patchFile"; \            rm -f "$patchFile"; \        done; \    }; \    patches $HTTPD_PATCHES; \    \    gnuArch="$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)"; \    ./configure \        --build="$gnuArch" \        --prefix="$HTTPD_PREFIX" \        --enable-mods-shared=reallyall \        --enable-mpms-shared=all \# PIE and hardening flags are unnecessary as Alpine enables them automatically (https://alpinelinux.org/about/)    ; \    make -j "$(nproc)"; \    make install; \    \    cd ..; \    rm -r src man manual; \    \    sed -ri \        -e 's!^(\s*CustomLog)\s+\S+!\1 /proc/self/fd/1!g' \        -e 's!^(\s*ErrorLog)\s+\S+!\1 /proc/self/fd/2!g' \        -e 's!^(\s*TransferLog)\s+\S+!\1 /proc/self/fd/1!g' \        "$HTTPD_PREFIX/conf/httpd.conf" \        "$HTTPD_PREFIX/conf/extra/httpd-ssl.conf" \    ; \    \    runDeps="$runDeps $( \        scanelf --needed --nobanner --format '%n#p' --recursive /usr/local \            | tr ',' '\n' \            | sort -u \            | awk 'system("[ -e /usr/local/lib/" $1 " ]") == 0 { next } { print "so:" $1 }' \    )"; \    apk add --no-network --virtual .httpd-rundeps $runDeps; \    apk del --no-network .build-deps; \    \# smoke test    httpd -v# https://httpd.apache.org/docs/2.4/stopping.html#gracefulstopSTOPSIGNAL SIGWINCHCOPY httpd-foreground /usr/local/bin/EXPOSE 80CMD ["httpd-foreground"]</code></pre>]]></content>
      
      
      <categories>
          
          <category> container </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker_001</title>
      <link href="2019/11/17/container/dockerfilee-001/"/>
      <url>2019/11/17/container/dockerfilee-001/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h4 id="Docker-MySQL-5-7"><a href="#Docker-MySQL-5-7" class="headerlink" title="Docker_MySQL 5.7"></a>Docker_MySQL 5.7</h4><pre class=" language-dockerfile"><code class="language-dockerfile">FROM debian:buster-slim# add our user and group first to make sure their IDs get assigned consistently, regardless of whatever dependencies get addedRUN groupadd -r mysql && useradd -r -g mysql mysqlRUN apt-get update && apt-get install -y --no-install-recommends gnupg dirmngr && rm -rf /var/lib/apt/lists/*# add gosu for easy step-down from rootENV GOSU_VERSION 1.7RUN set -x \    && apt-get update && apt-get install -y --no-install-recommends ca-certificates wget && rm -rf /var/lib/apt/lists/* \    && wget -O /usr/local/bin/gosu "https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$(dpkg --print-architecture)" \    && wget -O /usr/local/bin/gosu.asc "https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$(dpkg --print-architecture).asc" \    && export GNUPGHOME="$(mktemp -d)" \    && gpg --batch --keyserver ha.pool.sks-keyservers.net --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4 \    && gpg --batch --verify /usr/local/bin/gosu.asc /usr/local/bin/gosu \    && gpgconf --kill all \    && rm -rf "$GNUPGHOME" /usr/local/bin/gosu.asc \    && chmod +x /usr/local/bin/gosu \    && gosu nobody true \    && apt-get purge -y --auto-remove ca-certificates wgetRUN mkdir /docker-entrypoint-initdb.dRUN apt-get update && apt-get install -y --no-install-recommends \# for MYSQL_RANDOM_ROOT_PASSWORD        pwgen \# for mysql_ssl_rsa_setup        openssl \# FATAL ERROR: please install the following Perl modules before executing /usr/local/mysql/scripts/mysql_install_db:# File::Basename# File::Copy# Sys::Hostname# Data::Dumper        perl \# install "xz-utils" for .sql.xz docker-entrypoint-initdb.d files        xz-utils \    && rm -rf /var/lib/apt/lists/*RUN set -ex; \# gpg: key 5072E1F5: public key "MySQL Release Engineering <mysql-build@oss.oracle.com>" imported    key='A4A9406876FCBD3C456770C88C718D3B5072E1F5'; \    export GNUPGHOME="$(mktemp -d)"; \    gpg --batch --keyserver ha.pool.sks-keyservers.net --recv-keys "$key"; \    gpg --batch --export "$key" > /etc/apt/trusted.gpg.d/mysql.gpg; \    gpgconf --kill all; \    rm -rf "$GNUPGHOME"; \    apt-key list > /dev/nullENV MYSQL_MAJOR 5.7ENV MYSQL_VERSION 5.7.29-1debian10RUN echo "deb http://repo.mysql.com/apt/debian/ buster mysql-${MYSQL_MAJOR}" > /etc/apt/sources.list.d/mysql.list# the "/var/lib/mysql" stuff here is because the mysql-server postinst doesn't have an explicit way to disable the mysql_install_db codepath besides having a database already "configured" (ie, stuff in /var/lib/mysql/mysql)# also, we set debconf keys to make APT a little quieterRUN { \        echo mysql-community-server mysql-community-server/data-dir select ''; \        echo mysql-community-server mysql-community-server/root-pass password ''; \        echo mysql-community-server mysql-community-server/re-root-pass password ''; \        echo mysql-community-server mysql-community-server/remove-test-db select false; \    } | debconf-set-selections \    && apt-get update && apt-get install -y mysql-server="${MYSQL_VERSION}" && rm -rf /var/lib/apt/lists/* \    && rm -rf /var/lib/mysql && mkdir -p /var/lib/mysql /var/run/mysqld \    && chown -R mysql:mysql /var/lib/mysql /var/run/mysqld \# ensure that /var/run/mysqld (used for socket and lock files) is writable regardless of the UID our mysqld instance ends up having at runtime    && chmod 777 /var/run/mysqld \# comment out a few problematic configuration values    && find /etc/mysql/ -name '*.cnf' -print0 \        | xargs -0 grep -lZE '^(bind-address|log)' \        | xargs -rt -0 sed -Ei 's/^(bind-address|log)/#&/' \# don't reverse lookup hostnames, they are usually another container    && echo '[mysqld]\nskip-host-cache\nskip-name-resolve' > /etc/mysql/conf.d/docker.cnfVOLUME /var/lib/mysqlCOPY docker-entrypoint.sh /usr/local/bin/RUN ln -s usr/local/bin/docker-entrypoint.sh /entrypoint.sh # backwards compatENTRYPOINT ["docker-entrypoint.sh"]EXPOSE 3306 33060CMD ["mysqld"]</code></pre><h4 id="Docker-NGINX-1-17-9"><a href="#Docker-NGINX-1-17-9" class="headerlink" title="Docker_NGINX_1.17.9"></a>Docker_NGINX_1.17.9</h4><pre class=" language-dockerfile"><code class="language-dockerfile">FROM alpine:3.10LABEL maintainer="NGINX Docker Maintainers <docker-maint@nginx.com>"ENV NGINX_VERSION 1.17.9ENV NJS_VERSION   0.3.9ENV PKG_RELEASE   1RUN set -x \# create nginx user/group first, to be consistent throughout docker variants    && addgroup -g 101 -S nginx \    && adduser -S -D -H -u 101 -h /var/cache/nginx -s /sbin/nologin -G nginx -g nginx nginx \    && apkArch="$(cat /etc/apk/arch)" \    && nginxPackages=" \        nginx=${NGINX_VERSION}-r${PKG_RELEASE} \        nginx-module-xslt=${NGINX_VERSION}-r${PKG_RELEASE} \        nginx-module-geoip=${NGINX_VERSION}-r${PKG_RELEASE} \        nginx-module-image-filter=${NGINX_VERSION}-r${PKG_RELEASE} \        nginx-module-njs=${NGINX_VERSION}.${NJS_VERSION}-r${PKG_RELEASE} \    " \    && case "$apkArch" in \        x86_64) \# arches officially built by upstream            set -x \            && KEY_SHA512="e7fa8303923d9b95db37a77ad46c68fd4755ff935d0a534d26eba83de193c76166c68bfe7f65471bf8881004ef4aa6df3e34689c305662750c0172fca5d8552a *stdin" \            && apk add --no-cache --virtual .cert-deps \                openssl \            && wget -O /tmp/nginx_signing.rsa.pub https://nginx.org/keys/nginx_signing.rsa.pub \            && if [ "$(openssl rsa -pubin -in /tmp/nginx_signing.rsa.pub -text -noout | openssl sha512 -r)" = "$KEY_SHA512" ]; then \                echo "key verification succeeded!"; \                mv /tmp/nginx_signing.rsa.pub /etc/apk/keys/; \            else \                echo "key verification failed!"; \                exit 1; \            fi \            && apk del .cert-deps \            && apk add -X "https://nginx.org/packages/mainline/alpine/v$(egrep -o '^[0-9]+\.[0-9]+' /etc/alpine-release)/main" --no-cache $nginxPackages \            ;; \        *) \# we're on an architecture upstream doesn't officially build for# let's build binaries from the published packaging sources            set -x \            && tempDir="$(mktemp -d)" \            && chown nobody:nobody $tempDir \            && apk add --no-cache --virtual .build-deps \                gcc \                libc-dev \                make \                openssl-dev \                pcre-dev \                zlib-dev \                linux-headers \                libxslt-dev \                gd-dev \                geoip-dev \                perl-dev \                libedit-dev \                mercurial \                bash \                alpine-sdk \                findutils \            && su nobody -s /bin/sh -c " \                export HOME=${tempDir} \                && cd ${tempDir} \                && hg clone https://hg.nginx.org/pkg-oss \                && cd pkg-oss \                && hg up ${NGINX_VERSION}-${PKG_RELEASE} \                && cd alpine \                && make all \                && apk index -o ${tempDir}/packages/alpine/${apkArch}/APKINDEX.tar.gz ${tempDir}/packages/alpine/${apkArch}/*.apk \                && abuild-sign -k ${tempDir}/.abuild/abuild-key.rsa ${tempDir}/packages/alpine/${apkArch}/APKINDEX.tar.gz \                " \            && cp ${tempDir}/.abuild/abuild-key.rsa.pub /etc/apk/keys/ \            && apk del .build-deps \            && apk add -X ${tempDir}/packages/alpine/ --no-cache $nginxPackages \            ;; \    esac \# if we have leftovers from building, let's purge them (including extra, unnecessary build deps)    && if [ -n "$tempDir" ]; then rm -rf "$tempDir"; fi \    && if [ -n "/etc/apk/keys/abuild-key.rsa.pub" ]; then rm -f /etc/apk/keys/abuild-key.rsa.pub; fi \    && if [ -n "/etc/apk/keys/nginx_signing.rsa.pub" ]; then rm -f /etc/apk/keys/nginx_signing.rsa.pub; fi \# Bring in gettext so we can get `envsubst`, then throw# the rest away. To do this, we need to install `gettext`# then move `envsubst` out of the way so `gettext` can# be deleted completely, then move `envsubst` back.    && apk add --no-cache --virtual .gettext gettext \    && mv /usr/bin/envsubst /tmp/ \    \    && runDeps="$( \        scanelf --needed --nobanner /tmp/envsubst \            | awk '{ gsub(/,/, "\nso:", $2); print "so:" $2 }' \            | sort -u \            | xargs -r apk info --installed \            | sort -u \    )" \    && apk add --no-cache $runDeps \    && apk del .gettext \    && mv /tmp/envsubst /usr/local/bin/ \# Bring in tzdata so users could set the timezones through the environment# variables    && apk add --no-cache tzdata \# forward request and error logs to docker log collector    && ln -sf /dev/stdout /var/log/nginx/access.log \    && ln -sf /dev/stderr /var/log/nginx/error.logEXPOSE 80STOPSIGNAL SIGTERMCMD ["nginx", "-g", "daemon off;"]</code></pre>]]></content>
      
      
      <categories>
          
          <category> container </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker_000</title>
      <link href="2019/11/15/container/dockerfilee-000/"/>
      <url>2019/11/15/container/dockerfilee-000/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h4 id="Dockerfile构建镜像"><a href="#Dockerfile构建镜像" class="headerlink" title="Dockerfile构建镜像"></a>Dockerfile构建镜像</h4><pre><code>通过Dockerfile创建镜像虽然可以自己制作 rootfs(见&#39;容器文件系统那些事儿&#39;)，但Docker 提供了一种更便捷的方式，叫作 Dockerfiledocker build命令用于根据给定的Dockerfile和上下文以构建Docker镜像。docker build语法：# docker build [OPTIONS] &lt;PATH | URL | -&gt;1. 常用选项说明--build-arg，设置构建时的变量--no-cache，默认false。设置该选项，将不使用Build Cache构建镜像--pull，默认false。设置该选项，总是尝试pull镜像的最新版本--compress，默认false。设置该选项，将使用gzip压缩构建的上下文--disable-content-trust，默认true。设置该选项，将对镜像进行验证--file, -f，Dockerfile的完整路径，默认值为‘PATH/Dockerfile’--isolation，默认--isolation=&quot;default&quot;，即Linux命名空间；其他还有process或hyperv--label，为生成的镜像设置metadata--squash，默认false。设置该选项，将新构建出的多个层压缩为一个新层，但是将无法在多个镜像之间共享新层；设置该选项，实际上是创建了新image，同时保留原有image。--tag, -t，镜像的名字及tag，通常name:tag或者name格式；可以在一次构建中为一个镜像设置多个tag--network，默认default。设置该选项，Set the networking mode for the RUN instructions during build--quiet, -q ，默认false。设置该选项，Suppress the build output and print image ID on success--force-rm，默认false。设置该选项，总是删除掉中间环节的容器--rm，默认--rm=true，即整个构建过程成功后删除中间环节的容器2. PATH | URL | -说明：给出命令执行的上下文。上下文可以是构建执行所在的本地路径，也可以是远程URL，如Git库、tarball或文本文件等。如果是Git库，如https://github.com/docker/rootfs.git#container:docker，则隐含先执行git clone --depth 1 --recursive，到本地临时目录；然后再将该临时目录发送给构建进程。构建镜像的进程中，可以通过ADD命令将上下文中的任何文件（注意文件必须在上下文中）加入到镜像中。-表示通过STDIN给出Dockerfile或上下文。示例：    docker build - &lt; Dockerfile说明：该构建过程只有Dockerfile，没有上下文    docker build - &lt; context.tar.gz说明：其中Dockerfile位于context.tar.gz的根路径    docker build -t champagne/bbauto:latest -t champagne/bbauto:v2.1 .    docker build -f dockerfiles/Dockerfile.debug -t myapp_debug .2.1、 创建镜像所在的文件夹和Dockerfile文件           命令：          1、mkdir sinatra          2、cd sinatra          3、touch Dockerfile 2.2、 在Dockerfile文件中写入指令，每一条指令都会更新镜像的信息例如：          # This is a comment          FROM ubuntu:14.04          MAINTAINER tiger tiger@localhost.localdomain         RUN apt-get update &amp;&amp; apt-get install -y ruby ruby-dev          RUN gem install sinatra           格式说明：           每行命令都是以  INSTRUCTION statement 形式，就是命令+ 清单的模式。命令要大写，&quot;#&quot;是注解。          FROM 命令是告诉docker 我们的镜像什么。          MAINTAINER 是描述 镜像的创建人。          RUN 命令是在镜像内部执行。就是说他后面的命令应该是针对镜像可以运行的命令。  2.3、创建镜像           命令：docker build -t tiger/sinatra:v2 .          docker build  是docker创建镜像的命令          -t 是标识新建的镜像属于 ouruser的           sinatra是仓库的名称          ：v2 是tag           &quot;.&quot;是用来指明 我们的使用的Dockerfile文件当前目录的          详细执行过程：        [root@master sinatra]# docker build -t tiger/sinatra:v2 .         Sending build context to Docker daemon 2.048 kB        Step 1 : FROM daocloud.io/ubuntu:14.04        Trying to pull repository daocloud.io/ubuntu ...         14.04: Pulling from daocloud.io/ubuntu        f3ead5e8856b: Pull complete         Digest: sha256:ea2b82924b078d9c8b5d3f0db585297a5cd5b9c2f7b60258cdbf9d3b9181d828         ---&gt; 2ff3b426bbaa        Step 2 : MAINTAINER tiger tiger@localhost.localdomain         ---&gt; Running in 948396c9edaa         ---&gt; 227da301bad8        Removing intermediate container 948396c9edaa        Step 3 : RUN apt-get update &amp;&amp; apt-get install -y ruby ruby-dev         ...        Step 4 : RUN gem install sinatra        ---&gt; Running in 89234cb493d9 2.4、创建完成后，从镜像创建容器          #docker run -t -i tiger/sinatra:v2 /bin/bash</code></pre><p>Dockerfile分为四个部分: 基础镜像信息、维护者信息、镜像操作指令和容器启动指令。 即FROM、MAINTAINER、RUN、CMD四个部分</p><h5 id="指令说明"><a href="#指令说明" class="headerlink" title="指令说明"></a>指令说明</h5><pre><code>FROM         指定所创建镜像的基础镜像MAINTAINER   制定维护者信息RUN          运行命令CMD          容器启动是默认执行的命令LABEL        指定生成镜像的元数据标签信息EXPOSE       声明镜像内服务所监听的端口ENV          指定环境变量ADD          复制指定src路径的内容到容器的dest路径下，如果src为tar文件，则自动解压到dest路径下copy         复制指定src路径的内容到镜像的dest路径下ENTERPOINT   指定镜像的默认入口VOLUME       创建数据卷挂载点USER         指定运行容器是的用户名或UIDWORKDIR      配置工作目录ARG          指定镜像内使用的参数ONBUILD      配置当所创建的镜像作为其他镜像的基础镜像时，所执行创建操作指令STOPSIGAL    容器退出信号值HEALTHCHECK  如何进行健康检查SHELL        指定使用shell的默认shell类型</code></pre><h5 id="nginx-dockerfile示例"><a href="#nginx-dockerfile示例" class="headerlink" title="nginx-dockerfile示例"></a>nginx-dockerfile示例</h5><p>vim Dockerfile</p><pre><code>FROM centos:7.2.1511ENV TZ=Asia/ShanghaiRUN yum -y install epel* \    yum -y install gcc openssl openssl-devel  pcre-devel zlib-develADD nginx-1.14.2.tar.gz /opt/WORKDIR /opt/nginx-1.14.2RUN ./configure --prefix=/opt/nginx  --http-log-path=/opt/nginx/logs/access.log --error-log-path=/opt/nginx/logs/error.log --http-client-body-temp-path=/opt/nginx/client/  --http-proxy-temp-path=/opt/nginx/proxy/  --with-http_stub_status_module --with-file-aio --with-http_flv_module --with-http_gzip_static_module --with-stream --with-threads --user=www --group=wwwRUN make &amp;&amp; make installRUN groupadd www &amp;&amp; useradd -g www wwwWORKDIR /opt/nginxRUN rm -rf /opt/nginx-1.14.2ENV NGINX_HOME=/opt/nginxENV PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/nginx/sbinEXPOSE 80 443CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]</code></pre><p>需要先下载nginx-1.14.2.tar.gz在Dockerfile同级目录下，然后执行如下命令 docker build -t nginx_image ./Dockerfile</p><h5 id="tomcat-dockerfile示例"><a href="#tomcat-dockerfile示例" class="headerlink" title="tomcat-dockerfile示例"></a>tomcat-dockerfile示例</h5><pre><code>FROM centos:7.4.1708ADD jdk-8u171-linux-x64.tar.gz /usr/local/ADD apache-tomcat-7.0.88.tar.gz /usr/local/WORKDIR /usr/local/RUN mv jdk1.8.0_171 jdk &amp;&amp; mv apache-tomcat-7.0.88 tomcatENV JAVA_HOME=/usr/local/jdkENV CLASS_PATH=$JAVA_HOME/lib:$JAVA_HOME/jre/libENV PATH=$JAVA_HOME/bin:$PATHENV CATALINA_HOME /usr/local/tomcatEXPOSE 8080CMD /usr/local/tomcat/bin/catalina.sh run</code></pre><p>需要先下载jdk和tomcat在dockerfile的同级目录下，然后执行如下命令 docker build -t tomcat_image ./Dockerfile</p><h4 id="容器网络"><a href="#容器网络" class="headerlink" title="容器网络"></a>容器网络</h4><p><img src="https://i.loli.net/2019/06/10/5cfe19e2a618834176.jpg" alt=""></p><pre><code>小规模docker环境大部分运行在单台主机上，如果公司大规模采用docker，那么多个宿主机上的docker如何互联Docker默认的内部ip为172.17.42.0网段，所以必须要修改其中一台的默认网段以免ip冲突。#vim /etc/sysconfig/docker-networkDOCKER_NETWORK_OPTIONS= --bip=172.18.42.1/16#rebootdocker 130上：#route add -net 172.18.0.0/16 gw 192.168.18.128docker 128上：#route add -net 172.17.0.0/16 gw 192.168.18.130现在两台宿主机里的容器就可以通信了。</code></pre><h4 id="容器固定IP"><a href="#容器固定IP" class="headerlink" title="容器固定IP"></a>容器固定IP</h4><pre><code>docker安装后，默认会创建三种网络类型，bridge、host和none显示当前网络：# docker network listNETWORK ID            NAME                DRIVER              SCOPE90b22f633d2f          bridge              bridge              locale0b365da7fd2          host                host                localda7b7a090837         none                null                localbridge:网络桥接默认情况下启动、创建容器都是用该模式，所以每次docker容器重启时会按照顺序获取对应ip地址，这就导致容器每次重启，ip都发生变化none：无指定网络启动容器时，可以通过–network=none,docker容器不会分配局域网iphost：主机网络docker容器的网络会附属在主机上，两者是互通的。创建固定ip容器1、创建自定义网络类型，并且指定网段#docker network create --subnet=192.168.0.0/16 staticnet通过docker network ls可以查看到网络类型中多了一个staticnet2、使用新的网络类型创建并启动容器#docker run -it --name userserver --net staticnet --ip 192.168.0.2 centos:6 /bin/bash通过docker inspect可以查看容器ip为192.168.0.2，关闭容器并重启，发现容器ip并未发生改变</code></pre>]]></content>
      
      
      <categories>
          
          <category> container </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>zabbix-微信报警设置</title>
      <link href="2019/11/05/monitor/zabbix-pei-zhi-qi-ye-wei-xin-bao-jing/"/>
      <url>2019/11/05/monitor/zabbix-pei-zhi-qi-ye-wei-xin-bao-jing/</url>
      
        <content type="html"><![CDATA[<h2 id="zabbix-微信报警设置"><a href="#zabbix-微信报警设置" class="headerlink" title="zabbix 微信报警设置"></a>zabbix 微信报警设置</h2><h4 id="一、主要获取三个参数-企业ID、用户账号、AgentId-和Secret："><a href="#一、主要获取三个参数-企业ID、用户账号、AgentId-和Secret：" class="headerlink" title="一、主要获取三个参数:企业ID、用户账号、AgentId,和Secret："></a>一、主要获取三个参数:企业ID、用户账号、AgentId,和Secret：</h4><h5 id="1-获取企业ID"><a href="#1-获取企业ID" class="headerlink" title="1.获取企业ID"></a>1.获取企业ID</h5><p><img src="https://s1.ax1x.com/2020/04/24/J0OeUI.png" alt="J0OeUI.png"></p><h5 id="2-获取AgentId-和Secret3"><a href="#2-获取AgentId-和Secret3" class="headerlink" title="2.获取AgentId,和Secret3"></a>2.获取AgentId,和Secret3</h5><p>这里要先点通讯录创建一个部门，然后再点应用小程序创建应用，填写logo、名称、和选择部门就可以了</p><p><a href="https://imgchr.com/i/J0Om5t" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/04/24/J0Om5t.png" alt="J0Om5t.png"></a></p><h5 id="3-获取用户账号"><a href="#3-获取用户账号" class="headerlink" title="3.获取用户账号"></a>3.获取用户账号</h5><p><img src="https://s1.ax1x.com/2020/04/24/J0OYan.png" alt="J0OYan.png"></p><p><img src="https://s1.ax1x.com/2020/04/24/J0OaGV.png" alt="J0OaGV.png"></p><h5 id="4-测试gentId-和Secret"><a href="#4-测试gentId-和Secret" class="headerlink" title="4.测试gentId,和Secret"></a>4.测试gentId,和Secret</h5><p>这个是接口调用测试gentId,和Secret的地址：<a href="https://work.weixin.qq.com/api/devtools/devtool.php" target="_blank" rel="noopener">https://work.weixin.qq.com/api/devtools/devtool.php</a></p><p>这里看到有HTTP/1.1 200 OK 就说明接口有效了，其它的不管。</p><p><img src="https://s1.ax1x.com/2020/04/24/J0OyZ9.png" alt="J0OyZ9.png"></p><p><img src="https://s1.ax1x.com/2020/04/24/J0O2Px.png" alt="J0O2Px.png"></p><h4 id="二、调用的shell脚本方式，脚本如下："><a href="#二、调用的shell脚本方式，脚本如下：" class="headerlink" title="二、调用的shell脚本方式，脚本如下："></a>二、调用的shell脚本方式，脚本如下：</h4><h6 id="这里要注意的是填写正确的通讯录-部门ID，可以点那个下线三个点那里。"><a href="#这里要注意的是填写正确的通讯录-部门ID，可以点那个下线三个点那里。" class="headerlink" title="这里要注意的是填写正确的通讯录 部门ID，可以点那个下线三个点那里。"></a>这里要注意的是填写正确的通讯录 部门ID，可以点那个下线三个点那里。</h6><p><img src="https://s1.ax1x.com/2020/04/24/J0O7dA.png" alt="J0O7dA.png"></p><pre class=" language-shell"><code class="language-shell">[root@cyy alertscripts]# vim wechat.sh#!/usr/bin/env bash#!/usr/bin/env bash## Author: cyylog# Email: cyylog@aliyun.com# Date: 2019/09/25# Github:    https://github.com/cyylog# Usage:    Wechat alert script for zabbix# if [ $# -eq 0 ] || [[ "$1" == "-h" || "$1" == "--help" ]];then        echo "Usage of $0:"        echo -e " --CorpID=string"        echo -e " --Secret=string"        echo -e " --AgentID=string"        echo -e " --UserID=string"        echo -e " --Msg=string"        exitfi#ops=(-c -s -a -u)#args=(CorpID Secret AgentID UserID)#while [ $# -gt 0 ];do#    [ "$1" == "-m" ] && Msg="$2" && shift 2#    for i in {0..3};do#        [ "$1" == "${ops[i]}" ] &&  eval ${args[i]}="$2"#    done#    shift 2#donefor i in "$@";do        echo $i|grep Msg &> /dev/null && msg=$(echo $i|sed 's/.*=//') && Msg="$msg" && continue        eval "$(echo $i|sed 's/--//')"done#echo $CorpID#echo $Secret#echo $UserID#echo $AgentID#echo $Msg#GURL="https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=$CorpID&corpsecret=$Secret"Token=$(/usr/bin/curl -s -G $GURL |awk -F \" '{print $10}')PURL="https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=$Token"Info(){        printf '{\n'        printf '\t"touser": "'"$UserID"\"",\n"        printf '\t"msgtype": "text",\n'        printf '\t"agentid": "'"$AgentID"\"",\n"        printf '\t"text": {\n'        printf '\t\t"content": "'"$Msg"\""\n"        printf '\t},\n'        printf '\t"safe":"0"\n'        printf '}\n'}/usr/bin/curl --data-ascii "$(Info)" $PURLecho[root@cyy alertscripts]# chmod +x wechat.sh[root@cyy alertscripts]# ./wechat.sh  "这里一个测试"     //可以这样直接调试，然后登陆到企业微信查看该部门的群成员是否收到此信息脚本测试通过后就是在zabbix控制台上设置了</code></pre><h4 id="三、zabbix-控制台添加新媒体"><a href="#三、zabbix-控制台添加新媒体" class="headerlink" title="三、zabbix 控制台添加新媒体"></a>三、zabbix 控制台添加新媒体</h4><h5 id="1-点管理-gt-报警媒介类型-gt-创建媒介类型"><a href="#1-点管理-gt-报警媒介类型-gt-创建媒介类型" class="headerlink" title="1.点管理 -&gt; 报警媒介类型 -&gt; 创建媒介类型"></a>1.点管理 -&gt; 报警媒介类型 -&gt; 创建媒介类型</h5><p><a href="https://imgchr.com/i/J0X1W6" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/04/24/J0X1W6.png" alt="J0X1W6.png"></a></p><pre class=" language-shell"><code class="language-shell">--AgentID=1000002--CorpID=ww74c********56c    --Secret=-c-3Xw*****************j-Zj6cw--Msg={ALERT.MESSAGE}--UserID={ALERT.SENDTO}</code></pre><h5 id="2-然后再设置上用户：点管理-—-gt-创建用户（微信报警的用户）"><a href="#2-然后再设置上用户：点管理-—-gt-创建用户（微信报警的用户）" class="headerlink" title="2.然后再设置上用户：点管理 —&gt; 创建用户（微信报警的用户）"></a>2.然后再设置上用户：点管理 —&gt; 创建用户（微信报警的用户）</h5><p><img src="https://s1.ax1x.com/2020/04/24/J0XYOe.png" alt="J0XYOe.png"></p><h5 id="3-再点用户旁边的-报警媒介-进行设置（收件人要填写用户的账号）"><a href="#3-再点用户旁边的-报警媒介-进行设置（收件人要填写用户的账号）" class="headerlink" title="3.再点用户旁边的 报警媒介 进行设置（收件人要填写用户的账号）"></a>3.再点用户旁边的 报警媒介 进行设置（收件人要填写用户的账号）</h5><p><strong>第一步的第3点获取的账号</strong></p><p><img src="https://s1.ax1x.com/2020/04/24/J0XaTA.png" alt="J0XaTA.png"></p><h6 id="到这里就基本都设置完成了，可以设置个触发器和动作来测试脚本。"><a href="#到这里就基本都设置完成了，可以设置个触发器和动作来测试脚本。" class="headerlink" title="到这里就基本都设置完成了，可以设置个触发器和动作来测试脚本。"></a>到这里就基本都设置完成了，可以设置个触发器和动作来测试脚本。</h6>]]></content>
      
      
      <categories>
          
          <category> monitor </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zabbix </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nexus3 搭建 maven</title>
      <link href="2019/10/09/devops/centos7-shi-yong-nexus3-da-jian-maven-si-fu/"/>
      <url>2019/10/09/devops/centos7-shi-yong-nexus3-da-jian-maven-si-fu/</url>
      
        <content type="html"><![CDATA[<h2 id="CentOS7-使用-Nexus3-搭建-maven-私服"><a href="#CentOS7-使用-Nexus3-搭建-maven-私服" class="headerlink" title="CentOS7 使用 Nexus3 搭建 maven 私服"></a>CentOS7 使用 Nexus3 搭建 maven 私服</h2><h3 id="1、Nexus3-简介"><a href="#1、Nexus3-简介" class="headerlink" title="1、Nexus3 简介"></a>1、Nexus3 简介</h3><p>　　Maven是一个采用纯Java编写的开源项目管理工具, Maven采用了一种被称之为Project Object Model(POM)概念来管理项目，所有的项目配置信息都被定义在一个叫做POM.xml的文件中, 通过该文件Maven可以管理项目的整个生命周期，包括清除、编译，测试，报告、打包、部署等等。目前Apache下绝大多数项目都已经采用Maven进行管理. 而Maven本身还支持多种插件, 可以方便更灵活的控制项目, 开发人员的主要任务应该是关注商业逻辑并去实现它, 而不是把时间浪费在学习如何在不同的环境中去依赖jar包,项目部署等。<br>maven和ant都是软件构建工具（软件管理工具),maven比ant更加强大，已经取代了ant,jar包的声明式依赖描述。maven有jar包的仓库。svn是一个软件的版本控制工具，是一个协同开发工具。svn的仓库存放的是项目的源码，历史版本的备份，声明每次版本的修改情况。</p><p>　　私服是架设在局域网的一种特殊的远程仓库，目的是代理远程仓库及部署第三方构件。有了私服之后，当 Maven 需要下载构件时，直接请求私服，私服上存在则下载到本地仓库；否则，私服请求外部的远程仓库，将构件下载到私服，再提供给本地仓库下载。</p><p>　　<a href="https://imgtu.com/i/ggFZKs" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/16/ggFZKs.png" alt="ggFZKs.png"></a></p><p><strong>需求：</strong></p><p>公司没有maven私服，需要用用手动打jar包的方式添加依赖很不友好，所以需要搭建 Nexus3 私服。</p><h3 id="2、搭建-maven-私服"><a href="#2、搭建-maven-私服" class="headerlink" title="2、搭建 maven 私服"></a>2、搭建 maven 私服</h3><p>1.下载maven压缩包  apache-maven-3.5.4-bin.tar.gz ,然后解压  tar -zxf apache-maven-3.5.4-bin.tar.gz</p><p>2.添加环境变量</p><pre><code>vi /etc/profile</code></pre><p>在文件下方添加如下内容（这里的MAVEN_HOME需要改为你自己的maven解压目录）：</p><pre><code>export JAVA_HOME=&quot;/opt/jdk1.8&quot;export MAVEN_HOME=&quot;/opt/apache-maven-3.5.4&quot;export PATH=&quot;$JAVA_HOME/bin:$MAVEN_HOME/bin:$PATH&quot;</code></pre><p>然后保存退出。</p><p>3.输入命令 mvn version 看到如下内容说明安装成功了。</p><p><a href="https://imgtu.com/i/ggFKaV" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/16/ggFKaV.png" alt="ggFKaV.png"></a></p><h3 id="3、部署-nexus3"><a href="#3、部署-nexus3" class="headerlink" title="3、部署 nexus3"></a>3、部署 nexus3</h3><h4 id="1、下载"><a href="#1、下载" class="headerlink" title="1、下载"></a>1、下载</h4><p>由于专业版的nexus是收费的，所以我下载的是开源版 Nexus OSS,下载地址为 <a href="https://www.sonatype.com/download-oss-sonatype" target="_blank" rel="noopener">https://www.sonatype.com/download-oss-sonatype</a></p><p><a href="https://imgtu.com/i/ggFM5T" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/16/ggFM5T.png" alt="ggFM5T.png"></a></p><p>点击红框区域即可下载得到文件nexus-3.13.0-01-unix.tar.gz，然后上传到服务器目录下，我的是/opt目录。</p><h4 id="2、解压"><a href="#2、解压" class="headerlink" title="2、解压"></a>2、解压</h4><pre><code>cd /opttar -zxf nexus-3.13.0-01-unix.tar.gz</code></pre><p>解压后会多出两个目录，nexus-3.13.0-01和sonatype-work。</p><h4 id="3、启动"><a href="#3、启动" class="headerlink" title="3、启动"></a>3、启动</h4><pre><code>1 cd nexus-3.13.0-01/bin/2 ./nexus start</code></pre><p><a href="https://imgtu.com/i/ggFlPU" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/16/ggFlPU.png" alt="ggFlPU.png"></a></p><p>看到如图所示内容表明我们已经启动成功了，游览器输入<a href="http://localhost:8081即可访问。">http://localhost:8081即可访问。</a></p><p><strong>注意：</strong></p><p>1.Nexus3开始访问URL已经变了，以前是<a href="http://localhost:8081/nexus，这个坑了我好一会儿。" target="_blank" rel="noopener">http://localhost:8081/nexus，这个坑了我好一会儿。</a></p><p>2.启动后如果你立即访问可能发现什么都没有，不要急这个启动需要一定时间，30秒后到1分钟后再尝试访问，这个开始我以为出问题了。</p><p><a href="https://imgtu.com/i/ggFYrR" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/16/ggFYrR.png" alt="ggFYrR.png"></a>点击右上角的sign in登录，输入账户admin，密码admin123即可登录成功。</p><h4 id="4、仓库介绍"><a href="#4、仓库介绍" class="headerlink" title="4、仓库介绍"></a>4、仓库介绍</h4><p><a href="https://imgtu.com/i/ggFdIK" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/16/ggFdIK.png" alt="ggFdIK.png"></a></p><p>按图中标识顺序点击，就可以看到有这些仓库，现在分别介绍它们，分为三种类型：</p><p><strong>proxy</strong>：是远程仓库的代理。比如说在nexus中配置了一个central repository的proxy，当用户向这个proxy请求一个artifact，这个proxy就会先在本地查找，如果找不到的话，就会从远程仓库下载，然后返回给用户，相当于起到一个中转的作用。　　　　</p><p><strong>Hosted</strong>：是宿主仓库，用户可以把自己的一些构件，deploy到hosted中，也可以手工上传构件到hosted里。比如说oracle的驱动程序，ojdbc6.jar，在central repository是获取不到的，就需要手工上传到hosted里，一般用来存放公司自己的jar包；<br><strong>Group</strong>：是仓库组，在maven里没有这个概念，是nexus特有的。目的是将上述多个仓库聚合，对用户暴露统一的地址，这样用户就不需要在pom中配置多个地址，只要统一配置group的地址就可以了右边那个Repository Path可以点击进去，看到仓库中artifact列表。不过要注意浏览器缓存，<strong>当你的项目希望在多个repository使用资源时就不需要多次引用了，只需要引用一个group即可</strong>。</p><p><strong>maven-public：</strong>maven-central、maven-release和maven-snapshot三个库的合集。</p><p><strong>maven-release：</strong>用来存放release版本的jar包。</p><p><strong>maven-snapshot：</strong>用来存放snapshot版本的jar包。</p><h3 id="4、上传jar包到maven私服"><a href="#4、上传jar包到maven私服" class="headerlink" title="4、上传jar包到maven私服"></a>4、上传jar包到maven私服</h3><h3 id="1、添加仓库认证"><a href="#1、添加仓库认证" class="headerlink" title="1、添加仓库认证"></a>1、添加仓库认证</h3><p>找到本地电脑的setting.xml，打开后找到servers节点，在里面添加如下内容。</p><pre><code>&lt;server&gt;        &lt;id&gt;releases&lt;/id&gt;        &lt;username&gt;admin&lt;/username&gt;        &lt;password&gt;admin123&lt;/password&gt;    &lt;/server&gt;    &lt;server&gt;        &lt;id&gt;snapshots&lt;/id&gt;        &lt;username&gt;admin&lt;/username&gt;        &lt;password&gt;admin123&lt;/password&gt;    &lt;/server&gt;</code></pre><h3 id="4-2在项目的pom-xml添加远程发布的私服仓库地址"><a href="#4-2在项目的pom-xml添加远程发布的私服仓库地址" class="headerlink" title="4.2在项目的pom.xml添加远程发布的私服仓库地址"></a><strong>4.2在项目的pom.xml添加远程发布的私服仓库地址</strong></h3><pre><code> 1     &lt;distributionManagement&gt; 2         &lt;repository&gt; 3             &lt;!--此id要与setting.xml里面server的id对应--&gt; 4             &lt;id&gt;releases&lt;/id&gt; 5             &lt;name&gt;releases Repository&lt;/name&gt; 6             &lt;url&gt;http://192.168.75.132:8081/repository/maven-releases/&lt;/url&gt; 7         &lt;/repository&gt; 8         &lt;snapshotRepository&gt; 9             &lt;id&gt;snapshots&lt;/id&gt;10             &lt;name&gt;snapshots&lt;/name&gt;11             &lt;url&gt;http://192.168.75.132:8081/repository/maven-snapshots/&lt;/url&gt;12         &lt;/snapshotRepository&gt;13     &lt;/distributionManagement&gt;</code></pre><p>这里的192.168.75.132是我虚拟机的IP地址，这里的URL可以点击仓库查看详情获取。</p><h3 id="3、发布"><a href="#3、发布" class="headerlink" title="3、发布"></a>3、发布</h3><p><a href="https://imgtu.com/i/ggFrxH" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/16/ggFrxH.png" alt="ggFrxH.png"></a></p><p>先点击clean,在点击deploy就会自动根据项目的版本上传到对应的仓库（<strong>如果pom.xml上版本是1.1-SNAPSHOT则会deploy到maven-snapshot，如果是1.1.RELEASE则会deploy到maven-release</strong>）。</p><p>一般打包时maven会自动执行单元测试很耗时间，如果想略过该过程可以在pom文件添加如下插件。</p><pre><code>1 &lt;!-- 打包跳过测试--&gt;2             &lt;plugin&gt;3                 &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;4                 &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;5                 &lt;version&gt;2.18.1&lt;/version&gt;6                 &lt;configuration&gt;7                     &lt;skipTests&gt;true&lt;/skipTests&gt;8                 &lt;/configuration&gt;9             &lt;/plugin&gt;</code></pre><p>上传结果如图：</p><p><a href="https://imgtu.com/i/ggF6sA" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/16/ggF6sA.png" alt="ggF6sA.png"></a></p><p>然后在maven仓库里就可以找到我们刚刚上传的jar包了。</p><p><a href="https://imgtu.com/i/ggF5Rg" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/05/16/ggF5Rg.png" alt="ggF5Rg.png"></a></p><p>注意：maven仓库的Deployment policy一定要设置成allow redeploy，否则会上传失败。</p><h3 id="5、从私服下载jar包"><a href="#5、从私服下载jar包" class="headerlink" title="5、从私服下载jar包"></a>5、从私服下载jar包</h3><h4 id="1、添加仓库地址"><a href="#1、添加仓库地址" class="headerlink" title="1、添加仓库地址"></a>1、添加仓库地址</h4><pre><code>&lt;repositories&gt;        &lt;repository&gt;            &lt;id&gt;releases&lt;/id&gt;            &lt;name&gt;maven-public&lt;/name&gt;            &lt;url&gt;http://192.168.75.132:8081/repository/maven-public/&lt;/url&gt;            &lt;snapshots&gt;                &lt;enabled&gt;true&lt;/enabled&gt;            &lt;/snapshots&gt;            &lt;releases&gt;                &lt;enabled&gt;true&lt;/enabled&gt;            &lt;/releases&gt;        &lt;/repository&gt;    &lt;/repositories&gt;</code></pre><p>针对单个项目，这个可以添加到项目的pom.xml文件里，如果很多项目都需要可以添加到setting.xml文件中。</p><h4 id="2、添加依赖，以下为示例"><a href="#2、添加依赖，以下为示例" class="headerlink" title="2、添加依赖，以下为示例"></a>2、添加依赖，以下为示例</h4><pre><code>&lt;dependency&gt;            &lt;groupId&gt;cn.sp&lt;/groupId&gt;            &lt;artifactId&gt;kafka-spring-boot&lt;/artifactId&gt;            &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;</code></pre><p>然后一刷新发现项目里就有了。</p><h3 id="6、常见错误及解决办法"><a href="#6、常见错误及解决办法" class="headerlink" title="6、常见错误及解决办法"></a>6、常见错误及解决办法</h3><p><strong>问题一：上传报错误码405，Failed to transfer file。</strong></p><p><strong>解决方法：</strong>仔细查看报错信息就会发现，是上传的url错了,反正原因就是repository的地址写错了。</p><p><strong>问题二：错误码401或者403</strong></p><p><strong>解决方法：</strong>其实403错误就是“禁止访问”的含义，所以问题的根源肯定在授权上面。Maven在默认情况下会使用deployment帐号(默认密码deploy)登录的系统，但是关键的Nexus中Releases仓库默认的Deployment Policy是“Disable Redeploy”，所以无法部署的问题在这个地方，方法是将其修改为“Allow Redeploy”就可以了。401就是Maven settings.xml没有设置密码</p>]]></content>
      
      
      <categories>
          
          <category> DevOps </category>
          
      </categories>
      
      
        <tags>
            
            <tag> maven </tag>
            
            <tag> Nexus3 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搭建Gitlab</title>
      <link href="2019/10/05/devops/da-jian-gitlab/"/>
      <url>2019/10/05/devops/da-jian-gitlab/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p>Gitlab Server 部署</p><h3 id="1、环境准备"><a href="#1、环境准备" class="headerlink" title="1、环境准备"></a>1、环境准备</h3><pre><code>1.系统版本：CentOS7.42.Gitlab版本：gitlab-ee 11.0.13.初始化系统环境4.关闭防火墙[root@localhost ~]#  systemctl stop iptables firewalld[root@localhost ~]#  systemctl disable iptables firewalld5.开启邮件服务[root@vm1 ~]# systemctl start postfix[root@vm1 ~]# systemctl enable postfix6.关闭SELinux[root@localhost ~]#  sed -ri &#39;/SELINUX=/cSELINUX=disabled&#39; /etc/selinux/config[root@localhost ~]#  setenforce 0           # 临时关闭SELinux[root@localhost ~]#  reboot</code></pre><h3 id="2、部署Gitlab"><a href="#2、部署Gitlab" class="headerlink" title="2、部署Gitlab"></a>2、部署Gitlab</h3><pre><code>1.安装Gitlab社区版/企业版2.安装gitlab依赖包[root@localhost ~]# yum install -y curl openssh-server openssh-clients postfix cronie policycoreutils-python# gitlab-ce 10.x.x以后的版本需要依赖policycoreutils-python3.开启postfix，并设置开机自启[root@localhost ~]# systemctl start postfix;systemctl enable postfix4.选择添加yum源安装gitlab(根据需求配置源)（1）添加阿里源# vim /etc/yum.repos.d/gitlab-ce.repo[gitlab-ce]name=gitlab-cebaseurl=http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7Repo_gpgcheck=0Enabled=1Gpgkey=https://packages.gitlab.com/gpg.key（2） 添加清华源# vim gitlab-ce.repo[gitlab-ce]name=Gitlab CE Repositorybaseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el$releasever/gpgcheck=0enabled=1# vim gitlab-ee.repo[gitlab-ee]name=Gitlab EE Repositorybaseurl=https://mirrors.tuna.tsinghua.edu.cn/gitlab-ee/yum/el$releasever/gpgcheck=0enabled=1# vim runner_gitlab-ci-multi-runner.repo[runner_gitlab-ci-multi-runner]name=runner_gitlab-ci-multi-runnerbaseurl=https://packages.gitlab.com/runner/gitlab-ci-multi-runner/el/7/$basearchrepo_gpgcheck=1gpgcheck=0enabled=1gpgkey=https://packages.gitlab.com/runner/gitlab-ci-multi-runner/gpgkeysslverify=1sslcacert=/etc/pki/tls/certs/ca-bundle.crtmetadata_expire=300[runner_gitlab-ci-multi-runner-source]name=runner_gitlab-ci-multi-runner-sourcebaseurl=https://packages.gitlab.com/runner/gitlab-ci-multi-runner/el/7/SRPMSrepo_gpgcheck=1gpgcheck=0enabled=1gpgkey=https://packages.gitlab.com/runner/gitlab-ci-multi-runner/gpgkeysslverify=1sslcacert=/etc/pki/tls/certs/ca-bundle.crtmetadata_expire=300(3) 添加官方源curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ee/script.rpm.sh | sudo bash5.安装包下载https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/https://mirrors.tuna.tsinghua.edu.cn/gitlab-ee/yum/el7/6.根据需要选择ce/ee[root@localhost ~]# yum -y install gitlab-ce                    # 自动安装最新版[root@localhost ~]# yum -y install gitlab-ce-x.x.x              # 安装指定版本Gitlab[root@localhost ~]# yum -y install gitlab-ce warning: gitlab-ce-10.7.2-ce.0.el7.x86_64.rpm: Header V4 RSA/SHA1 Signature, key ID f27eab47: NOKEYPreparing...                          ################################# [100%]Updating / installing...   1:gitlab-ce-10.7.2-ce.0.el7        ################################# [100%]It looks like GitLab has not been configured yet; skipping the upgrade script.       *.                  *.      ***                 ***     *****               *****    .******             *******    ********            ********   ,,,,,,,,,***********,,,,,,,,,  ,,,,,,,,,,,*********,,,,,,,,,,,  .,,,,,,,,,,,*******,,,,,,,,,,,,      ,,,,,,,,,*****,,,,,,,,,.         ,,,,,,,****,,,,,,            .,,,***,,,,                ,*,.     _______ __  __          __    / ____(_) /_/ /   ____ _/ /_   / / __/ / __/ /   / __ `/ __ \  / /_/ / / /_/ /___/ /_/ / /_/ /  \____/_/\__/_____/\__,_/_.___/Thank you for installing GitLab!GitLab was unable to detect a valid hostname for your instance.Please configure a URL for your GitLab instance by setting `external_url`configuration in /etc/gitlab/gitlab.rb file.Then, you can start your GitLab instance by running the following command:  sudo gitlab-ctl reconfigureFor a comprehensive list of configuration options please see the Omnibus GitLab readmehttps://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md</code></pre><p>###3、配置 Gitlab</p><h4 id="1、查看Gitlab版本"><a href="#1、查看Gitlab版本" class="headerlink" title="1、查看Gitlab版本"></a>1、查看Gitlab版本</h4><pre><code>[root@localhost ~]# head -1 /opt/gitlab/version-manifest.txtgitlab-ce 10.1.1</code></pre><h4 id="2、Gitlab-配置文登录链接"><a href="#2、Gitlab-配置文登录链接" class="headerlink" title="2、Gitlab 配置文登录链接"></a>2、Gitlab 配置文登录链接</h4><pre><code>#设置登录链接[root@localhost ~]# vim /etc/gitlab/gitlab.rb***## GitLab URL##! URL on which GitLab will be reachable.##! For more details on configuring external_url see:##! https://docs.gitlab.com/omnibus/settings/configuration.html#configuring-the-external-url-for-gitlab# 没有域名，可以设置为本机IP地址external_url &#39;http://172.17.0.61&#39;***[root@localhost ~]# grep &quot;^external_url&quot; /etc/gitlab/gitlab.rbexternal_url &#39;http://172.17.0.61&#39;     #绑定监听的域名或IP</code></pre><h4 id="3、初始化-Gitlab-第一次使用配置时间较长"><a href="#3、初始化-Gitlab-第一次使用配置时间较长" class="headerlink" title="3、初始化 Gitlab (第一次使用配置时间较长)"></a>3、初始化 Gitlab (第一次使用配置时间较长)</h4><pre><code> [root@localhost ~]# gitlab-ctl reconfigure   .....</code></pre><h4 id="4、启动-Gitlab-服务"><a href="#4、启动-Gitlab-服务" class="headerlink" title="4、启动 Gitlab 服务"></a>4、启动 Gitlab 服务</h4><pre><code>[root@vm1 ~]# gitlab-ctl startok: run: gitaly: (pid 22896) 2922sok: run: gitlab-monitor: (pid 22914) 2921sok: run: gitlab-workhorse: (pid 22882) 2922sok: run: logrotate: (pid 22517) 2987sok: run: nginx: (pid 22500) 2993sok: run: node-exporter: (pid 22584) 2974sok: run: postgres-exporter: (pid 22946) 2919sok: run: postgresql: (pid 22250) 3047sok: run: prometheus: (pid 22931) 2920sok: run: redis: (pid 22190) 3053sok: run: redis-exporter: (pid 22732) 2962sok: run: sidekiq: (pid 22472) 3005sok: run: unicorn: (pid 22433) 3011s[root@vm1 ~]# [root@vm1 ~]# lsof -i:80COMMAND   PID       USER   FD   TYPE DEVICE SIZE/OFF NODE NAMEnginx   22500       root    7u  IPv4  50923      0t0  TCP *:http (LISTEN)nginx   22501 gitlab-www    7u  IPv4  50923      0t0  TCP *:http (LISTEN)[root@vm1 ~]# </code></pre><h4 id="5、Gitlab-设置-HTTPS-方式"><a href="#5、Gitlab-设置-HTTPS-方式" class="headerlink" title="5、Gitlab 设置 HTTPS 方式"></a>5、Gitlab 设置 HTTPS 方式</h4><pre><code>如果想要以上的 https 方式正常生效使用，则需要把 letsencrypt 自动生成证书的配置打开，这样在执行重新让配置生效命令 (gitlab-ctl reconfigure) 的时候会自动给域名生成免费的证书并自动在 gitlab 自带的 nginx 中加上相关的跳转配置，都是全自动的，非常方便。letsencrypt[&#39;enable&#39;] = true letsencrypt[&#39;contact_emails&#39;] = [&#39;caryyu@qq.com&#39;]     # 这应该是一组要添加为联系人的电子邮件地址</code></pre><h4 id="6、Gitlab-添加smtp邮件功能"><a href="#6、Gitlab-添加smtp邮件功能" class="headerlink" title="6、Gitlab 添加smtp邮件功能"></a>6、Gitlab 添加smtp邮件功能</h4><pre><code>[root@vm1 ~]# vim /etc/gitlab/gitlab.rbpostfix 并非必须的；根据具体情况配置，以 SMTP 的为例配置邮件服务器来实现通知；参考配置如下： ### Email Settings  gitlab_rails[&#39;gitlab_email_enabled&#39;] = true  gitlab_rails[&#39;gitlab_email_from&#39;] = &#39;system.notice@qq.com&#39;  gitlab_rails[&#39;gitlab_email_display_name&#39;] = &#39;gitlab.notice&#39;  gitlab_rails[&#39;gitlab_email_reply_to&#39;] = &#39;system.notice@qq.com&#39;  gitlab_rails[&#39;gitlab_email_subject_suffix&#39;] = &#39;gitlab&#39;  ### GitLab email server settings ###! Docs: https://docs.gitlab.com/omnibus/settings/smtp.html ###! **Use smtp instead of sendmail/postfix.**   gitlab_rails[&#39;smtp_enable&#39;] = true  gitlab_rails[&#39;smtp_address&#39;] = &quot;smtp.qq.com&quot;  gitlab_rails[&#39;smtp_port&#39;] = 465  gitlab_rails[&#39;smtp_user_name&#39;] = &quot;system.notice@qq.com&quot;  gitlab_rails[&#39;smtp_password&#39;] = &quot;xxxxx&quot;  gitlab_rails[&#39;smtp_domain&#39;] = &quot;qq.com&quot;  gitlab_rails[&#39;smtp_authentication&#39;] = &quot;login&quot;  gitlab_rails[&#39;smtp_enable_starttls_auto&#39;] = true  gitlab_rails[&#39;smtp_tls&#39;] = true[root@vm1 ~]# grep -P &quot;^[^#].*smtp_|user_email|gitlab_email&quot; /etc/gitlab/gitlab.rbgitlab_rails[&#39;gitlab_email_enabled&#39;] = truegitlab_rails[&#39;gitlab_email_from&#39;] = &#39;username@domain.cn&#39;gitlab_rails[&#39;gitlab_email_display_name&#39;] = &#39;Admin&#39;gitlab_rails[&#39;gitlab_email_reply_to&#39;] = &#39;usernamei@domain.cn&#39;gitlab_rails[&#39;gitlab_email_subject_suffix&#39;] = &#39;[gitlab]&#39;gitlab_rails[&#39;smtp_enable&#39;] = truegitlab_rails[&#39;smtp_address&#39;] = &quot;smtp.exmail.qq.com&quot;gitlab_rails[&#39;smtp_port&#39;] = 25 gitlab_rails[&#39;smtp_user_name&#39;] = &quot;username@domain.cn&quot;gitlab_rails[&#39;smtp_password&#39;] = &quot;password&quot;gitlab_rails[&#39;smtp_domain&#39;] = &quot;domain.cn&quot;gitlab_rails[&#39;smtp_authentication&#39;] = &quot;login&quot;gitlab_rails[&#39;smtp_enable_starttls_auto&#39;] = truegitlab_rails[&#39;smtp_tls&#39;] = falseuser[&#39;git_user_email&#39;] = &quot;username@domain.cn&quot;[root@vm1 ~]# gitlab-ctl reconfigure  #修改配置后需要初始化配置......[root@vm1 ~]# gitlab-ctl stopok: down: gitaly: 0s, normally upok: down: gitlab-monitor: 1s, normally upok: down: gitlab-workhorse: 0s, normally upok: down: logrotate: 1s, normally upok: down: nginx: 0s, normally upok: down: node-exporter: 1s, normally upok: down: postgres-exporter: 0s, normally upok: down: postgresql: 0s, normally upok: down: prometheus: 0s, normally upok: down: redis: 0s, normally upok: down: redis-exporter: 1s, normally upok: down: sidekiq: 0s, normally upok: down: unicorn: 1s, normally up[root@vm1 ~]# gitlab-ctl startok: run: gitaly: (pid 37603) 0sok: run: gitlab-monitor: (pid 37613) 0sok: run: gitlab-workhorse: (pid 37625) 0sok: run: logrotate: (pid 37631) 0sok: run: nginx: (pid 37639) 1sok: run: node-exporter: (pid 37644) 0sok: run: postgres-exporter: (pid 37648) 1sok: run: postgresql: (pid 37652) 0sok: run: prometheus: (pid 37660) 1sok: run: redis: (pid 37668) 0sok: run: redis-exporter: (pid 37746) 0sok: run: sidekiq: (pid 37750) 1sok: run: unicorn: (pid 37757) 0s</code></pre><h4 id="7、Gitlab-发送邮件测试"><a href="#7、Gitlab-发送邮件测试" class="headerlink" title="7、Gitlab 发送邮件测试"></a>7、Gitlab 发送邮件测试</h4><pre><code>[root@vm1 ~]# gitlab-rails console Loading production environment (Rails 4.2.10)irb(main):001:0&gt;  Notify.test_email(&#39;user@destination.com&#39;, &#39;Message Subject&#39;, &#39;Message Body&#39;).deliver_nowNotify#test_email: processed outbound mail in 2219.5msSent mail to user@destination.com (2469.5ms)Date: Fri, 04 May 2018 15:50:10 +0800From: Admin &lt;username@domain.cn&gt;Reply-To: Admin &lt;username@domain.cn&gt;To: user@destination.comMessage-ID: &lt;5aec10b24cfaa_93933fee282db10c162d@vm1.mail&gt;Subject: Message SubjectMime-Version: 1.0Content-Type: text/html; charset=UTF-8Content-Transfer-Encoding: 7bitAuto-Submitted: auto-generatedX-Auto-Response-Suppress: All&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/REC-html40/loose.dtd&quot;&gt;&lt;html&gt;&lt;body&gt;&lt;p&gt;Message Body&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;=&gt; #&lt;Mail::Message:70291731344240, Multipart: false, Headers: &lt;Date: Fri, 04 May 2018 15:50:10 +0800&gt;, &lt;From: Admin &lt;username@domain.cn&gt;&gt;, &lt;Reply-To: Admin &lt;username@domain.cn&gt;&gt;, &lt;To: user@destination.com&gt;, &lt;Message-ID: &lt;5aec10b24cfaa_93933fee282db10c162d@vm1.mail&gt;&gt;, &lt;Subject: Message Subject&gt;, &lt;Mime-Version: 1.0&gt;, &lt;Content-Type: text/html; charset=UTF-8&gt;, &lt;Content-Transfer-Encoding: 7bit&gt;, &lt;Auto-Submitted: auto-generated&gt;, &lt;X-Auto-Response-Suppress: All&gt;&gt;irb(main):002:0&gt;quit </code></pre><p>###3、<strong>gitlab的使用</strong> <strong>在浏览器中输入 <a href="http://192.168.60.119/" target="_blank" rel="noopener">http://192.168.60.119/</a> ，然后 change password: ，并使用root用户登录 即可 (后续动作根据提示操作)</strong></p><h4 id="1、gitlab-命令行修改密码"><a href="#1、gitlab-命令行修改密码" class="headerlink" title="1、gitlab 命令行修改密码"></a>1、gitlab 命令行修改密码</h4><pre><code>gitlab-rails console productionirb(main):001:0&gt; user = User.where(id: 1).first     # id为1的是超级管理员irb(main):002:0&gt;user.password = &#39;yourpassword&#39;      # 密码必须至少8个字符irb(main):003:0&gt;user.save!                          # 如没有问题 返回trueexit                                                # 退出</code></pre><h4 id="2、gitlab服务管理"><a href="#2、gitlab服务管理" class="headerlink" title="2、gitlab服务管理"></a>2、gitlab服务管理</h4><pre><code>gitlab-ctl start                        # 启动所有 gitlab 组件；gitlab-ctl stop                         # 停止所有 gitlab 组件；gitlab-ctl restart                      # 重启所有 gitlab 组件；gitlab-ctl status                       # 查看服务状态；gitlab-ctl reconfigure                  # 启动服务；vim /etc/gitlab/gitlab.rb               # 修改默认的配置文件；gitlab-ctl tail                         # 查看日志；</code></pre><p>3、登陆 Gitlab</p><p><img src="http://p3.pstatp.com/large/pgc-image/bab871f315204370a5a0fb7608617551" alt="Gitlab Server 部署"></p><p><strong>如果需要手工修改nginx的port ，可以在gitlab.rb中设置 nginx[‘listen_port’] = 8000 ，然后再次 gitlab-ctl reconfigure即可</strong></p><p><strong>登录 gitlab 如下所示(首次登陆设置 root 密码)：</strong></p><p><img src="http://p1.pstatp.com/large/pgc-image/8fbf9685623b4ca3a3db0db73eae8896" alt="Gitlab Server 部署"></p><p><strong>创建项目组 group ，组名为plat-sp ,如下所示:</strong></p><p><img src="http://p1.pstatp.com/large/pgc-image/30b33c344c914b10b7efdc44cae76214" alt="Gitlab Server 部署"></p><p><img src="http://p1.pstatp.com/large/pgc-image/cbd2fd9e30454e2c9514192f0706cb31" alt="Gitlab Server 部署"></p><p><strong>去掉用户的自动注册功能（安全）：</strong> admin are -&gt; settings -&gt; Sign-up Restrictions 去掉钩钩，然后拉到最下面保存，重新登录</p><p><img src="http://p3.pstatp.com/large/pgc-image/6cefb48804534f60b67e16168a7717a0" alt="Gitlab Server 部署"></p>]]></content>
      
      
      <categories>
          
          <category> DevOps </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Gitlab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux服务器被黑排查思路</title>
      <link href="2019/10/05/linux/fu-wu-qi-bei-hei-pai-cha-si-lu/"/>
      <url>2019/10/05/linux/fu-wu-qi-bei-hei-pai-cha-si-lu/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="账户和登录安全"><a href="#账户和登录安全" class="headerlink" title="账户和登录安全"></a>账户和登录安全</h3><p>账户安全是系统安全的第一道屏障，也是系统安全的核心，保障登录账户的安全，在一定程度上可以提高服务器的安全级别，下面重点介绍下 Linux 系统登录账户的安全设置方法。</p><h4 id="①删除特殊的账户和账户组"><a href="#①删除特殊的账户和账户组" class="headerlink" title="①删除特殊的账户和账户组"></a><strong>①删除特殊的账户和账户组</strong></h4><p>Linux 提供了各种不同角色的系统账号，在系统安装完成后，默认会安装很多不必要的用户和用户组。</p><p>如果不需要某些用户或者组，就要立即删除它，因为账户越多，系统就越不安全，很可能被黑客利用，进而威胁到服务器的安全。</p><p>Linux系统中可以删除的默认用户和组大致有如下这些：</p><p><strong>可删除的用户，</strong>如 adm，lp，sync，shutdown，halt，news，uucp，operator，games，gopher 等。</p><p><strong>可删除的组，</strong>如 adm，lp，news，uucp，games，dip，pppusers，popusers，slipusers 等。</p><h4 id="②关闭系统不需要的服务"><a href="#②关闭系统不需要的服务" class="headerlink" title="②关闭系统不需要的服务"></a><strong>②关闭系统不需要的服务</strong></h4><p>Linux 在安装完成后，绑定了很多没用的服务，这些服务默认都是自动启动的。</p><p>对于服务器来说，运行的服务越多，系统就越不安全，越少服务在运行，安全性就越好，因此关闭一些不需要的服务，对系统安全有很大的帮助。</p><p>具体哪些服务可以关闭，要根据服务器的用途而定，一般情况下，只要系统本身用不到的服务都认为是不必要的服务。</p><p>例如：某台 Linux 服务器用于 www 应用，那么除了 httpd 服务和系统运行是必须的服务外，其他服务都可以关闭。</p><p>下面这些服务一般情况下是不需要的，可以选择关闭：</p><p>anacron、auditd、autofs、avahi-daemon、avahi-dnsconfd、bluetooth、cpuspeed、firstboot、gpm、haldaemon、hidd、ip6tables、ipsec、isdn、lpd、mcstrans、messagebus、netfs、nfs、nfslock、nscd、pcscd portmap、readahead_early、restorecond、rpcgssd、rpcidmapd、rstatd、sendmail、setroubleshoot、yppasswdd ypserv</p><h4 id="③密码安全策略"><a href="#③密码安全策略" class="headerlink" title="③密码安全策略"></a><strong>③密码安全策略</strong></h4><p>在 Linux 下，远程登录系统有两种认证方式：</p><ul><li><strong>密码认证</strong></li><li><strong>密钥认证</strong></li></ul><p>密码认证方式是传统的安全策略，对于密码的设置，比较普遍的说法是：至少 6 个字符以上，密码要包含数字、字母、下划线、特殊符号等。</p><p>设置一个相对复杂的密码，对系统安全能起到一定的防护作用，但是也面临一些其他问题，例如密码暴力破解、密码泄露、密码丢失等，同时过于复杂的密码对运维工作也会造成一定的负担。</p><p>密钥认证是一种新型的认证方式，公用密钥存储在远程服务器上，专用密钥保存在本地，当需要登录系统时，通过本地专用密钥和远程服务器的公用密钥进行配对认证，如果认证成功，就成功登录系统。</p><p>这种认证方式避免了被暴力破解的危险，同时只要保存在本地的专用密钥不被黑客盗用，攻击者一般无法通过密钥认证的方式进入系统。</p><p>因此，在 Linux 下推荐用密钥认证方式登录系统，这样就可以抛弃密码认证登录系统的弊端。</p><p>Linux 服务器一般通过 SecureCRT、Putty、Xshell 之类的工具进行远程维护和管理，密钥认证方式的实现就是借助于 SecureCRT 软件和 Linux 系统中的 SSH 服务实现的。</p><h4 id="④合理使用-su、sudo-命令"><a href="#④合理使用-su、sudo-命令" class="headerlink" title="④合理使用 su、sudo 命令"></a><strong>④合理使用 su、sudo 命令</strong></h4><p><strong>su 命令：</strong>是一个切换用户的工具，经常用于将普通用户切换到超级用户下，当然也可以从超级用户切换到普通用户。</p><p>为了保证服务器的安全，几乎所有服务器都禁止了超级用户直接登录系统，而是通过普通用户登录系统，然后再通过 su 命令切换到超级用户下，执行一些需要超级权限的工作。</p><p>通过 su 命令能够给系统管理带来一定的方便，但是也存在不安全的因素，例如：系统有 10 个普通用户，每个用户都需要执行一些有超级权限的操作，就必须把超级用户的密码交给这 10 个普通用户。</p><p>如果这 10 个用户都有超级权限，通过超级权限可以做任何事，那么会在一定程度上对系统的安全造成了威协。</p><p>因此 su 命令在很多人都需要参与的系统管理中，并不是最好的选择，超级用户密码应该掌握在少数人手中，此时 sudo 命令就派上用场了。</p><p><strong>sudo 命令：</strong>允许系统管理员分配给普通用户一些合理的“权利”，并且不需要普通用户知道超级用户密码，就能让他们执行一些只有超级用户或其他特许用户才能完成的任务。</p><p>比如：系统服务重启、编辑系统配置文件等，通过这种方式不但能减少超级用户登录次数和管理时间，也提高了系统安全性。</p><p>因此，sudo 命令相对于权限无限制性的 su 来说，还是比较安全的，所以 sudo 也被称为受限制的 su，另外 sudo 也是需要事先进行授权认证的，所以也被称为授权认证的 su。</p><p><strong>sudo 执行命令的流程是：</strong>将当前用户切换到超级用户下，或切换到指定的用户下，然后以超级用户或其指定切换到的用户身份执行命令。</p><p>执行完成后，直接退回到当前用户，而这一切的完成要通过 sudo 的配置文件 /etc/sudoers 来进行授权。</p><p><strong>sudo 设计的宗旨是：</strong>赋予用户尽可能少的权限但仍允许它们完成自己的工作，这种设计兼顾了安全性和易用性。</p><p>因此，强烈推荐通过 sudo 来管理系统账号的安全，只允许普通用户登录系统，如果这些用户需要特殊的权限，就通过配置 /etc/sudoers 来完成，这也是多用户系统下账号安全管理的基本方式。</p><h4 id="⑤删减系统登录欢迎信息"><a href="#⑤删减系统登录欢迎信息" class="headerlink" title="⑤删减系统登录欢迎信息"></a><strong>⑤删减系统登录欢迎信息</strong></h4><p>系统的一些欢迎信息或版本信息，虽然能给系统管理者带来一定的方便，但是这些信息有时候可能被黑客利用，成为攻击服务器的帮凶。</p><p>为了保证系统的安全，可以修改或删除某些系统文件，需要修改或删除的文件有四个，分别是：</p><ul><li><strong>/etc/issue</strong></li><li><strong>/etc/issue.net</strong></li><li><strong>/etc/redhat-release</strong></li><li><strong>/etc/motd</strong></li></ul><p>/etc/issue 和 /etc/issue.net 文件都记录了操作系统的名称和版本号，当用户通过本地终端或本地虚拟控制台等登录系统时，/etc/issue 的文件内容就会显示。</p><p>当用户通过 ssh 或 telnet 等远程登录系统时，/etc/issue.net 文件内容就会在登录后显示。</p><p>在默认情况下 /etc/issue.net 文件的内容是不会在 ssh 登录后显示的，要显示这个信息可以修改 /etc/ssh/sshd_config 文件，在此文件中添加如下内容即可：Banner /etc/issue.net。</p><p>其实这些登录提示很明显泄漏了系统信息，为了安全起见，建议将此文件中的内容删除或修改。</p><p>/etc/redhat-release 文件也记录了操作系统的名称和版本号，为了安全起见，可以将此文件中的内容删除。</p><p>/etc/motd 文件是系统的公告信息。每次用户登录后，/etc/motd 文件的内容就会显示在用户的终端。</p><p>通过这个文件系统，管理员可以发布一些软件或硬件的升级、系统维护等通告信息，但是此文件的最大作用就是可以发布一些警告信息，当黑客登录系统后，会发现这些警告信息，进而产生一些震慑作用。</p><p>看过国外的一个报道，黑客入侵了一个服务器，而这个服务器却给出了欢迎登录的信息，因此法院不做任何裁决。</p><h3 id="远程访问和认证安全"><a href="#远程访问和认证安全" class="headerlink" title="远程访问和认证安全"></a><strong>远程访问和认证安全</strong></h3><h4 id="①远程登录取消-telnet-而采用-SSH-方式"><a href="#①远程登录取消-telnet-而采用-SSH-方式" class="headerlink" title="①远程登录取消 telnet 而采用 SSH 方式"></a><strong>①远程登录取消 telnet 而采用 SSH 方式</strong></h4><p>telnet 是一种古老的远程登录认证服务，它在网络上用明文传送口令和数据，因此别有用心的人就会非常容易截获这些口令和数据。</p><p>而且，telnet 服务程序的安全验证方式也极其脆弱，攻击者可以轻松将虚假信息传送给服务器。</p><p>现在远程登录基本抛弃了 telnet 这种方式，而取而代之的是通过 SSH 服务远程登录服务器。</p><h4 id="②合理使用-Shell-历史命令记录功能"><a href="#②合理使用-Shell-历史命令记录功能" class="headerlink" title="②合理使用 Shell 历史命令记录功能"></a><strong>②合理使用 Shell 历史命令记录功能</strong></h4><p>在 Linux 下可通过 history 命令查看用户所有的历史操作记录，同时 shell 命令操作记录默认保存在用户目录下的 .bash_history 文件中。</p><p>通过这个文件可以查询 shell 命令的执行历史，有助于运维人员进行系统审计和问题排查。</p><p>同时，在服务器遭受黑客攻击后，也可以通过这个命令或文件查询黑客登录服务器所执行的历史命令操作。</p><p>但是有时候黑客在入侵服务器后为了毁灭痕迹，可能会删除 .bash_history 文件，这就需要合理的保护或备份 .bash_history 文件。</p><h4 id="③启用-Tcp-Wrappers-防火墙"><a href="#③启用-Tcp-Wrappers-防火墙" class="headerlink" title="③启用 Tcp_Wrappers 防火墙"></a><strong>③启用 Tcp_Wrappers 防火墙</strong></h4><p>Tcp_Wrappers 是一个用来分析 TCP/IP 封包的软件，类似的 IP 封包软件还有 iptables。</p><p>Linux 默认都安装了 Tcp_Wrappers。作为一个安全的系统，Linux 本身有两层安全防火墙，通过 IP 过滤机制的 iptables 实现第一层防护。</p><p>iptables 防火墙通过直观地监视系统的运行状况，阻挡网络中的一些恶意攻击，保护整个系统正常运行，免遭攻击和破坏。</p><p>如果通过了第一层防护，那么下一层防护就是 Tcp_Wrappers 了。通过 Tcp_Wrappers 可以实现对系统中提供的某些服务的开放与关闭、允许和禁止，从而更有效地保证系统安全运行。</p><h3 id="文件系统安全"><a href="#文件系统安全" class="headerlink" title="文件系统安全"></a><strong>文件系统安全</strong></h3><h4 id="①锁定系统重要文件"><a href="#①锁定系统重要文件" class="headerlink" title="①锁定系统重要文件"></a><strong>①锁定系统重要文件</strong></h4><p>系统运维人员有时候可能会遇到通过 Root 用户都不能修改或者删除某个文件的情况，产生这种情况的大部分原因可能是这个文件被锁定了。</p><p>在 Linux 下锁定文件的命令是 Chattr，通过这个命令可以修改 ext2、ext3、ext4 文件系统下文件属性，但是这个命令必须有超级用户 Root 来执行。和这个命令对应的命令是 lsattr，这个命令用来查询文件属性。</p><p>对重要的文件进行加锁，虽然能够提高服务器的安全性，但是也会带来一些不便。</p><p>例如：在软件的安装、升级时可能需要去掉有关目录和文件的 immutable 属性和 append-only 属性，同时，对日志文件设置了 append-only 属性，可能会使日志轮换（logrotate）无法进行。</p><p>因此，在使用 Chattr 命令前，需要结合服务器的应用环境来权衡是否需要设置 immutable 属性和 append-only 属性。</p><p>另外，虽然通过 Chattr 命令修改文件属性能够提高文件系统的安全性，但是它并不适合所有的目录。Chattr 命令不能保护 /、/dev、/tmp、/var 等目录。</p><p>根目录不能有不可修改属性，因为如果根目录具有不可修改属性，那么系统根本无法工作：</p><ul><li>/dev 在启动时，syslog 需要删除并重新建立 /dev/log 套接字设备，如果设置了不可修改属性，那么可能出问题。</li><li>/tmp 目录会有很多应用程序和系统程序需要在这个目录下建立临时文件，也不能设置不可修改属性。</li><li>/var 是系统和程序的日志目录，如果设置为不可修改属性，那么系统写日志将无法进行，所以也不能通过 Chattr 命令保护。</li></ul><h4 id="②文件权限检查和修改"><a href="#②文件权限检查和修改" class="headerlink" title="②文件权限检查和修改"></a><strong>②文件权限检查和修改</strong></h4><p>不正确的权限设置直接威胁着系统的安全，因此运维人员应该能及时发现这些不正确的权限设置，并立刻修正，防患于未然。下面列举几种查找系统不安全权限的方法。</p><p>查找系统中任何用户都有写权限的文件或目录：</p><pre><code>查找文件：find / -type f -perm -2 -o -perm -20 |xargs ls -al查找目录：find / -type d -perm -2 -o -perm -20 |xargs ls –ld</code></pre><p>查找系统中所有含“s”位的程序：</p><pre><code>find / -type f -perm -4000 -o -perm -2000 -print | xargs ls –al</code></pre><p>含有“s”位权限的程序对系统安全威胁很大，通过查找系统中所有具有“s”位权限的程序，可以把某些不必要的“s”位程序去掉，这样可以防止用户滥用权限或提升权限的可能性。</p><p>检查系统中所有 suid 及 sgid 文件：</p><pre><code>find / -user root -perm -2000 -print -exec md5sum {} ;find / -user root -perm -4000 -print -exec md5sum {} ;</code></pre><p>将检查的结果保存到文件中，可在以后的系统检查中作为参考。</p><p>检查系统中没有属主的文件：</p><pre><code>find / -nouser -o –nogroup</code></pre><p>没有属主的孤儿文件比较危险，往往成为黑客利用的工具，因此找到这些文件后，要么删除掉，要么修改文件的属主，使其处于安全状态。</p><h4 id="③-tmp、-var-tmp、-dev-shm-安全设定"><a href="#③-tmp、-var-tmp、-dev-shm-安全设定" class="headerlink" title="③/tmp、/var/tmp、/dev/shm 安全设定"></a><strong>③/tmp、/var/tmp、/dev/shm 安全设定</strong></h4><p>在 Linux 系统中，主要有两个目录或分区用来存放临时文件，分别是 /tmp 和 /var/tmp。</p><p>存储临时文件的目录或分区有个共同点就是所有用户可读写、可执行，这就为系统留下了安全隐患。</p><p>攻击者可以将病毒或者木马脚本放到临时文件的目录下进行信息收集或伪装，严重影响服务器的安全。</p><p>此时，如果修改临时目录的读写执行权限，还有可能影响系统上应用程序的正常运行，因此，如果要兼顾两者，就需要对这两个目录或分区进行特殊的设置。</p><p>/dev/shm 是 Linux 下的一个共享内存设备，在 Linux 启动的时候系统默认会加载 /dev/shm，被加载的 /dev/shm 使用的是 tmpfs 文件系统，而 tmpfs 是一个内存文件系统，存储到 tmpfs 文件系统的数据会完全驻留在 RAM 中。</p><p>这样通过 /dev/shm 就可以直接操控系统内存，这将非常危险，因此如何保证 /dev/shm 安全也至关重要。</p><p>对于 /tmp 的安全设置，需要看 /tmp 是一个独立磁盘分区，还是一个根分区下的文件夹。</p><p>如果 /tmp 是一个独立的磁盘分区，那么设置非常简单，修改 /etc/fstab 文件中 /tmp 分区对应的挂载属性，加上 nosuid、noexec、nodev 三个选项即可。</p><p>修改后的 /tmp 分区挂载属性类似如下：</p><pre><code>LABEL=/tmp  /tmp ext3 rw,nosuid,noexec,nodev 0 0</code></pre><p>其中，nosuid、noexec、nodev 选项，表示不允许任何 suid 程序，并且在这个分区不能执行任何脚本等程序，并且不存在设备文件。</p><p>在挂载属性设置完成后，重新挂载 /tmp 分区，保证设置生效。</p><p>对于 /var/tmp，如果是独立分区，安装 /tmp 的设置方法是修改 /etc/fstab 文件即可。</p><p>如果是 /var 分区下的一个目录，那么可以将 /var/tmp 目录下所有数据移动到 /tmp 分区下，然后在 /var 下做一个指向 /tmp 的软连接即可。</p><p>也就是执行如下操作：</p><pre><code>[root@server ~]# mv /var/tmp/* /tmp[root@server ~]# ln -s  /tmp /var/tmp</code></pre><p>如果 /tmp 是根目录下的一个目录，那么设置稍微复杂，可以通过创建一个 loopback 文件系统来利用 Linux 内核的 loopback 特性将文件系统挂载到 /tmp 下，然后在挂载时指定限制加载选项即可。</p><p>一个简单的操作示例如下：</p><pre><code>[root@server ~]# dd if=/dev/zero of=/dev/tmpfs bs=1M count=10000[root@server ~]# mke2fs -j /dev/tmpfs[root@server ~]# cp -av /tmp /tmp.old[root@server ~]# mount -o loop,noexec,nosuid,rw /dev/tmpfs /tmp[root@server ~]# chmod 1777 /tmp[root@server ~]# mv -f /tmp.old/* /tmp/[root@server ~]# rm -rf /tmp.old</code></pre><p>最后，编辑 /etc/fstab，添加如下内容，以便系统在启动时自动加载 loopback 文件系统：</p><pre><code>/dev/tmpfs /tmp ext3 loop,nosuid,noexec,rw 0 0</code></pre><h3 id="Linux-后门入侵检测工具"><a href="#Linux-后门入侵检测工具" class="headerlink" title="Linux 后门入侵检测工具"></a><strong>Linux 后门入侵检测工具</strong></h3><p>Rootkit 是 Linux 平台下最常见的一种木马后门工具，它主要通过替换系统文件来达到入侵和和隐蔽的目的，这种木马比普通木马后门更加危险和隐蔽，普通的检测工具和检查手段很难发现这种木马。</p><p>Rootkit 攻击能力极强，对系统的危害很大，它通过一套工具来建立后门和隐藏行迹，从而让攻击者保住权限，以使它在任何时候都可以使用 Root 权限登录到系统。</p><p>Rootkit 主要有两种类型：文件级别和内核级别，下面分别进行简单介绍。</p><p>文件级别的 Rootkit 一般是通过程序漏洞或者系统漏洞进入系统后，通过修改系统的重要文件来达到隐藏自己的目的。</p><p>在系统遭受 Rootkit 攻击后，合法的文件被木马程序替代，变成了外壳程序，而其内部是隐藏着的后门程序。</p><p>通常容易被 Rootkit 替换的系统程序有 login、ls、ps、ifconfig、du、find、netstat 等，其中 login 程序是最经常被替换的。</p><p>因为当访问 Linux 时，无论是通过本地登录还是远程登录，/bin/login 程序都会运行，系统将通过 /bin/login 来收集并核对用户的账号和密码。</p><p>而 Rootkit 就是利用这个程序的特点，使用一个带有根权限后门密码的 /bin/login 来替换系统的 /bin/login，这样攻击者通过输入设定好的密码就能轻松进入系统。</p><p>此时，即使系统管理员修改 Root 密码或者清除 Root 密码，攻击者还是一样能通过 Root 用户登录系统。</p><p>攻击者通常在进入 Linux 系统后，会进行一系列的攻击动作，最常见的是安装嗅探器收集本机或者网络中其他服务器的重要数据。</p><p>在默认情况下，Linux 中也有一些系统文件会监控这些工具动作，例如 ifconfig 命令。</p><p>所以，攻击者为了避免被发现，会想方设法替换其他系统文件，常见的就是 ls、ps、ifconfig、du、find、netstat 等。</p><p>如果这些文件都被替换，那么在系统层面就很难发现 Rootkit 已经在系统中运行了。</p><p>这就是文件级别的 Rootkit，对系统维护很大，目前最有效的防御方法是定期对系统重要文件的完整性进行检查。</p><p>如果发现文件被修改或者被替换，那么很可能系统已经遭受了 Rootkit 入侵。</p><p>检查文件完整性的工具很多，常见的有 Tripwire、 aide 等，可以通过这些工具定期检查文件系统的完整性，以检测系统是否被 Rootkit 入侵。</p><p>内核级 Rootkit 是比文件级 Rootkit 更高级的一种入侵方式，它可以使攻击者获得对系统底层的完全控制权。</p><p>此时攻击者可以修改系统内核，进而截获运行程序向内核提交的命令，并将其重定向到入侵者所选择的程序并运行此程序。</p><p>也就是说，当用户要运行程序 A 时，被入侵者修改过的内核会假装执行 A 程序，而实际上却执行了程序 B。</p><p>内核级 Rootkit 主要依附在内核上，它并不对系统文件做任何修改，因此一般的检测工具很难检测到它的存在，这样一旦系统内核被植入 Rootkit，攻击者就可以对系统为所欲为而不被发现。</p><p>目前对于内核级的 Rootkit 还没有很好的防御工具，因此，做好系统安全防范就非常重要，将系统维持在最小权限内工作，只要攻击者不能获取 Root 权限，就无法在内核中植入 Rootkit。</p><h4 id="①Rootkit-后门检测工具-Chkrootkit"><a href="#①Rootkit-后门检测工具-Chkrootkit" class="headerlink" title="①Rootkit 后门检测工具 Chkrootkit"></a><strong>①Rootkit 后门检测工具 Chkrootkit</strong></h4><p>Chkrootkit 是一个 Linux 系统下查找并检测 Rootkit 后门的工具，它的官方地址：</p><pre><code>http://www.chkrootkit.org/</code></pre><p>Chkrootkit 没有包含在官方的 CentOS 源中，因此要采取手动编译的方法来安装，不过这种安装方法也更加安全。</p><p>Chkrootkit 的使用比较简单，直接执行 Chkrootkit 命令即可自动开始检测系统。</p><p>下面是某个系统的检测结果：</p><pre><code>[root@server chkrootkit]# /usr/local/chkrootkit/chkrootkitChecking `ifconfig&#39;... INFECTEDChecking `ls&#39;... INFECTEDChecking `login&#39;... INFECTEDChecking `netstat&#39;... INFECTEDChecking `ps&#39;... INFECTEDChecking `top&#39;... INFECTEDChecking `sshd&#39;... not infectedChecking `syslogd&#39;... not tested</code></pre><p>从输出可以看出，此系统的 ifconfig、ls、login、netstat、ps 和 top 命令已经被感染。</p><p>针对被感染 Rootkit 的系统，最安全而有效的方法就是备份数据重新安装系统。</p><p>Chkrootkit 在检查 Rootkit 的过程中使用了部分系统命令，因此，如果服务器被黑客入侵，那么依赖的系统命令可能也已经被入侵者替换，此时 Chkrootkit 的检测结果将变得完全不可信。</p><p>为了避免 Chkrootkit 的这个问题，可以在服务器对外开放前，事先将 Chkrootkit 使用的系统命令进行备份，在需要的时候使用备份的原始系统命令让 Chkrootkit 对 Rootkit 进行检测。</p><h4 id="②Rootkit-后门检测工具-RKHunter"><a href="#②Rootkit-后门检测工具-RKHunter" class="headerlink" title="②Rootkit 后门检测工具 RKHunter"></a><strong>②Rootkit 后门检测工具 RKHunter</strong></h4><p>RKHunter 是一款专业的检测系统是否感染 Rootkit 的工具，它通过执行一系列的脚本来确认服务器是否已经感染 Rootkit。</p><p>在官方的资料中，RKHunter 可以做的事情有：</p><pre><code>MD5校验测试，检测文件是否有改动，比较系统命令的md5，从而判断系统命令是否被篡改检测rootkit使用的二进制和系统工具文件检测特洛伊木马程序的特征码检测常用程序的文件属性是否异常检测系统相关的测试检测隐藏文件检测可疑的核心模块LKM检测系统已启动的监听端口</code></pre><p>在 Linux 终端使用 RKHunter 来检测，最大的好处在于每项的检测结果都有不同的颜色显示，如果是绿色的表示没有问题，如果是红色的，那就要引起关注了。</p><p>另外，在执行检测的过程中，在每个部分检测完成后，需要以 Enter 键来继续。</p><p>如果要让程序自动运行，可以执行如下命令：</p><pre><code>[root@server ~]# /usr/local/bin/rkhunter --check --skip-keypress</code></pre><p>同时，如果想让检测程序每天定时运行，那么可以在 /etc/crontab 中加入如下内容：</p><pre><code>30 09 * * * root /usr/local/bin/rkhunter --check --cronjob </code></pre><p>这样，RKHunter 检测程序就会在每天的 9:30 分运行一次。</p><h3 id="服务器遭受攻击后的处理过程"><a href="#服务器遭受攻击后的处理过程" class="headerlink" title="服务器遭受攻击后的处理过程"></a><strong>服务器遭受攻击后的处理过程</strong></h3><p>安全总是相对的，再安全的服务器也有可能遭受到攻击。</p><p>作为一个安全运维人员，要把握的原则是：尽量做好系统安全防护，修复所有已知的危险行为，同时，在系统遭受攻击后能够迅速有效地处理攻击行为，最大限度地降低攻击对系统产生的影响。</p><h4 id="①处理服务器遭受攻击的一般思路"><a href="#①处理服务器遭受攻击的一般思路" class="headerlink" title="①处理服务器遭受攻击的一般思路"></a><strong>①处理服务器遭受攻击的一般思路</strong></h4><p>系统遭受攻击并不可怕，可怕的是面对攻击束手无策，下面就详细介绍下在服务器遭受攻击后的一般处理思路。</p><p><strong>切断网络：</strong>所有的攻击都来自于网络，因此，在得知系统正遭受黑客的攻击后，首先要做的就是断开服务器的网络连接，这样除了能切断攻击源之外，也能保护服务器所在网络的其他主机。</p><p><strong>查找攻击源：</strong>可以通过分析系统日志或登录日志文件，查看可疑信息，同时也要查看系统都打开了哪些端口，运行哪些进程，并通过这些进程分析哪些是可疑的程序。</p><p>这个过程要根据经验和综合判断能力进行追查和分析。下面会详细介绍这个过程的处理思路。</p><p><strong>分析入侵原因和途径：</strong>既然系统遭到入侵，那么原因是多方面的，可能是系统漏洞，也可能是程序漏洞。</p><p>一定要查清楚是哪个原因导致的，并且还要查清楚遭到攻击的途径，找到攻击源，因为只有知道了遭受攻击的原因和途径，才能删除攻击源同时进行漏洞的修复。</p><p><strong>备份用户数据：</strong>在服务器遭受攻击后，需要立刻备份服务器上的用户数据，同时也要查看这些数据中是否隐藏着攻击源。</p><p>如果攻击源在用户数据中，一定要彻底删除，然后将用户数据备份到一个安全的地方。</p><p><strong>重新安装系统：</strong>永远不要认为自己能彻底清除攻击源，因为没有人能比黑客更了解攻击程序。</p><p>在服务器遭到攻击后，最安全也最简单的方法就是重新安装系统，因为大部分攻击程序都会依附在系统文件或者内核中，所以重新安装系统才能彻底清除攻击源。</p><p><strong>修复程序或系统漏洞：</strong>在发现系统漏洞或者应用程序漏洞后，首先要做的就是修复系统漏洞或者更改程序 Bug，因为只有将程序的漏洞修复完毕才能正式在服务器上运行。</p><p><strong>恢复数据和连接网络：</strong>将备份的数据重新复制到新安装的服务器上，然后开启服务，最后将服务器开启网络连接，对外提供服务。</p><h4 id="②检查并锁定可疑用户"><a href="#②检查并锁定可疑用户" class="headerlink" title="②检查并锁定可疑用户"></a><strong>②检查并锁定可疑用户</strong></h4><p>当发现服务器遭受攻击后，首先要切断网络连接，但是在有些情况下，比如无法马上切断网络连接时，就必须登录系统查看是否有可疑用户。</p><p>如果有可疑用户登录了系统，那么需要马上将这个用户锁定，然后中断此用户的远程连接。</p><h4 id="③查看系统日志"><a href="#③查看系统日志" class="headerlink" title="③查看系统日志"></a><strong>③查看系统日志</strong></h4><p>查看系统日志是查找攻击源最好的方法，可查的系统日志有 /var/log/messages、/var/log/secure 等。</p><p>这两个日志文件可以记录软件的运行状态以及远程用户的登录状态，还可以查看每个用户目录下的 .bash_history 文件。</p><p>特别是 /root 目录下的 .bash_history 文件，这个文件中记录着用户执行的所有历史命令。</p><h4 id="④检查并关闭系统可疑进程"><a href="#④检查并关闭系统可疑进程" class="headerlink" title="④检查并关闭系统可疑进程"></a><strong>④检查并关闭系统可疑进程</strong></h4><p>检查可疑进程的命令很多，例如 ps、top 等，但是有时候只知道进程的名称无法得知路径，此时可以通过如下命令查看。</p><p>首先通过 pidof 命令可以查找正在运行的进程 PID，例如要查找 sshd 进程的 PID。</p><p><strong>执行如下命令：</strong></p><pre><code>[root@server ~]# pidof sshd13276 12942 4284</code></pre><p>然后进入内存目录，查看对应 PID 目录下 exe 文件的信息：</p><pre><code>[root@server ~]# ls -al /proc/13276/exe lrwxrwxrwx 1 root root 0 Oct  4 22:09 /proc/13276/exe -&gt; /usr/sbin/sshd</code></pre><p>这样就找到了进程对应的完整执行路径。如果还要查看文件的句柄，可以查看如下目录：</p><pre><code>[root@server ~]# ls -al /proc/13276/fd</code></pre><p>通过这种方式基本可以找到任何进程的完整执行信息。</p><h4 id="⑤检查文件系统的完好性"><a href="#⑤检查文件系统的完好性" class="headerlink" title="⑤检查文件系统的完好性"></a><strong>⑤检查文件系统的完好性</strong></h4><p>检查文件属性是否发生变化是验证文件系统完好性最简单、最直接的方法，例如可以检查被入侵服务器上 /bin/ls 文件的大小是否与正常系统上此文件的大小相同，以验证文件是否被替换，但是这种方法比较低级。</p><p><strong>此时可以借助于 Linux 下 rpm 这个工具来完成验证，操作如下：</strong></p><pre><code>[root@server ~]# rpm -Va....L...  c /etc/pam.d/system-authS.5.....  c /etc/security/limits.confS.5....T  c /etc/sysctl.confS.5....T    /etc/sgml/docbook-simple.catS.5....T  c /etc/login.defsS.5.....  c /etc/openldap/ldap.confS.5....T  c /etc/sudoers</code></pre><h4 id="⑥重新安装系统恢复数据"><a href="#⑥重新安装系统恢复数据" class="headerlink" title="⑥重新安装系统恢复数据"></a><strong>⑥重新安装系统恢复数据</strong></h4><p>很多情况下，被攻击过的系统已经不再可信任，因此，最好的方法是将服务器上面数据进行备份，然后重新安装系统，最后再恢复数据即可。</p><p>数据恢复完成，马上对系统做上面介绍的安全加固策略，保证系统安全。</p><blockquote><p>原文链接如下：</p><p><a href="https://www.cnblogs.com/MYSQLZOUQI/p/5317916.html" target="_blank" rel="noopener">https://www.cnblogs.com/MYSQLZOUQI/p/5317916.html</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tmux-初探</title>
      <link href="2019/09/05/linux/rang-ni-de-linux-ku-qi-lai-xiao-bai-ye-neng-wan-zhuan-tmux/"/>
      <url>2019/09/05/linux/rang-ni-de-linux-ku-qi-lai-xiao-bai-ye-neng-wan-zhuan-tmux/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="Linux终端复用神器-tmux初探"><a href="#Linux终端复用神器-tmux初探" class="headerlink" title="Linux终端复用神器-tmux初探"></a>Linux终端复用神器-tmux初探</h3><pre><code>Tmux是一个优秀的终端复用软件，类似GNU Screen，但来自于OpenBSD，采用BSD授权。使用它最直观的好处就是，通过一个终端登录远程主机并运行tmux后，在其中可以开启多个控制台而无需再“浪费”多余的终端来连接这台远程主机。是BSD实现的Screen替代品，相对于Screen，它更加先进：支持屏幕切分，而且具备丰富的命令行参数，使其可以灵活、动态的进行各种布局和操作。</code></pre><p>废话不多说来个效果图<br><img src="https://i.loli.net/2018/12/14/5c139f4ab6ad2.jpg" alt="tmux"></p><h3 id="Tmux的使用场景"><a href="#Tmux的使用场景" class="headerlink" title="Tmux的使用场景"></a>Tmux的使用场景</h3><pre><code>1）可以某个程序在执行时一直是输出状态，需要结合nohup、&amp;来放在后台执行，并且ctrl+c结束。这时可以打开一个Tmux窗口，在该窗口里执行这个程序，用来保证该程序一直在执行中，只要Tmux这个窗口不关闭2）公司需要备份数据库时，数据量巨大，备份两三天弄不完，这时不小心关闭了终端窗口或误操作就前功尽弃了，使用Tmux会话运行命令或任务，就不用担心这些问题。3）下班后，你需要断开ssh或关闭电脑，将运行的命令或任务放置后台运行。4）关闭终端,再次打开时原终端里面的任务进程依然不会中断</code></pre><h3 id="Tmux功能："><a href="#Tmux功能：" class="headerlink" title="Tmux功能："></a>Tmux功能：</h3><pre><code>-  提供了强劲的、易于使用的命令行界面。-  可横向和纵向分割窗口。-  窗格可以自由移动和调整大小，或直接利用四个预设布局之一。-  支持 UTF-8 编码及 256 色终端。-  可在多个缓冲区进行复制和粘贴。-  可通过交互式菜单来选择窗口、会话及客户端。-  支持跨窗口搜索。-  支持自动及手动锁定窗口。</code></pre><h3 id="Tmux安装"><a href="#Tmux安装" class="headerlink" title="Tmux安装"></a>Tmux安装</h3><pre><code>yum -y install tmux</code></pre><h3 id="Tmux个性化配置"><a href="#Tmux个性化配置" class="headerlink" title="Tmux个性化配置"></a>Tmux个性化配置</h3><pre><code>此类配置可以在命令行模式中输入show-options -g查询tmux加上下列参数,实现个性化设置set-option -g base-index 1                        # 窗口的初始序号；默认为0，这里设置为1set-option -g display-time 5000                   # 提示信息的持续时间；设置足够的时间以避免看不清提示，单位为毫秒set-option -g repeat-time 1000                    # 控制台激活后的持续时间；设置合适的时间以避免每次操作都要先激活控制台，单位为毫秒set-option -g status-keys vi                      # 操作状态栏时的默认键盘布局；可以设置为vi或emacsset-option -g status-utf8 on                      # 开启状态栏的UTF-8支持---set-option -g status-bg blueset-option -g status-fg &#39;#bbbbbb&#39;set-option -g status-left-fg greenset-option -g status-left-bg blueset-option -g status-right-fg greenset-option -g status-right-bg blueset-option -g status-left-length 10               # 状态栏左方的内容长度；set-option -g status-right-length 15              # 状态栏右方的内容长度；建议把更多的空间留给状态栏左方（用于列出当前窗口）set-option -g status-left &#39;[#(whoami)]&#39;           # 状态栏左方的内容set-option -g status-right &#39;[#(date +&quot; %m-%d %H:%M &quot;)]&#39;     # 状态栏右方的内容；这里的设置将得到类似23:59的显示set-option -g status-justify &quot;centre&quot;             # 窗口列表居中显示set-option -g default-terminal &quot;screen-256color&quot;  # 支持256色显示分割窗口边界的颜色set-option -g pane-active-border-fg &#39;#55ff55&#39;set-option -g pane-border-fg &#39;#555555&#39;---此类设置可以在命令行模式中输入show-window-options -g查询set-window-option -g mode-keys vi    # 复制模式中的默认键盘布局；可以设置为vi或emacsset-window-option -g utf8 on         # 开启窗口的UTF-8支持set-window-option -g mode-mouse on   # 窗口切换后让人可以用鼠标上下滑动显示历史输出---窗口切分快捷键(没设置成功)bind \ split-window -h                      # 使用 \ 将窗口竖切bind - split-window -v                      # 使用 - 将窗口横切bind K confirm-before -p &quot;kill-window #W? (y/n)&quot; kill-window    # 使用大写 K 来关闭窗口bind &#39;&quot;&#39; choose-window                      # 双引号选择窗口---Pane之间切换的快捷键bind h select-pane -L                       # 定位到左边窗口的快捷键bind j select-pane -D                       # 定位到上边窗口的快捷键bind k select-pane -U                       # 定位到下方窗口的快捷键bind l select-pane -R                       # 定位到右边窗口的快捷键---设置window属性setw -g window-status-current-bg redsetw -g window-status-current-fg whitesetw -g window-status-current-attr brightsetw -g window-status-attr brightset-option -g window-status-format &#39;#I #W&#39;set-option -g window-status-current-format &#39; #I #W &#39;setw -g window-status-current-bg bluesetw -g window-status-current-fg green不使用prefix键，使用Ctrl和左右方向键方便切换窗口bind-key -n &quot;C-Left&quot; select-window -t :-bind-key -n &quot;C-Right&quot; select-window -t :+</code></pre><h3 id="tmux-session-使用介绍"><a href="#tmux-session-使用介绍" class="headerlink" title="tmux session 使用介绍"></a>tmux session 使用介绍</h3><pre><code>运行tmux并开启一个新的会话tmux显示所有会话tmux ls新建会话并指定会话名称（建议制定会话名称，以便了解该会话用途）tmux new -s &lt;session-name&gt;新建会话（不指定会话名称）tmux new接入上一个会话tmux a接入指定名称的会话tmux a -t &lt;session-name&gt;断开当前会话（还可以使用快捷键：control+b，再按d）tmux detach关闭指定会话tmux kill-session -t session-name关闭除指定会话外的所有会话tmux kill-session -a -t session-name在会话中切换control+b，再按s 显示会话列表，再进行会话切换销毁所有会话并停止tmuxtmux kill-serverG复制粘贴Ctrl+b   [          //进入复制模式空格+方向键      //选择回车                  //  确认Ctrl+b  [           //粘贴</code></pre><h3 id="需要注意的几点"><a href="#需要注意的几点" class="headerlink" title="需要注意的几点"></a>需要注意的几点</h3><pre><code>1）进入tmux面板后，一定要先按ctrl+b，然后松开，再按其他的组合键才生效。2）常用到的几个组合键：ctrl+b ?            显示快捷键帮助ctrl+b 空格键       采用下一个内置布局，这个很有意思，在多屏时，用这个就会将多有屏幕竖着展示ctrl+b !            把当前窗口变为新窗口ctrl+b  &quot;           模向分隔窗口ctrl+b %            纵向分隔窗口ctrl+b q            显示分隔窗口的编号ctrl+b o            跳到下一个分隔窗口。多屏之间的切换ctrl+b 上下键      上一个及下一个分隔窗口ctrl+b C-方向键    调整分隔窗口大小ctrl+b &amp;           确认后退出当前tmuxctrl+b [           复制模式，即将当前屏幕移到上一个的位置上，其他所有窗口都向前移动一个。ctrl+b c           创建新窗口ctrl+b n           选择下一个窗口ctrl+b l           最后使用的窗口ctrl+b p           选择前一个窗口ctrl+b w           以菜单方式显示及选择窗口ctrl+b s           以菜单方式显示和选择会话。这个常用到，可以选择进入哪个tmuxctrl+b t           显示时钟。然后按enter键后就会恢复到shell终端状态ctrl+b d           脱离当前会话；这样可以暂时返回Shell界面，输入tmux attach能够重新进入之前的会话</code></pre><h3 id="tmux的常规运维命令"><a href="#tmux的常规运维命令" class="headerlink" title="tmux的常规运维命令"></a>tmux的常规运维命令</h3><pre><code>1）安装命令：　[root@---title: tmux-初探date: 2018-12-07 13:59:25tags:  - tmux  - 骚操作---### Linux终端复用神器-tmux初探​```Tmux是一个优秀的终端复用软件，类似GNU Screen，但来自于OpenBSD，采用BSD授权。使用它最直观的好处就是，通过一个终端登录远程主机并运行tmux后，在其中可以开启多个控制台而无需再“浪费”多余的终端来连接这台远程主机。是BSD实现的Screen替代品，相对于Screen，它更加先进：支持屏幕切分，而且具备丰富的命令行参数，使其可以灵活、动态的进行各种布局和操作。​```废话不多说来个效果图![tmux](https://i.loli.net/2018/12/14/5c139f4ab6ad2.jpg)### Tmux的使用场景​```1）可以某个程序在执行时一直是输出状态，需要结合nohup、&amp;来放在后台执行，并且ctrl+c结束。这时可以打开一个Tmux窗口，在该窗口里执行这个程序，用来保证该程序一直在执行中，只要Tmux这个窗口不关闭2）公司需要备份数据库时，数据量巨大，备份两三天弄不完，这时不小心关闭了终端窗口或误操作就前功尽弃了，使用Tmux会话运行命令或任务，就不用担心这些问题。3）下班后，你需要断开ssh或关闭电脑，将运行的命令或任务放置后台运行。4）关闭终端,再次打开时原终端里面的任务进程依然不会中断​```&lt;!--more--&gt;### Tmux功能：​```-  提供了强劲的、易于使用的命令行界面。-  可横向和纵向分割窗口。-  窗格可以自由移动和调整大小，或直接利用四个预设布局之一。-  支持 UTF-8 编码及 256 色终端。-  可在多个缓冲区进行复制和粘贴。-  可通过交互式菜单来选择窗口、会话及客户端。-  支持跨窗口搜索。-  支持自动及手动锁定窗口。​```### Tmux安装​```yum -y install tmux​```### Tmux个性化配置​```此类配置可以在命令行模式中输入show-options -g查询tmux加上下列参数,实现个性化设置set-option -g base-index 1                        # 窗口的初始序号；默认为0，这里设置为1set-option -g display-time 5000                   # 提示信息的持续时间；设置足够的时间以避免看不清提示，单位为毫秒set-option -g repeat-time 1000                    # 控制台激活后的持续时间；设置合适的时间以避免每次操作都要先激活控制台，单位为毫秒set-option -g status-keys vi                      # 操作状态栏时的默认键盘布局；可以设置为vi或emacsset-option -g status-utf8 on                      # 开启状态栏的UTF-8支持---set-option -g status-bg blueset-option -g status-fg &#39;#bbbbbb&#39;set-option -g status-left-fg greenset-option -g status-left-bg blueset-option -g status-right-fg greenset-option -g status-right-bg blueset-option -g status-left-length 10               # 状态栏左方的内容长度；set-option -g status-right-length 15              # 状态栏右方的内容长度；建议把更多的空间留给状态栏左方（用于列出当前窗口）set-option -g status-left &#39;[#(whoami)]&#39;           # 状态栏左方的内容set-option -g status-right &#39;[#(date +&quot; %m-%d %H:%M &quot;)]&#39;     # 状态栏右方的内容；这里的设置将得到类似23:59的显示set-option -g status-justify &quot;centre&quot;             # 窗口列表居中显示set-option -g default-terminal &quot;screen-256color&quot;  # 支持256色显示分割窗口边界的颜色set-option -g pane-active-border-fg &#39;#55ff55&#39;set-option -g pane-border-fg &#39;#555555&#39;---此类设置可以在命令行模式中输入show-window-options -g查询set-window-option -g mode-keys vi    # 复制模式中的默认键盘布局；可以设置为vi或emacsset-window-option -g utf8 on         # 开启窗口的UTF-8支持set-window-option -g mode-mouse on   # 窗口切换后让人可以用鼠标上下滑动显示历史输出---窗口切分快捷键(没设置成功)bind \ split-window -h                      # 使用 \ 将窗口竖切bind - split-window -v                      # 使用 - 将窗口横切bind K confirm-before -p &quot;kill-window #W? (y/n)&quot; kill-window    # 使用大写 K 来关闭窗口bind &#39;&quot;&#39; choose-window                      # 双引号选择窗口---Pane之间切换的快捷键bind h select-pane -L                       # 定位到左边窗口的快捷键bind j select-pane -D                       # 定位到上边窗口的快捷键bind k select-pane -U                       # 定位到下方窗口的快捷键bind l select-pane -R                       # 定位到右边窗口的快捷键---设置window属性setw -g window-status-current-bg redsetw -g window-status-current-fg whitesetw -g window-status-current-attr brightsetw -g window-status-attr brightset-option -g window-status-format &#39;#I #W&#39;set-option -g window-status-current-format &#39; #I #W &#39;setw -g window-status-current-bg bluesetw -g window-status-current-fg green不使用prefix键，使用Ctrl和左右方向键方便切换窗口bind-key -n &quot;C-Left&quot; select-window -t :-bind-key -n &quot;C-Right&quot; select-window -t :+​```### tmux session 使用介绍​```运行tmux并开启一个新的会话tmux显示所有会话tmux ls新建会话并指定会话名称（建议制定会话名称，以便了解该会话用途）tmux new -s &lt;session-name&gt;新建会话（不指定会话名称）tmux new接入上一个会话tmux a接入指定名称的会话tmux a -t &lt;session-name&gt;断开当前会话（还可以使用快捷键：control+b，再按d）tmux detach关闭指定会话tmux kill-session -t session-name关闭除指定会话外的所有会话tmux kill-session -a -t session-name在会话中切换control+b，再按s 显示会话列表，再进行会话切换销毁所有会话并停止tmuxtmux kill-serverG复制粘贴Ctrl+b   [          //进入复制模式空格+方向键      //选择回车                  //  确认Ctrl+b  [           //粘贴​```### 需要注意的几点​```1）进入tmux面板后，一定要先按ctrl+b，然后松开，再按其他的组合键才生效。2）常用到的几个组合键：ctrl+b ?            显示快捷键帮助ctrl+b 空格键       采用下一个内置布局，这个很有意思，在多屏时，用这个就会将多有屏幕竖着展示ctrl+b !            把当前窗口变为新窗口ctrl+b  &quot;           模向分隔窗口ctrl+b %            纵向分隔窗口ctrl+b q            显示分隔窗口的编号ctrl+b o            跳到下一个分隔窗口。多屏之间的切换ctrl+b 上下键      上一个及下一个分隔窗口ctrl+b C-方向键    调整分隔窗口大小ctrl+b &amp;           确认后退出当前tmuxctrl+b [           复制模式，即将当前屏幕移到上一个的位置上，其他所有窗口都向前移动一个。ctrl+b c           创建新窗口ctrl+b n           选择下一个窗口ctrl+b l           最后使用的窗口ctrl+b p           选择前一个窗口ctrl+b w           以菜单方式显示及选择窗口ctrl+b s           以菜单方式显示和选择会话。这个常用到，可以选择进入哪个tmuxctrl+b t           显示时钟。然后按enter键后就会恢复到shell终端状态ctrl+b d           脱离当前会话；这样可以暂时返回Shell界面，输入tmux attach能够重新进入之前的会话​```### tmux的常规运维命令​```1）安装命令：　[root@Centos6 ~]# yum -y install tmux　　2）默认创建一个会话，以数字命名。（不推荐）[root@Centos6 ~]# tmux　　3）新建会话，比如新创建一个会话以&quot;ccc&quot;命名[root@Centos6 ~]# tmux new -s ccc加上参数-d，表示在后台新建会话root@bobo:~# tmux new -s shibo -droot@bobo:~# tmux lsshibo: 1 windows (created Tue Oct  2 19:22:32 2018) [135x35]4）查看创建得所有会话[root@Centos6 ~]# tmux ls0: 1 windows (created Wed Aug 30 17:58:20 2017) [112x22](attached)    #这里的attached表示该会话是当前会话aaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22]ccc: 1 windows (created Wed Aug 30 17:01:05 2017) [112x22]5）登录一个已知会话。即从终端环境进入会话。第一个参数a也可以写成attach。后面的aaa是会话名称。[root@Centos6 ~]# tmux a -t aaa 　　6）退出会话不是关闭：登到某一个会话后，依次按键ctrl-b + d，这样就会退化该会话，但不会关闭会话。如果直接ctrl + d，就会在退出会话的通话也关闭了该会话！7）关闭会话（销毁会话）[root@Centos6 ~]# tmux lsaaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22]bbb: 1 windows (created Wed Aug 30 19:02:09 2017) [112x22][root@Centos6 ~]# tmux kill-session -t bbb[root@Centos6 ~]# tmux lsaaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22]8）重命名会话[root@Centos6 ~]# tmux ls  wangshibo: 1 windows (created Sun Sep 30 10:17:00 2018) [136x29] (attached)[root@Centos6 ~]# tmux rename -t wangshibo kevin[root@Centos6 ~]# tmux lskevin: 1 windows (created Sun Sep 30 10:17:00 2018) [136x29] (attached)​```---title: tmux-初探date: 2018-12-07 13:59:25tags:  - tmux  - 骚操作---### Linux终端复用神器-tmux初探​```Tmux是一个优秀的终端复用软件，类似GNU Screen，但来自于OpenBSD，采用BSD授权。使用它最直观的好处就是，通过一个终端登录远程主机并运行tmux后，在其中可以开启多个控制台而无需再“浪费”多余的终端来连接这台远程主机。是BSD实现的Screen替代品，相对于Screen，它更加先进：支持屏幕切分，而且具备丰富的命令行参数，使其可以灵活、动态的进行各种布局和操作。​```废话不多说来个效果图![tmux](https://i.loli.net/2018/12/14/5c139f4ab6ad2.jpg)### Tmux的使用场景​```1）可以某个程序在执行时一直是输出状态，需要结合nohup、&amp;来放在后台执行，并且ctrl+c结束。这时可以打开一个Tmux窗口，在该窗口里执行这个程序，用来保证该程序一直在执行中，只要Tmux这个窗口不关闭2）公司需要备份数据库时，数据量巨大，备份两三天弄不完，这时不小心关闭了终端窗口或误操作就前功尽弃了，使用Tmux会话运行命令或任务，就不用担心这些问题。3）下班后，你需要断开ssh或关闭电脑，将运行的命令或任务放置后台运行。4）关闭终端,再次打开时原终端里面的任务进程依然不会中断​```&lt;!--more--&gt;### Tmux功能：​```-  提供了强劲的、易于使用的命令行界面。-  可横向和纵向分割窗口。-  窗格可以自由移动和调整大小，或直接利用四个预设布局之一。-  支持 UTF-8 编码及 256 色终端。-  可在多个缓冲区进行复制和粘贴。-  可通过交互式菜单来选择窗口、会话及客户端。-  支持跨窗口搜索。-  支持自动及手动锁定窗口。​```### Tmux安装​```yum -y install tmux​```### Tmux个性化配置​```此类配置可以在命令行模式中输入show-options -g查询tmux加上下列参数,实现个性化设置set-option -g base-index 1                        # 窗口的初始序号；默认为0，这里设置为1set-option -g display-time 5000                   # 提示信息的持续时间；设置足够的时间以避免看不清提示，单位为毫秒set-option -g repeat-time 1000                    # 控制台激活后的持续时间；设置合适的时间以避免每次操作都要先激活控制台，单位为毫秒set-option -g status-keys vi                      # 操作状态栏时的默认键盘布局；可以设置为vi或emacsset-option -g status-utf8 on                      # 开启状态栏的UTF-8支持---set-option -g status-bg blueset-option -g status-fg &#39;#bbbbbb&#39;set-option -g status-left-fg greenset-option -g status-left-bg blueset-option -g status-right-fg greenset-option -g status-right-bg blueset-option -g status-left-length 10               # 状态栏左方的内容长度；set-option -g status-right-length 15              # 状态栏右方的内容长度；建议把更多的空间留给状态栏左方（用于列出当前窗口）set-option -g status-left &#39;[#(whoami)]&#39;           # 状态栏左方的内容set-option -g status-right &#39;[#(date +&quot; %m-%d %H:%M &quot;)]&#39;     # 状态栏右方的内容；这里的设置将得到类似23:59的显示set-option -g status-justify &quot;centre&quot;             # 窗口列表居中显示set-option -g default-terminal &quot;screen-256color&quot;  # 支持256色显示分割窗口边界的颜色set-option -g pane-active-border-fg &#39;#55ff55&#39;set-option -g pane-border-fg &#39;#555555&#39;---此类设置可以在命令行模式中输入show-window-options -g查询set-window-option -g mode-keys vi    # 复制模式中的默认键盘布局；可以设置为vi或emacsset-window-option -g utf8 on         # 开启窗口的UTF-8支持set-window-option -g mode-mouse on   # 窗口切换后让人可以用鼠标上下滑动显示历史输出---窗口切分快捷键(没设置成功)bind \ split-window -h                      # 使用 \ 将窗口竖切bind - split-window -v                      # 使用 - 将窗口横切bind K confirm-before -p &quot;kill-window #W? (y/n)&quot; kill-window    # 使用大写 K 来关闭窗口bind &#39;&quot;&#39; choose-window                      # 双引号选择窗口---Pane之间切换的快捷键bind h select-pane -L                       # 定位到左边窗口的快捷键bind j select-pane -D                       # 定位到上边窗口的快捷键bind k select-pane -U                       # 定位到下方窗口的快捷键bind l select-pane -R                       # 定位到右边窗口的快捷键---设置window属性setw -g window-status-current-bg redsetw -g window-status-current-fg whitesetw -g window-status-current-attr brightsetw -g window-status-attr brightset-option -g window-status-format &#39;#I #W&#39;set-option -g window-status-current-format &#39; #I #W &#39;setw -g window-status-current-bg bluesetw -g window-status-current-fg green不使用prefix键，使用Ctrl和左右方向键方便切换窗口bind-key -n &quot;C-Left&quot; select-window -t :-bind-key -n &quot;C-Right&quot; select-window -t :+​```### tmux session 使用介绍​```运行tmux并开启一个新的会话tmux显示所有会话tmux ls新建会话并指定会话名称（建议制定会话名称，以便了解该会话用途）tmux new -s &lt;session-name&gt;新建会话（不指定会话名称）tmux new接入上一个会话tmux a接入指定名称的会话tmux a -t &lt;session-name&gt;断开当前会话（还可以使用快捷键：control+b，再按d）tmux detach关闭指定会话tmux kill-session -t session-name关闭除指定会话外的所有会话tmux kill-session -a -t session-name在会话中切换control+b，再按s 显示会话列表，再进行会话切换销毁所有会话并停止tmuxtmux kill-serverG复制粘贴Ctrl+b   [          //进入复制模式空格+方向键      //选择回车                  //  确认Ctrl+b  [           //粘贴​```### 需要注意的几点​```1）进入tmux面板后，一定要先按ctrl+b，然后松开，再按其他的组合键才生效。2）常用到的几个组合键：ctrl+b ?            显示快捷键帮助ctrl+b 空格键       采用下一个内置布局，这个很有意思，在多屏时，用这个就会将多有屏幕竖着展示ctrl+b !            把当前窗口变为新窗口ctrl+b  &quot;           模向分隔窗口ctrl+b %            纵向分隔窗口ctrl+b q            显示分隔窗口的编号ctrl+b o            跳到下一个分隔窗口。多屏之间的切换ctrl+b 上下键      上一个及下一个分隔窗口ctrl+b C-方向键    调整分隔窗口大小ctrl+b &amp;           确认后退出当前tmuxctrl+b [           复制模式，即将当前屏幕移到上一个的位置上，其他所有窗口都向前移动一个。ctrl+b c           创建新窗口ctrl+b n           选择下一个窗口ctrl+b l           最后使用的窗口ctrl+b p           选择前一个窗口ctrl+b w           以菜单方式显示及选择窗口ctrl+b s           以菜单方式显示和选择会话。这个常用到，可以选择进入哪个tmuxctrl+b t           显示时钟。然后按enter键后就会恢复到shell终端状态ctrl+b d           脱离当前会话；这样可以暂时返回Shell界面，输入tmux attach能够重新进入之前的会话​```### tmux的常规运维命令​```1）安装命令：　[root@---title: tmux-初探date: 2018-12-07 13:59:25tags:  - tmux  - 骚操作---### Linux终端复用神器-tmux初探​```Tmux是一个优秀的终端复用软件，类似GNU Screen，但来自于OpenBSD，采用BSD授权。使用它最直观的好处就是，通过一个终端登录远程主机并运行tmux后，在其中可以开启多个控制台而无需再“浪费”多余的终端来连接这台远程主机。是BSD实现的Screen替代品，相对于Screen，它更加先进：支持屏幕切分，而且具备丰富的命令行参数，使其可以灵活、动态的进行各种布局和操作。​```废话不多说来个效果图![tmux](https://i.loli.net/2018/12/14/5c139f4ab6ad2.jpg)### Tmux的使用场景​```1）可以某个程序在执行时一直是输出状态，需要结合nohup、&amp;来放在后台执行，并且ctrl+c结束。这时可以打开一个Tmux窗口，在该窗口里执行这个程序，用来保证该程序一直在执行中，只要Tmux这个窗口不关闭2）公司需要备份数据库时，数据量巨大，备份两三天弄不完，这时不小心关闭了终端窗口或误操作就前功尽弃了，使用Tmux会话运行命令或任务，就不用担心这些问题。3）下班后，你需要断开ssh或关闭电脑，将运行的命令或任务放置后台运行。4）关闭终端,再次打开时原终端里面的任务进程依然不会中断​```&lt;!--more--&gt;### Tmux功能：​```-  提供了强劲的、易于使用的命令行界面。-  可横向和纵向分割窗口。-  窗格可以自由移动和调整大小，或直接利用四个预设布局之一。-  支持 UTF-8 编码及 256 色终端。-  可在多个缓冲区进行复制和粘贴。-  可通过交互式菜单来选择窗口、会话及客户端。-  支持跨窗口搜索。-  支持自动及手动锁定窗口。​```### Tmux安装​```yum -y install tmux​```### Tmux个性化配置​```此类配置可以在命令行模式中输入show-options -g查询tmux加上下列参数,实现个性化设置set-option -g base-index 1                        # 窗口的初始序号；默认为0，这里设置为1set-option -g display-time 5000                   # 提示信息的持续时间；设置足够的时间以避免看不清提示，单位为毫秒set-option -g repeat-time 1000                    # 控制台激活后的持续时间；设置合适的时间以避免每次操作都要先激活控制台，单位为毫秒set-option -g status-keys vi                      # 操作状态栏时的默认键盘布局；可以设置为vi或emacsset-option -g status-utf8 on                      # 开启状态栏的UTF-8支持---set-option -g status-bg blueset-option -g status-fg &#39;#bbbbbb&#39;set-option -g status-left-fg greenset-option -g status-left-bg blueset-option -g status-right-fg greenset-option -g status-right-bg blueset-option -g status-left-length 10               # 状态栏左方的内容长度；set-option -g status-right-length 15              # 状态栏右方的内容长度；建议把更多的空间留给状态栏左方（用于列出当前窗口）set-option -g status-left &#39;[#(whoami)]&#39;           # 状态栏左方的内容set-option -g status-right &#39;[#(date +&quot; %m-%d %H:%M &quot;)]&#39;     # 状态栏右方的内容；这里的设置将得到类似23:59的显示set-option -g status-justify &quot;centre&quot;             # 窗口列表居中显示set-option -g default-terminal &quot;screen-256color&quot;  # 支持256色显示分割窗口边界的颜色set-option -g pane-active-border-fg &#39;#55ff55&#39;set-option -g pane-border-fg &#39;#555555&#39;---此类设置可以在命令行模式中输入show-window-options -g查询set-window-option -g mode-keys vi    # 复制模式中的默认键盘布局；可以设置为vi或emacsset-window-option -g utf8 on         # 开启窗口的UTF-8支持set-window-option -g mode-mouse on   # 窗口切换后让人可以用鼠标上下滑动显示历史输出---窗口切分快捷键(没设置成功)bind \ split-window -h                      # 使用 \ 将窗口竖切bind - split-window -v                      # 使用 - 将窗口横切bind K confirm-before -p &quot;kill-window #W? (y/n)&quot; kill-window    # 使用大写 K 来关闭窗口bind &#39;&quot;&#39; choose-window                      # 双引号选择窗口---Pane之间切换的快捷键bind h select-pane -L                       # 定位到左边窗口的快捷键bind j select-pane -D                       # 定位到上边窗口的快捷键bind k select-pane -U                       # 定位到下方窗口的快捷键bind l select-pane -R                       # 定位到右边窗口的快捷键---设置window属性setw -g window-status-current-bg redsetw -g window-status-current-fg whitesetw -g window-status-current-attr brightsetw -g window-status-attr brightset-option -g window-status-format &#39;#I #W&#39;set-option -g window-status-current-format &#39; #I #W &#39;setw -g window-status-current-bg bluesetw -g window-status-current-fg green不使用prefix键，使用Ctrl和左右方向键方便切换窗口bind-key -n &quot;C-Left&quot; select-window -t :-bind-key -n &quot;C-Right&quot; select-window -t :+​```### tmux session 使用介绍​```运行tmux并开启一个新的会话tmux显示所有会话tmux ls新建会话并指定会话名称（建议制定会话名称，以便了解该会话用途）tmux new -s &lt;session-name&gt;新建会话（不指定会话名称）tmux new接入上一个会话tmux a接入指定名称的会话tmux a -t &lt;session-name&gt;断开当前会话（还可以使用快捷键：control+b，再按d）tmux detach关闭指定会话tmux kill-session -t session-name关闭除指定会话外的所有会话tmux kill-session -a -t session-name在会话中切换control+b，再按s 显示会话列表，再进行会话切换销毁所有会话并停止tmuxtmux kill-serverG复制粘贴Ctrl+b   [          //进入复制模式空格+方向键      //选择回车                  //  确认Ctrl+b  [           //粘贴​```### 需要注意的几点​```1）进入tmux面板后，一定要先按ctrl+b，然后松开，再按其他的组合键才生效。2）常用到的几个组合键：ctrl+b ?            显示快捷键帮助ctrl+b 空格键       采用下一个内置布局，这个很有意思，在多屏时，用这个就会将多有屏幕竖着展示ctrl+b !            把当前窗口变为新窗口ctrl+b  &quot;           模向分隔窗口ctrl+b %            纵向分隔窗口ctrl+b q            显示分隔窗口的编号ctrl+b o            跳到下一个分隔窗口。多屏之间的切换ctrl+b 上下键      上一个及下一个分隔窗口ctrl+b C-方向键    调整分隔窗口大小ctrl+b &amp;           确认后退出当前tmuxctrl+b [           复制模式，即将当前屏幕移到上一个的位置上，其他所有窗口都向前移动一个。ctrl+b c           创建新窗口ctrl+b n           选择下一个窗口ctrl+b l           最后使用的窗口ctrl+b p           选择前一个窗口ctrl+b w           以菜单方式显示及选择窗口ctrl+b s           以菜单方式显示和选择会话。这个常用到，可以选择进入哪个tmuxctrl+b t           显示时钟。然后按enter键后就会恢复到shell终端状态ctrl+b d           脱离当前会话；这样可以暂时返回Shell界面，输入tmux attach能够重新进入之前的会话​```### tmux的常规运维命令​```1）安装命令：　[root@1000phone ~]# yum -y install tmux　　2）默认创建一个会话，以数字命名。（不推荐）[root@1000phone ~]# tmux　　3）新建会话，比如新创建一个会话以&quot;ccc&quot;命名[root@1000phone ~]# tmux new -s ccc加上参数-d，表示在后台新建会话root@1000phone:~# tmux new -s 1000phone -droot@1000phone:~# tmux ls1000phone: 1 windows (created Tue Oct  2 19:22:32 2018) [135x35]4）查看创建得所有会话[root@1000phone ~]# tmux ls0: 1 windows (created Wed Aug 30 17:58:20 2017) [112x22](attached)    #这里的attached表示该会话是当前会话1000phone: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22]ccc: 1 windows (created Wed Aug 30 17:01:05 2017) [112x22]5）登录一个已知会话。即从终端环境进入会话。第一个参数a也可以写成attach。后面的aaa是会话名称。[root@1000phone ~]# tmux a -t 1000phone 　　6）退出会话不是关闭：登到某一个会话后，依次按键ctrl-b + d，这样就会退化该会话，但不会关闭会话。如果直接ctrl + d，就会在退出会话的通话也关闭了该会话！7）关闭会话（销毁会话）[root@1000phone ~]# tmux ls1000phone: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22]bbb: 1 windows (created Wed Aug 30 19:02:09 2017) [112x22][root@1000phone ~]# tmux kill-session -t bbb[root@1000phone ~]# tmux ls1000phone: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22]8）重命名会话[root@1000phone ~]# tmux ls  tigerfive: 1 windows (created Sun Sep 30 10:17:00 2018) [136x29] (attached)[root@1000phone ~]# tmux rename -t tigerfive 1000phone[root@Centos6 ~]# tmux ls1000phone: 1 windows (created Sun Sep 30 10:17:00 2018) [136x29] (attached)​``` ~]# yum -y install tmux　　2）默认创建一个会话，以数字命名。（不推荐）[root@1000phone ~]# tmux　　3）新建会话，比如新创建一个会话以&quot;ccc&quot;命名[root@1000phone ~]# tmux new -s ccc加上参数-d，表示在后台新建会话root@1000phone:~# tmux new -s 1000phone -droot@1000phone:~# tmux ls1000phone: 1 windows (created Tue Oct  2 19:22:32 2018) [135x35]4）查看创建得所有会话[root@1000phone ~]# tmux ls0: 1 windows (created Wed Aug 30 17:58:20 2017) [112x22](attached)    #这里的attached表示该会话是当前会话aaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22]ccc: 1 windows (created Wed Aug 30 17:01:05 2017) [112x22]5）登录一个已知会话。即从终端环境进入会话。第一个参数a也可以写成attach。后面的aaa是会话名称。[root@1000phone ~]# tmux a -t aaa 　　6）退出会话不是关闭：登到某一个会话后，依次按键ctrl-b + d，这样就会退化该会话，但不会关闭会话。如果直接ctrl + d，就会在退出会话的通话也关闭了该会话！7）关闭会话（销毁会话）[root@1000phone ~]# tmux lsaaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22]bbb: 1 windows (created Wed Aug 30 19:02:09 2017) [112x22][root@1000phone ~]# tmux kill-session -t bbb[root@1000phone ~]# tmux lsaaa: 2 windows (created Wed Aug 30 16:54:33 2017) [112x22]8）重命名会话[root@1000phone ~]# tmux ls  wangshibo: 1 windows (created Sun Sep 30 10:17:00 2018) [136x29] (attached)[root@1000phone ~]# tmux rename -t wangshibo kevin[root@1000phone ~]# tmux lskevin: 1 windows (created Sun Sep 30 10:17:00 2018) [136x29] (attached)​```</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx压测和并发预估</title>
      <link href="2019/08/09/linux/nginx-ya-ce-he-bing-fa-yu-gu/"/>
      <url>2019/08/09/linux/nginx-ya-ce-he-bing-fa-yu-gu/</url>
      
        <content type="html"><![CDATA[<h1 id="Nginx压测和并发预估"><a href="#Nginx压测和并发预估" class="headerlink" title="Nginx压测和并发预估"></a>Nginx压测和并发预估</h1><h2 id="一-Nginx并发预估"><a href="#一-Nginx并发预估" class="headerlink" title="一.Nginx并发预估"></a>一.Nginx并发预估</h2><p>预估算法：<code>{（?G）*1024-system}/请求大小</code></p><blockquote><p>（?G）：表示内存大小<br>1024：表示内存容量标准进制<br>system：表示系统和服务占用的额外内存和需要预留的内存<br>请求大小：表示静态（一般为KB）或动态（一般为MB）的请求大小</p></blockquote><p>16核32G服务器，可以抗住4万多用于负载均衡的并发，最多可以抗住5-6万，跑满文件描述符。</p><h2 id="二-压测工具AB"><a href="#二-压测工具AB" class="headerlink" title="二.压测工具AB"></a>二.压测工具AB</h2><p>1.安装压力测试工具ab<br><code>yum install httpd-tools -y</code></p><p>2.了解压测工具使用方式<br><code>ab -n 200 -c 2 http://127.0.0.1/</code></p><p>//-n总的请求次数<br>//-c并发请求数<br>//-k是否开启长连接</p><p>3.参数详解<br><code>ab -n2000 -c2 http://127.0.0.1/index.html</code></p><pre><code>...Server Software:        nginx/1.12.2Server Hostname:        127.0.0.1Server Port:            80Document Path:          /index.htmlDocument Length:        19 bytesConcurrency Level:      200# 总花费总时长Time taken for tests:   1.013 seconds# 总请求数Complete requests:      2000# 请求失败数Failed requests:        0Write errors:           0Total transferred:      510000 bytesHTML transferred:       38000 bytes# 每秒多少请求/s(总请求出/总共完成的时间)Requests per second:    9333.23 [#/sec] (mean)# 客户端访问服务端, 单个请求所需花费的时间Time per request:       101.315 [ms] (mean)# 服务端处理请求的时间Time per request:       0.507 [ms] (mean, across all concurrent requests)# 判断网络传输速率, 观察网络是否存在瓶颈Transfer rate:          491.58 [Kbytes/sec] received</code></pre><h2 id="三-查看并发连接数和连接状态"><a href="#三-查看并发连接数和连接状态" class="headerlink" title="三.查看并发连接数和连接状态"></a>三.查看并发连接数和连接状态</h2><p>1.查看Web服务器（Nginx Apache）的并发请求数及其TCP连接状态</p><pre><code>netstat -n | awk &#39;/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}&#39;netstat -n | awk &#39;/^tcp/ {++state[$NF]} END {for(key in state) print key,&quot;t&quot;,state[key]}&#39;</code></pre><p>返回结果一般如下</p><pre><code>LAST_ACK 5 （正在等待处理的请求数）SYN_RECV 30ESTABLISHED 1597 （正常数据传输状态）FIN_WAIT1 51FIN_WAIT2 504TIME_WAIT 1057 （处理完毕，等待超时结束的请求数）</code></pre><p>其他参数说明</p><pre><code>CLOSED：无连接是活动的或正在进行LISTEN：服务器在等待进入呼叫SYN_RECV：一个连接请求已经到达，等待确认SYN_SENT：应用已经开始，打开一个连接ESTABLISHED：正常数据传输状态FIN_WAIT1：应用说它已经完成FIN_WAIT2：另一边已同意释放ITMED_WAIT：等待所有分组死掉CLOSING：两边同时尝试关闭TIME_WAIT：另一边已初始化一个释放LAST_ACK：等待所有分组死掉</code></pre><p>2.查看Nginx或apache的运行进程数</p><pre><code>ps -ef | grep nginx | wc -lps -ef | grep httpd | wc -l</code></pre><p>3.查看Web服务器进程连接数</p><pre><code>netstat -antp | grep 80 | grep ESTABLISHED -c</code></pre><hr>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx性能优化</title>
      <link href="2019/08/05/linux/nginx-xing-neng-you-hua/"/>
      <url>2019/08/05/linux/nginx-xing-neng-you-hua/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><p><img src="https://p6-tt.byteimg.com/large/pgc-image/95d788eda3ed45b58b6e982192a7a650" alt="img"></p><p>当我需要进行性能优化时，说明我们服务器无法满足日益增长的业务。性能优化是一个比较大的课题，需要从以下几个方面进行探讨</p><ul><li>当前系统结构瓶颈</li><li>了解业务模式</li><li>性能与安全</li></ul><h4 id="1、当前系统结构瓶颈"><a href="#1、当前系统结构瓶颈" class="headerlink" title="1、当前系统结构瓶颈"></a>1、当前系统结构瓶颈</h4><p>首先需要了解的是当前系统瓶颈，用的是什么，跑的是什么业务。里面的服务是什么样子，每个服务最大支持多少并发。比如针对nginx而言，我们处理静态资源效率最高的瓶颈是多大？能支持多少qps访问请求？怎么得出系统当前的结构瓶颈？</p><p>可以通过查看当前cpu负荷，内存使用率，进程使用率来做简单判断。还可以通过操作系统的一些工具来判断当前系统性能瓶颈，如分析对应的日志，查看请求数量。也可以通过nginx http_stub_status_module模块来查看对应的连接数，总握手次数，总请求数。也可以对线上进行压力测试，来了解当前的系统能性能，并发数，做好性能评估。</p><h4 id="2、了解业务模式"><a href="#2、了解业务模式" class="headerlink" title="2、了解业务模式"></a>2、了解业务模式</h4><p>虽然我们是在做性能优化，但还是要熟悉业务，最终目的都是为业务服务的。我们要了解每一个接口业务类型是什么样的业务，比如电子商务抢购模式，这种情况平时流量会很小，但是到了抢购时间，流量一下子就会猛涨。也要了解系统层级结构，每一层在中间层做的是代理还是动静分离，还是后台进行直接服务。需要我们对业务接入层和系统层次要有一个梳理</p><h4 id="3、性能与安全"><a href="#3、性能与安全" class="headerlink" title="3、性能与安全"></a>3、性能与安全</h4><p>性能与安全也是一个需要考虑的因素，往往大家注重性能忽略安全或注重安全又忽略性能。比如说我们在设计防火墙时，如果规则过于全面肯定会对性能方面有影响。如果对性能过于注重在安全方面肯定会留下很大隐患。所以大家要评估好两者的关系，把握好两者的孰重孰轻，以及整体的相关性。权衡好对应的点。</p><h4 id="4、系统与nginx性能优化"><a href="#4、系统与nginx性能优化" class="headerlink" title="4、系统与nginx性能优化"></a>4、系统与nginx性能优化</h4><p>大家对相关的系统瓶颈及现状有了一定的了解之后，就可以根据影响性能方面做一个全体的评估和优化。</p><ul><li>网络（网络流量、是否有丢包，网络的稳定性都会影响用户请求）</li><li>系统（系统负载、饱和、内存使用率、系统的稳定性、硬件磁盘是否有损坏）</li><li>服务（连接优化、内核性能优化、http服务请求优化都可以在nginx中根据业务来进行设置）</li><li>程序（接口性能、处理请求速度、每个程序的执行效率）</li><li>数据库、底层服务</li></ul><p>上面列举出来每一级都会有关联，也会影响整体性能，这里主要关注的是nginx服务这一层。</p><h5 id="1、文件句柄"><a href="#1、文件句柄" class="headerlink" title="1、文件句柄"></a>1、文件句柄</h5><p>在linux/unix操作系统中一切皆文件，我们的设备是文件，文件是文件，文件夹也是文件。当我们用户每发起一次请求，就会产生一个文件句柄。文件句柄可以简单的理解为文件句柄就是一个索引。文件句柄就会随着请求量的增多,进程调用频繁增加，那么产生的文件句柄也就会越多。</p><p>系统默认对文件句柄是有限制的，不可能会让一个进程无限制的调用句柄。因为系统资源是有限的，所以我们需要限制每一个服务能够使用多大的文件句柄。操作系统默认使用的文件句柄是1024个句柄。</p><h5 id="2、设置方式"><a href="#2、设置方式" class="headerlink" title="2、设置方式"></a>2、设置方式</h5><ul><li>系统全局性修改</li><li>用户局部性修改</li><li>进程局部性修改</li></ul><h5 id="3、系统全局性修该和用户局部性修改"><a href="#3、系统全局性修该和用户局部性修改" class="headerlink" title="3、系统全局性修该和用户局部性修改"></a>3、系统全局性修该和用户局部性修改</h5><pre><code>[root@server ~]#vim /etc/security/limits.conf</code></pre><p>在文件最下面找到</p><pre><code>#*               soft    core            0#*               hard    rss             10000#@student        hard    nproc           20#@faculty        soft    nproc           20#@faculty        hard    nproc           50#ftp             hard    nproc           0#@student        -       maxlogins       4#root只是针对root这个用户来限制，soft只是发提醒，操作系统不会强制限制,一般的站点设置为一万左右就ok了root soft nofile 65535root hard nofile 65535# *代表通配符 所有的用户*    soft nofile 25535*    hard nofile 25535</code></pre><p>可以看到root和<em>，root代表是root用户，</em>代表的是所有用户，后面的数字就是文件句柄大小。大家可以根据个人业务来进行设置。</p><h5 id="4、进程局部性修改"><a href="#4、进程局部性修改" class="headerlink" title="4、进程局部性修改"></a>4、进程局部性修改</h5><pre><code>[root@server ~]#vim /etc/nginx/nginx.confuser  nginx;worker_processes  1;  error_log  /var/log/nginx/error.log warn;pid        /var/run/nginx.pid;worker_rlimit_nofile 65535; #进程限制events {    worker_connections  1024;}http {    include       /etc/nginx/mime.types;    default_type  application/octet-stream;    log_format  main  &#39;$http_user_agent&#39; &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;                      &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39;                      &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &#39;                      &#39;&quot;$args&quot; &quot;$request_uri&quot;&#39;;    access_log  /var/log/nginx/access.log  main;    sendfile        on;     #tcp_nopush     on;     keepalive_timeout  65;     #gzip  on;     include /etc/nginx/conf.d/*.conf;}</code></pre><p>worker_rlimit_nofile 是在进程上面进行限制。</p><h5 id="5、cpu的亲和配置"><a href="#5、cpu的亲和配置" class="headerlink" title="5、cpu的亲和配置"></a>5、cpu的亲和配置</h5><p>cpu的亲和能够使nginx对于不同的work工作进程绑定到不同的cpu上面去。就能够减少在work间不断切换cpu，把进程通常不会在处理器之间频繁迁移，进程迁移的频率小，来减少性能损耗。nginx 亲和配置</p><p>查看物理cpu</p><pre><code>[root@server ~]#cat /proc/cpuinfo|grep &quot;physical id&quot;|sort |uniq|wc -l</code></pre><p>查看cpu核心数</p><pre><code>[root@server ~]#cat /proc/cpuinfo|grep &quot;cpu cores&quot;|uniq</code></pre><p>查看cpu使用率</p><pre><code>[root@server ~]#top  回车后按 1</code></pre><h5 id="6、配置worker-processes"><a href="#6、配置worker-processes" class="headerlink" title="6、配置worker_processes"></a>6、配置worker_processes</h5><pre><code>[root@server ~]#vim /etc/nginx/nginx.conf</code></pre><p>将刚才查看到自己cpu * cpu核心就是worker_processes</p><pre><code>worker_processes 2; #根据自己cpu核心数配置</code></pre><h5 id="7、cpu亲和配置"><a href="#7、cpu亲和配置" class="headerlink" title="7、cpu亲和配置"></a>7、cpu亲和配置</h5><p>假如小菜的配置是2cpu，每个cpu是8核。配置如下</p><pre><code>worker_processes 16;worker_cpu_affinity 1010101010101010 0101010101010101;</code></pre><p>配置完成后可以通过下面命令查看nginx进程配置在哪个核上</p><pre><code>[root@server ~]#ps -eo pid,args,psr |grep [n]ginx</code></pre><p>在nginx 1.9版本之后，就帮我们自动绑定了cpu;</p><pre><code>worker_cpu_affinity auto;</code></pre><h4 id="5、nginx通用配置优化"><a href="#5、nginx通用配置优化" class="headerlink" title="5、nginx通用配置优化"></a>5、nginx通用配置优化</h4><pre><code>[root@server ~]#vim /etc/nginx/nginx.conf#将nginx进程设置为普通用户，为了安全考虑user nginx; #当前启动的worker进程，官方建议是与系统核心数一直worker_processes 2;#方式一， 第一个work进程绑定第一个cpu核心，第二个work进程绑定到第二个cpu核心，依次内推 直到弟16个#wokrer_cpu_affinity 0000000000000000 0000000000000001 0000000000000010 0000000000000100 ... 1000000000000000#方式二，当 worker_processes 2 时，表明 第一work进程可以绑定第 2 4 6 8 10 12 14 16 核心，那么第二work进程就绑定 奇数核心#worker_cpu_affinity 1010101010101010 0101010101010101;#方式三，就是自动分配绑定worker_cpu_affinity auto;#日志配置成warnerror_log /var/log/nginx/error.log warn; pid /var/run/nginx.pid;#针对 nginx 句柄的文件限制worker_rlimit_nofile 35535;#事件模型events {    #使用epoll内核模型    user epoll;    #每一个进程可以处理多少个连接，如果是多核可以将连接数调高 worker_processes * 1024    worker_connections 10240;}http {    include       /etc/nginx/mime.types;    default_type  application/octet-stream;    charset utf-8;  #设置字符集    #设置日志输出格式，根据自己的情况设置    log_format  main  &#39;$http_user_agent&#39; &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;                      &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39;                      &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &#39;                      &#39;&quot;$args&quot; &quot;$request_uri&quot;&#39;;    access_log  /var/log/nginx/access.log  main;    sendfile        on;   #对静态资源的处理比较有效    #tcp_nopush     on;   #如果做静态资源服务器可以打开    #tcp_nodeny     on;   #当nginx做动态的服务时可以选择打开    keepalive_timeout  65;     ########    #Gzip module    gzip  on;    #文件压缩默认可以打开    gzip_disable &quot;MSIE [1-6]\.&quot;; #对于有些浏览器不能识别压缩，需要过滤如ie6    gzip_http_version 1.1;    include /etc/nginx/conf.d/*.conf;}#查看 核心绑定的nginx work进程[root@server ~]#ps -eo pid,args,psr | grep [n]ginx</code></pre><h4 id="6、ab接口压力测试工具"><a href="#6、ab接口压力测试工具" class="headerlink" title="6、ab接口压力测试工具"></a>6、ab接口压力测试工具</h4><p>ab是Apache超文本传输协议(HTTP)的性能测试工具。其设计意图是描绘当前所安装的Apache的执行性能，主要是显示你安装的Apache每秒可以处理多少个请求。</p><pre><code># 安装工具[root@server ~]#yum install httpd-tools# 使用[root@server ~]#ab -n 2000 -c 2 http://127.0.0.1/index.html-n 总的请求数-c 并发数-k 是否开启长连接</code></pre><h5 id="1、参数选项"><a href="#1、参数选项" class="headerlink" title="1、参数选项"></a>1、参数选项</h5><pre><code>-n：即requests，用于指定压力测试总共的执行次数-c：即concurrency，用于指定的并发数-t：即timelimit，等待响应的最大时间(单位：秒)-b：即windowsize，TCP发送/接收的缓冲大小(单位：字节)-p：即postfile，发送POST请求时需要上传的文件，此外还必须设置-T参数-u：即putfile，发送PUT请求时需要上传的文件，此外还必须设置-T参数-T：即content-type，用于设置Content-Type请求头信息，例如：application/x-www-form-urlencoded，默认值为text/plain-v：即verbosity，指定打印帮助信息的冗余级别-w：以HTML表格形式打印结果-i：使用HEAD请求代替GET请求-x：插入字符串作为table标签的属性-y：插入字符串作为tr标签的属性-z：插入字符串作为td标签的属性-C：添加cookie信息，例如：&quot;Apache=1234&quot;(可以重复该参数选项以添加多个)-H：添加任意的请求头，例如：&quot;Accept-Encoding: gzip&quot;，请求头将会添加在现有的多个请求头之后(可以重复该参数选项以添加多个)-A：添加一个基本的网络认证信息，用户名和密码之间用英文冒号隔开-P：添加一个基本的代理认证信息，用户名和密码之间用英文冒号隔开-X：指定使用的和端口号，例如:&quot;126.10.10.3:88&quot;-V：打印版本号并退出-k：使用HTTP的KeepAlive特性-d：不显示百分比-S：不显示预估和警告信息-g：输出结果信息到gnuplot格式的文件中-e：输出结果信息到CSV格式的文件中-r：指定接收到错误信息时不退出程序-H：显示用法信息，其实就是ab -help</code></pre><h5 id="2、内容解释"><a href="#2、内容解释" class="headerlink" title="2、内容解释"></a>2、内容解释</h5><pre><code>Server Software:        nginx/1.10.2 (服务器软件名称及版本信息)Server Hostname:        192.168.1.106(服务器主机名)Server Port:            80 (服务器端口)Document Path:          /index1.html. (供测试的URL路径)Document Length:        3721 bytes (供测试的URL返回的文档大小)Concurrency Level:      1000 (并发数)Time taken for tests:   2.327 seconds (压力测试消耗的总时间)Complete requests:      5000 (的总次数)Failed requests:        688 (失败的请求数)Write errors:           0 (网络连接写入错误数)Total transferred:      17402975 bytes (传输的总数据量)HTML transferred:       16275725 bytes (HTML文档的总数据量)Requests per second:    2148.98 [#/sec] (mean) (平均每秒的请求数) 这个是非常重要的参数数值，服务器的吞吐量 Time per request:       465.338 [ms] (mean) (所有并发用户(这里是1000)都请求一次的平均时间)Time  request:          0.247 [ms] (mean, across all concurrent requests) (单个用户请求一次的平均时间)Transfer rate:          7304.41 [Kbytes/sec] received 每秒获取的数据长度 (传输速率，单位：KB/s)...Percentage of the requests served within a certain time (ms)  50%    347  ## 50%的请求在347ms内返回   66%    401  ## 60%的请求在401ms内返回   75%    431  80%    516  90%    600  95%    846  98%   1571  99%   1593 100%   1619 (longest request)</code></pre><h5 id="3、示例演示"><a href="#3、示例演示" class="headerlink" title="3、示例演示"></a>3、示例演示</h5><pre><code>[root@server ~]#ab -n 50 -c 20 http://walidream.com/sub_module</code></pre><p>输出内容</p><pre><code>Server Software:        nginx/1.14.1Server Hostname:        walidream.comServer Port:            80Document Path:          /sub_moduleDocument Length:        169 bytesConcurrency Level:      20Time taken for tests:   0.005 secondsComplete requests:      50Failed requests:        0Write errors:           0Non-2xx responses:      50Total transferred:      14900 bytesHTML transferred:       8450 bytesRequests per second:    9746.59 [#/sec] (mean)Time per request:       2.052 [ms] (mean)Time per request:       0.103 [ms] (mean, across all concurrent requests)Transfer rate:          2836.41 [Kbytes/sec] receivedConnection Times (ms)              min  mean[+/-sd] median   maxConnect:        0    0   0.1      0       1Processing:     1    1   0.3      1       2Waiting:        0    1   0.2      1       1Total:          1    2   0.3      2       2Percentage of the requests served within a certain time (ms)  50%      2  66%      2  75%      2  80%      2  90%      2  95%      2  98%      2  99%      2 100%      2 (longest request)</code></pre><h5 id="5、注意事项"><a href="#5、注意事项" class="headerlink" title="5、注意事项"></a>5、注意事项</h5><p>● 测试机与被测试机要分开</p><p>● 不要对线上的服务器做压力测试</p><p>● 观察测试工具ab所在机器，以及被测试的前端机的CPU、内存、网络等都不超过最高限度的75%</p><h5 id="6、ab性能指标"><a href="#6、ab性能指标" class="headerlink" title="6、ab性能指标"></a>6、ab性能指标</h5><h6 id="1、吞吐率（Requests-per-second）"><a href="#1、吞吐率（Requests-per-second）" class="headerlink" title="1、吞吐率（Requests per second）"></a>1、吞吐率（Requests per second）</h6><p>服务器并发处理能力的量化描述，单位是reqs/s，指的是在某个并发用户数下单位时间内处理的请求数。某个并发用户数下单位时间内能处理的最大请求数，称之为最大吞吐率。记住：吞吐率是基于并发用户数的。这句话代表了两个含义：</p><pre><code>● 吞吐率和并发用户数相关● 不同的并发用户数下，吞吐率一般是不同的</code></pre><p>计算公式：总请求数/处理完成这些请求数所花费的时间，即</p><pre><code>Request per second=Complete requests/Time taken for tests</code></pre><p>必须要说明的是，这个数值表示当前机器的整体性能，值越大越好</p><h6 id="2、并发连接数（The-number-of-concurrent-connections）"><a href="#2、并发连接数（The-number-of-concurrent-connections）" class="headerlink" title="2、并发连接数（The number of concurrent connections）"></a>2、并发连接数（The number of concurrent connections）</h6><p>并发连接数指的是某个时刻服务器所接受的请求数目，简单的讲，就是一个会话。</p><h6 id="3、并发用户数（Concurrency-Level）"><a href="#3、并发用户数（Concurrency-Level）" class="headerlink" title="3、并发用户数（Concurrency Level）"></a>3、并发用户数（Concurrency Level）</h6><p>要注意区分这个概念和并发连接数之间的区别，一个用户可能同时会产生多个会话，也即连接数。在HTTP/1.1下，IE7支持两个并发连接，IE8支持6个并发连接，FireFox3支持4个并发连接，所以相应的，我们的并发用户数就得除以这个基数。</p><h6 id="4-用户平均请求等待时间（Time-per-request）"><a href="#4-用户平均请求等待时间（Time-per-request）" class="headerlink" title="4.用户平均请求等待时间（Time per request）"></a>4.用户平均请求等待时间（Time per request）</h6><p>计算公式：处理完成所有请求数所花费的时间/（总请求数/并发用户数），即：</p><pre><code>Time per request=Time taken for tests/（Complete requests/Concurrency Level）</code></pre><h6 id="5-服务器平均请求等待时间（Time-per-request-across-all-concurrent-requests）"><a href="#5-服务器平均请求等待时间（Time-per-request-across-all-concurrent-requests）" class="headerlink" title="5.服务器平均请求等待时间（Time per request:across all concurrent requests）"></a>5.服务器平均请求等待时间（Time per request:across all concurrent requests）</h6><p>计算公式：处理完成所有请求数所花费的时间/总请求数，即：</p><pre><code>Time taken for/testsComplete requests</code></pre><p>可以看到，它是吞吐率的倒数。同时，它也等于用户平均请求等待时间/并发用户数，即</p><pre><code>Time per request/Concurrency Level</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zabbix-源码安装</title>
      <link href="2019/08/05/monitor/zabbix-yuan-ma-an-zhuang/"/>
      <url>2019/08/05/monitor/zabbix-yuan-ma-an-zhuang/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="Zabbix源码安装"><a href="#Zabbix源码安装" class="headerlink" title="Zabbix源码安装"></a>Zabbix源码安装</h3><h4 id="1-前期准备"><a href="#1-前期准备" class="headerlink" title="1:前期准备"></a>1:前期准备</h4><p> 注意安装zabbix需要lnmp环境可以使用脚本安装lnmp</p><p>这里我进行源码安装一步步的操作</p><p>建议使用脚本进行 用源码安装比较慢</p><h5 id="1-关闭防火墙和selinux-建议可以实行放行策略"><a href="#1-关闭防火墙和selinux-建议可以实行放行策略" class="headerlink" title="(1) 关闭防火墙和selinux 建议可以实行放行策略"></a>(1) 关闭防火墙和selinux 建议可以实行放行策略</h5><h5 id="2-创建安装目录"><a href="#2-创建安装目录" class="headerlink" title="(2)创建安装目录"></a>(2)创建安装目录</h5><pre class=" language-shell"><code class="language-shell">   mkdir -pv /cyylog/{mysql-5.7,nginx-1.16,php-7.2,zabbix-4.4}   mkdir -pv /cyylog/mysql-5.7/data   ln -s /cyylog/mysql-5.7 /cyylog/mysql   ln -s /cyylog/nginx-1.16 /cyylog/nginx   ln -s /cyylog/php-7.2 /cyylog/php   ln -s /cyylog/zabbix-4.4 /cyylog/zabbix</code></pre><h5 id="3-创建用户"><a href="#3-创建用户" class="headerlink" title="(3)创建用户"></a>(3)创建用户</h5><pre class=" language-shell"><code class="language-shell">   useradd -s /sbin/nologin mysql   useradd -s /sbin/nologin nginx   useradd -s /sbin/nologin zabbix</code></pre><p>也可执行脚本</p><h4 id="2-安装mysql"><a href="#2-安装mysql" class="headerlink" title="2:安装mysql"></a>2:安装mysql</h4><h5 id="1-下载mysql源码包"><a href="#1-下载mysql源码包" class="headerlink" title="(1)下载mysql源码包"></a>(1)下载mysql源码包</h5><pre class=" language-shell"><code class="language-shell">wget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.29.tar.gzwget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-boost-5.7.29.tar.gz</code></pre><h5 id="2-使用yum安装依赖包"><a href="#2-使用yum安装依赖包" class="headerlink" title="(2) 使用yum安装依赖包"></a><strong>(2)</strong> 使用yum安装依赖包</h5><pre class=" language-shell"><code class="language-shell">yum install -y cmake gcc gcc-c++ openssl-devel ncurses-devel</code></pre><h5 id="3-解压并进入进行安装"><a href="#3-解压并进入进行安装" class="headerlink" title="(3) 解压并进入进行安装"></a><strong>(3)</strong> 解压并进入进行安装</h5><pre class=" language-shell"><code class="language-shell">tar xvf mysql-5.7.29.tar.gztar xvf mysql-boost-5.7.29.tar.gz -C /cyylog/配置cmake \-DCMAKE_INSTALL_PREFIX=/cyylog/mysql-5.7 \-DMYSQL_DATADIR=/cyylog/mysql-5.7/data \-DDEFAULT_CHARSET=utf8 \-DDEFAULT_COLLATION=utf8_unicode_ci \-DWITH_READLINE=1 \-DWITH_SSL=system \-DWITH_EMBEDDED_SERVER=1 \-DENABLED_LOCAL_INFILE=1 \-DDEFAULT_COLLATION=utf8_general_ci \-DWITH_MYISAM_STORAGE_ENGINE=1 \-DWITH_INNOBASE_STORAGE_ENGINE=1 \-DWITH_DEBUG=0 \-DWITH_BOOST=/cyylog/mysql-5.7.29/boost/boost_1_59_0编译且安装 make & make install</code></pre><h5 id="4-创建需要的文件及更改属主和属组"><a href="#4-创建需要的文件及更改属主和属组" class="headerlink" title="(4) 创建需要的文件及更改属主和属组"></a><strong>(4)</strong> 创建需要的文件及更改属主和属组</h5><pre class=" language-shell"><code class="language-shell">mkdir -pv /cyylog/mysql/logtouch /cyylog/mysql/log/mariadb.logtouch /cyylog/mysql/log/mariadb.pidchown -R /cyylog/{mysql-5.7,mysql-5.7.29,mysql}</code></pre><h5 id="5-初始化数据"><a href="#5-初始化数据" class="headerlink" title="(5) 初始化数据"></a><strong>(5)</strong> 初始化数据</h5><pre class=" language-shell"><code class="language-shell">修改配置文件 vim /etc/my.cnf[mysqld]datadir=/cyylog/mysql/data #数据存储的地方socket=/cyylog/mysql/mysql.sock #sock文件的路径skip-grant-tables #跳过登录认证user=mysqlexplicit_defaults_for_timestamp=true[mysqld_safe]log-error=/cyylog/mysql/log/mariadb.log #错误日志存放的地方pid-file=/cyylog/mysql/log/mariadb.pid</code></pre><h5 id="6-添加至环境变量"><a href="#6-添加至环境变量" class="headerlink" title="(6) 添加至环境变量"></a><strong>(6)</strong> 添加至环境变量</h5><pre class=" language-shell"><code class="language-shell">vim /etc/profile 修改末尾添加两行export PATH=$PATH:/cyylog/mysql/support-filesexport PATH=$PATH:/cyylog/mysql/bin保存退出刷新环境变量 source /etc/profile/</code></pre><h5 id="7-初始化启动mysql"><a href="#7-初始化启动mysql" class="headerlink" title="(7) 初始化启动mysql"></a><strong>(7)</strong> 初始化启动mysql</h5><pre class=" language-shell"><code class="language-shell">mysqld --initialize --user=mysql --basedir=/cyylog/mysql --datadir=/cyylog/mysql/datamysql.server startln -s /cyylog/mysql/mysql.sock /tmp/</code></pre><h5 id="8-下载zabbix源码包并进行解压"><a href="#8-下载zabbix源码包并进行解压" class="headerlink" title="(8) 下载zabbix源码包并进行解压"></a><strong>(8)</strong> 下载zabbix源码包并进行解压</h5><pre class=" language-shell"><code class="language-shell">wget https://sourceforge.net/projects/zabbix/files/ZABBIX%20Latest%20Stable/4.4.5/zabbix-4.4.5.tar.gztar xvf zabbix-4.4.5.tar.gzcd zabbix-4.4.5/database/mysql登录mysql   命令为 mysql -u root 进入后执行以下命令use mysql;create database zabbix default character set utf8;update mysql.user set authentication_string=password('修改的密码') where user='root';use zabbix;source schema.sql;source images.sql;source data.sql;quit;   最后恢复密码登录mysql 修改文件vim /etc/my.cnf去掉 skip-grant-tables保存退出重启mysql服务 mysql.sercer restart添加lib文件echo “/cyylog/mysql/lib” > /etc/ld.so.conf.d/mysql.confldconfig -v</code></pre><h4 id="3-安装nginx"><a href="#3-安装nginx" class="headerlink" title="3:安装nginx"></a>3:安装nginx</h4><h5 id="1-下载-nginx-并解压"><a href="#1-下载-nginx-并解压" class="headerlink" title="(1) 下载 nginx  并解压"></a>(1) 下载 nginx  并解压</h5><pre class=" language-shell"><code class="language-shell">wget http://nginx.org/download/nginx-1.16.1.tar.gztar xvf nginx-1.16.1.tar.gz</code></pre><h5 id="2-编译安装并添加环境变量"><a href="#2-编译安装并添加环境变量" class="headerlink" title="(2) 编译安装并添加环境变量"></a><strong>(2)</strong> 编译安装并添加环境变量</h5><pre class=" language-shell"><code class="language-shell">cd nginx-1.16.1./configure --prefix=/cyylog/nginx-1.16 --user=nginx --group=nginx --without-select_module --without-poll_module --with-http_ssl_module --with-pcre --with-debugmake make install 添加变量vim /etc/profile 追加一行export PATH=$PATH://cyylog/nginx/sbin保存退出刷新变量source /etc/profile</code></pre><h5 id="3-更改-nginx-的属主和属组以及修改配置文件"><a href="#3-更改-nginx-的属主和属组以及修改配置文件" class="headerlink" title="(3)更改 nginx 的属主和属组以及修改配置文件"></a><strong>(3)</strong>更改 nginx 的属主和属组以及修改配置文件</h5><pre class=" language-shell"><code class="language-shell">chown nginx:nginx -R /cyylog/nginx-1.16修改配置文件vim /cyylog/nginx/conf/nginx.conf修改启动用户 user nginx;启动nginx  nginx</code></pre><h4 id="4-安装php"><a href="#4-安装php" class="headerlink" title="4:安装php"></a>4:安装php</h4><h5 id="1-下载php源码并井进行解压"><a href="#1-下载php源码并井进行解压" class="headerlink" title="(1) 下载php源码并井进行解压"></a><strong>(1)</strong> <strong>下载php源码并井进行解压</strong></h5><pre class=" language-shell"><code class="language-shell">wget https://www.php.net/distributions/php-7.2.27.tar.gztar xvf php-7.2.27.tar.gz</code></pre><p><strong>(2)</strong> <strong>安装及解决依赖</strong></p><pre class=" language-shell"><code class="language-shell">yum install -y libxml2-devel openssl-devel net-snmp net-snmp-devel libcurl-devel libjpeg-devel libpng-devel libicu-devel openldap-devel bzip2 bzip2-devel freetype-devel gmp-devel readline-devel libxslt-devel fontconfigcd php-7.2.27./configure --prefix=/cyylog/php-7.2 --with-mysqli=/cyylog/mysql/bin/mysql_config --enable-inline-optimization --enable-fpm --enable-soap --enable-pcntl --enable-xml --with-libxml-dir --with-xmlrpc --with-openssl --with-mhash --with-pcre-regex --with-sqlite3 --with-zlib --enable-bcmath --with-iconv --with-bz2 --enable-calendar --with-curl --with-cdb --enable-dom --enable-exif --enable-fileinfo --enable-filter --with-pcre-dir --enable-ftp --with-gd --with-openssl-dir --with-jpeg-dir --with-png-dir --with-freetype-dir --with-gettext --with-gmp --with-mhash --enable-json --enable-mbstring --disable-mbregex --disable-mbregex-backtrack --with-libmbfl --with-onig --enable-pdo --with-pdo-mysql --with-zlib-dir --with-pdo-sqlite --with-readline --enable-session --enable-shmop --enable-simplexml --enable-sockets --enable-sysvmsg --enable-sysvsem --enable-sysvshm --enable-wddx --with-libxml-dir --with-xsl --enable-zip --enable-mysqlnd-compression-support --with-pear --without-pear make make install</code></pre><h5 id="3-拷贝服务和配置文件及属主和属组"><a href="#3-拷贝服务和配置文件及属主和属组" class="headerlink" title="(3) 拷贝服务和配置文件及属主和属组"></a><strong>(3)</strong> 拷贝服务和配置文件及属主和属组</h5><pre class=" language-shell"><code class="language-shell">cp /root/php-7.2.27/sapi/fpm/php-fpm.service /usr/lib/systemd/system/php-fpm.servicecp /cyylog/php-7.2/etc/{php-fpm.conf.default,php-fpm.conf}cp /cyylog/php-7.2/etc/php-fpm.d/www.conf{.default,}cp php.ini-production /cyylog/php-7.2/lib/php.inichown nginx:nginx -R /cyylog/php-7.2</code></pre><p><strong>(4)</strong> <strong>修改配置文件并启动</strong></p><pre class=" language-shell"><code class="language-shell">#### 修改php.ini配置文件vim /cyylog/php/lib/php.ini 修改四行post_max_size = 16Mmax_execution_time = 300max_input_time = 300date.timezone = PRC#### 启动php服务systemctl start php-fpm.service && systemctl enable php-fpm.service#### 修改nginx.conf文件是nginx支持phpvim /cyylog/nginx/conf/nginx.conf 修改如下 location ~ \.php$ {            root           /cyylog/nginx/html;            fastcgi_pass   127.0.0.1:9000;            fastcgi_index  index.php;            fastcgi_param  SCRIPT_FILENAME  /cyylog/nginx/html$fastcgi_script_name;            include        fastcgi_params;        }#### 编写测试php文件 vim /cyylog/nginx/html/index.php          <?php phpinfo(); ?>#### 重启nginx服务 nginx -s reload    重启nginx服务 nginx -s reload</code></pre><h4 id="5-安装zabbix"><a href="#5-安装zabbix" class="headerlink" title="5:安装zabbix"></a>5:安装zabbix</h4><h5 id="1-安装依赖以及编译安装"><a href="#1-安装依赖以及编译安装" class="headerlink" title="(1) 安装依赖以及编译安装"></a><strong>(1)</strong> 安装依赖以及编译安装</h5><pre class=" language-shell"><code class="language-shell">yum localinstall -y libevent-devel-2.0.21-4.el7.x86_64.rpmyum install unixODBC-devel mysql-devel net-snmp-devel libxml2-devel libcurl-devel libevent-devel -y配置cd zabbix-4.4.5./configure --prefix=/cyylog/zabbix-4.4 --enable-server --enable-agent --with-mysql=/cyylog/mysql/bin/mysql_config --enable-ipv6 --with-netsnmp --with-libcurl --with-libxml2make make install</code></pre><p>(2) 配置环境变量</p><pre class=" language-shell"><code class="language-shell">vim /etc/profile 追加一行export PATH=$PATH://cyylog/zabbix/sbin#### 保存退出 刷新 source /etc/profile</code></pre><p>(3) 修改配置文件</p><pre class=" language-shell"><code class="language-shell">vim /cyylog/zabbix/etc/zabbix_server.conf  ##修改如下DBUser=rootDBPassword=beimi123拷贝zabbix至nginx的目录下cp -R frontends/php/* /cyylog/nginx/html/重启nginx服务  nginx -s reload</code></pre><p>访问页面ok就行</p><p>注意连接数据库那个步骤需要将服务器ip改为127.0.0.1 不能使用localhost</p><p>否则会报错</p><p>接下会有个配置文件无法安装需手动下载下来传到ngin目录下</p><p>最后完成</p><p>登录账户为 admin 密码zabbix</p><p>登录后界面为</p><p><img src="C:%5CUsers%5CCyy%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200523132054294.png" alt="image-20200523132054294"></p>]]></content>
      
      
      <categories>
          
          <category> monitor </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zabbix </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>zabbix-邮箱报警设置</title>
      <link href="2019/07/05/monitor/zabbix-you-jian-bao-jing/"/>
      <url>2019/07/05/monitor/zabbix-you-jian-bao-jing/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="Zabbix-邮件报警"><a href="#Zabbix-邮件报警" class="headerlink" title="Zabbix 邮件报警"></a>Zabbix 邮件报警</h3><h4 id="前期准备工作："><a href="#前期准备工作：" class="headerlink" title="前期准备工作："></a>前期准备工作：</h4><p>电脑登录网易邮箱配置，把自己的授权码看一下，并写入配置文件</p><h5 id="server端安装配置邮件服务器"><a href="#server端安装配置邮件服务器" class="headerlink" title="server端安装配置邮件服务器"></a><strong>server端安装配置邮件服务器</strong></h5><pre class=" language-shell"><code class="language-shell">[root@master ~]# yum -y install mailx[root@master ~]# mailx -V12.5 7/5/10</code></pre><h5 id="配置公网邮箱信息：发邮件："><a href="#配置公网邮箱信息：发邮件：" class="headerlink" title="配置公网邮箱信息：发邮件："></a><strong>配置公网邮箱信息</strong>：发邮件：</h5><pre class=" language-shell"><code class="language-shell">[root@master ~]#  vim /etc/mail.rc    #追加以下内容set from=cyylog@163.com    #（邮箱地址） set smtp=smtp.163.com    #smtp服务器） 发邮件服务器 ---163默认set smtp-auth-user=cyylog@163.com    #(用户名) set smtp-auth-password=Password    #（邮箱密码）授权之后的密码set smtp-auth=login            #默认######    测试[root@master ~]# echo "test mail from zabbix.server.com" |mail -s "test mail" cyylog@163.com</code></pre><h6 id="然后163邮箱就会收到信息"><a href="#然后163邮箱就会收到信息" class="headerlink" title="然后163邮箱就会收到信息"></a>然后163邮箱就会收到信息</h6><p><img src="https://s1.ax1x.com/2020/05/23/Yv2C6g.png" alt="Yv2C6g.png"></p><h4 id="报警媒体的配置"><a href="#报警媒体的配置" class="headerlink" title="报警媒体的配置:"></a>报警媒体的配置:</h4><p>首先需要配置 Zabbix 的邮件功能。<br>点击 管理-&gt;报警媒介类型-&gt;创建媒体类型</p><p><img src="https://s1.ax1x.com/2020/05/23/YvWEWV.png" alt="YvWEWV.png"></p><p><strong>然后在页面中填入你的报警媒介类型信息,例如下图所示:</strong><br><strong>注：脚本名称任意，存放于<code>/usr/lib/zabbix/alertscripts</code> (生产上的测试服放这：<code>s /usr/local/zabbix/share/zabbix/alertscripts）</code></strong> </p><p>名称：sendmail //名称任意<br>类型：脚本<br>脚本名称：sendmail.sh<br>脚本参数： //一定要写，否则可能发送不成功<br>{ALERT.SENDTO} //照填，收件人变量<br>{ALERT.SUBJECT} //照填，邮件主题变量，变量值来源于‘动作’中的‘默认接收人’<br>{ALERT.MESSAGE} //照填，邮件正文变量，变量值来源于‘动作’中的‘默认信息’</p><p><strong>配置完成后,不要忘记点击存档,保存你的配置。</strong></p><p><img src="https://s1.ax1x.com/2020/05/23/YvWRmQ.png" alt="YvWRmQ.png"></p><h6 id="修改zabbix服务端配置文件＆编写脚本："><a href="#修改zabbix服务端配置文件＆编写脚本：" class="headerlink" title="修改zabbix服务端配置文件＆编写脚本："></a>修改zabbix服务端配置文件＆编写脚本：</h6><pre class=" language-shell"><code class="language-shell"># 查看指定脚本的存储路径:[root@master ~]# vim /etc/zabbix/zabbix_server.confAlertScriptsPath=/usr/lib/zabbix/alertscripts编写邮件脚本:[root@master alertscripts]# cd /usr/lib/zabbix/alertscripts[root@master alertscripts]# vim sendmail.sh #!/bin/sh #export.UTF-8 -----字符集可以删除掉#send mailmessages=echo $3 | tr '\r\n' '\n'subject=echo $2 | tr '\r\n' '\n'echo "${messages}" | mail -s "${subject}" $1 >>/tmp/mailx.log 2>&1修改权限：[root@master alertscripts]# chmod u+x sendmail.sh && chown zabbix.zabbix sendmail.sh</code></pre><p>创建的脚本名称要和定义的脚本名称一样</p><p><strong>修改admin用户的报警媒介：</strong><br>用户默认是没有设置报警媒介的，设置后就可以接收报警消息了。</p><p><img src="https://s1.ax1x.com/2020/05/23/YvIrM6.png" alt="YvIrM6.png"></p><p><img src="https://s1.ax1x.com/2020/05/23/YvoeQx.png" alt="YvoeQx.png"></p><h6 id="触发器的配置"><a href="#触发器的配置" class="headerlink" title="触发器的配置:"></a><strong>触发器的配置:</strong></h6><p>接下来,点击配置-&gt;主机</p><p>我们给 agent-19 这台主机增加一个触发器。点击 agent-19 这一行中的“触发器”,然后再点击创建触发器。<br>该页各配置项含义如下:<br>名称:填入触发器的名字<br>表达式:用于配置触发器的触发条件,点击添加按钮有条件选项。 —-键值<br>多重事件产生:如果选中,则问题如果持续多重的发生则每次都触发,否则只触发一次<br>点击表达式右侧的添加按钮:</p><p><img src="https://s1.ax1x.com/2020/05/23/YvT75Q.png" alt="YvT75Q.png"></p><p>再点击项目右侧的选择,选择我们之前配置过的“web.server.online.monitor”,并设置触发的阀值,如下图所示</p><p><img src="https://s1.ax1x.com/2020/05/23/YvTL2n.png" alt="YvTL2n.png"></p><p>Zabbix 会自动生成表达式。接下来根据情况选择事件的严重性。配置完毕后,点击存档保存。</p><p><img src="https://s1.ax1x.com/2020/05/23/YvTxbT.png" alt="YvTxbT.png"></p><p><strong>动作的配置</strong>:<br>点击:配置-&gt;动作-&gt;事件源下拉菜单中选择触发器-&gt;创建动作<br>可以在内容中使用 Zabbix 内置宏,邮件发出时会自动将宏替换成对应的值。 </p><p>名称：<br>任意写</p><p>默认接收人：</p><pre><code>故障级别：{TRIGGER.STATUS}。服务器：【{HOSTNAME1} 】 发生：{TRIGGER.NAME} 故障！ 注：默认接收人：相当于邮件的主题默认信息：邮件的主题告警主机：{HOSTNAME1} 告警时间：{EVENT.DATE} {EVENT.TIME}告警等级：{TRIGGER.SEVERITY} 告警信息：{TRIGGER.NAME}告警项目：{TRIGGER.KEY1} 问题详情：{ITEM.NAME}：{ITEM.VALUE}当前状态：{TRIGGER.STATUS}：{ITEM.VALUE1} 事件ID：{EVENT.ID}</code></pre><p>恢复邮件：<br>恢复主题：</p><pre><code>服务器：【{HOSTNAME1}】故障已恢复。故障原因：{TRIGGER.NAME} 恢复信息：恢复邮件的正文。当故障恢复正常后也发邮件通知一下。 </code></pre><p><img src="https://s1.ax1x.com/2020/05/23/Yv7iG9.png" alt="Yv7iG9.png"></p><p>点击:操作-&gt;编辑：</p><p><img src="https://s1.ax1x.com/2020/05/23/Yv7kx1.png" alt="Yv7kx1.png"></p><p>发送间隔：60秒<br>步骤：发送10次发送到：admin用户<br>仅使用：sendmail方式发送 —-脚本。 方式可以自行设置，根据实际工作要求</p><p><img src="https://s1.ax1x.com/2020/05/23/Yv7QGd.png" alt="Yv7QGd.png"></p><p>需要特别解释一下的是“步骤”部分的配置。所谓步骤是指报警可以有多个步骤,做不同的报警。例如,自从 1 到 3,就是指报警的步骤有三个。步骤持续时间就是一定时间后如果监控人员仍未响应报警就进入下一个报警步骤。<br>例如,发邮件给你报警,如果60 秒后你没响应,那就发 jabber 信息提醒你。如果 60 秒后还没响应,那就发短信给你。要是还没响应,就没有然后了。你可以形象的把它理解为 Zabbix 的一哭二闹三上吊。<br>到此,一个邮件报警功能就配置完毕了。如果你想立即看到结果,可以修改触发器的条件,将条件的阀值设置为 N&gt;0.0003。你马上就会收到 Zabbix 发来的报警邮件了。</p><h4 id="补充：邮件美化"><a href="#补充：邮件美化" class="headerlink" title="补充：邮件美化"></a>补充：邮件美化</h4><p>（修改默认信息）</p><pre class=" language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>table</span> <span class="token attr-name">border</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>1<span class="token punctuation">"</span></span>  <span class="token attr-name">bordercolor</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>black<span class="token punctuation">"</span></span> <span class="token attr-name">cellspacing</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>0px<span class="token punctuation">"</span></span> <span class="token attr-name">cellpadding</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>4px<span class="token punctuation">"</span></span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>tr</span> <span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>td</span><span class="token punctuation">></span></span>告警主机<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>td</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>td</span> <span class="token attr-name">bgcolor</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>#FF3333<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>{HOSTNAME1}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>td</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>tr</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>tr</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>td</span><span class="token punctuation">></span></span>告警时间<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>td</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>td</span><span class="token punctuation">></span></span>{EVENT.DATE} {EVENT.TIME}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>td</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>tr</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>tr</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>td</span><span class="token punctuation">></span></span>告警等级<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>td</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>td</span><span class="token punctuation">></span></span>{TRIGGER.SEVERITY}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>td</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>tr</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>tr</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>td</span><span class="token punctuation">></span></span>告警信息<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>td</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>td</span><span class="token punctuation">></span></span>{TRIGGER.NAME}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>td</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>tr</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>tr</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>td</span><span class="token punctuation">></span></span>告警项目<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>td</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>td</span><span class="token punctuation">></span></span>{TRIGGER.KEY1}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>td</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>tr</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>tr</span> <span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>td</span><span class="token punctuation">></span></span>问题详情<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>td</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>td</span> <span class="token attr-name">bgcolor</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>#FF3333<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>{ITEM.NAME}:<span class="token entity" title="&nbsp;">&amp;nbsp;</span>{ITEM.VALUE}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>td</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>tr</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>tr</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>td</span><span class="token punctuation">></span></span>当前状态<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>td</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>td</span><span class="token punctuation">></span></span>{TRIGGER.STATUS}:<span class="token entity" title="&nbsp;">&amp;nbsp;</span>{ITEM.VALUE1}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>td</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>tr</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>tr</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>td</span><span class="token punctuation">></span></span>事件ID<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>td</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>td</span><span class="token punctuation">></span></span>{EVENT.ID}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>td</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>tr</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>table</span><span class="token punctuation">></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> monitor </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zabbix </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL部署之源码安装</title>
      <link href="2019/05/27/sql/mysql-bu-shu-zhi-yuan-ma-an-zhuang/"/>
      <url>2019/05/27/sql/mysql-bu-shu-zhi-yuan-ma-an-zhuang/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h4 id="所需要的依赖及安装MySQL的包"><a href="#所需要的依赖及安装MySQL的包" class="headerlink" title="所需要的依赖及安装MySQL的包"></a>所需要的依赖及安装MySQL的包</h4><pre class=" language-shell"><code class="language-shell"># yum -y update# yum -y groupinstall "Development Tools"# yum -y install gcc gcc-c++ ncurses ncurses-devel bison libgcrypt perl make cmake# wget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-boost-5.7.24.tar.gz</code></pre><h4 id="在系统中添加运行mysqld进程的用户mysql"><a href="#在系统中添加运行mysqld进程的用户mysql" class="headerlink" title="在系统中添加运行mysqld进程的用户mysql"></a>在系统中添加运行mysqld进程的用户mysql</h4><pre class=" language-shell"><code class="language-shell">[root@mysql_source ~]# groupadd mysql[root@mysql_source ~]# useradd -M -g mysql -s /sbin/nologin mysql</code></pre><h4 id="在系统中添加自定义MySQL数据库目录及其他必要目录"><a href="#在系统中添加自定义MySQL数据库目录及其他必要目录" class="headerlink" title="在系统中添加自定义MySQL数据库目录及其他必要目录"></a>在系统中添加自定义MySQL数据库目录及其他必要目录</h4><pre class=" language-shell"><code class="language-shell">[root@mysql_source ~]# mkdir -p /usr/local/mysqld/{data,mysql,log,tmp}[root@mysql_source ~]# chown -R mysql:mysql /usr/local/mysqld/*</code></pre><h4 id="将mysql-boost-5-7-24-tar-gz解压到当前目录-并执行部署操作"><a href="#将mysql-boost-5-7-24-tar-gz解压到当前目录-并执行部署操作" class="headerlink" title="将mysql-boost-5.7.24.tar.gz解压到当前目录,并执行部署操作"></a>将mysql-boost-5.7.24.tar.gz解压到当前目录,并执行部署操作</h4><pre class=" language-shell"><code class="language-shell">[root@mysql_source ~]# tar xf mysql-boost-5.7.24.tar.gz[root@mysql_source ~]# cd mysql-5.7.24[root@mysql_source mysql-5.7.24]# $ cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysqld/mysql \-DMYSQL_DATADIR=/usr/local/mysqld/data \-DWITH_BOOST=/root/mysql-5.7.24/boost \-DDEFAULT_CHARSET=utf8......-- Configuring done-- Generating done-- Build files have been written to: /root/mysql-5.7.24[root@mysql_source mysql-5.7.24]# echo $?0[root@mysql_source mysql-5.7.24]# make -j `lscpu | awk 'NR==4{ print $2 }'`......[100%] Built target udf_example[root@mysql_source mysql-5.7.24]# echo $?0[root@mysql_source mysql-5.7.24]# make install......-- Installing: /usr/local/mysqld/mysql/support-files/mysql.server[root@mysql_source mysql-5.7.24]# echo $?0[root@mysql_source mysql-5.7.24]#Congratulations Complete!</code></pre><h4 id="初始化MySQL安装配置"><a href="#初始化MySQL安装配置" class="headerlink" title="初始化MySQL安装配置"></a>初始化MySQL安装配置</h4><h5 id="1-提升MySQL命令为系统级别命令"><a href="#1-提升MySQL命令为系统级别命令" class="headerlink" title="1.提升MySQL命令为系统级别命令"></a>1.提升MySQL命令为系统级别命令</h5><pre class=" language-shell"><code class="language-shell">[root@mysql_source ~]# echo "export PATH=$PATH:/usr/local/mysqld/mysql/bin" >>/etc/profile[root@mysql_source ~]# source /etc/profile</code></pre><h5 id="2-拷贝默认配置文件至-etc-my-cnf中"><a href="#2-拷贝默认配置文件至-etc-my-cnf中" class="headerlink" title="2.拷贝默认配置文件至/etc/my.cnf中"></a>2.拷贝默认配置文件至/etc/my.cnf中</h5><pre class=" language-shell"><code class="language-shell">[root@mysql_source mysql]# chown -R mysql.mysql /usr/local/mysqld/*[root@mysql_source ~]# cd /usr/local/mysqld/mysql/mysql-test/include[root@mysql_source include]# cp /etc/{my.cnf,my.cnf.bak}[root@mysql_source include]# cp default_mysqld.cnf /etc/my.cnfcp：是否覆盖"/etc/my.cnf"？ y[root@mysql_source include]# vim /etc/my.cnf[mysqld]basedir = /usr/local/mysqld/mysqldatadir = /usr/local/mysqld/datatmpdir = /usr/local/mysqld/tmpsocket = /usr/local/mysqld/tmp/mysql.sockpid_file = /usr/local/mysqld/tmp/mysqld.pidlog_error = /usr/local/mysqld/log/mysql_error.logslow_query_log_file = /usr/local/mysqld/log/slow_warn.logserver_id = 11user = mysqlport = 3306bind-address = 0.0.0.0character-set-server = utf8default_storage_engine = InnoDB</code></pre><h5 id="3-执行数据库服务初始化操作"><a href="#3-执行数据库服务初始化操作" class="headerlink" title="3.执行数据库服务初始化操作"></a>3.执行数据库服务初始化操作</h5><pre class=" language-shell"><code class="language-shell">[root@mysql_source mysql]# mysqld --defaults-file=/etc/my.cnf --initialize --user='mysql'[root@mysql_source mysql]#</code></pre><h5 id="4-启动mysqld服务"><a href="#4-启动mysqld服务" class="headerlink" title="4.启动mysqld服务"></a>4.启动mysqld服务</h5><pre class=" language-shell"><code class="language-shell">[root@mysql_source mysql]# mysqld_safe --defaults-file=/etc/my.cnf &[1] 257052018-12-28T09:19:35.334751Z mysqld_safe Logging to '/usr/local/mysqld/log/mysql_error.log'.2018-12-28T09:19:35.379829Z mysqld_safe Starting mysqld daemon with databases from /usr/local/mysqld/data</code></pre><h5 id="5-设置mysql-socket软链接到mysql命令指定的目录中"><a href="#5-设置mysql-socket软链接到mysql命令指定的目录中" class="headerlink" title="5.设置mysql.socket软链接到mysql命令指定的目录中"></a>5.设置mysql.socket软链接到mysql命令指定的目录中</h5><pre class=" language-shell"><code class="language-shell">[root@mysql_source ～]# ln -s /usr/local/mysqld/tmp/mysql.sock /tmp/mysql.sock</code></pre><p>6.配置mysqld服务的管理工具</p><pre class=" language-shell"><code class="language-shell">[root@mysql_source support-files]# cd /usr/local/mysqld/mysql/support-files[root@mysql_source support-files]# cp mysql.server /etc/init.d/mysqld[root@mysql_source support-files]# chkconfig --add mysqld[root@mysql_source support-files]# chkconfig mysqld on</code></pre><h4 id="登录数据库并进行更改密码"><a href="#登录数据库并进行更改密码" class="headerlink" title="登录数据库并进行更改密码"></a>登录数据库并进行更改密码</h4><pre class=" language-shell"><code class="language-shell">[root@mysql_source mysql]# grep "password" /usr/local/mysqld/log/mysql_error.log2018-12-28T09:18:34.214401Z 1 [Note] A temporary password is generated for root@localhost: ejhszb2:m3wJ[root@mysql_source tmp]# mysql -uroot -p"ejhszb2:m3wJ"mysql: [Warning] Using a password on the command line interface can be insecure.Welcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 2Server version: 5.7.24-logCopyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.mysql> alter user 'root'@'localhost' identified by "(Cyylog..1228)";平常中常用的MySQL部署参数:<参考使用>    -DCMAKE_INSTALL_PREFIX=/usr/local/mysqld/mysql \    -DMYSQL_DATADIR=/usr/local/mysqld/data \    -DDOWNLOAD_BOOST=1 \    -DWITH_BOOST=/root/mysql-5.7.24/boost \    -DSYSCONFDIR=/etc \    -DWITH_INNOBASE_STORAGE_ENGINE=1 \    -DWITH_PARTITION_STORAGE_ENGINE=1 \    -DWITH_FEDERATED_STORAGE_ENGINE=1 \    -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \    -DWITH_MYISAM_STORAGE_ENGINE=1 \    -DENABLED_LOCAL_INFILE=1 \    -DENABLE_DTRACE=0 \    -DDEFAULT_CHARSET=utf8 \    -DDEFAULT_COLLATION=utf8_general_ci \    -DWITH_EMBEDDED_SERVER=1</code></pre><h4 id="绕过验证密码登录-修改密码"><a href="#绕过验证密码登录-修改密码" class="headerlink" title="绕过验证密码登录 修改密码"></a>绕过验证密码登录 修改密码</h4><pre class=" language-shell"><code class="language-shell">[root@mysql ~]# vim /etc/my.cnf[mysqld]skip-grant-tables=1[root@mysql ~]# systemctl restart mysqld[root@mysql ~]# mysql -urootWelcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 2Server version: 5.7.24 MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.mysql> alter user 'root'@'localhost' identified by "(Cyylog..1229)";ERROR 1290 (HY000): The MySQL server is running with the --skip-grant-tables option so it cannot execute this statementmysql> show databases;+--------------------+| Database           |+--------------------+| information_schema || mysql              || performance_schema || sys                |+--------------------+4 rows in set (0.00 sec)mysql> use mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql> show tables;..................| user                      |+---------------------------+31 rows in set (0.00 sec)mysql> select User,Host,authentication_string from user;+---------------+-----------+-------------------------------------------+| User          | Host      | authentication_string                     |+---------------+-----------+-------------------------------------------+| root          | localhost | *C4571A0C807D96143700250EC4BA41780025A97F || mysql.session | localhost | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE || mysql.sys     | localhost | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE |+---------------+-----------+-------------------------------------------+3 rows in set (0.00 sec)mysql> update user set authentication_string=password('(Cyylog@@1229)') where user='root';Query OK, 1 row affected, 1 warning (0.00 sec)Rows matched: 1  Changed: 1  Warnings: 1[root@mysql ~]# vim /etc/my.cnf[mysqld]#skip-grant-tables=1[root@mysql ~]# systemctl restart mysqld[root@mysql ~]# mysql -uroot -p"(Cyylog@@1229)"mysql: [Warning] Using a password on the command line interface can be insecure.Welcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 2Server version: 5.7.24 MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.mysql></code></pre>]]></content>
      
      
      <categories>
          
          <category> SQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx平滑升级</title>
      <link href="2019/04/27/linux/nginx-ping-hua-sheng-ji/"/>
      <url>2019/04/27/linux/nginx-ping-hua-sheng-ji/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h5 id="Nginx-平滑升级"><a href="#Nginx-平滑升级" class="headerlink" title="Nginx 平滑升级"></a>Nginx 平滑升级</h5><h6 id="1、查看现有的-nginx-编译参数"><a href="#1、查看现有的-nginx-编译参数" class="headerlink" title="1、查看现有的 nginx 编译参数"></a>1、查看现有的 nginx 编译参数</h6><pre class=" language-shell"><code class="language-shell">[root@web ~]#/usr/local/nginx/sbin/nginx -V</code></pre><p>按照原来的编译参数安装 nginx 的方法进行安装，<strong>只需要到 make，千万不要 make install</strong></p><h6 id="2、编译新的-nginx-源码包"><a href="#2、编译新的-nginx-源码包" class="headerlink" title="2、编译新的 nginx 源码包"></a>2、编译新的 nginx 源码包</h6><p>编译新Nginx源码，安装路径需与旧版一致 (详细过程可参见：Nginx编译安装与配置使用)</p><pre class=" language-shell"><code class="language-shell">[root@web ~]#./configure --prefix=/usr/local/nginx-1.14.0 --user=www --group=www --with-http_ssl_module --with-openssl=/path/to/openssl_src[root@web ~]#make</code></pre><h6 id="3、备份原-nginx-二进制文件"><a href="#3、备份原-nginx-二进制文件" class="headerlink" title="3、备份原 nginx 二进制文件"></a>3、备份原 nginx 二进制文件</h6><p>备份二进制文件和 nginx 的配置文件（期间nginx不会停止服务）</p><pre class=" language-shell"><code class="language-shell">[root@web ~]#mv /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx_$(date +%F)</code></pre><p>4、复制新的nginx二进制文件，进入新的nginx源码包</p><pre class=" language-shell"><code class="language-shell">[root@web ~]#cp /usr/local/nginx-1.14.0/objs/nginx /usr/local/nginx/sbin/</code></pre><p>5、测试新版本的nginx是否正常</p><pre class=" language-shell"><code class="language-shell">[root@web ~]#/usr/local/nginx/sbin/nginx -t</code></pre><p>6、给nginx发送平滑迁移信号（若不清楚pid路径，请查看nginx配置文件）</p><pre class=" language-shell"><code class="language-shell">[root@web ~]#kill -USR2 cat /var/run/nginx.pid</code></pre><p>7、查看nginx pid，会出现一个nginx.pid.oldbin</p><pre class=" language-shell"><code class="language-shell">[root@web ~]#ll /var/run/nginx.pid*</code></pre><p>8、从容关闭旧的Nginx进程</p><pre class=" language-shell"><code class="language-shell">[root@web ~]#kill -WINCH cat /var/run/nginx.pid.oldbin</code></pre><p>9、此时不重载配置启动旧的工作进程</p><pre class=" language-shell"><code class="language-shell">[root@web ~]#kill -HUP cat /var/run/nginx.pid.oldbin</code></pre><p>10、结束工作进程，完成此次升级</p><pre class=" language-shell"><code class="language-shell">[root@web ~]#kill -QUIT cat /var/run/nginx.pid.oldbin</code></pre><p>11、验证Nginx是否升级成功</p><pre class=" language-shell"><code class="language-shell">[root@web ~]#usr/local/nginx/sbin/nginx -V</code></pre><h5 id="升级实战"><a href="#升级实战" class="headerlink" title="升级实战"></a>升级实战</h5><h6 id="1、安装配置1-6版本的-nginx"><a href="#1、安装配置1-6版本的-nginx" class="headerlink" title="1、安装配置1.6版本的 nginx"></a>1、安装配置1.6版本的 nginx</h6><pre class=" language-shell"><code class="language-shell">[root@web ~]# yum install -y gcc gcc-c++ pcre-devel openssl-devel zlib-devel[root@web ~]# tar zxvf nginx-1.6.0.tar.gz -C /usr/src/[root@web ~]# cd /usr/src/nginx-1.6.0/[root@web nginx-1.6.0]# ./configure --prefix=/usr/local/nginx --user=nginx --group=nginx --with-http_stub_status_module[root@web nginx-1.6.0]# make [root@web nginx-1.6.0]# make install[root@web nginx-1.6.0]# ln -s /usr/local/nginx/sbin/* /usr/sbin/[root@web nginx-1.6.0]# useradd -M -s /sbin/nologin nginx [root@web nginx-1.6.0]# nginx [root@web nginx-1.6.0]# netstat -anput | grep nginx tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 19008/nginx: master</code></pre><h6 id="2、查看-nginx-版本"><a href="#2、查看-nginx-版本" class="headerlink" title="2、查看 nginx 版本"></a>2、查看 nginx 版本</h6><pre class=" language-shell"><code class="language-shell">[root@web nginx-1.6.0]# nginx -vnginx version: nginx/1.6.0</code></pre><h6 id="3、查看-nginx-现有安装的模块"><a href="#3、查看-nginx-现有安装的模块" class="headerlink" title="3、查看 nginx 现有安装的模块"></a>3、查看 nginx 现有安装的模块</h6><pre class=" language-shell"><code class="language-shell">[root@web nginx-1.6.0]# nginx -Vnginx version: nginx/1.6.0built by gcc 4.8.5 20150623 (Red Hat 4.8.5-11) (GCC) configure arguments: --prefix=/usr/local/nginx --user=nginx --group=nginx --with-http_stub_status_module</code></pre><h6 id="4、访问验证"><a href="#4、访问验证" class="headerlink" title="4、访问验证"></a>4、访问验证</h6><pre class=" language-shell"><code class="language-shell">[root@web nginx-1.6.0]# echo "nginx1.6.0" > /usr/local/nginx/html/index.html[root@web nginx-1.6.0]# elinks 192.168.20.167</code></pre><p><a href="https://imgchr.com/i/GFh7KH" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/03/28/GFh7KH.md.png" alt="GFh7KH.md.png"></a></p><h6 id="5、升级-nginx"><a href="#5、升级-nginx" class="headerlink" title="5、升级 nginx"></a>5、升级 nginx</h6><p>将 nginx 版本进行升级 并在不影响业务的情况下添加 SSL 和 pcre 模块</p><pre class=" language-shell"><code class="language-shell">[root@web ~]# tar zxvf nginx-1.11.2.tar.gz -C /usr/src/[root@web ~]# cd /usr/src/nginx-1.11.2/[root@web nginx-1.11.2]# ./configure --prefix=/usr/local/nginx --user=nginx --group=ngiinx --with-http_stub_status_module --with-http_ssl_module --with-pcre[root@web nginx-1.11.2]# make[root@web nginx-1.11.2]# cd[root@web ~]# mv /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx_old [root@web ~]# cp /usr/src/nginx-1.11.2/objs/nginx /usr/local/nginx/sbin/[root@web ~]# mv /usr/local/nginx/conf/nginx.conf /usr/local/nginx/conf/nginx.conf.old[root@Centos ~]# cp /usr/src/nginx-1.11.2/conf/nginx.conf /usr/local/nginx/conf/nginx.conf[root@web ~]# kill -USR2 `cat /usr/local/nginx/logs/nginx.pid`[root@web ~]# ls /usr/local/nginx/logs/access.log error.log nginx.pid[root@web ~]# ps aux | grep nginx root 19008 0.0 0.0 24324 944 ? Ss 14:07 0:00 nginx: master process nginxnginx 19009 0.0 0.1 26832 1744 ? S 14:07 0:00 nginx: worker processroot 53194 0.0 0.0 112660 976 pts/0 R+ 14:36 0:00 grep --color=auto ngin</code></pre><h6 id="6、验证-nginx-是否升级成功"><a href="#6、验证-nginx-是否升级成功" class="headerlink" title="6、验证 nginx 是否升级成功"></a>6、验证 nginx 是否升级成功</h6><p><img src="https://s1.ax1x.com/2020/03/28/GFhgbR.png" alt="GFhgbR.png"></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka入门</title>
      <link href="2019/04/26/sql/kafka-ru-men/"/>
      <url>2019/04/26/sql/kafka-ru-men/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h1 id="KAFKA-消息中间件"><a href="#KAFKA-消息中间件" class="headerlink" title="KAFKA 消息中间件"></a>KAFKA 消息中间件</h1><h2 id="1、认识kafka"><a href="#1、认识kafka" class="headerlink" title="1、认识kafka"></a><strong>1、认识kafka</strong></h2><h3 id="1-1-kafka简介"><a href="#1-1-kafka简介" class="headerlink" title="1.1 kafka简介"></a><strong>1.1 kafka简介</strong></h3><p>Kafka 是一个分布式流媒体平台</p><p>kafka官网：<a href="http://kafka.apache.org/" target="_blank" rel="noopener">http://kafka.apache.org/</a></p><p>（1）流媒体平台有三个关键功能：</p><ul><li><strong>发布和订阅记录流</strong>，类似于消息队列或企业消息传递系统。</li><li>以<strong>容错的持久方式存储记录流</strong>。</li><li>记录发生时处理流。</li></ul><p>（2）Kafka通常用于两大类应用：</p><ul><li>构建可在<strong>系统或应用程序之间</strong>可靠获取数据的实时流数据管道</li><li>构建转换或响应数据流的实时流应用程序</li></ul><p>要了解Kafka如何做这些事情，让我们深入探讨Kafka的能力。</p><p>（3）首先是几个概念：</p><ul><li>Kafka作为一个集群运行在一个或多个可跨多个<strong>数据中心的服务器</strong>上。</li><li>Kafka集群以称为 <strong>topics主题</strong> 的类别存储记录流。</li><li>每条记录都包含<strong>一个键，一个值和一个时间戳</strong>。</li></ul><p>（4）Kafka有四个核心API：</p><ul><li><strong>Producer API（生产者API）</strong>允许应用程序<strong>发布</strong>记录流至一个或多个kafka的<strong>topics（主题）</strong>。</li><li><strong>Consumer API（消费者API）</strong>允许应用程序<strong>订阅一个或多个topics（主题）</strong>，并处理所产生的对他们记录的数据流。</li><li><strong>Streams API（流API）</strong>允许应用程序充当<strong>流处理器</strong>，从一个或多个<strong>topics（主题）</strong>消耗的输入流，并产生一个输出流至一个或多个输出的topics（主题），<strong>有效地变换所述输入流，以输出流</strong>。</li><li><strong>Connector API（连接器API）</strong>允许构建和运行kafka <strong>topics（主题）连接到现有的应用程序或数据系统中重用生产者或消费者</strong>。例如，关系数据库的连接器可能捕获对表的每个更改。</li></ul><p><img src="https://s1.ax1x.com/2020/04/26/J632xH.png" alt="J632xH.png"></p><p>　　在Kafka中，<strong>客户端和服务器之间的通信</strong>是通过简单，高性能，语言无关的<strong>TCP协议</strong>完成的。此协议已版本化并保持与旧版本的向后兼容性。Kafka提供Java客户端，但客户端有多种语言版本。</p><h3 id="1-2-Topics主题-和-partitions分区"><a href="#1-2-Topics主题-和-partitions分区" class="headerlink" title="1.2 Topics主题 和 partitions分区"></a><strong>1.2 Topics主题 和 partitions分区</strong></h3><p>我们首先深入了解 Kafka 为记录流提供的核心抽象 - 主题topics</p><p>　　<strong>一个Topic可以认为是一类消息，每个topic将被分成多个partition(区)</strong>,每个partition在存储层面是append log文件</p><p>　　<strong>主题是发布记录的类别或订阅源名称</strong>。Kafka的主题总是多用户; 也就是说，一个主题可以有零个，一个或多个消费者订阅写入它的数据。</p><p>　　对于<strong>每个主题</strong>，Kafka群集都维护一个如下所示的<strong>分区</strong>日志：</p><p><img src="https://s1.ax1x.com/2020/04/26/J63fsA.png" alt="J63fsA.png"></p><p>　　<strong>每个分区都是一个有序的，不可变的记录序列</strong>，不断附加到结构化的提交日志中。分区中的记录每个都分配了<strong>一个称为偏移的顺序ID号</strong>，它唯一地标识分区中的每个记录。</p><p>　　<strong>Kafka集群持久保存所有已发布的记录 - 无论是否已使用 - 使用可配置的保留期</strong>。例如，如果保留策略设置为两天，则在发布记录后的两天内，它可供使用，之后将被丢弃以释放空间。<strong>Kafka的性能在数据大小方面实际上是恒定的，因此长时间存储数据不是问题。</strong></p><p><img src="https://s1.ax1x.com/2020/04/26/J63IdP.png" alt="J63IdP.png"></p><p>　　实际上，基<strong>于每个消费者保留的唯一元数据是该消费者在日志中的偏移或位置</strong>。这种偏移由消费者控制：通常消费者在读取记录时会线性地提高其偏移量，但事实上，由于该位置由消费者控制，因此它可以按照自己喜欢的任何顺序消费记录。例如，消费者可以重置为较旧的偏移量来重新处理过去的数据，或者跳到最近的记录并从“现在”开始消费。</p><p>　　这些功能组合意味着Kafka 消费者consumers 非常cheap - 他们可以来来往往对集群或其他消费者没有太大影响。例如，您可以使用我们的命令行工具“tail”任何主题的内容，而无需更改任何现有使用者所消耗的内容。</p><p>　　<strong>日志中的分区有多种用途</strong>。首先，它们允许日志扩展到超出适合单个服务器的大小。每个单独的分区必须适合托管它的服务器，但<strong>主题可能有许多分区</strong>，因此它可以处理任意数量的数据。其次，它们充当了并行性的单位 - 更多的是它。</p><h3 id="1-3-Distribution-分配"><a href="#1-3-Distribution-分配" class="headerlink" title="1.3 Distribution 分配"></a><strong>1.3 Distribution</strong> <strong>分配</strong></h3><p>　　一个Topic的多个partitions,被分布在kafka集群中的多个server上;每个server(kafka实例)负责partitions中消息的读写操作;此外kafka还可以配置partitions需要备份的个数(replicas),每个partition将会被备份到多台机器上,以提高可用性.</p><p>　　基于replicated方案,那么就意味着需要对多个备份进行调度;每个partition都有一个server为”leader”;leader负责所有的读写操作,如果leader失效,那么将会有其他follower来接管(成为新的leader);follower只是单调的和leader跟进,同步消息即可..由此可见作为leader的server承载了全部的请求压力,因此从集群的整体考虑,有多少个partitions就意味着有多少个”leader”,kafka会将”leader”均衡的分散在每个实例上,来确保整体的性能稳定。</p><h3 id="1-4-Producers生产者-和-Consumers消费者"><a href="#1-4-Producers生产者-和-Consumers消费者" class="headerlink" title="1.4 Producers生产者 和 Consumers消费者"></a><strong>1.4 Producers生产者 和 Consumers消费者</strong></h3><h4 id="1-4-1-Producers生产者"><a href="#1-4-1-Producers生产者" class="headerlink" title="1.4.1 Producers生产者"></a><strong>1.4.1 Producers生产者</strong></h4><p>　　Producers 将数据<strong>发布到指定的topics 主题</strong>。同时Producer 也能决定将此消息归属于哪个partition;比如基于”round-robin”方式或者通过其他的一些算法等。</p><h4 id="1-4-2-Consumers"><a href="#1-4-2-Consumers" class="headerlink" title="1.4.2 Consumers"></a><strong>1.4.2</strong> <strong>Consumers</strong></h4><ul><li>本质上kafka只支持Topic.<strong>每个consumer属于一个consumer group</strong>;反过来说,每个group中可以有多个consumer.发送到Topic的消息,只会<strong>被订阅此Topic的每个group中的一个consumer消费</strong>。</li><li>如果所有使用者实例具有相同的使用者组，则记录将有效地在使用者实例上进行<strong>负载平衡</strong>。</li><li>如果所有消费者实例具有不同的消费者组，则每个记录将<strong>广播到所有消费者进程</strong>。</li></ul><p><img src="https://s1.ax1x.com/2020/04/26/J63oIf.png" alt="J63oIf.png"></p><p>　　分析：两个服务器Kafka群集，托管四个分区（P0-P3），包含两个使用者组。消费者组A有两个消费者实例，B组有四个消费者实例。</p><p>　　在Kafka中实现消费consumption 的方式是通过在消费者实例上划分日志中的<strong>分区</strong>，以便每个实例在任何时间点都是分配的“公平份额”的独占消费者。维护组中成员资格的过程由Kafka协议动态处理。如果新实例加入该组，他们将从该组的其他成员接管一些分区; 如果实例死亡，其分区将分发给其余实例。</p><p>　　<strong>Kafka仅提供分区内记录的总订单</strong>，而不是主题中不同分区之间的记录。对于大多数应用程序而言，按分区排序与按键分区数据的能力相结合就足够了。但是，如果您需要对记录进行总订单，则可以使用仅包含一个分区的主题来实现，但这将意味着每个使用者组只有一个使用者进程。</p><h3 id="1-5-Consumers-kafka确保"><a href="#1-5-Consumers-kafka确保" class="headerlink" title="1.5 Consumers kafka确保"></a><strong>1.5 Consumers kafka确保</strong></h3><ul><li><strong>发送到partitions中的消息将会按照它接收的顺序追加到日志中</strong>。也就是说，如果记录M1由与记录M2相同的生成者发送，并且首先发送M1，则M1将具有比M2更低的偏移并且在日志中更早出现。</li><li>消费者实例按照它们存储在日志中的顺序查看记录。对于消费者而言,<strong>它们消费消息的顺序和日志中消息顺序一致</strong>。</li><li>如果Topic的”replicationfactor”为N,那么允许N-1个kafka实例失效，我们将容忍最多N-1个服务器故障，而不会丢失任何提交到日志的记录。</li></ul><h3 id="1-6-kafka-作为消息系统"><a href="#1-6-kafka-作为消息系统" class="headerlink" title="1.6 kafka**作为消息系统**"></a><strong>1.6 kafka**</strong>作为消息系统**</h3><p>Kafka的流概念与传统的企业邮件系统相比如何？</p><p>（1）传统消息系统</p><p>　　消息传统上有两种模型：queuing排队 and publish-subscribe发布 - 订阅。在队列中，消费者池可以从服务器读取并且每个记录转到其中一个; 在发布 - 订阅中，记录被广播给所有消费者。这两种模型中的每一种都有优点和缺点。排队的优势在于它允许您在多个消费者实例上划分数据处理，从而可以扩展您的处理。不幸的是，一旦一个进程读取它已经消失的数据，队列就不是多用户。发布 - 订阅允许您将数据广播到多个进程，但由于每条消息都发送给每个订阅者，因此无法进行扩展处理。</p><p>kafka的消费者群体概念概括了这两个概念。与队列一样，使用者组允许您将处理划分为一组进程（使用者组的成员）。与发布 - 订阅一样，Kafka允许您向多个消费者组广播消息。</p><p>（2）kafka 的优势</p><p>　　<strong>Kafka模型的优势在于每个主题都具有这些属性</strong> - 它可以扩展处理并且也是多用户 - 不需要选择其中一个。</p><p>　　与传统的消息系统相比，Kafka具有<strong>更强的订购保证</strong>。</p><p>　　传统队列在服务器上按顺序保留记录，如果多个消费者从队列中消耗，则服务器按照存储顺序分发记录。但是，虽然服务器按顺序分发记录，但是记录是异步传递给消费者的，因此它们可能会在不同的消费者处出现故障。这实际上意味着在存在并行消耗的情况下丢失记录的顺序。消息传递系统通常通过具有“独占消费者”概念来解决这个问题，该概念只允许一个进程从队列中消耗，但当然这意味着处理中没有并行性。</p><p>　　<strong>kafka做得更好。通过在主题中具有并行性概念 - 分区 - ，Kafka能够在消费者流程池中提供订购保证和负载平衡</strong>。这是通过将主题中的分区分配给使用者组中的使用者来实现的，以便每个分区仅由该组中的一个使用者使用。通过这样做，我们确保使用者是该分区的唯一读者并按顺序使用数据。由于有许多分区，这仍然可以平衡许多消费者实例的负载。但请注意，消费者组中的消费者实例不能超过分区。</p><h3 id="1-7-kafka作为存储系统"><a href="#1-7-kafka作为存储系统" class="headerlink" title="1.7 kafka作为存储系统"></a><strong>1.7 kafka作为存储系统</strong></h3><ul><li>任何允许发布与消费消息分离的消息的消息队列实际上充当了正在进行的消息的存储系统。Kafka的不同之处在于它是<strong>一个非常好的存储系统</strong>。</li><li><strong>写入Kafka的数据将写入磁盘并进行复制以实现容错</strong>。Kafka允许生产者等待确认，以便在完全复制之前写入不被认为是完整的，并且即使写入的服务器失败也保证写入仍然存在。</li><li><strong>磁盘结构Kafka很好地使用了规模</strong> - 无论服务器上有50 KB还是50 TB的持久数据，Kafka都会执行相同的操作。</li><li>由于认真对待存储并允许客户端控制其读取位置，您可以将<strong>Kafka视为一种专用于高性能，低延迟提交日志存储，复制和传播的专用分布式文件系统</strong>。</li><li>有关Kafka的提交日志存储和复制设计的详细信息，请阅读<a href="https://kafka.apache.org/documentation/#design" target="_blank" rel="noopener">此</a>页面。</li></ul><h3 id="1-8-kafka用于流处理"><a href="#1-8-kafka用于流处理" class="headerlink" title="1.8 kafka用于流处理"></a><strong>1.8 kafka用于流处理</strong></h3><ul><li>仅仅读取，写入和存储数据流是不够的，目的是实现<strong>流的实时处理</strong>。</li><li>在Kafka中，流处理器是指<strong>从输入主题获取连续数据流，对此输入执行某些处理以及生成连续数据流以输出主题的任何内容</strong>。</li><li>例如，零售应用程序可能会接收销售和发货的输入流，并输出重新排序流和根据此数据计算的价格调整。</li><li>可以使用生产者和消费者API直接进行简单处理。但是，对于更复杂的转换，Kafka提供了完全集成的Streams API。这允许构建执行非平凡处理的应用程序，这些应用程序可以计算流的聚合或将流连接在一起。</li><li>此工具有助于解决此类应用程序面临的难题：处理无序数据，在代码更改时重新处理输入，执行有状态计算等。</li><li>流API构建在Kafka提供的核心原语上：它使用生产者和消费者API进行输入，使用Kafka进行有状态存储，并在流处理器实例之间使用相同的组机制来实现容错。</li></ul><h2 id="2、kafka使用场景"><a href="#2、kafka使用场景" class="headerlink" title="2、kafka使用场景"></a><strong>2、kafka使用场景</strong></h2><h3 id="2-1-消息Messaging"><a href="#2-1-消息Messaging" class="headerlink" title="2.1 消息Messaging"></a><strong>2.1 消息Messaging</strong></h3><p>　　<strong>Kafka可以替代更传统的消息代理</strong>。消息代理的使用有多种原因（将处理与数据生成器分离，缓冲未处理的消息等）。<strong>与大多数消息传递系统相比，Kafka具有更好的吞吐量，内置分区，复制和容错功能</strong>，这使其成为大规模消息处理应用程序的理想解决方案。</p><p>　　根据经验，消息传递的使用通常相对较低，但可能需要较低的端到端延迟，并且通常取决于Kafka提供的强大的耐用性保证。</p><p>　　在这个领域，Kafka可与传统的消息传递系统（如<a href="http://activemq.apache.org/" target="_blank" rel="noopener">ActiveMQ</a>或 <a href="https://www.rabbitmq.com/" target="_blank" rel="noopener">RabbitMQ</a>）相媲美。</p><h3 id="2-2-网站活动跟踪"><a href="#2-2-网站活动跟踪" class="headerlink" title="2.2 网站活动跟踪"></a><strong>2.2 网站活动跟踪</strong></h3><p>　　Kafka的原始用例是能够将用户活动跟踪管道重建为一组实时发布 - 订阅源。这意味着站点活动（页面查看，搜索或用户可能采取的其他操作）将发布到中心主题，每个活动类型包含一个主题。这些源可用于订购一系列用例，<strong>包括实时处理，实时监控以及加载到Hadoop或离线数据仓库系统以进行脱机处理和报告</strong>。</p><p>　　活动跟踪通常非常高，因为为每个用户页面视图生成了许多活动消息。</p><h3 id="2-3-度量Metrics"><a href="#2-3-度量Metrics" class="headerlink" title="2.3 度量Metrics"></a><strong>2.3 度量Metrics</strong></h3><p>　　<strong>Kafka通常用于运营监控数据</strong>。这涉及从分布式应用程序聚合统计信息以生成操作数据的集中式提要。</p><h3 id="2-4-日志聚合"><a href="#2-4-日志聚合" class="headerlink" title="2.4 日志聚合"></a><strong>2.4 日志聚合</strong></h3><p>　　许多人使用Kafka作为日志聚合解决方案的替代品。日志聚合通常从服务器收集物理日志文件，并将它们放在中央位置（可能是文件服务器或HDFS）进行处理。<strong>Kafka抽象出文件的细节，并将日志或事件数据作为消息流更清晰地抽象出来</strong>。这允许更低延迟的处理并更容易支持多个数据源和分布式数据消耗。与Scribe或Flume等以日志为中心的系统相比，<strong>Kafka提供了同样出色的性能，由于复制而具有更强的耐用性保证，以及更低的端到端延迟。</strong></p><h3 id="2-5-流处理"><a href="#2-5-流处理" class="headerlink" title="2.5 流处理"></a><strong>2.5 流处理</strong></h3><p>　　许多Kafka用户在处理由多个阶段组成的管道时处理数据，<strong>其中原始输入数据从Kafka主题中消费，然后聚合，丰富或以其他方式转换为新主题以供进一步消费或后续处理</strong>。</p><p>　　例如，用于推荐新闻文章的处理管道可以从RSS订阅源抓取文章内容并将其发布到“文章”主题; 进一步处理可能会对此内容进行规范化或重复数据删除，并将已清理的文章内容发布到新主题; 最终处理阶段可能会尝试向用户推荐此内容。此类处理管道基于各个主题创建实时数据流的图形。从0.10.0.0开始，这是一个轻量级但功能强大的流处理库，名为<a href="http://kafka.apache.org/documentation/streams" target="_blank" rel="noopener">Kafka Streams</a> 在Apache Kafka中可用于执行如上所述的此类数据处理。除了Kafka Streams之外，其他开源流处理工具包括<a href="https://storm.apache.org/" target="_blank" rel="noopener">Apache Storm</a>和 <a href="http://samza.apache.org/" target="_blank" rel="noopener">Apache Samza</a>。</p><h3 id="2-6-Event-Sourcing"><a href="#2-6-Event-Sourcing" class="headerlink" title="2.6 Event Sourcing"></a><strong>2.6 Event Sourcing</strong></h3><p>　　Event Sourcing是一种应用程序设计风格，其中状态更改记录为按时间排序的记录序列。Kafka对非常大的存储日志数据的支持使其成为以这种风格构建的应用程序的出色后端。</p><h3 id="2-7-提交日志"><a href="#2-7-提交日志" class="headerlink" title="2.7 提交日志"></a><strong>2.7 提交日志</strong></h3><p>　　<strong>Kafka可以作为分布式系统的一种外部提交日志</strong>。该日志有助于在节点之间复制数据，并充当故障节点恢复其数据的重新同步机制。Kafka中的日志压缩功能有助于支持此用法。在这种用法中，Kafka类似于<a href="https://bookkeeper.apache.org/" target="_blank" rel="noopener">Apache BookKeeper</a>项目。</p><h2 id="3、kafka安装"><a href="#3、kafka安装" class="headerlink" title="3、kafka安装"></a><strong>3、kafka安装</strong></h2><h3 id="3-1-下载安装"><a href="#3-1-下载安装" class="headerlink" title="3.1 下载安装"></a><strong>3.1 下载安装</strong></h3><p>到官网<a href="http://kafka.apache.org/downloads.html" target="_blank" rel="noopener">http://kafka.apache.org/downloads.html</a>下载想要的版本；我这里下载的最新稳定版2.1.0</p><p>注：由于Kafka控制台脚本对于基于Unix和Windows的平台是不同的，因此在Windows平台上使用bin\windows\ 而不是bin/ 将脚本扩展名更改为.bat。</p><pre><code>[root@along ~]# wget http://mirrors.shu.edu.cn/apache/kafka/2.1.0/kafka_2.11-2.1.0.tgz[root@along ~]# tar -C /data/ -xvf kafka_2.11-2.1.0.tgz[root@along ~]# cd /data/kafka_2.11-2.1.0/</code></pre><p>　　</p><h3 id="3-2-配置启动zookeeper"><a href="#3-2-配置启动zookeeper" class="headerlink" title="3.2 配置启动zookeeper"></a><strong>3.2 配置启动zookeeper</strong></h3><p>　　kafka正常运行，必须配置zookeeper，否则无论是kafka集群还是客户端的生存者和消费者都无法正常的工作的；所以需要配置启动zookeeper服务。</p><p>（1）zookeeper需要java环境</p><pre><code>[root@along ~]# yum -y install java-1.8.0</code></pre><p>（2）这里kafka下载包已经包括zookeeper服务，所以只需修改配置文件，启动即可。</p><p>如果需要下载指定zookeeper版本；可以单独去zookeeper官网<a href="http://mirrors.shu.edu.cn/apache/zookeeper/" target="_blank" rel="noopener">http://mirrors.shu.edu.cn/apache/zookeeper/</a>下载指定版本。</p><pre><code>[root@along ~]# cd /data/kafka_2.11-2.1.0/[root@along kafka_2.11-2.1.0]# grep &quot;^[^#]&quot; config/zookeeper.properties dataDir=/tmp/zookeeper        #数据存储目录clientPort=2181               #zookeeper端口maxClientCnxns=0</code></pre><p>注：可自行添加修改zookeeper配置</p><h3 id="3-3-配置kafka"><a href="#3-3-配置kafka" class="headerlink" title="3.3 配置kafka"></a><strong>3.3 配置kafka</strong></h3><p>（1）修改配置文件</p><pre><code>[root@along kafka_2.11-2.1.0]# grep &quot;^[^#]&quot; config/server.properties broker.id=0 listeners=PLAINTEXT://localhost:9092num.network.threads=3 num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=/tmp/kafka-logsnum.partitions=1num.recovery.threads.per.data.dir=1offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=localhost:2181zookeeper.connection.timeout.ms=6000group.initial.rebalance.delay.ms=0</code></pre><p>注：可根据自己需求修改配置文件</p><ul><li>broker.id：唯一标识ID</li><li>listeners=PLAINTEXT://localhost:9092：kafka服务监听地址和端口</li><li>log.dirs：日志存储目录</li><li>zookeeper.connect：指定zookeeper服务</li></ul><p>（2）配置环境变量</p><pre><code>[root@along ~]# vim /etc/profile.d/kafka.shexport KAFKA_HOME=&quot;/data/kafka_2.11-2.1.0&quot;export PATH=&quot;${KAFKA_HOME}/bin:$PATH&quot;[root@along ~]# source /etc/profile.d/kafka.sh</code></pre><p>　　</p><p>（3）配置服务启动脚本</p><pre class=" language-shell"><code class="language-shell">[root@along ~]# vim /etc/init.d/kafka#!/bin/sh## chkconfig: 345 99 01# description: Kafka## File : Kafka## Description: Starts and stops the Kafka server# source /etc/rc.d/init.d/functions KAFKA_HOME=/data/kafka_2.11-2.1.0KAFKA_USER=rootexport LOG_DIR=/tmp/kafka-logs [ -e /etc/sysconfig/kafka ] && . /etc/sysconfig/kafka # See how we were called.case "$1" in  start)    echo -n "Starting Kafka:"    /sbin/runuser -s /bin/sh $KAFKA_USER -c "nohup $KAFKA_HOME/bin/kafka-server-start.sh $KAFKA_HOME/config/server.properties > $LOG_DIR/server.out 2> $LOG_DIR/server.err &"    echo " done."    exit 0    ;;  stop)    echo -n "Stopping Kafka: "    /sbin/runuser -s /bin/sh $KAFKA_USER  -c "ps -ef | grep kafka.Kafka | grep -v grep | awk '{print \$2}' | xargs kill"    echo " done."    exit 0    ;;  hardstop)    echo -n "Stopping (hard) Kafka: "    /sbin/runuser -s /bin/sh $KAFKA_USER  -c "ps -ef | grep kafka.Kafka | grep -v grep | awk '{print \$2}' | xargs kill -9"    echo " done."    exit 0    ;;  status)    c_pid=`ps -ef | grep kafka.Kafka | grep -v grep | awk '{print $2}'`    if [ "$c_pid" = "" ] ; then      echo "Stopped"      exit 3    else      echo "Running $c_pid"      exit 0    fi    ;;  restart)    stop    start    ;;  *)    echo "Usage: kafka {start|stop|hardstop|status|restart}"    exit 1    ;;esac</code></pre><p>　chmod +x kafka </p><p>​    chkconfig –add kafka  添加到服务器中</p><p>​    chkconfig kafka on 设置开机自动启动　</p><h3 id="3-4-启动kafka服务"><a href="#3-4-启动kafka服务" class="headerlink" title="3.4 启动kafka服务"></a><strong>3.4 启动kafka服务</strong></h3><p>（1）后台启动zookeeper服务</p><pre class=" language-shell"><code class="language-shell">[root@along ~]# nohup zookeeper-server-start.sh /data/kafka_2.11-2.1.0/config/zookeeper.properties &</code></pre><p>（2）启动kafka服务</p><pre class=" language-shell"><code class="language-shell">[root@along ~]# service kafka startStarting kafka (via systemctl):                            [  OK  ][root@along ~]# service kafka statusRunning 86018[root@along ~]# ss -nutlNetid State      Recv-Q Send-Q     Local Address:Port                    Peer Address:Port                              tcp   LISTEN     0      50                    :::9092                              :::*                 tcp   LISTEN     0      50                    :::2181                              :::*</code></pre><p>　　</p><h2 id="4、kafka使用简单入门"><a href="#4、kafka使用简单入门" class="headerlink" title="4、kafka使用简单入门"></a><strong>4、kafka使用简单入门</strong></h2><h3 id="4-1-创建主题topics"><a href="#4-1-创建主题topics" class="headerlink" title="4.1 创建主题topics"></a><strong>4.1 创建主题topics</strong></h3><p>创建一个名为“along”的主题，它只包含一个分区，只有一个副本：</p><pre class=" language-shell"><code class="language-shell">[root@along ~]# kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic along Created topic "along".</code></pre><p>如果我们运行list topic命令，我们现在可以看到该主题：</p><pre class=" language-shell"><code class="language-shell">[root@along ~]# kafka-topics.sh --list --zookeeper localhost:2181 along</code></pre><p>　　</p><h3 id="4-2-发送一些消息"><a href="#4-2-发送一些消息" class="headerlink" title="4.2 发送一些消息"></a><strong>4.2 发送一些消息</strong></h3><p>Kafka附带一个命令行客户端，它将从文件或标准输入中获取输入，并将其作为消息发送到Kafka集群。默认情况下，每行将作为单独的消息发送。</p><p>运行生产者，然后在控制台中键入一些消息以发送到服务器。</p><pre><code>[root@along ~]# kafka-console-producer.sh --broker-list localhost:9092 --topic along&gt;This is a message&gt;This is another message</code></pre><p>　　</p><h3 id="4-3-启动消费者"><a href="#4-3-启动消费者" class="headerlink" title="4.3 启动消费者"></a><strong>4.3 启动消费者</strong></h3><p>Kafka还有一个命令行使用者，它会将消息转储到标准输出。</p><pre><code>[root@along ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic along --from-beginning This is a message This is another message</code></pre><p>所有命令行工具都有其他选项; 运行不带参数的命令将显示更详细地记录它们的使用信息。</p><h2 id="5、设置多代理kafka群集"><a href="#5、设置多代理kafka群集" class="headerlink" title="5、设置多代理kafka群集"></a><strong>5、设置多代理kafka群集</strong></h2><p>　　到目前为止，我们一直在与一个broker运行，但这并不好玩。对于Kafka，单个代理只是一个大小为1的集群，因此除了启动一些代理实例之外没有太多变化。但是为了感受它，让我们将我们的集群扩展到三个节点（仍然在我们的本地机器上）。</p><h3 id="5-1-准备配置文件"><a href="#5-1-准备配置文件" class="headerlink" title="5.1 准备配置文件"></a><strong>5.1 准备配置文件</strong></h3><pre class=" language-shell"><code class="language-shell">[root@along kafka_2.11-2.1.0]# cd /data/kafka_2.11-2.1.0/[root@along kafka_2.11-2.1.0]# cp config/server.properties config/server-1.properties[root@along kafka_2.11-2.1.0]# cp config/server.properties config/server-2.properties[root@along kafka_2.11-2.1.0]# vim config/server-1.properties    broker.id=1    listeners=PLAINTEXT://:9093log.dirs=/tmp/kafka-logs-1[root@along kafka_2.11-2.1.0]# vim config/server-2.propertiesbroker.id=2listeners=PLAINTEXT://:9094log.dirs=/tmp/kafka-logs-2</code></pre><p>注：该<strong>broker.id</strong> 属性是群集中每个节点的<strong>唯一</strong>且永久的名称。我们必须覆盖端口和日志目录，因为我们在同一台机器上运行这些，并且我们希望让所有代理尝试在同一端口上注册或覆盖彼此的数据。</p><h3 id="5-2-开启集群另2个kafka服务"><a href="#5-2-开启集群另2个kafka服务" class="headerlink" title="5.2 开启集群另2个kafka服务"></a><strong>5.2 开启集群另2个kafka服务</strong></h3><pre><code>[root@along ~]# nohup kafka-server-start.sh /data/kafka_2.11-2.1.0/config/server-1.properties &amp;[root@along ~]# nohup kafka-server-start.sh /data/kafka_2.11-2.1.0/config/server-2.properties &amp;[root@along ~]# ss -nutlNetid State      Recv-Q Send-Q     Local Address:Port                    Peer Address:Port                          tcp   LISTEN     0      50      ::ffff:127.0.0.1:9092                              :::*                 tcp   LISTEN     0      50      ::ffff:127.0.0.1:9093                              :::*                                tcp   LISTEN     0      50      ::ffff:127.0.0.1:9094                              :::*</code></pre><p>　　</p><h3 id="5-3-在集群中进行操作"><a href="#5-3-在集群中进行操作" class="headerlink" title="5.3 在集群中进行操作"></a><strong>5.3 在集群中进行操作</strong></h3><p>（1）现在创建一个复制因子为3的新主题my-replicated-topic</p><pre><code>[root@along ~]# kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic Created topic &quot;my-replicated-topic&quot;.</code></pre><p>　　</p><p>（2）在一个集群中，运行“describe topics”命令查看哪个broker正在做什么</p><pre><code>[root@along ~]# kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic Topic:my-replicated-topic   PartitionCount:1    ReplicationFactor:3 Configs:Topic: my-replicated-topic  Partition: 0    Leader: 2   Replicas: 2,0,1 Isr: 2,0,1</code></pre><p>注释：第一行给出了所有分区的摘要，每个附加行提供有关一个分区的信息。由于我们只有一个分区用于此主题，因此只有一行。</p><ul><li>“leader”是负责给定分区的所有读取和写入的节点。每个节点将成为随机选择的分区部分的领导者。</li><li>“replicas”是复制此分区日志的节点列表，无论它们是否为领导者，或者即使它们当前处于活动状态。</li><li>“isr”是“同步”复制品的集合。这是副本列表的子集，该列表当前处于活跃状态并且已经被领导者捕获。</li></ul><p>请注意，Leader: 2，在我的示例中，节点2 是该主题的唯一分区的Leader。</p><p>（3）可以在我们创建的原始主题上运行相同的命令，以查看它的位置</p><pre><code>[root@along ~]# kafka-topics.sh --describe --zookeeper localhost:2181 --topic along Topic:along PartitionCount:1    ReplicationFactor:1 Configs:   Topic: along    Partition: 0    Leader: 0   Replicas: 0 Isr: 0</code></pre><p>　　</p><p>（4）向我们的新主题发布一些消息：</p><pre><code>[root@along ~]# kafka-console-producer.sh --broker-list localhost:9092 --topic my-replicated-topic&gt;my test message 1&gt;my test message 2&gt;^C</code></pre><p>　　</p><p>（5）现在让我们使用这些消息：</p><pre><code>[root@along ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic my-replicated-topicmy test message 1my test message 2</code></pre><p>　　</p><h3 id="5-4-测试集群的容错性"><a href="#5-4-测试集群的容错性" class="headerlink" title="5.4 测试集群的容错性"></a><strong>5.4 测试集群的容错性</strong></h3><p>（1）现在让我们测试一下容错性。Broker 2 充当leader 所以让我们杀了它：</p><pre><code>[root@along ~]# ps aux | grep server-2.properties |awk &#39;{print $2}&#39;106737[root@along ~]# kill -9 106737[root@along ~]# ss -nutltcp   LISTEN     0      50      ::ffff:127.0.0.1:9092                              :::*                       tcp   LISTEN     0      50      ::ffff:127.0.0.1:9093                              :::*</code></pre><p>　　</p><p>（2）leader 已切换到其中一个从属节点，节点2不再位于同步副本集中：</p><pre><code>[root@along ~]# kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic Topic:my-replicated-topic   PartitionCount:1    ReplicationFactor:3 Configs:    Topic: my-replicated-topic  Partition: 0    Leader: 0   Replicas: 2,0,1 Isr: 0,1</code></pre><p>　　</p><p>（3）即使最初接受写入的leader 已经失败，这些消息仍可供消费：</p><pre><code>[root@along ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic my-replicated-topicmy test message 1my test message 2</code></pre><p>　　</p><h2 id="6、-使用Kafka-Connect导入-导出数据"><a href="#6、-使用Kafka-Connect导入-导出数据" class="headerlink" title="6、**使用Kafka Connect导入/导出数据**"></a><strong>6、**</strong>使用Kafka Connect导入/导出数据**</h2><p>　　从控制台写入数据并将其写回控制台是一个方便的起点，但有时候可能希望使用<strong>其他来源的数据或将数据从Kafka导出到其他系统</strong>。对于许多系统，您可以<strong>使用Kafka Connect导入或导出数据</strong>，而不是编写自定义集成代码。</p><p>　　<strong>Kafka Connect是Kafka附带的工具，用于向Kafka导入和导出数据</strong>。它是一个可扩展的工具，运行连接器，实现与外部系统交互的自定义逻辑。在本快速入门中，我们将了解如何使用简单的连接器运行Kafka Connect，这些连接器将数据从文件导入Kafka主题并将数据从Kafka主题导出到文件。</p><p>（1）首先创建一些种子数据进行测试：</p><pre><code>[root@along ~]# echo -e &quot;foo\nbar&quot; &gt; test.txt</code></pre><p>或者在Windows上：</p><pre><code>&gt; echo foo&gt; test.txt&gt; echo bar&gt;&gt; test.txt</code></pre><p>　　</p><p>（2）接下来，<strong>启动两个以独立模式运行的连接器</strong>，这意味着它们在单个本地专用进程中运行。提供三个配置文件作为参数。</p><ul><li>第一个始终是Kafka Connect流程的配置，包含常见配置，例如要连接的Kafka代理和数据的序列化格式。</li><li>其余配置文件均指定要创建的连接器。这些文件包括唯一的连接器名称，要实例化的连接器类以及连接器所需的任何其他配置。</li></ul><pre><code>[root@along ~]# connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties[2019-01-16 16:16:31,884] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:67)[2019-01-16 16:16:31,903] INFO WorkerInfo values:... ...</code></pre><p>　　注：Kafka附带的这些示例配置文件使用您之前启动的默认本地群集配置并创建两个连接器：第一个是源连接器，它从输入文件读取行并生成每个Kafka主题，第二个是宿连接器从Kafka主题读取消息并将每个消息生成为输出文件中的一行。</p><p>（3）验证是否导入成功（另起终端）</p><p>在启动过程中，您将看到许多日志消息，包括一些指示正在实例化连接器的日志消息。</p><p>① 一旦Kafka Connect进程启动，源连接器应该开始从test.txt主题读取行并将其生成到主题connect-test，并且接收器连接器应该开始从主题读取消息connect-test 并将它们写入文件test.sink.txt。我们可以通过检查输出文件的内容来验证数据是否已通过整个管道传递：</p><pre><code>[root@along ~]# cat test.sink.txtfoobar</code></pre><p>　　</p><p>② 请注意，数据存储在Kafka主题中connect-test，因此我们还可以运行控制台使用者来查看主题中的数据（或使用自定义使用者代码来处理它）：</p><pre><code>[root@along ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning{&quot;schema&quot;:{&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false},&quot;payload&quot;:&quot;foo&quot;}{&quot;schema&quot;:{&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false},&quot;payload&quot;:&quot;bar&quot;}</code></pre><p>　　</p><p>（4）继续追加数据，验证</p><pre><code>[root@along ~]# echo Another line&gt;&gt; test.txt   [root@along ~]# cat test.sink.txtfoobarAnother line[root@along ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning{&quot;schema&quot;:{&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false},&quot;payload&quot;:&quot;foo&quot;}{&quot;schema&quot;:{&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false},&quot;payload&quot;:&quot;bar&quot;}{&quot;schema&quot;:{&quot;type&quot;:&quot;string&quot;,&quot;optional&quot;:false},&quot;payload&quot;:&quot;Another line&quot;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> SQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka集群搭建</title>
      <link href="2019/04/26/sql/kafka-ji-qun-da-jian/"/>
      <url>2019/04/26/sql/kafka-ji-qun-da-jian/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="常用Message-Queue对比"><a href="#常用Message-Queue对比" class="headerlink" title="常用Message Queue对比"></a>常用Message Queue对比</h3><p><strong>RabbitMQ</strong></p><pre><code>RabbitMQ是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正因如此，它非常重量级，更适合于企业级的开发。同时实现了Broker构架，这意味着消息在发送给客户端时先在中心队列排队。对路由，负载均衡或者数据持久化都有很好的支持。</code></pre><p><strong>Redis</strong></p><pre><code>Redis是一个基于Key-Value对的NoSQL数据库，开发维护很活跃。虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。测试数据分为128Bytes、512Bytes、1K和10K四个不同大小的数据。实验表明：入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。</code></pre><p><strong>ZeroMQ</strong></p><pre><code>ZeroMQ号称最快的消息队列系统，尤其针对大吞吐量的需求场景。ZeroMQ能够实现RabbitMQ不擅长的高级/复杂的队列，但是开发人员需要自己组合多种技术框架，技术上的复杂度是对这MQ能够应用成功的挑战。ZeroMQ具有一个独特的非中间件的模式，你不需要安装和运行一个消息服务器或中间件，因为你的应用程序将扮演这个服务器角色。你只需要简单的引用ZeroMQ程序库，可以使用NuGet安装，然后你就可以愉快的在应用程序之间发送消息了。但是ZeroMQ仅提供非持久性的队列，也就是说如果宕机，数据将会丢失。其中，Twitter的Storm 0.9.0以前的版本中默认使用ZeroMQ作为数据流的传输（Storm从0.9版本开始同时支持ZeroMQ和Netty作为传输模块）。</code></pre><p><strong>ActiveMQ</strong></p><pre><code>ActiveMQ是Apache下的一个子项目。 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。同时类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景。</code></pre><p><strong>Kafka/Jafka</strong></p><pre><code>Kafka是Apache下的一个子项目，是一个高性能跨语言分布式发布/订阅消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行加载机制统一了在线和离线的消息处理。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统</code></pre><h3 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h3><p>producer： 消息生产者，发布消息到 kafka 集群的终端或服务。<br>broker： kafka 集群中包含的服务器。<br>topic：每条发布到 kafka 集群的消息属于的类别，即 kafka 是面向 topic 的。<br>partition： partition 是物理上的概念，每个 topic 包含一个或多个 partition。kafka 分配的单位是 partition。<br>consumer： 从 kafka 集群中消费消息的终端或服务。<br>Consumer group： high-level consumer API 中，每个 consumer 都属于一个 consumer group，每条消息只能被 consumer group 中的一个 Consumer 消费，但可以被多个 consumer group 消费。<br>replica： partition 的副本，保障 partition 的高可用。<br>leader： replica 中的一个角色， producer 和 consumer 只跟 leader 交互。<br>follower： replica 中的一个角色，从 leader 中复制数据。<br>controller： kafka 集群中的其中一个服务器，用来进行 leader election 以及 各种 failover。<br>zookeeper： kafka 通过 zookeeper 来存储集群的 meta 信息</p><h3 id="单实例Kafka"><a href="#单实例Kafka" class="headerlink" title="单实例Kafka"></a>单实例Kafka</h3><p>前提条件：安装JDK、设置JAVA_HOME、PATH环境变量。</p><p>wget <a href="http://mirrors.hust.edu.cn/apache/kafka/1.1.0/kafka_2.12-1.1.0.tgz" target="_blank" rel="noopener">http://mirrors.hust.edu.cn/apache/kafka/1.1.0/kafka_2.12-1.1.0.tgz</a></p><h4 id="1-Terminal-A"><a href="#1-Terminal-A" class="headerlink" title="(1) Terminal A"></a>(1) Terminal A</h4><pre class=" language-shell"><code class="language-shell">[root@sdopenswan-jp ~]# lsconfigserver.sh  kafka_2.12-0.10.2.1.tgz[root@sdopenswan-jp ~]# tar xfz kafka_2.12-0.10.2.1.tgz[root@sdopenswan-jp ~]# lsconfigserver.sh  kafka_2.12-0.10.2.1  kafka_2.12-0.10.2.1.tgz[root@sdopenswan-jp ~]# cd kafka_2.12-0.10.2.1[root@sdopenswan-jp kafka_2.12-0.10.2.1]# vim config/zookeeper.properties[root@sdopenswan-jp kafka_2.12-0.10.2.1]# grep -Pv "^#" config/zookeeper.propertiesdataDir=zkdata1clientPort=2181maxClientCnxns=0[root@sdopenswan-jp kafka_2.12-0.10.2.1]# bin/zookeeper-server-start.sh config/zookeeper.properties &      #启动zookeeper[root@sdopenswan-jp kafka_2.12-0.10.2.1]# lsbin  config  libs  LICENSE  logs  NOTICE  site-docs  zkdata1[root@sdopenswan-jp kafka_2.12-0.10.2.1]# ls zkdata1/version-2[root@sdopenswan-jp kafka_2.12-0.10.2.1]# vim config/server.properties[root@sdopenswan-jp kafka_2.12-0.10.2.1]# grep -Pv "^($|#)" config/server.propertiesbroker.id=0listeners=PLAINTEXT://:9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=kfkdata1num.partitions=1num.recovery.threads.per.data.dir=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=localhost:2181zookeeper.connection.timeout.ms=6000[root@sdopenswan-jp kafka_2.12-0.10.2.1]# bin/kafka-server-start.sh config/server.properties[root@sdopenswan-jp kafka_2.12-0.10.2.1]# lsbin  config  kfkdata1  libs  LICENSE  logs  NOTICE  site-docs  zkdata1[root@sdopenswan-jp kafka_2.12-0.10.2.1]# ls kfkdata1/cleaner-offset-checkpoint  meta.properties  recovery-point-offset-checkpoint  replication-offset-checkpoint[root@sdopenswan-jp kafka_2.12-0.10.2.1]# jps3538 Jps2964 QuorumPeerMain3214 Kafka[root@sdopenswan-jp kafka_2.12-0.10.2.1]#</code></pre><p>Kafka 占tcp 9092 端口，而zookeeper占 tcp 2181端口</p><h4 id="2-Terminal-B-创建-一个topic"><a href="#2-Terminal-B-创建-一个topic" class="headerlink" title="(2) Terminal B   创建 一个topic"></a>(2) Terminal B   创建 一个topic</h4><pre class=" language-shell"><code class="language-shell">[root@sdopenswan-jp kafka_2.12-0.10.2.1]# bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partition 1 --topic myfirst-topicWARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both.Created topic "myfirst_topic".[root@sdopenswan-jp kafka_2.12-0.10.2.1]# ls kfkdata1/cleaner-offset-checkpoint  meta.properties  myfirst_topic-0  recovery-point-offset-checkpoint  replication-offset-checkpoint[root@sdopenswan-jp kafka_2.12-0.10.2.1]# ls kfkdata1/myfirst-topic-0/00000000000000000000.index  00000000000000000000.log  00000000000000000000.timeindex[root@sdopenswan-jp kafka_2.12-0.10.2.1]#[root@sdopenswan-jp kafka_2.12-0.10.2.1]# bin/kafka-topics.sh --list --zookeeper localhost:2181myfirst-topic[root@sdopenswan-jp kafka_2.12-0.10.2.1]# bin/kafka-console-producer.sh --topic myfirst-topic --broker-list localhost:9092hello world !hello kafka myfirst_topic </code></pre><h4 id="3-Terminal-C-consumer端连接到zookeeper-读取信息"><a href="#3-Terminal-C-consumer端连接到zookeeper-读取信息" class="headerlink" title="(3) Terminal C  # consumer端连接到zookeeper 读取信息"></a>(3) Terminal C  # consumer端连接到zookeeper 读取信息</h4><pre class=" language-shell"><code class="language-shell">[root@sdopenswan-jp kafka_2.12-0.10.2.1]# bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic myfirst_topic --from-beginningUsing the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper].hello world !hello kafka myfirst_topic</code></pre><h3 id="配置文件说明"><a href="#配置文件说明" class="headerlink" title="配置文件说明"></a>配置文件说明</h3><h4 id="Zookeeper配置"><a href="#Zookeeper配置" class="headerlink" title="Zookeeper配置"></a>Zookeeper配置</h4><p>1)  在zoo.cfg中追加以下内容：</p><pre class=" language-shell"><code class="language-shell">server.n=ip:portA:portB#n是服务器标识号（1~255）#ip是服务器ip地址#portA是与leader进行信息交换的端口#portB是在leader宕机后，进行leader选举所用的端口例：server.1=200.31.157.116:20881:30881server.2=200.31.157.116:20882:30882server.3=200.31.157.117:20881:30881tickTime：毫秒级的基本时间单位，其他时间如心跳/超时等都为该单位时间的整数倍。initLimit：tickTime的倍数，表示leader选举结束后，followers与leader同步需要的时间，leader的数据非常多或followers比较多时，该值应适当大一些。syncLimit：tickTime的倍数，表示follower和observer与leader交互时的最大等待时间，是在与leader同步完毕之后，正常请求转发或ping等消息交互时的超时时间。clientPort：监听客户端连接的服务端口，若一台服务器上安装多个ZooKeeper server，则需要设置不同的端口号。dataDir：内存数据库快照地址，事务日志地址（除非由dataLogDir另行指定）。</code></pre><p>2)  在$dataDir下新建文件myid，并写入服务器标识号</p><pre class=" language-shell"><code class="language-shell">#/tmp/zookeeper为dataDircd /tmp/zookeeper/vim myid#在myid中添加服务器标识号</code></pre><h4 id="Kafka配置"><a href="#Kafka配置" class="headerlink" title="Kafka配置"></a>Kafka配置</h4><p>在配置文件server.properties修改如下内容：</p><pre class=" language-shell"><code class="language-shell">#broker.id是broker的标识，具有唯一性broker.id=0#端口号默认为9092port=9092#host.name位kafka所在机器的iphost.name=10.18.42.251#设置zookeeper，可连接多个zookeeper服务器zookeeper.connect=200.31.157.116:2182,200.31.157.116:2183,200.31.157.117:2182</code></pre><h3 id="多实例Kafka"><a href="#多实例Kafka" class="headerlink" title="多实例Kafka"></a>多实例Kafka</h3><h4 id="1-配置并启动zookeeper"><a href="#1-配置并启动zookeeper" class="headerlink" title="(1)配置并启动zookeeper"></a>(1)配置并启动zookeeper</h4><pre class=" language-shell"><code class="language-shell">[root@sdopenswan-jp kafka_2.12-0.10.2.1]# vim config/zookeeper.properties[root@sdopenswan-jp kafka_2.12-0.10.2.1]# grep -Pv "^#" config/zookeeper.propertiesdataDir=zkdata1clientPort=2181maxClientCnxns=0tickTime=2000initLimit=5syncLimit=2server.0=172.16.1.16:2888:3888server.1=172.16.2.59:2888:3888server.2=172.16.0.198:2888:3888[root@sdopenswan-jp kafka_2.12-0.10.2.1]# echo 0 > zkdata1/myid[root@sdredis01-jp kafka_2.12-0.10.2.1]# vim config/zookeeper.properties[root@sdredis01-jp kafka_2.12-0.10.2.1]# grep -Pv "^#" config/zookeeper.propertiesdataDir=zkdata1clientPort=2181maxClientCnxns=0tickTime=2000initLimit=5syncLimit=2server.0=172.16.1.16:2888:3888server.1=172.16.2.59:2888:3888server.2=172.16.0.198:2888:3888[root@sdredis01-jp kafka_2.12-0.10.2.1]# lsbin  config  libs  LICENSE  NOTICE  site-docs[root@sdredis01-jp kafka_2.12-0.10.2.1]# mkdir zkdata1[root@sdredis01-jp kafka_2.12-0.10.2.1]# echo 1 >  zkdata1/myid[root@sdredis01-jp kafka_2.12-0.10.2.1]#[root@sdredis02-jp kafka_2.12-0.10.2.1]# vim config/zookeeper.properties[root@sdredis02-jp kafka_2.12-0.10.2.1]# grep -Pv "^#" config/zookeeper.propertiesdataDir=zkdata1clientPort=2181maxClientCnxns=0tickTime=2000initLimit=5syncLimit=2server.0=172.16.1.16:2888:3888server.1=172.16.2.59:2888:3888server.2=172.16.0.198:2888:3888[root@sdredis02-jp kafka_2.12-0.10.2.1]# mkdir zkdata1[root@sdredis02-jp kafka_2.12-0.10.2.1]# echo 2 > zkdata1/myid[root@sdredis02-jp kafka_2.12-0.10.2.1]#[root@sdopenswan-jp kafka_2.12-0.10.2.1]#  bin/zookeeper-server-start.sh config/zookeeper.properties &[root@sdredis01-jp kafka_2.12-0.10.2.1]# bin/zookeeper-server-start.sh config/zookeeper.properties &[root@sdredis02-jp kafka_2.12-0.10.2.1]# bin/zookeeper-server-start.sh config/zookeeper.properties &</code></pre><h4 id="2-配置并启动kafka"><a href="#2-配置并启动kafka" class="headerlink" title="(2)配置并启动kafka"></a>(2)配置并启动kafka</h4><pre class=" language-shell"><code class="language-shell">[root@sdopenswan-jp kafka_2.12-0.10.2.1]# vim config/server.properties[root@sdopenswan-jp kafka_2.12-0.10.2.1]# grep -Pv "^($|#)" config/server.propertiesbroker.id=0listeners=PLAINTEXT://:9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=kfklognum.partitions=3num.recovery.threads.per.data.dir=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=172.16.1.16:2181,172.16.2.59:2181,172.16.0.198:2181zookeeper.connection.timeout.ms=6000[root@sdopenswan-jp kafka_2.12-0.10.2.1]# vim config/consumer.properties[root@sdopenswan-jp kafka_2.12-0.10.2.1]# grep -Pv "^($|#)" config/consumer.propertieszookeeper.connect=172.16.1.16:2181,172.16.2.59:2181,172.16.0.198:2181zookeeper.connection.timeout.ms=6000group.id=test-consumer-group[root@sdopenswan-jp kafka_2.12-0.10.2.1]# vim config/producer.properties[root@sdopenswan-jp kafka_2.12-0.10.2.1]# grep -Pv "^($|#)" config/producer.propertiesbootstrap.servers=172.16.1.16:9092,172.16.2.59:9092,172.16.0.198:9092compression.type=none[root@sdopenswan-jp kafka_2.12-0.10.2.1]#[root@sdredis01-jp kafka_2.12-0.10.2.1]# vim config/server.properties[root@sdredis01-jp kafka_2.12-0.10.2.1]# grep -Pv "^($|#)" config/server.propertiesbroker.id=1listeners=PLAINTEXT://:9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=kfklognum.partitions=3num.recovery.threads.per.data.dir=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=172.16.1.16:2181,172.16.2.59:2181,172.16.0.198:2181zookeeper.connection.timeout.ms=6000[root@sdredis01-jp kafka_2.12-0.10.2.1]# vim config/consumer.properties[root@sdredis01-jp kafka_2.12-0.10.2.1]# grep -Pv "^($|#)" config/consumer.propertieszookeeper.connect=172.16.1.16:2181,172.16.2.59:2181,172.16.0.198:2181zookeeper.connection.timeout.ms=6000group.id=test-consumer-group[root@sdredis01-jp kafka_2.12-0.10.2.1]# vim config/producer.properties[root@sdredis01-jp kafka_2.12-0.10.2.1]# grep -Pv "^($|#)" config/producer.propertiesbootstrap.servers=172.16.1.16:9092,172.16.2.59:9092,172.16.0.198:9092compression.type=none[root@sdredis01-jp kafka_2.12-0.10.2.1]#[root@sdredis02-jp kafka_2.12-0.10.2.1]# vim config/server.properties[root@sdredis02-jp kafka_2.12-0.10.2.1]# grep -Pv "^($|#)" config/server.propertiesbroker.id=2listeners=PLAINTEXT://:9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=kfklognum.partitions=3num.recovery.threads.per.data.dir=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=172.16.1.16:2181,172.16.2.59:2181,172.16.0.198:2181zookeeper.connection.timeout.ms=6000[root@sdredis02-jp kafka_2.12-0.10.2.1]# vim config/consumer.properties[root@sdredis02-jp kafka_2.12-0.10.2.1]# grep -Pv "^($|#)" config/consumer.propertieszookeeper.connect=172.16.1.16:2181,172.16.2.59:2181,172.16.0.198:2181zookeeper.connection.timeout.ms=6000group.id=test-consumer-group[root@sdredis02-jp kafka_2.12-0.10.2.1]# vim config/producer.properties[root@sdredis02-jp kafka_2.12-0.10.2.1]# grep -Pv "^($|#)" config/producer.propertiesbootstrap.servers=172.16.1.16:9092,172.16.2.59:9092,172.16.0.198:9092compression.type=none[root@sdredis02-jp kafka_2.12-0.10.2.1]#</code></pre><p>三台机器分别启动  bin/kafka-server-start.sh config/server.properties &amp;</p><h4 id="3-测试"><a href="#3-测试" class="headerlink" title="(3)测试"></a>(3)测试</h4><pre class=" language-shell"><code class="language-shell">[root@sdredis02-jp kafka_2.12-0.10.2.1]# bin/kafka-topics.sh --create --zookeeper 172.16.0.198:2181  --replication-factor 3 --partitions 1 --topic yc01_topicWARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both.Created topic "yc01_topic".[root@sdredis02-jp kafka_2.12-0.10.2.1]# bin/kafka-topics.sh --list --zookeeper 172.16.0.198:2181myfirst_topicyc01_topic[root@sdredis02-jp kafka_2.12-0.10.2.1]# bin/kafka-topics.sh --describe --zookeeper 172.16.0.198:2181Topic:myfirst_topic    PartitionCount:1    ReplicationFactor:1    Configs:    Topic: myfirst_topic    Partition: 0    Leader: 0    Replicas: 0    Isr: 0Topic:yc01_topic    PartitionCount:1    ReplicationFactor:3    Configs:    Topic: yc01_topic    Partition: 0    Leader: 1    Replicas: 1,2,0    Isr: 1,2,0[root@sdredis02-jp kafka_2.12-0.10.2.1]#[root@sdredis01-jp kafka_2.12-0.10.2.1]# bin/kafka-console-producer.sh --broker-list 172.16.1.16:9092,172.16.2.59:9092,172.16.0.198:9092 --topic yc01_topichello multi instance kafka[root@sdredis02-jp kafka_2.12-0.10.2.1]# bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic yc01_topic --from-beginningUsing the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper].hello multi instance kafka</code></pre><h4 id="4-查看zookeeper状态"><a href="#4-查看zookeeper状态" class="headerlink" title="(4)查看zookeeper状态"></a>(4)查看zookeeper状态</h4><pre class=" language-shell"><code class="language-shell">[root@sdopenswan-jp kafka_2.12-0.10.2.1]# echo stat|nc 127.0.0.1 2181Zookeeper version: 3.4.9-1757313, built on 08/23/2016 06:50 GMTClients: /127.0.0.1:46010[0](queued=0,recved=1,sent=0) /172.16.0.198:53940[1](queued=0,recved=875,sent=875)Latency min/avg/max: 0/0/4Received: 890Sent: 889Connections: 2Outstanding: 0Zxid: 0x100000060Mode: leaderNode count: 33[root@sdopenswan-jp kafka_2.12-0.10.2.1]#[root@sdredis01-jp kafka_2.12-0.10.2.1]# echo stat|nc 127.0.0.1 2181Zookeeper version: 3.4.9-1757313, built on 08/23/2016 06:50 GMTClients: /127.0.0.1:53466[0](queued=0,recved=1,sent=0)Latency min/avg/max: 0/0/0Received: 2Sent: 1Connections: 1Outstanding: 0Zxid: 0x10000005dMode: followerNode count: 33[root@sdredis02-jp kafka_2.12-0.10.2.1]# echo stat|nc 127.0.0.1 2181Zookeeper version: 3.4.9-1757313, built on 08/23/2016 06:50 GMTClients: /172.16.2.59:53354[1](queued=0,recved=952,sent=952) /172.16.1.16:53038[1](queued=0,recved=1018,sent=1023) /127.0.0.1:49478[0](queued=0,recved=1,sent=0)Latency min/avg/max: 0/0/15Received: 2566Sent: 2572Connections: 3Outstanding: 0Zxid: 0x100000060Mode: followerNode count: 33[root@sdredis02-jp kafka_2.12-0.10.2.1]#</code></pre><h4 id="5-常用命令总结"><a href="#5-常用命令总结" class="headerlink" title="(5)常用命令总结"></a>(5)常用命令总结</h4><pre class=" language-shell"><code class="language-shell">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 2 --partitions 4 --topic testbin/kafka-topics.sh --describe --zookeeper bin/kafka-console-producer.sh --broker-list localhost:9092 --topic testbin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic testbin/kafka-console-producer.sh --broker-list localhost:9092 --topic test --producer.config config/producer.propertiesbin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --new-consumer --from-beginning --consumer.config config/consumer.propertiesbin/kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --listbin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zkconnect localhost:2181 --group testbin/kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --describe --group test-consumer-groupbin/kafka-preferred-replica-election.sh --zookeeper zk_host:port/chrootbin/kafka-producer-perf-test.sh --topic test --num-records 100 --record-size 1 --throughput 100  --producer-props bootstrap.servers=localhost:9092</code></pre><p>用户在客户端可以通过 telnet 或 nc 向 ZooKeeper 提交相应的命令</p><ol><li>可以通过命令：echo stat|nc 127.0.0.1 2181 来查看哪个节点被选择作为follower或者leader</li><li>使用echo ruok|nc 127.0.0.1 2181 测试是否启动了该Server，若回复imok表示已经启动。</li><li>echo dump| nc 127.0.0.1 2181 ,列出未经处理的会话和临时节点。</li><li>echo kill | nc 127.0.0.1 2181 ,关掉server</li><li>echo conf | nc 127.0.0.1 2181 ,输出相关服务配置的详细信息。</li><li>echo cons | nc 127.0.0.1 2181 ,列出所有连接到服务器的客户端的完全的连接 / 会话的详细信息。</li><li>echo envi |nc 127.0.0.1 2181 ,输出关于服务环境的详细信息（区别于 conf 命令）。</li><li>echo reqs | nc 127.0.0.1 2181 ,列出未经处理的请求。</li><li>echo wchs | nc 127.0.0.1 2181 ,列出服务器 watch 的详细信息。</li><li>echo wchc | nc 127.0.0.1 2181 ,通过 session 列出服务器 watch 的详细信息，它的输出是一个与 watch 相关的会话的列表。</li><li>echo wchp | nc 127.0.0.1 2181 ,通过路径列出服务器 watch 的详细信息。它输出一个与 session 相关的路径</li></ol><h3 id="补充新实验过程-参考"><a href="#补充新实验过程-参考" class="headerlink" title="补充新实验过程(参考)"></a>补充新实验过程(参考)</h3><p>teacher配置如下：</p><pre class=" language-shell"><code class="language-shell">[root@teacher ~]# vim /etc/profile[root@teacher ~]# source /etc/profile[root@teacher ~]# echo $JAVA_HOME/usr/java/latest[root@teacher ~]# which java/usr/java/latest/bin/java[root@teacher ~]# java -versionjava version "1.8.0_162"Java(TM) SE Runtime Environment (build 1.8.0_162-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.162-b12, mixed mode)[root@teacher ~]#[root@teacher ~]# scp /etc/profile node2:/etc/profile                                                                                100% 1859   549.7KB/s   00:00    [root@teacher ~]# scp /etc/profile node3:/etc/profile                                                                                100% 1859   448.7KB/s   00:00    [root@teacher ~]#[root@teacher ~]# tar xf kafka_2.12-1.1.0.tgz  -C /usr/local/[root@teacher opt]# cd /usr/local/[root@teacher local]# ln -s kafka_2.12-1.1.0/ kafka[root@teacher local]# lsbin  etc  games  include  kafka  kafka_2.12-1.1.0  lib  lib64  libexec  logstash  php  sbin  share  src  zabbix[root@teacher local]# cd kafka[root@teacher kafka]# mkdir zkdata[root@teacher kafka]# mkdir kfklog[root@teacher kafka]# echo 0 > zkdata/myid[root@teacher kafka]# vim config/zookeeper.properties [root@teacher kafka]# grep -Pv "^(#|$)" config/zookeeper.propertiesdataDir=zkdataclientPort=2181maxClientCnxns=0tickTime=2000initLimit=5syncLimit=2server.0=192.168.233.102:2888:3888server.1=192.168.233.103:2888:3888server.2=192.168.233.104:2888:3888[root@teacher kafka]# vim config/server.properties [root@teacher kafka]# grep -Pv "^(#|$)" config/server.properties broker.id=0listeners=PLAINTEXT://:9092advertised.listeners=PLAINTEXT://192.168.233.102:9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=kfklognum.partitions=3num.recovery.threads.per.data.dir=1offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=192.168.233.102:2181,192.168.233.103:2181,192.168.233.104:2181zookeeper.connection.timeout.ms=6000group.initial.rebalance.delay.ms=0[root@teacher kafka]# vim config/consumer.properties [root@teacher kafka]# grep -Pv "^(#|$)" config/consumer.properties bootstrap.servers=192.168.233.102:9092,192.168.233.103:9092,192.168.233.104:9092zookeeper.connect=192.168.233.102:2181,192.168.233.103:2181,192.168.233.104:2181group.id=test-consumer-group[root@teacher kafka]# vim config/producer.properties [root@teacher kafka]# grep -Pv "^(#|$)" config/producer.properties bootstrap.servers=192.168.233.102:9092,192.168.233.103:9092,192.168.233.104:9092compression.type=none[root@teacher ~]# cd /usr/local/[root@teacher local]# scp -r kafkakafka/             kafka_2.12-1.1.0/  [root@teacher local]# scp -r kafka_2.12-1.1.0 node2:/usr/local/</code></pre><p>node2配置如下：</p><pre class=" language-shell"><code class="language-shell">[root@node2 ~]# java -version java version "1.8.0_162"Java(TM) SE Runtime Environment (build 1.8.0_162-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.162-b12, mixed mode)[root@node2 ~]# source /etc/profile[root@node2 ~]# echo $JAVA_HOME/usr/java/latest[root@node2 ~]# which java/usr/java/latest/bin/java[root@node2 ~]# tail -3  /etc/hosts192.168.233.102 teacher192.168.233.103 node2192.168.233.104 node3[root@node2 ~]# cd /usr/local/[root@node2 local]# ln -s kafka_2.12-1.1.0 kafka[root@node2 local]# cd kafka[root@node2 kafka]# echo 1 > zkdata/myid [root@node2 kafka]# vim config/server.properties [root@node2 kafka]# vim config/consumer.properties [root@node2 kafka]# vim config/producer.properties [root@node2 kafka]# grep -Pv "^(#|$)" config/zookeeper.properties dataDir=zkdataclientPort=2181maxClientCnxns=0tickTime=2000initLimit=5syncLimit=2server.0=192.168.233.102:2888:3888server.1=192.168.233.103:2888:3888server.2=192.168.233.104:2888:3888[root@node2 kafka]# grep -Pv "^(#|$)" config/server.properties broker.id=1listeners=PLAINTEXT://:9092advertised.listeners=PLAINTEXT://192.168.233.103:9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=kfklognum.partitions=3num.recovery.threads.per.data.dir=1offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=192.168.233.102:2181,192.168.233.103:2181,192.168.233.104:2181zookeeper.connection.timeout.ms=6000group.initial.rebalance.delay.ms=0[root@node2 kafka]# grep -Pv "^(#|$)" config/consumer.properties bootstrap.servers=192.168.233.102:9092,192.168.233.103:9092,192.168.233.104:9092zookeeper.connect=192.168.233.102:2181,192.168.233.103:2181,192.168.233.104:2181group.id=test-consumer-group[root@node2 kafka]# grep -Pv "^(#|$)" config/producer.properties bootstrap.servers=192.168.233.102:9092,192.168.233.103:9092,192.168.233.104:9092compression.type=none[root@node2 kafka]#</code></pre><p>node3配置如下：</p><pre class=" language-shell"><code class="language-shell">[root@node3 ~]# cd /usr/local/[root@node3 local]# ln -s kafka_2.12-1.1.0 kafka[root@node3 local]# lsbin  etc  games  include  kafka  kafka_2.12-1.1.0  lib  lib64  libexec  sbin  share  src[root@node3 local]# cd kafka[root@node3 kafka]# lsbin  config  kfklog  libs  LICENSE  NOTICE  site-docs  zkdata[root@node3 kafka]# echo 2 > zkdata/myid [root@node3 kafka]# vim config/server.properties [root@node3 kafka]# grep -Pv "^(#|$)" config/zookeeper.properties dataDir=zkdataclientPort=2181maxClientCnxns=0tickTime=2000initLimit=5syncLimit=2server.0=192.168.233.102:2888:3888server.1=192.168.233.103:2888:3888server.2=192.168.233.104:2888:3888[root@node3 kafka]# grep -Pv "^(#|$)" config/server.properties broker.id=2listeners=PLAINTEXT://:9092advertised.listeners=PLAINTEXT://192.168.233.104:9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=kfklognum.partitions=3num.recovery.threads.per.data.dir=1offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=192.168.233.102:2181,192.168.233.103:2181,192.168.233.104:2181zookeeper.connection.timeout.ms=6000group.initial.rebalance.delay.ms=0[root@node3 kafka]# grep -Pv "^(#|$)" config/consumer.properties bootstrap.servers=192.168.233.102:9092,192.168.233.103:9092,192.168.233.104:9092zookeeper.connect=192.168.233.102:2181,192.168.233.103:2181,192.168.233.104:2181group.id=test-consumer-group[root@node3 kafka]# grep -Pv "^(#|$)" config/producer.properties bootstrap.servers=192.168.233.102:9092,192.168.233.103:9092,192.168.233.104:9092compression.type=none[root@node3 kafka]# </code></pre><p>启动zookeeper</p><pre class=" language-shell"><code class="language-shell">[root@teacher kafka]# bin/zookeeper-server-start.sh config/zookeeper.properties & [root@node2 kafka]# bin/zookeeper-server-start.sh config/zookeeper.properties &[root@node3 kafka]# bin/zookeeper-server-start.sh config/zookeeper.properties &</code></pre><p>启动kafka</p><pre class=" language-shell"><code class="language-shell">[root@teacher kafka]# bin/kafka-server-start.sh config/server.properties &[root@node2 kafka]#  bin/kafka-server-start.sh config/server.properties &[root@node3 kafka]#  bin/kafka-server-start.sh config/server.properties &</code></pre>]]></content>
      
      
      <categories>
          
          <category> SQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ansible-roles</title>
      <link href="2019/04/18/linux/ansible-roles/"/>
      <url>2019/04/18/linux/ansible-roles/</url>
      
        <content type="html"><![CDATA[<h2 id="ansible-roles"><a href="#ansible-roles" class="headerlink" title="ansible-roles"></a>ansible-roles</h2><h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1.简介"></a>1.简介</h3><p>roles则是在ansible中，playbooks的目录组织结构。<br>而模块化之后，成为roles的组织结构，易读，代码可重用，层次清晰。</p><h3 id="2-目标"><a href="#2-目标" class="headerlink" title="2.目标"></a>2.目标</h3><p>通过role远程部署nginx并配置</p><h3 id="3-目录结构"><a href="#3-目录结构" class="headerlink" title="3.目录结构"></a>3.目录结构</h3><p>[<img src="https://s1.ax1x.com/2020/09/28/0VbuwT.md.png" alt="0VbuwT.md.png"></p><pre><code>files/：存储由copy或script等模块调用的文件；tasks/：此目录中至少应该有一个名为main.yml的文件，用于定义各task；其它的文件需要由main.yml进行“包含”调用；handlers/：此目录中至少应该有一个名为main.yml的文件，用于定义各handler；其它的文件需要由main.yml进行“包含”调用；vars/：此目录中至少应该有一个名为main.yml的文件，用于定义各variable；其它的文件需要由main.yml进行“包含”调用；templates/：存储由template模块调用的模板文本；meta/：此目录中至少应该有一个名为main.yml的文件，定义当前角色的特殊设定及其依赖关系；其它的文件需要由main.yml进行“包含”调用；default/：此目录中至少应该有一个名为main.yml的文件，用于设定默认变量；</code></pre><p>准备目录结构</p><pre><code>mkdir roles/nginx/{files,handlers,tasks,templates,vars} -ptouch roles/site.yaml roles/nginx/{handlers,tasks,vars}/main.yamlecho tiger &gt; roles/nginx/files/index.htmlyum install -y nginx &amp;&amp; cp /etc/nginx/nginx.conf roles/nginx/templates/nginx.conf.j2</code></pre><h3 id="4-编写任务"><a href="#4-编写任务" class="headerlink" title="4.编写任务"></a>4.编写任务</h3><pre><code>vim roles/nginx/tasks/main.yaml---- name: install nginx packge  yum: name={{ item }} state=latest  with_items:  - epel-release  - nginx- name: copy index.html  copy: src=index.html dest=/usr/share/nginx/html/index.html- name: copy nginx.conf template  template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf  notify: restart nginx- name: make sure nginx service running  service: name=nginx state=started enabled=yes</code></pre><h3 id="5-准备配置文件"><a href="#5-准备配置文件" class="headerlink" title="5.准备配置文件"></a>5.准备配置文件</h3><pre><code>vim roles/nginx/templates/nginx.conf.j2worker_processes  {{ ansible_processor_cores }};   //调用内部已知变量worker_connections {{ worker_connections }};    //自定义变量</code></pre><h3 id="6-编写变量"><a href="#6-编写变量" class="headerlink" title="6.编写变量"></a>6.编写变量</h3><pre><code>vim roles/nginx/vars/main.yamlworker_connections: 10240</code></pre><h3 id="7-编写处理程序"><a href="#7-编写处理程序" class="headerlink" title="7.编写处理程序"></a>7.编写处理程序</h3><pre><code>vim roles/nginx/handlers/main.yaml---- name: restart nginx  service: name=nginx state=restarted</code></pre><h3 id="8-编写剧本"><a href="#8-编写剧本" class="headerlink" title="8.编写剧本"></a>8.编写剧本</h3><pre><code>vim roles/site.yaml- hosts: host4  roles:  - nginx</code></pre><h3 id="9-实施"><a href="#9-实施" class="headerlink" title="9.实施"></a>9.实施</h3><pre><code>ansible-playbook site.yaml --syntax-check  //测试ansible-playbook site.yaml    //实施剧本</code></pre><p>验证hosts</p><p><a href="https://imgchr.com/i/0VbwkD" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/09/28/0VbwkD.png" alt="0VbwkD.png"></a></p><p>引用变量案例：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># tree </span><span class="token keyword">.</span>├── site.yml├── templates│   └── order.j2└── vars    └── main.yml2 directories, 3 files</code></pre><p>总调度yml文件：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># cat site.yml </span>---- hosts: 192.168.19.154  user: root  vars:  - PROJECT: <span class="token string">"JAVA"</span>    SWITCH: <span class="token string">"ON"</span>    DBPORT: <span class="token string">"8080"</span>  tasks:  - name: create<span class="token punctuation">{</span><span class="token punctuation">{</span> PROJECT <span class="token punctuation">}</span><span class="token punctuation">}</span>directory    file: path<span class="token operator">=</span>/data/<span class="token punctuation">{</span><span class="token punctuation">{</span> PROJECT <span class="token punctuation">}</span><span class="token punctuation">}</span> state<span class="token operator">=</span>directory  - name: template transfor java    template: src<span class="token operator">=</span>order.j2 dest<span class="token operator">=</span>/data/<span class="token punctuation">{</span><span class="token punctuation">{</span> PROJECT <span class="token punctuation">}</span><span class="token punctuation">}</span>/order.conf</code></pre><p>注意:这里 - role: template 和 - template 是一样的！</p><p>其他yml文件，如下：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># cat templates/order.j2 </span>project: <span class="token punctuation">{</span><span class="token punctuation">{</span> PROJECT <span class="token punctuation">}</span><span class="token punctuation">}</span>switch: <span class="token punctuation">{</span><span class="token punctuation">{</span> SWITCH <span class="token punctuation">}</span><span class="token punctuation">}</span>dbport: <span class="token punctuation">{</span><span class="token punctuation">{</span> DBPORT <span class="token punctuation">}</span><span class="token punctuation">}</span>测试：<span class="token comment" spellcheck="true"># ansible-playbook templates.yml --syntax-check</span>playbook: templates.yml执行：PLAY <span class="token punctuation">[</span>192.168.19.154<span class="token punctuation">]</span> **********************************************************TASK <span class="token punctuation">[</span>Gathering Facts<span class="token punctuation">]</span> *********************************************************ok: <span class="token punctuation">[</span>192.168.19.154<span class="token punctuation">]</span>TASK <span class="token punctuation">[</span>createJAVAdirectory<span class="token punctuation">]</span> *****************************************************changed: <span class="token punctuation">[</span>192.168.19.154<span class="token punctuation">]</span>TASK <span class="token punctuation">[</span>template transfor java<span class="token punctuation">]</span> **************************************************changed: <span class="token punctuation">[</span>192.168.19.154<span class="token punctuation">]</span>PLAY RECAP *********************************************************************192.168.19.154             <span class="token keyword">:</span> ok<span class="token operator">=</span>3    changed<span class="token operator">=</span>2    unreachable<span class="token operator">=</span>0    failed<span class="token operator">=</span>0 <span class="token comment" spellcheck="true">#cat /data/JAVA/order.conf</span>project: JAVAswitch: ONdbport: 8080</code></pre>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Ansible </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ansible</title>
      <link href="2019/04/16/linux/ansible/"/>
      <url>2019/04/16/linux/ansible/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h1 id="自动化运维工具—ansible详解"><a href="#自动化运维工具—ansible详解" class="headerlink" title="自动化运维工具—ansible详解"></a>自动化运维工具—ansible详解</h1><h2 id="一、ansible-简介"><a href="#一、ansible-简介" class="headerlink" title="一、ansible 简介"></a>一、ansible 简介</h2><h3 id="1、ansible-是什么？"><a href="#1、ansible-是什么？" class="headerlink" title="1、ansible 是什么？"></a>1、ansible 是什么？</h3><p>　　ansible是目前最受运维欢迎的自动化运维工具，基于Python开发，集合了众多运维工具（SaltStack puppet、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能。<br> 　　ansible是基于 paramiko 开发的,并且基于模块化工作，本身没有批量部署的能力。真正具有批量部署的是ansible所运行的模块，ansible只是提供一种框架。ansible不需要在远程主机上安装client/agents，因为它们是基于ssh来和远程主机通讯的。ansible目前已经已经被红帽官方收购，是自动化运维工具中大家认可度最高的，并且上手容易，学习简单。是每位运维工程师必须掌握的技能之一。</p><h3 id="2、ansible-特点"><a href="#2、ansible-特点" class="headerlink" title="2、ansible 特点"></a>2、ansible 特点</h3><ol><li>部署简单，只需在主控端部署Ansible环境，被控端无需做任何操作；</li><li>默认使用SSH协议对设备进行管理；</li><li>有大量常规运维操作模块，可实现日常绝大部分操作；</li><li>配置简单、功能强大、扩展性强；</li><li>支持API及自定义模块，可通过Python轻松扩展；</li><li>通过Playbooks来定制强大的配置、状态管理；</li><li>轻量级，无需在客户端安装agent，更新时，只需在操作机上进行一次更新即可；</li><li>提供一个功能强大、操作性强的Web管理界面和REST API接口——AWX平台。</li></ol><h3 id="3、ansible-架构图"><a href="#3、ansible-架构图" class="headerlink" title="3、ansible 架构图"></a>3、ansible 架构图</h3><p><img src="https://s1.ax1x.com/2020/04/17/JEZyQO.png" alt="JEZyQO.png"></p><blockquote><p><code>Ansible</code>：Ansible核心程序。<br><code>HostInventory</code>：记录由Ansible管理的主机信息，包括端口、密码、ip等。<br><code>Playbooks</code>：“剧本”YAML格式文件，多个任务定义在一个文件中，定义主机需要调用哪些模块来完成的功能。<br><code>CoreModules</code>：<strong>核心模块</strong>，主要操作是通过调用核心模块来完成管理任务。<br><code>CustomModules</code>：自定义模块，完成核心模块无法完成的功能，支持多种语言。<br><code>ConnectionPlugins</code>：连接插件，Ansible和Host通信使用</p></blockquote><h2 id="二、ansible-任务执行"><a href="#二、ansible-任务执行" class="headerlink" title="二、ansible 任务执行"></a>二、ansible 任务执行</h2><h3 id="1、ansible-任务执行模式"><a href="#1、ansible-任务执行模式" class="headerlink" title="1、ansible 任务执行模式"></a>1、ansible 任务执行模式</h3><p>　　Ansible 系统由控制主机对被管节点的操作方式可分为两类，即<code>ad-hoc</code>和<code>playbook</code>：</p><ul><li>ad-hoc模式(点对点模式)<br>使用单个模块，支持批量执行单条命令。ad-hoc 命令是一种可以快速输入的命令，而且不需要保存起来的命令。<strong>就相当于bash中的一句话shell。</strong></li><li>playbook模式(剧本模式)<br>是Ansible主要管理方式，也是Ansible功能强大的关键所在。<strong>playbook通过多个task集合完成一类功能</strong>，如Web服务的安装部署、数据库服务器的批量备份等。可以简单地把playbook理解为通过组合多条ad-hoc操作的配置文件。</li></ul><h3 id="2、ansible-执行流程"><a href="#2、ansible-执行流程" class="headerlink" title="2、ansible 执行流程"></a>2、ansible 执行流程</h3><p> 　　简单理解就是Ansible在运行时， 首先读取<code>ansible.cfg</code>中的配置， 根据规则获取<code>Inventory</code>中的管理主机列表， 并行的在这些主机中执行配置的任务， 最后等待执行返回的结果。</p><h3 id="3、ansible-命令执行过程"><a href="#3、ansible-命令执行过程" class="headerlink" title="3、ansible 命令执行过程"></a>3、ansible 命令执行过程</h3><p><img src="https://s1.ax1x.com/2020/04/17/JEZ2eH.png" alt="JEZ2eH.png"></p><ol><li>加载自己的配置文件，默认<code>/etc/ansible/ansible.cfg</code>；</li><li>查找对应的主机配置文件，找到要执行的主机或者组；</li><li>加载自己对应的模块文件，如 command；</li><li>通过ansible将模块或命令生成对应的临时py文件(python脚本)， 并将该文件传输至远程服务器；</li><li>对应执行用户的家目录的<code>.ansible/tmp/XXX/XXX.PY</code>文件；</li><li>给文件 +x 执行权限；</li><li>执行并返回结果；</li><li>删除临时py文件，<code>sleep 0</code>退出；</li></ol><h2 id="三、ansible-配置详解"><a href="#三、ansible-配置详解" class="headerlink" title="三、ansible 配置详解"></a>三、ansible 配置详解</h2><h3 id="1、ansible-安装方式"><a href="#1、ansible-安装方式" class="headerlink" title="1、ansible 安装方式"></a>1、ansible 安装方式</h3><p>　　ansible安装常用两种方式，<code>yum 安装</code> 和 <code>pip 程序安装</code>。下面我们来详细介绍一下这两种安装方式。</p><h3 id="2、使用-pip（python的包管理模块）安装"><a href="#2、使用-pip（python的包管理模块）安装" class="headerlink" title="2、使用 pip（python的包管理模块）安装"></a>2、使用 pip（python的包管理模块）安装</h3><p>　　首先，我们需要安装一个<code>python-pip</code>包，安装完成以后，则直接使用<code>pip</code>命令来安装我们的包，具体操作过程如下：</p><pre><code>    yum install python-pip    pip install ansible</code></pre><h3 id="4、使用-yum-安装"><a href="#4、使用-yum-安装" class="headerlink" title="4、使用 yum 安装"></a>4、使用 yum 安装</h3><p>　　yum 安装是我们很熟悉的安装方式了。我们需要先安装一个<code>epel-release</code>包，然后再安装我们的 ansible 即可。</p><pre><code>    yum install epel-release -y    yum install ansible –y</code></pre><h3 id="5、ansible-程序结构"><a href="#5、ansible-程序结构" class="headerlink" title="5、ansible 程序结构"></a>5、ansible 程序结构</h3><p>安装目录如下(yum安装)：<br> 　   配置文件目录：/etc/ansible/<br>　　执行文件目录：/usr/bin/<br>　　Lib库依赖目录：/usr/lib/pythonX.X/site-packages/ansible/<br>　　Help文档目录：/usr/share/doc/ansible-X.X.X/<br>　　Man文档目录：/usr/share/man/man1/</p><h3 id="6、ansible配置文件查找顺序"><a href="#6、ansible配置文件查找顺序" class="headerlink" title="6、ansible配置文件查找顺序"></a>6、ansible配置文件查找顺序</h3><p>　　ansible与我们其他的服务在这一点上有很大不同，这里的配置文件查找是从多个地方找的，顺序如下：</p><ol><li>检查环境变量<code>ANSIBLE_CONFIG</code>指向的路径文件(export ANSIBLE_CONFIG=/etc/ansible.cfg)；</li><li><code>~/.ansible.cfg</code>，检查当前目录下的ansible.cfg配置文件；</li><li><code>/etc/ansible.cfg</code>检查etc目录的配置文件。</li></ol><h3 id="7、ansible配置文件"><a href="#7、ansible配置文件" class="headerlink" title="7、ansible配置文件"></a>7、ansible配置文件</h3><p>　　ansible 的配置文件为<code>/etc/ansible/ansible.cfg</code>，ansible 有许多参数，下面我们列出一些常见的参数：</p><pre><code>    inventory = /etc/ansible/hosts #这个参数表示资源清单inventory文件的位置    library = /usr/share/ansible   #指向存放Ansible模块的目录，支持多个目录方式，只要用冒号（：）隔开就可以    forks = 5       #并发连接数，默认为5    sudo_user = root        #设置默认执行命令的用户    remote_port = 22        #指定连接被管节点的管理端口，默认为22端口，建议修改，能够更加安全    host_key_checking = False #设置是否检查SSH主机的密钥，值为True/False。关闭后第一次连接不会提示配置实例    timeout = 60        #设置SSH连接的超时时间，单位为秒    log_path = /var/log/ansible.log     #指定一个存储ansible日志的文件（默认不记录日志）</code></pre><h3 id="8、ansuble主机清单"><a href="#8、ansuble主机清单" class="headerlink" title="8、ansuble主机清单"></a>8、ansuble主机清单</h3><p>　　在配置文件中，我们提到了资源清单，这个清单就是我们的主机清单，里面保存的是一些 ansible 需要连接管理的主机列表。我们可以来看看他的定义方式：</p><pre><code>1、 直接指明主机地址或主机名：    # green.example.com    # blue.example.com    # 192.168.100.1    # 192.168.100.102、 定义一个主机组[组名]把地址或主机名加进去    [mysql_test]    192.168.253.159    192.168.253.160    192.168.253.153</code></pre><p>　　需要注意的是，这里的组成员可以使用通配符来匹配，这样对于一些标准化的管理来说就很轻松方便了。<br> 　　我们可以根据实际情况来配置我们的主机列表，具体操作如下：</p><pre><code>[root@server ~]# vim /etc/ansible/hosts    [web]    192.168.37.122    192.168.37.133</code></pre><h2 id="四、ansible-常用命令"><a href="#四、ansible-常用命令" class="headerlink" title="四、ansible 常用命令"></a>四、ansible 常用命令</h2><h3 id="1、ansible-命令集"><a href="#1、ansible-命令集" class="headerlink" title="1、ansible 命令集"></a>1、ansible 命令集</h3><blockquote><p><code>/usr/bin/ansible</code>　　Ansibe AD-Hoc 临时命令执行工具，常用于临时命令的执行<br><code>/usr/bin/ansible-doc</code> 　　Ansible 模块功能查看工具<br><code>/usr/bin/ansible-galaxy</code>　　下载/上传优秀代码或Roles模块 的官网平台，基于网络的<br><code>/usr/bin/ansible-playbook</code>　　Ansible 定制自动化的任务集编排工具<br><code>/usr/bin/ansible-pull</code>　　Ansible远程执行命令的工具，拉取配置而非推送配置（使用较少，海量机器时使用，对运维的架构能力要求较高）<br><code>/usr/bin/ansible-vault</code>　　    Ansible 文件加密工具<br><code>/usr/bin/ansible-console</code>　　Ansible基于Linux Consoble界面可与用户交互的命令执行工具</p></blockquote><p>　　其中，我们比较常用的是<code>/usr/bin/ansible</code>和<code>/usr/bin/ansible-playbook</code>。</p><h3 id="2、ansible-doc-命令"><a href="#2、ansible-doc-命令" class="headerlink" title="2、ansible-doc 命令"></a>2、ansible-doc 命令</h3><p>　　ansible-doc 命令常用于获取模块信息及其使用帮助，一般用法如下：</p><pre><code>    ansible-doc -l              #获取全部模块的信息    ansible-doc -s MOD_NAME     #获取指定模块的使用帮助</code></pre><p>　　我们也可以查看一下ansible-doc的全部用法：</p><pre><code>[root@server ~]# ansible-docUsage: ansible-doc [options] [module...]Options:  -h, --help            show this help message and exit　　# 显示命令参数API文档  -l, --list            List available modules　　#列出可用的模块  -M MODULE_PATH, --module-path=MODULE_PATH　　#指定模块的路径                        specify path(s) to module library (default=None)  -s, --snippet         Show playbook snippet for specified module(s)　　#显示playbook制定模块的用法  -v, --verbose         verbose mode (-vvv for more, -vvvv to enable　　# 显示ansible-doc的版本号查看模块列表：                        connection debugging)  --version             show program&#39;s version number and exit</code></pre><p>　　我们可以来看一下，以mysql相关的为例：</p><pre><code>[root@server ~]# ansible-doc -l |grep mysqlmysql_db                           Add or remove MySQL databases from a remote...mysql_replication                  Manage MySQL replication                   mysql_user                         Adds or removes a user from a MySQL databas...mysql_variables                    Manage MySQL global variables      [root@server ~]# ansible-doc -s mysql_user</code></pre><h3 id="2、ansible-命令详解"><a href="#2、ansible-命令详解" class="headerlink" title="2、ansible 命令详解"></a>2、ansible 命令详解</h3><p>　　命令的具体格式如下：</p><pre><code>ansible &lt;host-pattern&gt; [-f forks] [-m module_name] [-a args]</code></pre><p>　　也可以通过<code>ansible -h</code>来查看帮助，下面我们列出一些比较常用的选项，并解释其含义：</p><blockquote><p><code>-a MODULE_ARGS</code> #模块的参数，如果执行默认COMMAND的模块，即是命令参数，如： “date”，“pwd”等等<br><code>-k</code>，<code>--ask-pass</code> #ask for SSH password。登录密码，提示输入SSH密码而不是假设基于密钥的验证<br><code>--ask-su-pass</code> #ask for su password。su切换密码<br><code>-K</code>，<code>--ask-sudo-pass</code> #ask for sudo password。提示密码使用sudo，sudo表示提权操作<br><code>--ask-vault-pass</code> #ask for vault password。假设我们设定了加密的密码，则用该选项进行访问<br><code>-B SECONDS</code> #后台运行超时时间<br><code>-C</code> #模拟运行环境并进行预运行，可以进行查错测试<br><code>-c CONNECTION</code> #连接类型使用<br><code>-f FORKS</code> #并行任务数，默认为5<br><code>-i INVENTORY</code> #指定主机清单的路径，默认为<code>/etc/ansible/hosts</code><br><code>--list-hosts</code> #查看有哪些主机组<br><code>-m MODULE_NAME</code> #执行模块的名字，默认使用 command 模块，所以如果是只执行单一命令可以不用 -m参数<br><code>-o</code> #压缩输出，尝试将所有结果在一行输出，一般针对收集工具使用<br><code>-S</code> #用 su 命令<br><code>-R SU_USER</code> #指定 su 的用户，默认为 root 用户<br><code>-s</code> #用 sudo 命令<br><code>-U SUDO_USER</code> #指定 sudo 到哪个用户，默认为 root 用户<br><code>-T TIMEOUT</code> #指定 ssh 默认超时时间，默认为10s，也可在配置文件中修改<br><code>-u REMOTE_USER</code> #远程用户，默认为 root 用户<br><code>-v</code> #查看详细信息，同时支持<code>-vvv</code>，<code>-vvvv</code>可查看更详细信息</p></blockquote><h3 id="3、ansible-配置公私钥"><a href="#3、ansible-配置公私钥" class="headerlink" title="3、ansible 配置公私钥"></a>3、ansible 配置公私钥</h3><p>　　上面我们已经提到过 ansible 是基于 ssh 协议实现的，所以其配置公私钥的方式与 ssh 协议的方式相同，具体操作步骤如下：</p><pre><code>#1.生成私钥[root@server ~]# ssh-keygen #2.向主机分发私钥[root@server ~]# ssh-copy-id root@192.168.37.122[root@server ~]# ssh-copy-id root@192.168.37.133</code></pre><p>　　这样的话，就可以实现无密码登录，我们的实验过程也会顺畅很多。<br> 　　注意，如果出现了一下报错：</p><pre><code>    -bash: ssh-copy-id: command not found</code></pre><p>　　那么就证明我们需要安装一个包：</p><pre><code>    yum -y install openssh-clientsansible</code></pre><p>　　把包安装上即可。</p><h2 id="五、ansible-常用模块"><a href="#五、ansible-常用模块" class="headerlink" title="五、ansible 常用模块"></a>五、ansible 常用模块</h2><h3 id="1、主机连通性测试"><a href="#1、主机连通性测试" class="headerlink" title="1、主机连通性测试"></a>1、主机连通性测试</h3><p>　　我们使用<code>ansible web -m ping</code>命令来进行主机连通性测试，效果如下：</p><pre><code>[root@server ~]# ansible web -m ping192.168.37.122 | SUCCESS =&gt; {    &quot;changed&quot;: false,     &quot;ping&quot;: &quot;pong&quot;}192.168.37.133 | SUCCESS =&gt; {    &quot;changed&quot;: false,     &quot;ping&quot;: &quot;pong&quot;}</code></pre><p>　　这样就说明我们的主机是连通状态的。接下来的操作才可以正常进行。</p><h3 id="2、command-模块"><a href="#2、command-模块" class="headerlink" title="2、command 模块"></a>2、command 模块</h3><p>　　这个模块可以直接在远程主机上执行命令，并将结果返回本主机。<br> 　　举例如下：</p><pre><code>[root@server ~]# ansible web -m command -a &#39;ss -ntl&#39;192.168.37.122 | SUCCESS | rc=0 &gt;&gt;State      Recv-Q Send-Q Local Address:Port               Peer Address:Port              LISTEN     0      128          *:111                      *:*                  LISTEN     0      5      192.168.122.1:53                       *:*                  LISTEN     0      128          *:22                       *:*                  LISTEN     0      128    127.0.0.1:631                      *:*                  LISTEN     0      128          *:23000                    *:*                  LISTEN     0      100    127.0.0.1:25                       *:*                  LISTEN     0      128         :::111                     :::*                  LISTEN     0      128         :::22                      :::*                  LISTEN     0      128        ::1:631                     :::*                  LISTEN     0      100        ::1:25                      :::*                  192.168.37.133 | SUCCESS | rc=0 &gt;&gt;State      Recv-Q Send-Q Local Address:Port               Peer Address:Port              LISTEN     0      128          *:111                      *:*                  LISTEN     0      128          *:22                       *:*                  LISTEN     0      128    127.0.0.1:631                      *:*                  LISTEN     0      128          *:23000                    *:*                  LISTEN     0      100    127.0.0.1:25                       *:*                  LISTEN     0      128         :::111                     :::*                  LISTEN     0      128         :::22                      :::*                  LISTEN     0      128        ::1:631                     :::*                  LISTEN     0      100        ::1:25                      :::*  </code></pre><p>　　命令模块接受命令名称，后面是空格分隔的列表参数。给定的命令将在所有选定的节点上执行。它不会通过shell进行处理，比如$HOME和操作如”&lt;”，”&gt;”，”|”，”;”，”&amp;” 工作（需要使用（shell）模块实现这些功能）。注意，该命令不支持<code>| 管道命令</code>。<br> 　　下面来看一看该模块下常用的几个命令：</p><blockquote><p>chdir　　　   # 在执行命令之前，先切换到该目录<br>executable    # 切换shell来执行命令，需要使用命令的绝对路径<br>free_form 　 # 要执行的Linux指令，一般使用Ansible的-a参数代替。<br>creates 　      # 一个文件名，当这个文件存在，则该命令不执行,可以用来做判断<br>removes        # 一个文件名，这个文件不存在，则该命令不执行</p></blockquote><p>　　下面我们来看看这些命令的执行效果：</p><pre><code>[root@server ~]# ansible web -m command -a &#39;chdir=/data/ ls&#39;  #先切换到/data/ 目录，再执行“ls”命令192.168.37.122 | SUCCESS | rc=0 &gt;&gt;aaa.jpgfastdfsmogdatatmpwebwKgleloeYoCAMLtZAAAWEekAtkc497.jpg192.168.37.133 | SUCCESS | rc=0 &gt;&gt;aaa.jpgfastdfsmogdatatmpwebwKgleloeYoCAMLtZAAAWEekAtkc497.jpg[root@server ~]# ansible web -m command -a &#39;creates=/data/aaa.jpg ls&#39;  #如果/data/aaa.jpg存在，则不执行“ls”命令192.168.37.122 | SUCCESS | rc=0 &gt;&gt;skipped, since /data/aaa.jpg exists192.168.37.133 | SUCCESS | rc=0 &gt;&gt;skipped, since /data/aaa.jpg exists[root@server ~]# ansible web -m command -a &#39;removes=/data/aaa.jpg cat /data/a&#39; #如果/data/aaa.jpg存在，则执行“cat /data/a”命令192.168.37.122 | SUCCESS | rc=0 &gt;&gt;hello192.168.37.133 | SUCCESS | rc=0 &gt;&gt;hello</code></pre><h3 id="3、shell-模块"><a href="#3、shell-模块" class="headerlink" title="3、shell 模块"></a>3、shell 模块</h3><p>　　shell模块可以在远程主机上调用shell解释器运行命令，支持shell的各种功能，例如管道等。</p><pre><code>[root@server ~]# ansible web -m shell -a &#39;cat /etc/passwd |grep &quot;keer&quot;&#39;192.168.37.122 | SUCCESS | rc=0 &gt;&gt;keer:x:10001:1000:keer:/home/keer:/bin/sh192.168.37.133 | SUCCESS | rc=0 &gt;&gt;keer:x:10001:10001::/home/keer:/bin/sh</code></pre><p>　　只要是我们的shell命令，都可以通过这个模块在远程主机上运行，这里就不一一举例了。</p><h3 id="4、copy-模块"><a href="#4、copy-模块" class="headerlink" title="4、copy 模块"></a>4、copy 模块</h3><p>　　这个模块用于将文件复制到远程主机，同时支持给定内容生成文件和修改权限等。<br> 　　其相关选项如下：</p><blockquote><p><code>src</code>　　　　 #被复制到远程主机的本地文件。可以是绝对路径，也可以是相对路径。如果路径是一个目录，则会递归复制，用法类似于”rsync”<br><code>content</code>　　#用于替换”src”，可以直接指定文件的值<br><code>dest</code>　　　   #必选项，将源文件复制到的远程主机的<strong>绝对路径</strong><br><code>backup</code>　　　#当文件内容发生改变后，在覆盖之前把源文件备份，备份文件包含时间信息<br><code>directory_mode</code>　　　　#递归设定目录的权限，默认为系统默认权限<br><code>force</code>　　　　#当目标主机包含该文件，但内容不同时，设为”yes”，表示强制覆盖；设为”no”，表示目标主机的目标位置不存在该文件才复制。默认为”yes”<br><code>others</code>　　　　#所有的 file 模块中的选项可以在这里使用</p></blockquote><p>用法举例如下：<br><strong>① 复制文件：</strong></p><pre><code>[root@server ~]# ansible web -m copy -a &#39;src=~/hello dest=/data/hello&#39; 192.168.37.122 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;checksum&quot;: &quot;22596363b3de40b06f981fb85d82312e8c0ed511&quot;,     &quot;dest&quot;: &quot;/data/hello&quot;,     &quot;gid&quot;: 0,     &quot;group&quot;: &quot;root&quot;,     &quot;md5sum&quot;: &quot;6f5902ac237024bdd0c176cb93063dc4&quot;,     &quot;mode&quot;: &quot;0644&quot;,     &quot;owner&quot;: &quot;root&quot;,     &quot;size&quot;: 12,     &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1512437093.55-228281064292921/source&quot;,     &quot;state&quot;: &quot;file&quot;,     &quot;uid&quot;: 0}192.168.37.133 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;checksum&quot;: &quot;22596363b3de40b06f981fb85d82312e8c0ed511&quot;,     &quot;dest&quot;: &quot;/data/hello&quot;,     &quot;gid&quot;: 0,     &quot;group&quot;: &quot;root&quot;,     &quot;md5sum&quot;: &quot;6f5902ac237024bdd0c176cb93063dc4&quot;,     &quot;mode&quot;: &quot;0644&quot;,     &quot;owner&quot;: &quot;root&quot;,     &quot;size&quot;: 12,     &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1512437093.74-44694985235189/source&quot;,     &quot;state&quot;: &quot;file&quot;,     &quot;uid&quot;: 0}</code></pre><p><strong>② 给定内容生成文件，并制定权限</strong></p><pre><code>[root@server ~]# ansible web -m copy -a &#39;content=&quot;I am keer\n&quot; dest=/data/name mode=666&#39;192.168.37.122 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;checksum&quot;: &quot;0421570938940ea784f9d8598dab87f07685b968&quot;,     &quot;dest&quot;: &quot;/data/name&quot;,     &quot;gid&quot;: 0,     &quot;group&quot;: &quot;root&quot;,     &quot;md5sum&quot;: &quot;497fa8386590a5fc89090725b07f175c&quot;,     &quot;mode&quot;: &quot;0666&quot;,     &quot;owner&quot;: &quot;root&quot;,     &quot;size&quot;: 10,     &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1512437327.37-199512601767687/source&quot;,     &quot;state&quot;: &quot;file&quot;,     &quot;uid&quot;: 0}192.168.37.133 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;checksum&quot;: &quot;0421570938940ea784f9d8598dab87f07685b968&quot;,     &quot;dest&quot;: &quot;/data/name&quot;,     &quot;gid&quot;: 0,     &quot;group&quot;: &quot;root&quot;,     &quot;md5sum&quot;: &quot;497fa8386590a5fc89090725b07f175c&quot;,     &quot;mode&quot;: &quot;0666&quot;,     &quot;owner&quot;: &quot;root&quot;,     &quot;size&quot;: 10,         &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1512437327.55-218104039503110/source&quot;,     &quot;state&quot;: &quot;file&quot;,     &quot;uid&quot;: 0}</code></pre><p>　　我们现在可以去查看一下我们生成的文件及其权限：</p><pre><code>[root@server ~]# ansible web -m shell -a &#39;ls -l /data/&#39;192.168.37.122 | SUCCESS | rc=0 &gt;&gt;total 28-rw-rw-rw-   1 root root   12 Dec  6 09:45 name192.168.37.133 | SUCCESS | rc=0 &gt;&gt;total 40-rw-rw-rw- 1 root     root       12 Dec  5 09:45 name</code></pre><p>　　可以看出我们的name文件已经生成，并且权限为666。<br><strong>③ 关于覆盖</strong><br> 　　我们把文件的内容修改一下，然后选择覆盖备份：</p><pre><code>[root@server ~]# ansible web -m copy -a &#39;content=&quot;I am keerya\n&quot; backup=yes dest=/data/name mode=666&#39;192.168.37.122 | SUCCESS =&gt; {    &quot;backup_file&quot;: &quot;/data/name.4394.2017-12-06@09:46:25~&quot;,     &quot;changed&quot;: true,     &quot;checksum&quot;: &quot;064a68908ab9971ee85dbc08ea038387598e3778&quot;,     &quot;dest&quot;: &quot;/data/name&quot;,     &quot;gid&quot;: 0,     &quot;group&quot;: &quot;root&quot;,     &quot;md5sum&quot;: &quot;8ca7c11385856155af52e560f608891c&quot;,     &quot;mode&quot;: &quot;0666&quot;,     &quot;owner&quot;: &quot;root&quot;,     &quot;size&quot;: 12,     &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1512438383.78-228128616784888/source&quot;,     &quot;state&quot;: &quot;file&quot;,     &quot;uid&quot;: 0}192.168.37.133 | SUCCESS =&gt; {    &quot;backup_file&quot;: &quot;/data/name.5962.2017-12-05@09:46:24~&quot;,     &quot;changed&quot;: true,     &quot;checksum&quot;: &quot;064a68908ab9971ee85dbc08ea038387598e3778&quot;,     &quot;dest&quot;: &quot;/data/name&quot;,     &quot;gid&quot;: 0,     &quot;group&quot;: &quot;root&quot;,     &quot;md5sum&quot;: &quot;8ca7c11385856155af52e560f608891c&quot;,     &quot;mode&quot;: &quot;0666&quot;,     &quot;owner&quot;: &quot;root&quot;,     &quot;size&quot;: 12,     &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1512438384.0-170718946740009/source&quot;,     &quot;state&quot;: &quot;file&quot;,     &quot;uid&quot;: 0}</code></pre><p>　　现在我们可以去查看一下：</p><pre><code>[root@server ~]# ansible web -m shell -a &#39;ls -l /data/&#39;192.168.37.122 | SUCCESS | rc=0 &gt;&gt;total 28-rw-rw-rw-   1 root root   12 Dec  6 09:46 name-rw-rw-rw-   1 root root   10 Dec  6 09:45 name.4394.2017-12-06@09:46:25~192.168.37.133 | SUCCESS | rc=0 &gt;&gt;total 40-rw-rw-rw- 1 root     root       12 Dec  5 09:46 name-rw-rw-rw- 1 root     root       10 Dec  5 09:45 name.5962.2017-12-05@09:46:24~</code></pre><p>　　可以看出，我们的源文件已经被备份，我们还可以查看一下<code>name</code>文件的内容：</p><pre><code>[root@server ~]# ansible web -m shell -a &#39;cat /data/name&#39;192.168.37.122 | SUCCESS | rc=0 &gt;&gt;I am keerya192.168.37.133 | SUCCESS | rc=0 &gt;&gt;I am keerya</code></pre><p>　　证明，这正是我们新导入的文件的内容。</p><h3 id="5、file-模块"><a href="#5、file-模块" class="headerlink" title="5、file 模块"></a>5、file 模块</h3><p>　　该模块主要用于设置文件的属性，比如创建文件、创建链接文件、删除文件等。<br> 　　下面是一些常见的命令：</p><blockquote><p><code>force</code>　　#需要在两种情况下强制创建软链接，一种是源文件不存在，但之后会建立的情况下；另一种是目标软链接已存在，需要先取消之前的软链，然后创建新的软链，有两个选项：yes|no<br><code>group</code>　　#定义文件/目录的属组。后面可以加上<code>mode</code>：定义文件/目录的权限<br><code>owner</code>　　#定义文件/目录的属主。后面必须跟上<code>path</code>：定义文件/目录的路径<br><code>recurse</code>　　#递归设置文件的属性，只对目录有效，后面跟上<code>src</code>：被链接的源文件路径，只应用于<code>state=link</code>的情况<br><code>dest</code>　　#被链接到的路径，只应用于<code>state=link</code>的情况<br><code>state</code>　　#状态，有以下选项：</p><p><code>directory</code>：如果目录不存在，就创建目录<br><code>file</code>：即使文件不存在，也不会被创建<br><code>link</code>：创建软链接<br><code>hard</code>：创建硬链接<br><code>touch</code>：如果文件不存在，则会创建一个新的文件，如果文件或目录已存在，则更新其最后修改时间<br><code>absent</code>：删除目录、文件或者取消链接文件</p></blockquote><p>　　用法举例如下：<br><strong>① 创建目录：</strong></p><pre><code>[root@server ~]# ansible web -m file -a &#39;path=/data/app state=directory&#39;192.168.37.122 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;gid&quot;: 0,     &quot;group&quot;: &quot;root&quot;,     &quot;mode&quot;: &quot;0755&quot;,     &quot;owner&quot;: &quot;root&quot;,     &quot;path&quot;: &quot;/data/app&quot;,     &quot;size&quot;: 6,     &quot;state&quot;: &quot;directory&quot;,     &quot;uid&quot;: 0}192.168.37.133 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;gid&quot;: 0,     &quot;group&quot;: &quot;root&quot;,     &quot;mode&quot;: &quot;0755&quot;,     &quot;owner&quot;: &quot;root&quot;,     &quot;path&quot;: &quot;/data/app&quot;,     &quot;size&quot;: 4096,     &quot;state&quot;: &quot;directory&quot;,     &quot;uid&quot;: 0}</code></pre><p>　　我们可以查看一下：</p><pre><code>[root@server ~]# ansible web -m shell -a &#39;ls -l /data&#39;192.168.37.122 | SUCCESS | rc=0 &gt;&gt;total 28drwxr-xr-x   2 root root    6 Dec  6 10:21 app192.168.37.133 | SUCCESS | rc=0 &gt;&gt;total 44drwxr-xr-x 2 root     root     4096 Dec  5 10:21 app</code></pre><p>　　可以看出，我们的目录已经创建完成。<br><strong>② 创建链接文件</strong></p><pre><code>[root@server ~]# ansible web -m file -a &#39;path=/data/bbb.jpg src=aaa.jpg state=link&#39;192.168.37.122 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;dest&quot;: &quot;/data/bbb.jpg&quot;,     &quot;gid&quot;: 0,     &quot;group&quot;: &quot;root&quot;,     &quot;mode&quot;: &quot;0777&quot;,     &quot;owner&quot;: &quot;root&quot;,     &quot;size&quot;: 7,     &quot;src&quot;: &quot;aaa.jpg&quot;,     &quot;state&quot;: &quot;link&quot;,     &quot;uid&quot;: 0}192.168.37.133 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;dest&quot;: &quot;/data/bbb.jpg&quot;,     &quot;gid&quot;: 0,     &quot;group&quot;: &quot;root&quot;,     &quot;mode&quot;: &quot;0777&quot;,     &quot;owner&quot;: &quot;root&quot;,     &quot;size&quot;: 7,     &quot;src&quot;: &quot;aaa.jpg&quot;,     &quot;state&quot;: &quot;link&quot;,     &quot;uid&quot;: 0}</code></pre><p>　　我们可以去查看一下：</p><pre><code>[root@server ~]# ansible web -m shell -a &#39;ls -l /data&#39;192.168.37.122 | SUCCESS | rc=0 &gt;&gt;total 28-rw-r--r--   1 root root 5649 Dec  5 13:49 aaa.jpglrwxrwxrwx   1 root root    7 Dec  6 10:25 bbb.jpg -&gt; aaa.jpg192.168.37.133 | SUCCESS | rc=0 &gt;&gt;total 44-rw-r--r-- 1 root     root     5649 Dec  4 14:44 aaa.jpglrwxrwxrwx 1 root     root        7 Dec  5 10:25 bbb.jpg -&gt; aaa.jpg</code></pre><p>　　我们的链接文件已经创建成功。<br><strong>③ 删除文件</strong></p><pre><code>[root@server ~]# ansible web -m file -a &#39;path=/data/a state=absent&#39;192.168.37.122 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;path&quot;: &quot;/data/a&quot;,     &quot;state&quot;: &quot;absent&quot;}192.168.37.133 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;path&quot;: &quot;/data/a&quot;,     &quot;state&quot;: &quot;absent&quot;}</code></pre><p>　　我们可以查看一下：</p><pre><code>[root@server ~]# ansible web -m shell -a &#39;ls /data/a&#39;192.168.37.122 | FAILED | rc=2 &gt;&gt;ls: cannot access /data/a: No such file or directory192.168.37.133 | FAILED | rc=2 &gt;&gt;ls: cannot access /data/a: No such file or directory</code></pre><p>　　发现已经没有这个文件了。</p><h3 id="6、fetch-模块"><a href="#6、fetch-模块" class="headerlink" title="6、fetch 模块"></a>6、fetch 模块</h3><p>　　该模块用于从远程某主机获取（复制）文件到本地。<br> 　　有两个选项：</p><blockquote><p><code>dest</code>：用来存放文件的目录<br><code>src</code>：在远程拉取的文件，并且必须是一个<strong>file</strong>，不能是<strong>目录</strong></p></blockquote><p>　　具体举例如下：</p><pre><code>[root@server ~]# ansible web -m fetch -a &#39;src=/data/hello dest=/data&#39;  192.168.37.122 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;checksum&quot;: &quot;22596363b3de40b06f981fb85d82312e8c0ed511&quot;,     &quot;dest&quot;: &quot;/data/192.168.37.122/data/hello&quot;,     &quot;md5sum&quot;: &quot;6f5902ac237024bdd0c176cb93063dc4&quot;,     &quot;remote_checksum&quot;: &quot;22596363b3de40b06f981fb85d82312e8c0ed511&quot;,     &quot;remote_md5sum&quot;: null}192.168.37.133 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;checksum&quot;: &quot;22596363b3de40b06f981fb85d82312e8c0ed511&quot;,     &quot;dest&quot;: &quot;/data/192.168.37.133/data/hello&quot;,     &quot;md5sum&quot;: &quot;6f5902ac237024bdd0c176cb93063dc4&quot;,     &quot;remote_checksum&quot;: &quot;22596363b3de40b06f981fb85d82312e8c0ed511&quot;,     &quot;remote_md5sum&quot;: null}</code></pre><p>　　我们可以在本机上查看一下文件是否复制成功。要注意，文件保存的路径是我们设置的接收目录下的<code>被管制主机ip</code>目录下：</p><pre><code>[root@server ~]# cd /data/[root@server data]# ls1  192.168.37.122  192.168.37.133  fastdfs  web[root@server data]# cd 192.168.37.122[root@server 192.168.37.122]# lsdata[root@server 192.168.37.122]# cd data/[root@server data]# lshello[root@server data]# pwd/data/192.168.37.122/data</code></pre><h3 id="7、cron-模块"><a href="#7、cron-模块" class="headerlink" title="7、cron 模块"></a>7、cron 模块</h3><p>　　该模块适用于管理<code>cron</code>计划任务的。<br> 　　其使用的语法跟我们的<code>crontab</code>文件中的语法一致，同时，可以指定以下选项：</p><blockquote><p><code>day=</code>           #日应该运行的工作( 1-31, <em>,</em> /2, )<br><code>hour=</code>         # 小时 ( 0-23, <em>,</em> /2, )<br><code>minute=</code>     #分钟( 0-59, <em>,</em> /2, )<br><code>month=</code>       # 月( 1-12, *, /2, )<br><code>weekday=</code>       # 周 ( 0-6 for Sunday-Saturday,, )<br><code>job=</code>           #指明运行的命令是什么<br><code>name=</code>        #定时任务描述<br><code>reboot</code>      # 任务在重启时运行，不建议使用，建议使用special_time<br><code>special_time</code> #特殊的时间范围，参数：reboot（重启时），annually（每年），monthly（每月），weekly（每周），daily（每天），hourly（每小时）<br><code>state</code>        #指定状态，present表示添加定时任务，也是默认设置，absent表示删除定时任务<br><code>user</code>          # 以哪个用户的身份执行</p></blockquote><p>　　举例如下：<br><strong>① 添加计划任务</strong></p><pre><code>[root@server ~]# ansible web -m cron -a &#39;name=&quot;ntp update every 5 min&quot; minute=*/5 job=&quot;/sbin/ntpdate 172.17.0.1 &amp;&gt; /dev/null&quot;&#39;192.168.37.122 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;envs&quot;: [],     &quot;jobs&quot;: [        &quot;ntp update every 5 min&quot;    ]}192.168.37.133 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;envs&quot;: [],     &quot;jobs&quot;: [        &quot;ntp update every 5 min&quot;    ]}</code></pre><p>　　我们可以去查看一下：</p><pre><code>[root@server ~]# ansible web -m shell -a &#39;crontab -l&#39;192.168.37.122 | SUCCESS | rc=0 &gt;&gt;#Ansible: ntp update every 5 min*/5 * * * * /sbin/ntpdate 172.17.0.1 &amp;&gt; /dev/null192.168.37.133 | SUCCESS | rc=0 &gt;&gt;#Ansible: ntp update every 5 min*/5 * * * * /sbin/ntpdate 172.17.0.1 &amp;&gt; /dev/null</code></pre><p>　　可以看出，我们的计划任务已经设置成功了。<br><strong>② 删除计划任务</strong><br> 　　如果我们的计划任务添加错误，想要删除的话，则执行以下操作：<br> 　　首先我们查看一下现有的计划任务：</p><pre><code>[root@server ~]# ansible web -m shell -a &#39;crontab -l&#39;192.168.37.122 | SUCCESS | rc=0 &gt;&gt;#Ansible: ntp update every 5 min*/5 * * * * /sbin/ntpdate 172.17.0.1 &amp;&gt; /dev/null#Ansible: df everyday* 15 * * * df -lh &gt;&gt; /tmp/disk_total &amp;&gt; /dev/null192.168.37.133 | SUCCESS | rc=0 &gt;&gt;#Ansible: ntp update every 5 min*/5 * * * * /sbin/ntpdate 172.17.0.1 &amp;&gt; /dev/null#Ansible: df everyday* 15 * * * df -lh &gt;&gt; /tmp/disk_total &amp;&gt; /dev/null</code></pre><p>　　然后执行删除操作：</p><pre><code>[root@server ~]# ansible web -m cron -a &#39;name=&quot;df everyday&quot; hour=15 job=&quot;df -lh &gt;&gt; /tmp/disk_total &amp;&gt; /dev/null&quot; state=absent&#39;192.168.37.122 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;envs&quot;: [],     &quot;jobs&quot;: [        &quot;ntp update every 5 min&quot;    ]}192.168.37.133 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;envs&quot;: [],     &quot;jobs&quot;: [        &quot;ntp update every 5 min&quot;    ]}</code></pre><p>　　删除完成后，我们再查看一下现有的计划任务确认一下：</p><pre><code>[root@server ~]# ansible web -m shell -a &#39;crontab -l&#39;192.168.37.122 | SUCCESS | rc=0 &gt;&gt;#Ansible: ntp update every 5 min*/5 * * * * /sbin/ntpdate 172.17.0.1 &amp;&gt; /dev/null192.168.37.133 | SUCCESS | rc=0 &gt;&gt;#Ansible: ntp update every 5 min*/5 * * * * /sbin/ntpdate 172.17.0.1 &amp;&gt; /dev/null</code></pre><p>　　我们的删除操作已经成功。</p><h3 id="8、yum-模块"><a href="#8、yum-模块" class="headerlink" title="8、yum 模块"></a>8、yum 模块</h3><p>　　顾名思义，该模块主要用于软件的安装。<br> 　　其选项如下：</p><blockquote><p><code>name=</code>　　  #所安装的包的名称<br><code>state=</code>　　#<code>present</code>—&gt;安装， <code>latest</code>—&gt;安装最新的, <code>absent</code>—&gt; 卸载软件。<br><code>update_cache</code>　　#强制更新yum的缓存<br><code>conf_file</code>　　#指定远程yum安装时所依赖的配置文件（安装本地已有的包）。<br><code>disable_pgp_check</code>　　#是否禁止GPG checking，只用于<code>present</code>or <code>latest</code>。<br><code>disablerepo</code>　　#临时禁止使用yum库。 只用于安装或更新时。<br><code>enablerepo</code>　　 #临时使用的yum库。只用于安装或更新时。</p></blockquote><p>　　下面我们就来安装一个包试试看：</p><pre><code>[root@server ~]# ansible web -m yum -a &#39;name=htop state=present&#39;192.168.37.122 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;msg&quot;: &quot;&quot;,     &quot;rc&quot;: 0,     &quot;results&quot;: [        &quot;Loaded plugins: fastestmirror, langpacks\nLoading mirror speeds from cached hostfile\nResolving Dependencies\n--&gt; Running transaction check\n---&gt; Package htop.x86_64 0:2.0.2-1.el7 will be installed\n--&gt; Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package         Arch              Version                Repository       Size\n================================================================================\nInstalling:\n htop            x86_64            2.0.2-1.el7            epel             98 k\n\nTransaction Summary\n================================================================================\nInstall  1 Package\n\nTotal download size: 98 k\nInstalled size: 207 k\nDownloading packages:\nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n  Installing : htop-2.0.2-1.el7.x86_64                                      1/1 \n  Verifying  : htop-2.0.2-1.el7.x86_64                                      1/1 \n\nInstalled:\n  htop.x86_64 0:2.0.2-1.el7                                                     \n\nComplete!\n&quot;    ]}192.168.37.133 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;msg&quot;: &quot;Warning: RPMDB altered outside of yum.\n** Found 3 pre-existing rpmdb problem(s), &#39;yum check&#39; output follows:\nipa-client-4.4.0-12.el7.centos.x86_64 has installed conflicts freeipa-client: ipa-client-4.4.0-12.el7.centos.x86_64\nipa-client-common-4.4.0-12.el7.centos.noarch has installed conflicts freeipa-client-common: ipa-client-common-4.4.0-12.el7.centos.noarch\nipa-common-4.4.0-12.el7.centos.noarch has installed conflicts freeipa-common: ipa-common-4.4.0-12.el7.centos.noarch\n&quot;,     &quot;rc&quot;: 0,     &quot;results&quot;: [        &quot;Loaded plugins: fastestmirror, langpacks\nLoading mirror speeds from cached hostfile\nResolving Dependencies\n--&gt; Running transaction check\n---&gt; Package htop.x86_64 0:2.0.2-1.el7 will be installed\n--&gt; Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package         Arch              Version                Repository       Size\n================================================================================\nInstalling:\n htop            x86_64            2.0.2-1.el7            epel             98 k\n\nTransaction Summary\n================================================================================\nInstall  1 Package\n\nTotal download size: 98 k\nInstalled size: 207 k\nDownloading packages:\nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n  Installing : htop-2.0.2-1.el7.x86_64                                      1/1 \n  Verifying  : htop-2.0.2-1.el7.x86_64                                      1/1 \n\nInstalled:\n  htop.x86_64 0:2.0.2-1.el7                                                     \n\nComplete!\n&quot;    ]}</code></pre><p>　　安装成功。</p><h3 id="9、service-模块"><a href="#9、service-模块" class="headerlink" title="9、service 模块"></a>9、service 模块</h3><p>　　该模块用于服务程序的管理。<br> 　　其主要选项如下：</p><blockquote><p><code>arguments</code> #命令行提供额外的参数<br><code>enabled</code>     #设置开机启动。<br><code>name=</code> #服务名称<br><code>runlevel</code> #开机启动的级别，一般不用指定。<br><code>sleep</code> #在重启服务的过程中，是否等待。如在服务关闭以后等待2秒再启动。(定义在剧本中。)<br><code>state</code> #有四种状态，分别为：<code>started</code>—&gt;启动服务， <code>stopped</code>—&gt;停止服务， <code>restarted</code>—&gt;重启服务， <code>reloaded</code>—&gt;重载配置</p></blockquote><p>　　下面是一些例子：<br><strong>① 开启服务并设置自启动</strong></p><pre><code>[root@server ~]# ansible web -m service -a &#39;name=nginx state=started enabled=true&#39; 192.168.37.122 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;enabled&quot;: true,     &quot;name&quot;: &quot;nginx&quot;,     &quot;state&quot;: &quot;started&quot;,     ……}192.168.37.133 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;enabled&quot;: true,     &quot;name&quot;: &quot;nginx&quot;,     &quot;state&quot;: &quot;started&quot;,     ……}</code></pre><p>　　我们可以去查看一下端口是否打开：</p><pre><code>[root@server ~]# ansible web -m shell -a &#39;ss -ntl&#39;192.168.37.122 | SUCCESS | rc=0 &gt;&gt;State      Recv-Q Send-Q Local Address:Port               Peer Address:Port              LISTEN     0      128          *:80                       *:*                                  192.168.37.133 | SUCCESS | rc=0 &gt;&gt;State      Recv-Q Send-Q Local Address:Port               Peer Address:Port                    LISTEN     0      128          *:80                       *:*                  </code></pre><p>　　可以看出我们的80端口已经打开。<br><strong>② 关闭服务</strong><br> 　　我们也可以通过该模块来关闭我们的服务：</p><pre><code>[root@server ~]# ansible web -m service -a &#39;name=nginx state=stopped&#39;192.168.37.122 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;name&quot;: &quot;nginx&quot;,     &quot;state&quot;: &quot;stopped&quot;,     ……}192.168.37.133 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;name&quot;: &quot;nginx&quot;,     &quot;state&quot;: &quot;stopped&quot;,     ……}</code></pre><p>　　一样的，我们来查看一下端口：</p><pre><code>[root@server ~]# ansible web -m shell -a &#39;ss -ntl | grep 80&#39;192.168.37.122 | FAILED | rc=1 &gt;&gt;192.168.37.133 | FAILED | rc=1 &gt;&gt;</code></pre><p>　　可以看出，我们已经没有80端口了，说明我们的nginx服务已经关闭了。</p><h3 id="10、user-模块"><a href="#10、user-模块" class="headerlink" title="10、user 模块"></a>10、user 模块</h3><p>　　该模块主要是用来管理用户账号。<br> 　　其主要选项如下：</p><blockquote><p><code>comment</code>　　# 用户的描述信息<br><code>createhome</code>　　# 是否创建家目录<br><code>force</code>　　# 在使用state=absent时, 行为与userdel –force一致.<br><code>group</code>　　# 指定基本组<br><code>groups</code>　　# 指定附加组，如果指定为(groups=)表示删除所有组<br><code>home</code>　　    # 指定用户家目录<br><code>move_home</code>　　# 如果设置为home=时, 试图将用户主目录移动到指定的目录<br><code>name</code>　　# 指定用户名<br><code>non_unique</code>　　# 该选项允许改变非唯一的用户ID值<br><code>password</code>　　# 指定用户密码<br><code>remove</code>　　# 在使用state=absent时, 行为是与userdel –remove一致<br><code>shell</code>　　# 指定默认shell<br><code>state</code>　　# 设置帐号状态，不指定为创建，指定值为absent表示删除<br><code>system</code>　　# 当创建一个用户，设置这个用户是系统用户。这个设置不能更改现有用户<br><code>uid</code>　　# 指定用户的uid</p></blockquote><p>　　举例如下：<br><strong>① 添加一个用户并指定其 uid</strong></p><pre><code>[root@server ~]# ansible web -m user -a &#39;name=keer uid=11111&#39;192.168.37.122 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;comment&quot;: &quot;&quot;,     &quot;createhome&quot;: true,     &quot;group&quot;: 11111,     &quot;home&quot;: &quot;/home/keer&quot;,     &quot;name&quot;: &quot;keer&quot;,     &quot;shell&quot;: &quot;/bin/bash&quot;,     &quot;state&quot;: &quot;present&quot;,     &quot;stderr&quot;: &quot;useradd: warning: the home directory already exists.\nNot copying any file from skel directory into it.\nCreating mailbox file: File exists\n&quot;,     &quot;system&quot;: false,     &quot;uid&quot;: 11111}192.168.37.133 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;comment&quot;: &quot;&quot;,     &quot;createhome&quot;: true,     &quot;group&quot;: 11111,     &quot;home&quot;: &quot;/home/keer&quot;,     &quot;name&quot;: &quot;keer&quot;,     &quot;shell&quot;: &quot;/bin/bash&quot;,     &quot;state&quot;: &quot;present&quot;,     &quot;stderr&quot;: &quot;useradd: warning: the home directory already exists.\nNot copying any file from skel directory into it.\nCreating mailbox file: File exists\n&quot;,     &quot;system&quot;: false,     &quot;uid&quot;: 11111}</code></pre><p>　　添加完成，我们可以去查看一下：</p><pre><code>[root@server ~]# ansible web -m shell -a &#39;cat /etc/passwd |grep keer&#39;192.168.37.122 | SUCCESS | rc=0 &gt;&gt;keer:x:11111:11111::/home/keer:/bin/bash192.168.37.133 | SUCCESS | rc=0 &gt;&gt;keer:x:11111:11111::/home/keer:/bin/bash</code></pre><p><strong>② 删除用户</strong></p><pre><code>[root@server ~]# ansible web -m user -a &#39;name=keer state=absent&#39;192.168.37.122 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;force&quot;: false,     &quot;name&quot;: &quot;keer&quot;,     &quot;remove&quot;: false,     &quot;state&quot;: &quot;absent&quot;}192.168.37.133 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;force&quot;: false,     &quot;name&quot;: &quot;keer&quot;,     &quot;remove&quot;: false,     &quot;state&quot;: &quot;absent&quot;}</code></pre><p>　　一样的，删除之后，我们去看一下：</p><pre><code>[root@server ~]# ansible web -m shell -a &#39;cat /etc/passwd |grep keer&#39;192.168.37.122 | FAILED | rc=1 &gt;&gt;192.168.37.133 | FAILED | rc=1 &gt;&gt;</code></pre><p>　　发现已经没有这个用户了。</p><h3 id="11、group-模块"><a href="#11、group-模块" class="headerlink" title="11、group 模块"></a>11、group 模块</h3><p>　　该模块主要用于添加或删除组。<br> 　　常用的选项如下：</p><blockquote><p><code>gid=</code>　　#设置组的GID号<br><code>name=</code>　　#指定组的名称<br><code>state=</code>　　#指定组的状态，默认为创建，设置值为<code>absent</code>为删除<br><code>system=</code>　　#设置值为<code>yes</code>，表示创建为系统组</p></blockquote><p>　　举例如下：<br><strong>① 创建组</strong></p><pre><code>[root@server ~]# ansible web -m group -a &#39;name=sanguo gid=12222&#39;192.168.37.122 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;gid&quot;: 12222,     &quot;name&quot;: &quot;sanguo&quot;,     &quot;state&quot;: &quot;present&quot;,     &quot;system&quot;: false}192.168.37.133 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;gid&quot;: 12222,     &quot;name&quot;: &quot;sanguo&quot;,     &quot;state&quot;: &quot;present&quot;,     &quot;system&quot;: false}</code></pre><p>　　创建过后，我们来查看一下：</p><pre><code>[root@server ~]# ansible web -m shell -a &#39;cat /etc/group | grep 12222&#39; 192.168.37.122 | SUCCESS | rc=0 &gt;&gt;sanguo:x:12222:192.168.37.133 | SUCCESS | rc=0 &gt;&gt;sanguo:x:12222:</code></pre><p>　　可以看出，我们的组已经创建成功了。<br><strong>② 删除组</strong></p><pre><code>[root@server ~]# ansible web -m group -a &#39;name=sanguo state=absent&#39;192.168.37.122 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;name&quot;: &quot;sanguo&quot;,     &quot;state&quot;: &quot;absent&quot;}192.168.37.133 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;name&quot;: &quot;sanguo&quot;,     &quot;state&quot;: &quot;absent&quot;}</code></pre><p>　　照例查看一下：</p><pre><code>[root@server ~]# ansible web -m shell -a &#39;cat /etc/group | grep 12222&#39; 192.168.37.122 | FAILED | rc=1 &gt;&gt;192.168.37.133 | FAILED | rc=1 &gt;&gt;</code></pre><p>　　已经没有这个组的相关信息了。</p><h3 id="12、script-模块"><a href="#12、script-模块" class="headerlink" title="12、script 模块"></a>12、script 模块</h3><p>　　该模块用于将本机的脚本在被管理端的机器上运行。<br> 　　该模块直接指定脚本的路径即可，我们通过例子来看一看到底如何使用的：<br> 　　首先，我们写一个脚本，并给其加上执行权限：</p><pre><code>[root@server ~]# vim /tmp/df.sh    #!/bin/bash    date &gt;&gt; /tmp/disk_total.log    df -lh &gt;&gt; /tmp/disk_total.log [root@server ~]# chmod +x /tmp/df.sh </code></pre><p>　　然后，我们直接运行命令来实现在被管理端执行该脚本：</p><pre><code>[root@server ~]# ansible web -m script -a &#39;/tmp/df.sh&#39;192.168.37.122 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;rc&quot;: 0,     &quot;stderr&quot;: &quot;Shared connection to 192.168.37.122 closed.\r\n&quot;,     &quot;stdout&quot;: &quot;&quot;,     &quot;stdout_lines&quot;: []}192.168.37.133 | SUCCESS =&gt; {    &quot;changed&quot;: true,     &quot;rc&quot;: 0,     &quot;stderr&quot;: &quot;Shared connection to 192.168.37.133 closed.\r\n&quot;,     &quot;stdout&quot;: &quot;&quot;,     &quot;stdout_lines&quot;: []}</code></pre><p>　　照例查看一下文件内容：</p><pre class=" language-repl"><code class="language-repl">[root@server ~]# ansible web -m shell -a 'cat /tmp/disk_total.log'192.168.37.122 | SUCCESS | rc=0 >>Tue Dec  5 15:58:21 CST 2017Filesystem      Size  Used Avail Use% Mounted on/dev/sda2        47G  4.4G   43G  10% /devtmpfs        978M     0  978M   0% /devtmpfs           993M   84K  993M   1% /dev/shmtmpfs           993M  9.1M  984M   1% /runtmpfs           993M     0  993M   0% /sys/fs/cgroup/dev/sda3        47G   33M   47G   1% /app/dev/sda1       950M  153M  798M  17% /boottmpfs           199M   16K  199M   1% /run/user/42tmpfs           199M     0  199M   0% /run/user/0192.168.37.133 | SUCCESS | rc=0 >>Tue Dec  5 15:58:21 CST 2017Filesystem      Size  Used Avail Use% Mounted on/dev/sda2        46G  4.1G   40G  10% /devtmpfs        898M     0  898M   0% /devtmpfs           912M   84K  912M   1% /dev/shmtmpfs           912M  9.0M  903M   1% /runtmpfs           912M     0  912M   0% /sys/fs/cgroup/dev/sda3       3.7G   15M  3.4G   1% /app/dev/sda1       1.9G  141M  1.6G   9% /boottmpfs           183M   16K  183M   1% /run/user/42tmpfs           183M     0  183M   0% /run/user/0</code></pre><p>　　可以看出已经执行成功了。</p><h3 id="13、setup-模块"><a href="#13、setup-模块" class="headerlink" title="13、setup 模块"></a>13、setup 模块</h3><p>　　该模块主要用于收集信息，是通过调用facts组件来实现的。<br> 　　facts组件是Ansible用于采集被管机器设备信息的一个功能，我们可以使用setup模块查机器的所有facts信息，可以使用filter来查看指定信息。整个facts信息被包装在一个JSON格式的数据结构中，ansible_facts是最上层的值。<br> 　　facts就是变量，内建变量 。每个主机的各种信息，cpu颗数、内存大小等。会存在facts中的某个变量中。调用后返回很多对应主机的信息，在后面的操作中可以根据不同的信息来做不同的操作。如redhat系列用yum安装，而debian系列用apt来安装软件。<br><strong>① 查看信息</strong><br> 　　我们可以直接用命令获取到变量的值，具体我们来看看例子：</p><pre><code>[root@server ~]# ansible web -m setup -a &#39;filter=&quot;*mem*&quot;&#39;   #查看内存192.168.37.122 | SUCCESS =&gt; {    &quot;ansible_facts&quot;: {        &quot;ansible_memfree_mb&quot;: 1116,         &quot;ansible_memory_mb&quot;: {            &quot;nocache&quot;: {                &quot;free&quot;: 1397,                 &quot;used&quot;: 587            },             &quot;real&quot;: {                &quot;free&quot;: 1116,                 &quot;total&quot;: 1984,                 &quot;used&quot;: 868            },             &quot;swap&quot;: {                &quot;cached&quot;: 0,                 &quot;free&quot;: 3813,                 &quot;total&quot;: 3813,                 &quot;used&quot;: 0            }        },         &quot;ansible_memtotal_mb&quot;: 1984    },     &quot;changed&quot;: false}192.168.37.133 | SUCCESS =&gt; {    &quot;ansible_facts&quot;: {        &quot;ansible_memfree_mb&quot;: 1203,         &quot;ansible_memory_mb&quot;: {            &quot;nocache&quot;: {                &quot;free&quot;: 1470,                 &quot;used&quot;: 353            },             &quot;real&quot;: {                &quot;free&quot;: 1203,                 &quot;total&quot;: 1823,                 &quot;used&quot;: 620            },             &quot;swap&quot;: {                &quot;cached&quot;: 0,                 &quot;free&quot;: 3813,                 &quot;total&quot;: 3813,                 &quot;used&quot;: 0            }        },         &quot;ansible_memtotal_mb&quot;: 1823    },     &quot;changed&quot;: false}</code></pre><p>　　我们可以通过命令查看一下内存的大小以确认一下是否一致：</p><pre><code>[root@server ~]# ansible web -m shell -a &#39;free -m&#39;192.168.37.122 | SUCCESS | rc=0 &gt;&gt;              total        used        free      shared  buff/cache   availableMem:           1984         404        1122           9         457        1346Swap:          3813           0        3813192.168.37.133 | SUCCESS | rc=0 &gt;&gt;              total        used        free      shared  buff/cache   availableMem:           1823         292        1207           9         323        1351Swap:          3813           0        3813</code></pre><p>　　可以看出信息是一致的。<br><strong>② 保存信息</strong><br> 　　我们的setup模块还有一个很好用的功能就是可以保存我们所筛选的信息至我们的主机上，同时，文件名为我们被管制的主机的IP，这样方便我们知道是哪台机器出的问题。<br> 　　我们可以看一看例子：</p><pre><code>[root@server tmp]# ansible web -m setup -a &#39;filter=&quot;*mem*&quot;&#39; --tree /tmp/facts192.168.37.122 | SUCCESS =&gt; {    &quot;ansible_facts&quot;: {        &quot;ansible_memfree_mb&quot;: 1115,         &quot;ansible_memory_mb&quot;: {            &quot;nocache&quot;: {                &quot;free&quot;: 1396,                 &quot;used&quot;: 588            },             &quot;real&quot;: {                &quot;free&quot;: 1115,                 &quot;total&quot;: 1984,                 &quot;used&quot;: 869            },             &quot;swap&quot;: {                &quot;cached&quot;: 0,                 &quot;free&quot;: 3813,                 &quot;total&quot;: 3813,                 &quot;used&quot;: 0            }        },         &quot;ansible_memtotal_mb&quot;: 1984    },     &quot;changed&quot;: false}192.168.37.133 | SUCCESS =&gt; {    &quot;ansible_facts&quot;: {        &quot;ansible_memfree_mb&quot;: 1199,         &quot;ansible_memory_mb&quot;: {            &quot;nocache&quot;: {                &quot;free&quot;: 1467,                 &quot;used&quot;: 356            },             &quot;real&quot;: {                &quot;free&quot;: 1199,                 &quot;total&quot;: 1823,                 &quot;used&quot;: 624            },             &quot;swap&quot;: {                &quot;cached&quot;: 0,                 &quot;free&quot;: 3813,                 &quot;total&quot;: 3813,                 &quot;used&quot;: 0            }        },         &quot;ansible_memtotal_mb&quot;: 1823    },     &quot;changed&quot;: false}</code></pre><p>　　然后我们可以去查看一下：</p><pre><code>[root@server ~]# cd /tmp/facts/[root@server facts]# ls192.168.37.122  192.168.37.133[root@server facts]# cat 192.168.37.122 {&quot;ansible_facts&quot;: {&quot;ansible_memfree_mb&quot;: 1115, &quot;ansible_memory_mb&quot;: {&quot;nocache&quot;: {&quot;free&quot;: 1396, &quot;used&quot;: 588}, &quot;real&quot;: {&quot;free&quot;: 1115, &quot;total&quot;: 1984, &quot;used&quot;: 869}, &quot;swap&quot;: {&quot;cached&quot;: 0, &quot;free&quot;: 3813, &quot;total&quot;: 3813, &quot;used&quot;: 0}}, &quot;ansible_memtotal_mb&quot;: 1984}, &quot;changed&quot;: false}</code></pre><h2 id="六、Ansible-playbook-简介"><a href="#六、Ansible-playbook-简介" class="headerlink" title="六、Ansible playbook 简介"></a>六、Ansible playbook 简介</h2><p>　　<strong>playbook 是 ansible 用于配置，部署，和管理被控节点的剧本。</strong><br>　　通过 playbook 的详细描述，执行其中的一系列 tasks ，可以让远端主机达到预期的状态。playbook 就像 Ansible 控制器给被控节点列出的的一系列 to-do-list ，而被控节点必须要完成。<br>　　也可以这么理解，playbook 字面意思，即剧本，现实中由演员按照剧本表演，在Ansible中，这次由计算机进行表演，由计算机安装，部署应用，提供对外服务，以及组织计算机处理各种各样的事情。</p><h2 id="七、Ansible-playbook使用场景"><a href="#七、Ansible-playbook使用场景" class="headerlink" title="七、Ansible playbook使用场景"></a>七、Ansible playbook使用场景</h2><p>　　执行一些简单的任务，使用ad-hoc命令可以方便的解决问题，但是有时一个设施过于复杂，需要大量的操作时候，执行的ad-hoc命令是不适合的，这时最好使用playbook。<br>　　就像执行shell命令与写shell脚本一样，也可以理解为批处理任务，不过playbook有自己的语法格式。<br>　　使用playbook你可以方便的重用这些代码，可以移植到不同的机器上面，像函数一样，最大化的利用代码。在你使用Ansible的过程中，你也会发现，你所处理的大部分操作都是编写playbook。可以把常见的应用都编写成playbook，之后管理服务器会变得十分简单。</p><h2 id="八、Ansible-playbook格式"><a href="#八、Ansible-playbook格式" class="headerlink" title="八、Ansible playbook格式"></a>八、Ansible playbook格式</h2><h3 id="1、格式简介"><a href="#1、格式简介" class="headerlink" title="1、格式简介"></a>1、格式简介</h3><p>　　<strong>playbook由YMAL语言编写。</strong>YAML( /ˈjæməl/ )参考了其他多种语言，包括：XML、C语言、Python、Perl以及电子邮件格式RFC2822，Clark Evans在2001年5月在首次发表了这种语言，另外Ingy döt Net与OrenBen-Kiki也是这语言的共同设计者。<br>　　YMAL格式是类似于JSON的文件格式，便于人理解和阅读，同时便于书写。首先学习了解一下YMAL的格式，对我们后面书写playbook很有帮助。以下为playbook常用到的YMAL格式：<br>　　1、文件的第一行应该以 “—“ (三个连字符)开始，表明YMAL文件的开始。<br>　　2、在同一行中，#之后的内容表示注释，类似于shell，python和ruby。<br>　　3、YMAL中的列表元素以”-”开头然后紧跟着一个空格，后面为元素内容。<br>　　4、同一个列表中的元素应该保持相同的缩进。否则会被当做错误处理。<br>　　5、play中hosts，variables，roles，tasks等对象的表示方法都是键值中间以”:”分隔表示，”:”后面还要增加一个空格。<br>　　下面是一个举例：</p><pre><code>---#安装与运行mysql服务- hosts: node1  remote_user: root  tasks:      - name: install mysql-server package      yum: name=mysql-server state=present    - name: starting mysqld service      service: name=mysql state=started</code></pre><p>　　我们的文件名称应该以<code>.yml</code>结尾，像我们上面的例子就是<code>mysql.yml</code>。其中，有三个部分组成：</p><blockquote><p><code>host部分</code>：使用 hosts 指示使用哪个主机或主机组来运行下面的 tasks ，每个 playbook 都必须指定 hosts ，hosts也<strong>可以使用通配符格式</strong>。主机或主机组在 inventory 清单中指定，可以使用系统默认的<code>/etc/ansible/hosts</code>，也可以自己编辑，在运行的时候加上<code>-i</code>选项，指定清单的位置即可。在运行清单文件的时候，<code>–list-hosts</code>选项会显示那些主机将会参与执行 task 的过程中。<br><code>remote_user</code>：指定远端主机中的哪个用户来登录远端系统，在远端系统执行 task 的用户，可以任意指定，也可以使用 sudo，但是用户必须要有执行相应 task 的权限。<br><code>tasks</code>：指定远端主机将要执行的一系列动作。tasks 的核心为 ansible 的模块，前面已经提到模块的用法。tasks 包含 <code>name</code> 和<code>要执行的模块</code>，name 是可选的，只是为了便于用户阅读，不过还是建议加上去，模块是必须的，同时也要给予模块相应的参数。</p></blockquote><p>　　使用ansible-playbook运行playbook文件，得到如下输出信息，输出内容为JSON格式。并且由不同颜色组成，便于识别。一般而言<br>| 绿色代表执行成功，系统保持原样<br>| 黄色代表系统代表系统状态发生改变<br>| 红色代表执行失败，显示错误输出<br>　　执行有三个步骤：1、收集facts  2、执行tasks  3、报告结果</p><h3 id="2、核心元素"><a href="#2、核心元素" class="headerlink" title="2、核心元素"></a>2、核心元素</h3><p>　　Playbook的核心元素：</p><blockquote><p><code>Hosts</code>：主机组；<br><code>Tasks</code>：任务列表；<br><code>Variables</code>：变量，设置方式有四种；<br><code>Templates</code>：包含了模板语法的文本文件；<br><code>Handlers</code>：由特定条件触发的任务；</p></blockquote><h3 id="3、基本组件"><a href="#3、基本组件" class="headerlink" title="3、基本组件"></a>3、基本组件</h3><p>　　Playbooks配置文件的基础组件：</p><blockquote><p><code>Hosts</code>：运行指定任务的目标主机<br><code>remote_user</code>：在远程主机上执行任务的用户；<br><code>sudo_user</code>：<br><code>tasks</code>：任务列表</p><p>　　格式：<br>　　　　tasks：<br>　　　　　　– name: TASK_NAME<br>　　　　　　 module: arguments<br>　　　　　　 notify: HANDLER_NAME<br>　　　　　　 handlers:<br>　　　　　　– name: HANDLER_NAME<br>　　　　　　 module: arguments</p></blockquote><blockquote><p><code>模块，模块参数</code>：</p><p>　　格式：<br>　　　　(1) action: module arguments<br>　　　　(2) module: arguments<br>　　　　注意：shell和command模块后面直接跟命令，而非key=value类的参数列表；</p></blockquote><blockquote><p><code>handlers</code>：任务，在特定条件下触发；接收到其它任务的通知时被触发；</p></blockquote><p>　　(1) 某任务的状态在运行后为changed时，可通过“notify”通知给相应的handlers；<br>　　(2) 任务可以通过“tags“打标签，而后可在ansible-playbook命令上使用-t指定进行调用；</p><h5 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h5><p><strong>① 定义playbook</strong></p><pre><code>[root@server ~]# cd /etc/ansible[root@server ansible]# vim nginx.yml---- hosts: web  remote_user: root  tasks:    - name: install nginx      yum: name=nginx state=present    - name: copy nginx.conf      copy: src=/tmp/nginx.conf dest=/etc/nginx/nginx.conf backup=yes      notify: reload　　　　#当nginx.conf发生改变时，通知给相应的handlers      tags: reloadnginx　　　#打标签    - name: start nginx service      service: name=nginx state=started      tags: startnginx　　　#打标签  handlers:　　#注意，前面没有-，是两个空格    - name: reload      service: name=nginx state=restarted　　#为了在进程中能看出来</code></pre><p><strong>② 测试运行结果</strong><br>　　写完了以后，我们就可以运行了：</p><pre><code>[root@server ansible]# ansible-playbook nginx.yml</code></pre><p>　　现在我们可以看看两台机器的端口是否开启：</p><pre><code>[root@server ansible]# ansible web -m shell -a &#39;ss -nutlp |grep nginx&#39;192.168.37.122 | SUCCESS | rc=0 &gt;&gt;tcp    LISTEN     0      128       *:80                    *:*                   users:((&quot;nginx&quot;,pid=8304,fd=6),(&quot;nginx&quot;,pid=8303,fd=6))192.168.37.133 | SUCCESS | rc=0 &gt;&gt;tcp    LISTEN     0      128       *:80                    *:*                   users:((&quot;nginx&quot;,pid=9671,fd=6),(&quot;nginx&quot;,pid=9670,fd=6))</code></pre><p><strong>③ 测试标签</strong><br>　　我们在里面已经打上了一个标签，所以可以直接引用标签。但是我们需要先把服务关闭，再来运行剧本并引用标签：</p><pre><code>[root@server ansible]# ansible web -m shell -a &#39;systemctl stop nginx&#39;[root@server ansible]# ansible-playbook nginx.yml -t startnginx</code></pre><p><strong>④ 测试notify</strong><br>　　我们还做了一个<code>notify</code>，来测试一下：<br>　　首先，它的触发条件是配置文件被改变，所以我们去把配置文件中的端口改一下：</p><pre><code>[root@server ansible]# vim /tmp/nginx.conf    listen       8080;</code></pre><p>　　然后我们重新加载一下这个剧本：</p><pre><code> [root@server ansible]# ansible-playbook nginx.yml -t reloadnginx</code></pre><p>　　发现我们执行的就是reload段以及我们定义的<code>notify</code>部分。<br>　　我们来看一看我们的端口号：</p><p>　　发现我们执行的就是reload段以及我们定义的<code>notify</code>部分。<br>　　我们来看一看我们的端口号：</p><pre><code>[root@server ansible]# ansible web -m shell -a &#39;ss -ntlp | grep nginx&#39;192.168.37.122 | SUCCESS | rc=0 &gt;&gt;LISTEN     0      128          *:8080                     *:*                   users:((&quot;nginx&quot;,pid=2097,fd=6),(&quot;nginx&quot;,pid=2096,fd=6))192.168.37.133 | SUCCESS | rc=0 &gt;&gt;LISTEN     0      128          *:8080                     *:*                   users:((&quot;nginx&quot;,pid=3061,fd=6),(&quot;nginx&quot;,pid=3060,fd=6))</code></pre><p>　　可以看出，我们的nginx端口已经变成了8080。　　</p><h3 id="4、variables-部分"><a href="#4、variables-部分" class="headerlink" title="4、variables 部分"></a>4、variables 部分</h3><p>　　上文中，我们说到了<code>variables</code>是变量，有四种定义方法，现在我们就来说说这四种定义方法：</p><h4 id="①-facts-：可直接调用"><a href="#①-facts-：可直接调用" class="headerlink" title="① facts ：可直接调用"></a>① facts ：可直接调用</h4><p>　　上一篇中，我们有说到<code>setup</code>这个模块，这个模块就是通过调用facts组件来实现的。我们这里的<code>variables</code>也可以直接调用<code>facts</code>组件。<br>　　具体的<code>facters</code>我们可以使用<code>setup</code>模块来获取，然后直接放入我们的剧本中调用即可。</p><pre><code>ansible_all_ipv4_addresses：仅显示ipv4的信息 ---&gt; [u&#39;192.168.95.143&#39;]ansible_eth0[&#39;ipv4&#39;][&#39;address&#39;]：仅显示ipv4的信息 ---&gt; eth0 的ip地址ansible_devices：仅显示磁盘设备信息ansible_distribution：显示是什么系统，例：centos,suse等ansible_distribution_version：仅显示系统版本ansible_machine：显示系统类型，例：32位，还是64位ansible_eth0：仅显示eth0的信息ansible_hostname：仅显示主机名ansible_kernel：仅显示内核版本ansible_lvm：显示lvm相关信息ansible_memtotal_mb：显示系统总内存ansible_memfree_mb：显示可用系统内存ansible_memory_mb：详细显示内存情况ansible_swaptotal_mb：显示总的swap内存ansible_swapfree_mb：显示swap内存的可用内存ansible_mounts：显示系统磁盘挂载情况ansible_processor：显示cpu个数(具体显示每个cpu的型号)ansible_processor_vcpus：显示cpu个数(只显示总的个数)ansible_python_version：显示python版本</code></pre><p>例如：批量修改主机 host 文件</p><pre class=" language-yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token punctuation">-</span> <span class="token key atrule">hosts</span><span class="token punctuation">:</span> web    <span class="token key atrule">vars</span><span class="token punctuation">:</span>            <span class="token key atrule">IP</span><span class="token punctuation">:</span> <span class="token string">"{{ ansible_eth0['ipv4']['address'] }}"</span>    <span class="token key atrule">tasks</span><span class="token punctuation">:</span>          <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> 将原有的hosts文件备份              <span class="token key atrule">shell</span><span class="token punctuation">:</span> mv /etc/hosts /etc/hosts_bak          <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> 将ansible端的hosts复制到各自机器上              <span class="token key atrule">copy</span><span class="token punctuation">:</span> src=/root/hosts dest=/etc/ owner=root group=root mode=0644          <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> 在新的hosts文件后面追加各自机器内网ip和hostname              <span class="token key atrule">lineinfile</span><span class="token punctuation">:</span> dest=/etc/hosts line="<span class="token punctuation">{</span><span class="token punctuation">{</span> IP <span class="token punctuation">}</span><span class="token punctuation">}</span>  <span class="token punctuation">{</span><span class="token punctuation">{</span> ansible_hostname <span class="token punctuation">}</span><span class="token punctuation">}</span>"</code></pre><h4 id="②-用户自定义变量"><a href="#②-用户自定义变量" class="headerlink" title="② 用户自定义变量"></a>② 用户自定义变量</h4><p>　　我们也可以直接使用用户自定义变量，想要自定义变量有以下两种方式：</p><blockquote><p>通过命令行传入</p></blockquote><p>　　<code>ansible-playbook</code>命令的命令行中的<code>-e VARS, --extra-vars=VARS</code>，这样就可以直接把自定义的变量传入。</p><blockquote><p>在playbook中定义变量</p></blockquote><p>　　我们也可以直接在playbook中定义我们的变量：</p><pre><code>vars:　　- var1: value1　　- var2: value2</code></pre><h5 id="举例-1"><a href="#举例-1" class="headerlink" title="举例"></a>举例</h5><p><strong>① 定义剧本</strong><br>　　我们就使用全局替换把我们刚刚编辑的文件修改一下：</p><pre><code>[root@server ansible]# vim nginx.yml</code></pre><p><img src="https://s1.ax1x.com/2020/04/16/JEZEz8.png" alt="JEZEz8.png"><br><img src="https://s1.ax1x.com/2020/04/16/JEZmLQ.png" alt="JEZmLQ.png">　　这样一来，我们的剧本就定义完成了。<br><strong>② 拷贝配置文件</strong><br>　　我们想要在被监管的机器上安装什么服务的话，就直接在我们的server端上把该服务的配置文件拷贝到我们的<code>/tmp/</code>目录下。这样我们的剧本才能正常运行。<br>　　我们就以<code>keepalived</code>服务为例：</p><pre class=" language-shell"><code class="language-shell">[root@server ansible]# cp /etc/keepalived/keepalived.conf /tmp/keepalived.conf</code></pre><p><strong>③ 运行剧本，变量由命令行传入</strong></p><pre><code>[root@server ansible]# ansible-playbook nginx.yml -e rpmname=keepalived</code></pre><p><img src="https://s1.ax1x.com/2020/04/16/JEZKds.png" alt="JEZKds.png"><br><strong>④ 修改剧本，直接定义变量</strong><br>　　同样的，我们可以直接在剧本中把变量定义好，这样就不需要在通过命令行传入了。以后想要安装不同的服务，直接在剧本里把变量修改一下即可。</p><pre><code>[root@server ansible]# vim nginx.yml</code></pre><p>![img](E:/学习晋升文件汇总/Linux架构学习入门/4. network_manager/19-20天-企业自动化运维工具Aansible实战/assets/1204916-20171208112356562-1275040347.png)<br><strong>⑤ 运行定义过变量的剧本</strong><br>　　我们刚刚已经把变量定义在剧本里面了。现在我们来运行一下试试看：</p><pre><code>[root@server ansible]# ansible-playbook nginx.yml</code></pre><p><img src="https://s1.ax1x.com/2020/04/16/JEZMon.png" alt="JEZMon.png"><br>　　发现这样也是可以的~</p><h4 id="③-通过roles传递变量"><a href="#③-通过roles传递变量" class="headerlink" title="③ 通过roles传递变量"></a>③ 通过roles传递变量</h4><p>　　具体的，我们下文中说到 roles 的时候再详细说明。</p><h4 id="④-Host-Inventory"><a href="#④-Host-Inventory" class="headerlink" title="④ Host Inventory"></a>④ Host Inventory</h4><p>　　我们也可以直接在主机清单中定义。<br>　　定义的方法如下：</p><blockquote><p>向不同的主机传递不同的变量：</p></blockquote><pre><code>　　IP/HOSTNAME varaiable=value var2=value2</code></pre><blockquote><p>向组中的主机传递相同的变量：</p></blockquote><pre><code>　　[groupname:vars]　　variable=value</code></pre><p>Ansible Inventory 内置参数</p><p>![Ansible Inventory 内置参数](E:/学习晋升文件汇总/Linux架构学习入门/4. network_manager/19-20天-企业自动化运维工具Aansible实战/assets/Ansible Inventory 内置参数.png)</p><p>使用内置变量把用户名密码写在Inventory中，也就是/etc/ansible/hosts文件里，缺点就是<strong>暴露了账号密码</strong>，不安全。如果有多个主机需要使用同样的变量，可以用组变量的形式，书写格式如下：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token punctuation">[</span>web<span class="token punctuation">]</span>192.168.100.10192.168.100.11192.168.100.12 <span class="token punctuation">[</span>web<span class="token punctuation">:</span>vars<span class="token punctuation">]</span>  <span class="token comment" spellcheck="true">#给名为webservers的组定义一个变量，:vars是固定格式</span>ansible_ssh_port=22ansible_ssh_user='root'ansible_ssh_pass='1234.com'</code></pre><h3 id="5、模板-templates"><a href="#5、模板-templates" class="headerlink" title="5、模板 templates"></a>5、模板 templates</h3><p>　　模板是一个文本文件，嵌套有脚本（使用模板编程语言编写）。<br>　　<code>Jinja2</code>：Jinja2是python的一种模板语言，以Django的模板语言为原本。<br>模板支持：</p><pre><code>　　字符串：使用单引号或双引号；　　数字：整数，浮点数；　　列表：[item1, item2, ...]　　元组：(item1, item2, ...)　　字典：{key1:value1, key2:value2, ...}　　布尔型：true/false　　算术运算：　　　　+, -, *, /, //, %, **　　比较操作：　　　　==, !=, &gt;, &gt;=, &lt;, &lt;=　　逻辑运算：　　　　and, or, not</code></pre><p>　　通常来说，模板都是通过引用变量来运用的。</p><h5 id="举例-2"><a href="#举例-2" class="headerlink" title="举例"></a>举例</h5><p><strong>① 定义模板</strong><br>　　我们直接把之前定义的<code>/tmp/nginx.conf</code>改个名，然后编辑一下，就可以定义成我们的模板文件了：</p><pre><code>[root@server ansible]# cd /tmp[root@server tmp]# mv nginx.conf nginx.conf.j2[root@server tmp]# vim nginx.conf.j2    worker_processes  {{ ansible_processor_vcpus }};    listen       {{ nginxport }};</code></pre><p><strong>② 修改剧本</strong><br>　　我们现在需要去修改剧本来定义变量：</p><pre><code>[root@server ansible]# vim nginx.yml</code></pre><p><a href="https://imgchr.com/i/JEZtL4" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/04/16/JEZtL4.png" alt="JEZtL4.png"></a><br>　　需要修改的部分如图所示。</p><p>  copy 也需要修改为 template</p><p><strong>③ 运行剧本</strong><br>　　上面的准备工作完成后，我们就可以去运行剧本了：</p><pre><code>[root@server ansible]# ansible-playbook nginx.yml -t reloadnginxPLAY [web] *********************************************************************TASK [setup] *******************************************************************ok: [192.168.37.122]ok: [192.168.37.133]TASK [copy nginx.conf] *********************************************************ok: [192.168.37.122]ok: [192.168.37.133]PLAY RECAP *********************************************************************192.168.37.122             : ok=2    changed=0    unreachable=0    failed=0   192.168.37.133             : ok=2    changed=0    unreachable=0    failed=0 </code></pre><h3 id="6、条件测试"><a href="#6、条件测试" class="headerlink" title="6、条件测试"></a>6、条件测试</h3><p>when语句：在task中使用，jinja2的语法格式。<br>举例如下：</p><pre><code>tasks:- name: install conf file to centos7  template: src=files/nginx.conf.c7.j2  when: ansible_distribution_major_version == &quot;7&quot;- name: install conf file to centos6  template: src=files/nginx.conf.c6.j2  when: ansible_distribution_major_version == &quot;6&quot;</code></pre><p>循环：迭代，需要重复执行的任务；<br>　　对迭代项的引用，固定变量名为”item”，而后，要在task中使用with_items给定要迭代的元素列表；<br>举例如下：</p><pre><code>tasks:- name: unstall web packages  yum: name={{ item }} state=absent  with_items:  - httpd  - php  - php-mysql</code></pre><h3 id="7、字典"><a href="#7、字典" class="headerlink" title="7、字典"></a>7、字典</h3><p>　　ansible playbook 还支持字典功能。举例如下：</p><pre><code>- name: install some packages  yum: name={{ item }} state=present  with_items:    - nginx    - memcached    - php-fpm- name: add some groups  group: name={{ item }} state=present  with_items:    - group11    - group12    - group13- name: add some users  user: name={{ item.name }} group={{ item.group }} state=present  with_items:    - { name: &#39;user11&#39;, group: &#39;group11&#39; }    - { name: &#39;user12&#39;, group: &#39;group12&#39; }    - { name: &#39;user13&#39;, group: &#39;group13&#39; }</code></pre><h3 id="8、角色订制：roles"><a href="#8、角色订制：roles" class="headerlink" title="8、角色订制：roles"></a>8、角色订制：roles</h3><h4 id="①-简介"><a href="#①-简介" class="headerlink" title="① 简介"></a>① 简介</h4><p>　　对于以上所有的方式有个弊端就是无法实现复用假设在同时部署Web、db、ha 时或不同服务器组合不同的应用就需要写多个yml文件。很难实现灵活的调用。<br>　　roles 用于层次性、结构化地组织playbook。roles 能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需要在playbook中使用include指令即可。简单来讲，roles就是通过分别将变量(vars)、文件(file)、任务(tasks)、模块(modules)及处理器(handlers)放置于单独的目录中，并可以便捷地include它们的一种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程等场景中。</p><h4 id="②-角色集合"><a href="#②-角色集合" class="headerlink" title="② 角色集合"></a>② 角色集合</h4><p>角色集合：roles/<br>mysql/<br>httpd/<br>nginx/<br>files/：存储由copy或script等模块调用的文件；<br>tasks/：此目录中至少应该有一个名为main.yml的文件，用于定义各task；其它的文件需要由main.yml进行“包含”调用；<br>handlers/：此目录中至少应该有一个名为main.yml的文件，用于定义各handler；其它的文件需要由main.yml进行“包含”调用；<br>vars/：此目录中至少应该有一个名为main.yml的文件，用于定义各variable；其它的文件需要由main.yml进行“包含”调用；<br>templates/：存储由template模块调用的模板文本；<br>meta/：此目录中至少应该有一个名为main.yml的文件，定义当前角色的特殊设定及其依赖关系；其它的文件需要由main.yml进行“包含”调用；<br>default/：此目录中至少应该有一个名为main.yml的文件，用于设定默认变量；</p><h4 id="③-角色定制实例"><a href="#③-角色定制实例" class="headerlink" title="③ 角色定制实例"></a>③ 角色定制实例</h4><p><strong>1. 在roles目录下生成对应的目录结构</strong></p><pre><code>[root@server ansible]# cd roles/[root@server roles]# ls[root@server roles]# mkdir -pv ./{nginx,mysql,httpd}/{files,templates,vars,tasks,handlers,meta,default}[root@server roles]# tree.├── httpd│   ├── default│   ├── files│   ├── handlers│   ├── meta│   ├── tasks│   ├── templates│   └── vars├── mysql│   ├── default│   ├── files│   ├── handlers│   ├── meta│   ├── tasks│   ├── templates│   └── vars└── nginx    ├── default    ├── files    ├── handlers    ├── meta    ├── tasks    ├── templates    └── vars24 directories, 0 files</code></pre><p><strong>2. 定义配置文件</strong><br>　　我们需要修改的配置文件为<code>/tasks/main.yml</code>，下面，我们就来修改一下：</p><pre><code>[root@server roles]# vim nginx/tasks/main.yml- name: cp  copy: src=nginx-1.10.2-1.el7.ngx.x86_64.rpm dest=/tmp/nginx-1.10.2-1.el7.ngx.x86_64.rpm- name: install  yum: name=/tmp/nginx-1.10.2-1.el7.ngx.x86_64.rpm state=latest- name: conf  template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf  tags: nginxconf  notify: new conf to reload- name: start service  service: name=nginx state=started enabled=true</code></pre><p><strong>3. 放置我们所需要的文件到指定目录</strong><br>　　因为我们定义的角色已经有了新的组成方式，所以我们需要把文件都放到指定的位置，这样，才能让配置文件找到这些并进行加载。<br>　　rpm包放在<code>files</code>目录下，模板放在<code>templates</code>目录下：</p><pre><code>[root@server nginx]# cp /tmp/nginx-1.10.2-1.el7.ngx.x86_64.rpm ./files/[root@server nginx]# cp /tmp/nginx.conf.j2 ./templates/[root@server nginx]# tree.├── default├── files│   └── nginx-1.10.2-1.el7.ngx.x86_64.rpm├── handlers├── meta├── tasks│   └── main.yml├── templates│   └── nginx.conf.j2└── vars7 directories, 3 files</code></pre><p><strong>4. 修改变量文件</strong><br>　　我们在模板中定义的变量，也要去配置文件中加上：</p><pre><code>[root@server nginx]# vim vars/main.ymlnginxprot: 9999</code></pre><p><strong>5. 定义handlers文件</strong><br>　　我们在配置文件中定义了<code>notify</code>，所以我么也需要定义<code>handlers</code>，我们来修改配置文件：</p><pre><code>[root@server nginx]# vim handlers/main.yml- name: new conf to reload  service: name=nginx state=restarted</code></pre><p><strong>6. 定义剧本文件</strong><br>　　接下来，我们就来定义剧本文件，由于大部分设置我们都单独配置在了roles里面，所以，接下来剧本就只需要写一点点内容即可：</p><pre><code>[root@server ansible]# vim roles.yml - hosts: web  remote_user: root  roles:    - nginx</code></pre><p><strong>7. 启动服务</strong><br>　　剧本定义完成以后，我们就可以来启动服务了：</p><pre><code>[root@server ansible]# ansible-playbook roles.ymlPLAY [web] *********************************************************************TASK [setup] *******************************************************************ok: [192.168.37.122]ok: [192.168.37.133]TASK [nginx : cp] **************************************************************ok: [192.168.37.122]ok: [192.168.37.133]TASK [nginx : install] *********************************************************changed: [192.168.37.122]changed: [192.168.37.133]TASK [nginx : conf] ************************************************************changed: [192.168.37.122]changed: [192.168.37.133]TASK [nginx : start service] ***************************************************changed: [192.168.37.122]changed: [192.168.37.133]RUNNING HANDLER [nginx : new conf to reload] ***********************************changed: [192.168.37.122]changed: [192.168.37.133]PLAY RECAP *********************************************************************192.168.37.122             : ok=6    changed=4    unreachable=0    failed=0   192.168.37.133             : ok=6    changed=4    unreachable=0    failed=0   </code></pre><p>　　启动过后照例查看端口号：</p><pre><code>[root@server ansible]# ansible web -m shell -a &quot;ss -ntulp |grep 9999&quot;192.168.37.122 | SUCCESS | rc=0 &gt;&gt;tcp    LISTEN     0      128       *:9999                  *:*                   users:((&quot;nginx&quot;,pid=7831,fd=6),(&quot;nginx&quot;,pid=7830,fd=6),(&quot;nginx&quot;,pid=7829,fd=6))192.168.37.133 | SUCCESS | rc=0 &gt;&gt;tcp    LISTEN     0      128       *:9999                  *:*                   users:((&quot;nginx&quot;,pid=9654,fd=6),(&quot;nginx&quot;,pid=9653,fd=6),(&quot;nginx&quot;,pid=9652,fd=6))</code></pre><p>　　可以看出我们的剧本已经执行成功。</p><h2 id="九、Ansible使用jinja2管理配置文件以及jinja2语法简介"><a href="#九、Ansible使用jinja2管理配置文件以及jinja2语法简介" class="headerlink" title="九、Ansible使用jinja2管理配置文件以及jinja2语法简介"></a>九、Ansible使用jinja2管理配置文件以及jinja2语法简介</h2><h3 id="1、Jinja2介绍"><a href="#1、Jinja2介绍" class="headerlink" title="1、Jinja2介绍"></a>1、Jinja2介绍</h3><p>Jinja2是基于python的模板引擎，功能比较类似于PHP的smarty，J2ee的Freemarker和velocity。它能完全支持unicode，并具有集成的沙箱执行环境，应用广泛。jinja2使用BSD授权</p><p>Jinja2的语法是由variables(变量)和statement(语句)组成，如下；</p><h4 id="1、variables：可以输出数据"><a href="#1、variables：可以输出数据" class="headerlink" title="1、variables：可以输出数据"></a>1、variables：可以输出数据</h4><pre><code> my_variables </code></pre>{{ some_dudes_name | capitalize }}<h4 id="2、statements-可以用来创建条件和循环等"><a href="#2、statements-可以用来创建条件和循环等" class="headerlink" title="2、statements: 可以用来创建条件和循环等"></a>2、statements: 可以用来创建条件和循环等</h4><pre class=" language-bash"><code class="language-bash">if语句：<span class="token punctuation">{</span>% <span class="token keyword">if</span> my_conditional %<span class="token punctuation">}</span> <span class="token punctuation">..</span>.<span class="token punctuation">{</span>% endif %<span class="token punctuation">}</span><span class="token keyword">for</span> 语句：<span class="token punctuation">{</span>% <span class="token keyword">for</span> item <span class="token keyword">in</span> all_items %<span class="token punctuation">}</span><span class="token variable"><span class="token variable">`</span>item<span class="token variable">`</span></span> ……<span class="token punctuation">{</span>% endfor %<span class="token punctuation">}</span></code></pre><p>从上面第二个variables的例子中可以看出，jinja2支持使用带过滤器的Unix型管道操作符，有很多的内置过滤器可供使用。我们可以仅仅用一堆简单if和for就可以建立几乎任何的常规配置文件，不过如果你有意更进一步，jinja2 documentation （<a href="http://jinja.pocoo.org/docs/dev/）包含了很多有趣的东西可供了解。我们可以看到ansible允许在模板中使用诸如绘制时间此类的一些额外的模板变量" target="_blank" rel="noopener">http://jinja.pocoo.org/docs/dev/）包含了很多有趣的东西可供了解。我们可以看到ansible允许在模板中使用诸如绘制时间此类的一些额外的模板变量</a></p><p>第一个例子：引用变量</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#cd roles/template/</span><span class="token keyword">.</span>├── meta│   └── main.yml├── tasks│   ├── template.yml  │   └── main.yml├── templates│   ├── order.j2└── vars    └── main.yml</code></pre><p>总调度yml文件：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#cat templates.yml</span>---- hosts: 10.0.90.27  user: root  gather_facts: <span class="token boolean">false</span>  roles:   - role: template</code></pre><p>注意:这里 - role: template 和 - template 是一样的！</p><p>其他yml文件，如下：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#cat tasks/main.yml</span>- include: template.yml<span class="token comment" spellcheck="true">#cat tasks/template.yml</span>- name: create <span class="token punctuation">{</span><span class="token punctuation">{</span> PROJECT <span class="token punctuation">}</span><span class="token punctuation">}</span> directory  file: dest<span class="token operator">=</span>/data/<span class="token punctuation">{</span><span class="token punctuation">{</span> PROJECT <span class="token punctuation">}</span><span class="token punctuation">}</span> state<span class="token operator">=</span>directory- name: template transfor java <span class="token function">dir</span>  template: src<span class="token operator">=</span>order.j2 dest<span class="token operator">=</span>/data/<span class="token punctuation">{</span><span class="token punctuation">{</span> PROJECT <span class="token punctuation">}</span><span class="token punctuation">}</span>/order.conf<span class="token comment" spellcheck="true">#cat templates/order.j2</span>project: <span class="token punctuation">{</span><span class="token punctuation">{</span> PROJECT <span class="token punctuation">}</span><span class="token punctuation">}</span>switch: <span class="token punctuation">{</span><span class="token punctuation">{</span> SWITCH <span class="token punctuation">}</span><span class="token punctuation">}</span>dbport: <span class="token punctuation">{</span><span class="token punctuation">{</span> DBPORT <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">#cat vars/main.yml</span>PROJECT: <span class="token string">"JAVA"</span>SWITCH: <span class="token string">"ON"</span>DBPORT: <span class="token string">"8080"</span>测试：<span class="token comment" spellcheck="true"># ansible-playbook templates.yml --syntax-check</span>playbook: templates.yml执行：<span class="token comment" spellcheck="true"># ansible-playbook templates.yml </span>PLAY <span class="token punctuation">[</span>10.0.90.27<span class="token punctuation">]</span> **************************************************************TASK <span class="token punctuation">[</span>template <span class="token keyword">:</span> include<span class="token punctuation">]</span> ***************************************************included: /etc/ansible/roles/template/tasks/template.yml <span class="token keyword">for</span> 10.0.90.27TASK <span class="token punctuation">[</span>template <span class="token keyword">:</span> create JAVA directory<span class="token punctuation">]</span> *************************************changed: <span class="token punctuation">[</span>10.0.90.27<span class="token punctuation">]</span>TASK <span class="token punctuation">[</span>template <span class="token keyword">:</span> template transfor java dir<span class="token punctuation">]</span> ********************************changed: <span class="token punctuation">[</span>10.0.90.27<span class="token punctuation">]</span>PLAY RECAP *********************************************************************10.0.90.27                 <span class="token keyword">:</span> ok<span class="token operator">=</span>3    changed<span class="token operator">=</span>2    unreachable<span class="token operator">=</span>0    failed<span class="token operator">=</span>0   <span class="token comment" spellcheck="true">#到10.0.90.27查看结果</span><span class="token comment" spellcheck="true">#cat /data/JAVA/order.conf</span>project: JAVAswitch: ONdbport: 8080</code></pre><p>第二个例子：for 语句</p><p>为远程主机生成服务器列表，加入该列表从192.168.13.201 web01.test.com 到192.168.13.211 web11.test.com 结束，如果手动添加就很不科学了，这里需要使用jinja2语法的for循环通过模板批量生成对应的配置文件，如下：</p><p>ansible目录结构：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#cd /etc/ansible/roles/test_hosts</span><span class="token keyword">.</span>├── meta│   └── main.yml├── tasks│   ├── file1.yml│   └── main.yml├── templates│   └── test1.j2└── vars    └── main.yml</code></pre><p>各个目录下yml文件内容：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># cat tasks/file1.yml </span>- name: ansible jinja2 template <span class="token keyword">for</span> hosts config  template: src<span class="token operator">=</span>test1.j2 dest<span class="token operator">=</span>/etc/httpd/conf/httpd.conf.test<span class="token comment" spellcheck="true"># cat tasks/main.yml </span>- include: file1.yml<span class="token comment" spellcheck="true"># cat templates/test1.j2 </span><span class="token punctuation">{</span>% <span class="token keyword">for</span> <span class="token function">id</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span>201,212<span class="token punctuation">)</span> %<span class="token punctuation">}</span>192.168.13.<span class="token punctuation">{</span><span class="token punctuation">{</span> <span class="token function">id</span> <span class="token punctuation">}</span><span class="token punctuation">}</span> web<span class="token punctuation">{</span><span class="token punctuation">{</span> <span class="token string">"%03d"</span> <span class="token operator">|</span>format<span class="token punctuation">(</span>id-200<span class="token punctuation">)</span> <span class="token punctuation">}</span><span class="token punctuation">}</span>.test.com<span class="token punctuation">{</span>% endfor %<span class="token punctuation">}</span>解释：<span class="token punctuation">{</span><span class="token punctuation">{</span> <span class="token function">id</span> <span class="token punctuation">}</span><span class="token punctuation">}</span> 提取for循环中对应的变量id值<span class="token string">"%02d"</span>   调用的是python内置的字符串格式化输出（%d格式化整数）因为是01,02这种格式，所以是保留2位，故用02然后将结果通过管道符 “<span class="token operator">|</span>” 传递给format 函数做二次处理。</code></pre><p>执行结果：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#cat httpd.conf.test</span>192.168.13.201 web01.test.com192.168.13.202 web02.test.com192.168.13.203 web03.test.com192.168.13.204 web04.test.com192.168.13.205 web05.test.com192.168.13.206 web06.test.com192.168.13.207 web07.test.com192.168.13.208 web08.test.com192.168.13.209 web09.test.com192.168.13.210 web10.test.com192.168.13.211 web11.test.com</code></pre><p>第三个例子：if语句</p><p>说明：如果定义端口号，就绑定定义的端口号，如果不定义端口号，就绑定默认端口号</p><pre class=" language-bash"><code class="language-bash">ansible目录结果<span class="token comment" spellcheck="true">#cd /etc/ansible/roles/mysql_cnf</span><span class="token comment" spellcheck="true">#tree</span><span class="token keyword">.</span>├── meta│   └── main.yml├── tasks│   └── main.yml├── templates│   └── test3.j2└── vars</code></pre><p>主要的yml文件是templates目录下面的test3.j2</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># cat templates/test3.j2 </span><span class="token punctuation">{</span>% <span class="token keyword">if</span> PORT %<span class="token punctuation">}</span>bind_address<span class="token operator">=</span>10.0.90.27:<span class="token punctuation">{</span><span class="token punctuation">{</span> PORT <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">{</span>% <span class="token keyword">else</span> %<span class="token punctuation">}</span>bind_address<span class="token operator">=</span>10.0.90.27:3306<span class="token punctuation">{</span>% endif %<span class="token punctuation">}</span></code></pre><p>playbook主文件</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># cat jinj2_test.yml </span>---- hosts: 10.0.90.27  user: root  gather_facts: <span class="token boolean">false</span>  vars:    PORT: 3136  tasks:    - name: copy <span class="token function">file</span> to client      template: src<span class="token operator">=</span>/etc/ansible/roles/mysql_cnf/templates/test3.j2 dest<span class="token operator">=</span>/root/my.cnf</code></pre><p>执行：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># ansible-playbook jinj2_test.yml</span>PLAY <span class="token punctuation">[</span>10.0.90.27<span class="token punctuation">]</span> **************************************************************TASK <span class="token punctuation">[</span>copy <span class="token function">file</span> to client<span class="token punctuation">]</span> *****************************************************changed: <span class="token punctuation">[</span>10.0.90.27<span class="token punctuation">]</span>PLAY RECAP *********************************************************************10.0.90.27                 <span class="token keyword">:</span> ok<span class="token operator">=</span>1    changed<span class="token operator">=</span>1    unreachable<span class="token operator">=</span>0    failed<span class="token operator">=</span>0</code></pre><p>查看</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># cat my.cnf </span>bind_address<span class="token operator">=</span>10.0.90.27:3136</code></pre><p>如果将vars变量去掉，执行结果：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># cat jinj2_test.yml </span>---- hosts: 10.0.90.27  user: root  gather_facts: <span class="token boolean">false</span>  vars:    PORT: <span class="token boolean">false</span>  tasks:    - name: copy <span class="token function">file</span> to client      template: src<span class="token operator">=</span>/etc/ansible/roles/mysql_cnf/templates/test3.j2 dest<span class="token operator">=</span>/root/my.cnf</code></pre><p>查看：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># cat my.cnf </span>bind_address<span class="token operator">=</span>10.0.90.27:3306</code></pre><h4 id="3、Jinja-default-设定"><a href="#3、Jinja-default-设定" class="headerlink" title="3、Jinja default()设定"></a>3、Jinja default()设定</h4><p>精通程序编码的朋友皆知，default()默认值的设定有助于程序的健壮性和简洁性。所幸Jinja也支持该功能，上面的例子中生成Mysql配置文件中的端口定义，如果指定则PORT=3136，否则PORT=3306，我们将该案例改造为使用default()试试</p><p>编辑/etc/ansible/roles/mysql_cnf/templates/test3.j2内容如下,这种方法更简介。</p><p>bind_address=10.0.90.27:3306</p><h3 id="2、ansible使用jiaja2生成apache多主机配置"><a href="#2、ansible使用jiaja2生成apache多主机配置" class="headerlink" title="2、ansible使用jiaja2生成apache多主机配置"></a>2、ansible使用jiaja2生成apache多主机配置</h3><h4 id="1、创建目录，创建好之后如下："><a href="#1、创建目录，创建好之后如下：" class="headerlink" title="1、创建目录，创建好之后如下："></a>1、创建目录，创建好之后如下：</h4><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#cd /etc/ansible/roles/apache_conf</span><span class="token comment" spellcheck="true"># tree ./</span>./├── meta│   └── main.yml├── tasks│   ├── file.yml│   └── main.yml├── templates│   └── apache.config.j2└── vars    └── main.yml4 directories, 5 files</code></pre><h4 id="2、创建tasks调度文件，如下："><a href="#2、创建tasks调度文件，如下：" class="headerlink" title="2、创建tasks调度文件，如下："></a>2、创建tasks调度文件，如下：</h4><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#cat file.yml </span>- name: ansible jinja2 template <span class="token keyword">for</span> apache config  template: src<span class="token operator">=</span>apache.config.j2 dest<span class="token operator">=</span>/etc/httpd/conf/httpd.conf.template<span class="token comment" spellcheck="true">#cat main.yml </span>- include: file.yml</code></pre><h4 id="3、创建apache的jinja2模板文件，如下："><a href="#3、创建apache的jinja2模板文件，如下：" class="headerlink" title="3、创建apache的jinja2模板文件，如下："></a>3、创建apache的jinja2模板文件，如下：</h4><pre class=" language-cpp"><code class="language-cpp"><span class="token macro property">#cat apache.config.j2 </span>NameVirtualHost <span class="token operator">*</span><span class="token operator">:</span><span class="token number">80</span><span class="token punctuation">{</span><span class="token operator">%</span> <span class="token keyword">for</span> vhost in apache_vhost <span class="token operator">%</span><span class="token punctuation">}</span><span class="token operator">&lt;</span>VirtualHost <span class="token operator">*</span><span class="token operator">:</span><span class="token number">80</span><span class="token operator">></span>ServerName <span class="token punctuation">{</span><span class="token punctuation">{</span> vhost<span class="token punctuation">.</span>servername <span class="token punctuation">}</span><span class="token punctuation">}</span>DocumentRoot <span class="token punctuation">{</span><span class="token punctuation">{</span> vhost<span class="token punctuation">.</span>documentroot <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">{</span><span class="token operator">%</span> <span class="token keyword">if</span> vhost<span class="token punctuation">.</span>serveradmin is defined <span class="token operator">%</span><span class="token punctuation">}</span>ServerAdmin <span class="token punctuation">{</span><span class="token punctuation">{</span> vhost<span class="token punctuation">.</span>serveradmin <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">{</span><span class="token operator">%</span> endif <span class="token operator">%</span><span class="token punctuation">}</span><span class="token operator">&lt;</span>Directory <span class="token string">"{{ vhost.documentroot }}"</span><span class="token operator">></span>AllowOverride AllOptions <span class="token operator">-</span>Indexes FollowSymLinksOrder allow<span class="token punctuation">,</span>denyAllow from all<span class="token operator">&lt;</span><span class="token operator">/</span>Directory<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>VirtualHost<span class="token operator">></span><span class="token punctuation">{</span><span class="token operator">%</span> endfor <span class="token operator">%</span><span class="token punctuation">}</span></code></pre><h4 id="4、创建变量，如下："><a href="#4、创建变量，如下：" class="headerlink" title="4、创建变量，如下："></a>4、创建变量，如下：</h4><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#cat vars/main.yml</span>apache_vhost:- <span class="token punctuation">{</span>servername: <span class="token string">"apache.test1.com"</span>, documentroot: <span class="token string">"/data/test1/"</span><span class="token punctuation">}</span>- <span class="token punctuation">{</span>servername: <span class="token string">"apache.test2.com"</span>, documentroot: <span class="token string">"/data/test2/"</span><span class="token punctuation">}</span></code></pre><h4 id="5、创建总调度yml文件，如下："><a href="#5、创建总调度yml文件，如下：" class="headerlink" title="5、创建总调度yml文件，如下："></a>5、创建总调度yml文件，如下：</h4><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#cat /etc/ansible/apache_test.yml </span>---- hosts: 10.0.90.27  user: root  gather_facts: no  roles:   - <span class="token punctuation">{</span> role: apache_conf <span class="token punctuation">}</span></code></pre><h4 id="6、测试："><a href="#6、测试：" class="headerlink" title="6、测试："></a>6、测试：</h4><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#ansible-playbook apache_test.yml --syntax-check</span>playbook: apache_test.yml</code></pre><h4 id="7、执行测试"><a href="#7、执行测试" class="headerlink" title="7、执行测试"></a>7、执行测试</h4><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#ansible-playbook apache_test.yml </span>PLAY <span class="token punctuation">[</span>10.0.90.27<span class="token punctuation">]</span> **************************************************************TASK <span class="token punctuation">[</span>apache_conf <span class="token keyword">:</span> include<span class="token punctuation">]</span> ***************************************************included: /etc/ansible/roles/apache_conf/tasks/file.yml <span class="token keyword">for</span> 10.0.90.27TASK <span class="token punctuation">[</span>apache_conf <span class="token keyword">:</span> ansible jinja2 template <span class="token keyword">for</span> apache config<span class="token punctuation">]</span> *****************changed: <span class="token punctuation">[</span>10.0.90.27<span class="token punctuation">]</span>PLAY RECAP *********************************************************************10.0.90.27                 <span class="token keyword">:</span> ok<span class="token operator">=</span>2    changed<span class="token operator">=</span>1    unreachable<span class="token operator">=</span>0    failed<span class="token operator">=</span>0</code></pre><h4 id="8、到客户端查看"><a href="#8、到客户端查看" class="headerlink" title="8、到客户端查看"></a>8、到客户端查看</h4><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#cat httpd.conf.template </span>NameVirtualHost *:80<span class="token operator">&lt;</span>VirtualHost *:80<span class="token operator">></span>ServerName apache.test1.comDocumentRoot /data/test1/<span class="token operator">&lt;</span>Directory <span class="token string">"/data/test1/"</span><span class="token operator">></span>AllowOverride AllOptions -Indexes FollowSymLinksOrder allow,denyAllow from all<span class="token operator">&lt;</span>/Directory<span class="token operator">></span><span class="token operator">&lt;</span>/VirtualHost<span class="token operator">></span><span class="token operator">&lt;</span>VirtualHost *:80<span class="token operator">></span>ServerName apache.test2.comDocumentRoot /data/test2/<span class="token operator">&lt;</span>Directory <span class="token string">"/data/test2/"</span><span class="token operator">></span>AllowOverride AllOptions -Indexes FollowSymLinksOrder allow,denyAllow from all<span class="token operator">&lt;</span>/Directory<span class="token operator">></span><span class="token operator">&lt;</span>/VirtualHost<span class="token operator">></span></code></pre><h2 id="3、ansible使用jiaja2生成nginx一个模板多种不同配置"><a href="#3、ansible使用jiaja2生成nginx一个模板多种不同配置" class="headerlink" title="3、ansible使用jiaja2生成nginx一个模板多种不同配置"></a>3、ansible使用jiaja2生成nginx一个模板多种不同配置</h2><p>说明：为2台Nginx Proxy，1台Nginx Web通过一套模板生成对应的配置</p><h4 id="1、ansible目录结构："><a href="#1、ansible目录结构：" class="headerlink" title="1、ansible目录结构："></a>1、ansible目录结构：</h4><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># cd roles/nginx_conf/</span><span class="token comment" spellcheck="true">#tree</span><span class="token keyword">.</span>├── files├── meta│   └── main.yml├── tasks│   ├── file.yml│   └── main.yml├── templates│   └── nginx.conf.j2└── vars    └── main.yml</code></pre><h4 id="2、tasks目录下文件内容："><a href="#2、tasks目录下文件内容：" class="headerlink" title="2、tasks目录下文件内容："></a>2、tasks目录下文件内容：</h4><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#cat tasks/file.yml </span>- name: nginx.j2 template transfer example   template: src<span class="token operator">=</span>nginx.conf.j2 dest<span class="token operator">=</span>/etc/nginx/nginx.conf.template<span class="token comment" spellcheck="true">#cat tasks/main.yml </span>- include: file.yml</code></pre><h4 id="3、nginx模板文件"><a href="#3、nginx模板文件" class="headerlink" title="3、nginx模板文件"></a>3、nginx模板文件</h4><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#cat templates/nginx.conf.j2 </span><span class="token punctuation">{</span>% <span class="token keyword">if</span> nginx_use_proxy %<span class="token punctuation">}</span><span class="token punctuation">{</span>% <span class="token keyword">for</span> proxy <span class="token keyword">in</span> nginx_proxies %<span class="token punctuation">}</span>upstream <span class="token punctuation">{</span><span class="token punctuation">{</span> proxy.name <span class="token punctuation">}</span><span class="token punctuation">}</span>   <span class="token comment" spellcheck="true">#server 127.0.0.1:{{ proxy.port }};</span>   server <span class="token punctuation">{</span><span class="token punctuation">{</span> ansible_eth0.ipv4.address <span class="token punctuation">}</span><span class="token punctuation">}</span>:<span class="token punctuation">{</span><span class="token punctuation">{</span> proxy.port <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">{</span>% endfor %<span class="token punctuation">}</span><span class="token punctuation">{</span>% endif%<span class="token punctuation">}</span>server <span class="token punctuation">{</span>    listen 80<span class="token punctuation">;</span>    servername <span class="token punctuation">{</span><span class="token punctuation">{</span> nginx_server_name <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span>    access_log off<span class="token punctuation">;</span>    error_log /etc/nginx/nginx_error.log<span class="token punctuation">;</span>    rewrite ^ https://<span class="token variable">$server_name</span><span class="token variable">$request_uri?</span> permanent<span class="token punctuation">;</span><span class="token punctuation">}</span>server <span class="token punctuation">{</span>    listen 443 ssl<span class="token punctuation">;</span>    server_name <span class="token punctuation">{</span><span class="token punctuation">{</span> nginx_server_name <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span>    ssl_certificate /etc/nginx/ssl/<span class="token punctuation">{</span><span class="token punctuation">{</span> nginx_ssl_cert_name <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span>    ssl_certificate_key /etc/nginx/ssl/<span class="token punctuation">{</span><span class="token punctuation">{</span> nginx_ssl_cert_key <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span>    root <span class="token punctuation">{</span><span class="token punctuation">{</span> nginx_web_root <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span>    index index.html index.html<span class="token punctuation">;</span><span class="token punctuation">{</span>% <span class="token keyword">if</span> nginx_use_auth %<span class="token punctuation">}</span>   auth_basic  <span class="token string">"Restricted"</span><span class="token punctuation">;</span>   auth_basic_user_file /etc/nginx/<span class="token punctuation">{</span><span class="token punctuation">{</span> project_name <span class="token punctuation">}</span><span class="token punctuation">}</span>.htpasswd<span class="token punctuation">;</span><span class="token punctuation">{</span>% endif %<span class="token punctuation">}</span><span class="token punctuation">{</span>% <span class="token keyword">if</span> nginx_use_proxy %<span class="token punctuation">}</span><span class="token punctuation">{</span>% <span class="token keyword">for</span> proxy <span class="token keyword">in</span> nginx_proxies %<span class="token punctuation">}</span>   location <span class="token punctuation">{</span><span class="token punctuation">{</span> proxy.location <span class="token punctuation">}</span><span class="token punctuation">}</span> <span class="token punctuation">{</span>      proxy_set_header X-Real-IP <span class="token variable">$remote_addr</span><span class="token punctuation">;</span>      proxy_set_header X-Forwarded-Proto http<span class="token punctuation">;</span>      proxy_set_header X-Url-Scheme <span class="token variable">$scheme</span><span class="token punctuation">;</span>      proxy_set_header X-Forwarded-For <span class="token variable">$proxy_add_x_forwarded_for</span><span class="token punctuation">;</span>      proxy_set_header Host <span class="token variable">$http_host</span><span class="token punctuation">;</span>      proxy_set_header X-NginX-Proxy <span class="token boolean">true</span><span class="token punctuation">;</span>      proxy_redirect off<span class="token punctuation">;</span>      proxy_pass http://<span class="token punctuation">{</span><span class="token punctuation">{</span> proxy.name <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span>      <span class="token keyword">break</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">{</span>% endfor %<span class="token punctuation">}</span><span class="token punctuation">{</span>% endif %<span class="token punctuation">}</span><span class="token punctuation">{</span>% <span class="token keyword">if</span> nginx_server_static %<span class="token punctuation">}</span>   location / <span class="token punctuation">{</span>       try_files <span class="token variable">$url</span> <span class="token variable">$url</span>/ <span class="token operator">=</span>404<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">{</span>% endif %<span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><h4 id="4、ansible变量文件"><a href="#4、ansible变量文件" class="headerlink" title="4、ansible变量文件"></a>4、ansible变量文件</h4><pre class=" language-bash"><code class="language-bash"><span class="token function">cat</span> vars/main.yml nginx_server_name: www.testnginx.comnginx_web_root: /data/html/nginx_proxies:- name: suspicious  location: /  port: 1234- name: suspicious-api  location: /api  port: 4567</code></pre><h4 id="5、ansible主playbook文件"><a href="#5、ansible主playbook文件" class="headerlink" title="5、ansible主playbook文件"></a>5、ansible主playbook文件</h4><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#cat nginx_test.yml </span><span class="token comment" spellcheck="true">##The first roles</span>- name: Nginx Proxy Server<span class="token string">'s Config Dynamic Create  hosts: "10.0.90.25:10.0.90.26"  remote_user: root  vars:    nginx_use_proxy: true    nginx_ssl_cert_name: ifa.crt    nginx_ssl_cert_key: ifa.key    nginx_use_auth: true    project_name: suspicious    nginx_server_static: true  gather_facts: true  roles:     -  role: nginx_conf##The second roles- name: Nginx WebServer'</span>s Config Dynamic Create  hosts: 10.0.90.27  remote_user: root  vars:    nginx_use_proxy: <span class="token boolean">false</span>    nginx_ssl_cert_name: ifa.crt    nginx_ssl_cert_key: ifa.crt    nginx_use_auth: <span class="token boolean">false</span>    project_name: suspicious    nginx_server_static: <span class="token boolean">false</span>  gather_facts: <span class="token boolean">false</span>  roles:     -  role: nginx_conf</code></pre><h4 id="6、测试并执行："><a href="#6、测试并执行：" class="headerlink" title="6、测试并执行："></a>6、测试并执行：</h4><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#ansible-playbook nginx_test.yml --syntax-check</span>playbook: nginx_test.yml执行：<span class="token comment" spellcheck="true"># ansible-playbook nginx_test.yml</span>PLAY <span class="token punctuation">[</span>Nginx Proxy Server<span class="token string">'s Config Dynamic Create] ******************************TASK [setup] *******************************************************************ok: [10.0.90.25]ok: [10.0.90.26]TASK [nginx_conf : include] ****************************************************included: /etc/ansible/roles/nginx_conf/tasks/file.yml for 10.0.90.25, 10.0.90.26TASK [nginx_conf : nginx.j2 template transfer example] *************************changed: [10.0.90.26]changed: [10.0.90.25]PLAY [Nginx WebServer'</span>s Config Dynamic Create<span class="token punctuation">]</span> *********************************TASK <span class="token punctuation">[</span>nginx_conf <span class="token keyword">:</span> include<span class="token punctuation">]</span> ****************************************************included: /etc/ansible/roles/nginx_conf/tasks/file.yml <span class="token keyword">for</span> 10.0.90.27TASK <span class="token punctuation">[</span>nginx_conf <span class="token keyword">:</span> nginx.j2 template transfer example<span class="token punctuation">]</span> *************************changed: <span class="token punctuation">[</span>10.0.90.27<span class="token punctuation">]</span>PLAY RECAP *********************************************************************10.0.90.25                 <span class="token keyword">:</span> ok<span class="token operator">=</span>3    changed<span class="token operator">=</span>1    unreachable<span class="token operator">=</span>0    failed<span class="token operator">=</span>0   10.0.90.26                 <span class="token keyword">:</span> ok<span class="token operator">=</span>3    changed<span class="token operator">=</span>1    unreachable<span class="token operator">=</span>0    failed<span class="token operator">=</span>0   10.0.90.27                 <span class="token keyword">:</span> ok<span class="token operator">=</span>2    changed<span class="token operator">=</span>1    unreachable<span class="token operator">=</span>0    failed<span class="token operator">=</span>0</code></pre><h4 id="7、查看检测执行结果"><a href="#7、查看检测执行结果" class="headerlink" title="7、查看检测执行结果"></a>7、查看检测执行结果</h4><p>到Nginx Proxy 服务器查看配置文件</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#cat nginx.conf.template </span>upstream suspicious   <span class="token comment" spellcheck="true">#server 127.0.0.1:1234;</span>   server 10.0.90.26:1234<span class="token punctuation">;</span><span class="token punctuation">}</span>upstream suspicious-api   <span class="token comment" spellcheck="true">#server 127.0.0.1:4567;</span>   server 10.0.90.26:4567<span class="token punctuation">;</span><span class="token punctuation">}</span>server <span class="token punctuation">{</span>    listen 80<span class="token punctuation">;</span>    servername www.testnginx.com<span class="token punctuation">;</span>    access_log off<span class="token punctuation">;</span>    error_log /etc/nginx/nginx_error.log<span class="token punctuation">;</span>    rewrite ^ https://<span class="token variable">$server_name</span><span class="token variable">$request_uri?</span> permanent<span class="token punctuation">;</span><span class="token punctuation">}</span>server <span class="token punctuation">{</span>    listen 443 ssl<span class="token punctuation">;</span>    server_name www.testnginx.com<span class="token punctuation">;</span>    ssl_certificate /etc/nginx/ssl/ifa.crt<span class="token punctuation">;</span>    ssl_certificate_key /etc/nginx/ssl/ifa.key<span class="token punctuation">;</span>    root /data/html/<span class="token punctuation">;</span>    index index.html index.html<span class="token punctuation">;</span>   auth_basic  <span class="token string">"Restricted"</span><span class="token punctuation">;</span>   auth_basic_user_file /etc/nginx/suspicious.htpasswd<span class="token punctuation">;</span>   location / <span class="token punctuation">{</span>      proxy_set_header X-Real-IP <span class="token variable">$remote_addr</span><span class="token punctuation">;</span>      proxy_set_header X-Forwarded-Proto http<span class="token punctuation">;</span>      proxy_set_header X-Url-Scheme <span class="token variable">$scheme</span><span class="token punctuation">;</span>      proxy_set_header X-Forwarded-For <span class="token variable">$proxy_add_x_forwarded_for</span><span class="token punctuation">;</span>      proxy_set_header Host <span class="token variable">$http_host</span><span class="token punctuation">;</span>      proxy_set_header X-NginX-Proxy <span class="token boolean">true</span><span class="token punctuation">;</span>      proxy_redirect off<span class="token punctuation">;</span>      proxy_pass http://suspicious<span class="token punctuation">;</span>      <span class="token keyword">break</span><span class="token punctuation">;</span><span class="token punctuation">}</span>   location /api <span class="token punctuation">{</span>      proxy_set_header X-Real-IP <span class="token variable">$remote_addr</span><span class="token punctuation">;</span>      proxy_set_header X-Forwarded-Proto http<span class="token punctuation">;</span>      proxy_set_header X-Url-Scheme <span class="token variable">$scheme</span><span class="token punctuation">;</span>      proxy_set_header X-Forwarded-For <span class="token variable">$proxy_add_x_forwarded_for</span><span class="token punctuation">;</span>      proxy_set_header Host <span class="token variable">$http_host</span><span class="token punctuation">;</span>      proxy_set_header X-NginX-Proxy <span class="token boolean">true</span><span class="token punctuation">;</span>      proxy_redirect off<span class="token punctuation">;</span>      proxy_pass http://suspicious-api<span class="token punctuation">;</span>      <span class="token keyword">break</span><span class="token punctuation">;</span><span class="token punctuation">}</span>   location / <span class="token punctuation">{</span>       try_files <span class="token variable">$url</span> <span class="token variable">$url</span>/ <span class="token operator">=</span>404<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>到Nginx Web 服务器上查看配置文件</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#cat nginx.conf.template </span>server <span class="token punctuation">{</span>    listen 80<span class="token punctuation">;</span>    servername www.testnginx.com<span class="token punctuation">;</span>    access_log off<span class="token punctuation">;</span>    error_log /etc/nginx/nginx_error.log<span class="token punctuation">;</span>    rewrite ^ https://<span class="token variable">$server_name</span><span class="token variable">$request_uri?</span> permanent<span class="token punctuation">;</span><span class="token punctuation">}</span>server <span class="token punctuation">{</span>    listen 443 ssl<span class="token punctuation">;</span>    server_name www.testnginx.com<span class="token punctuation">;</span>    ssl_certificate /etc/nginx/ssl/ifa.crt<span class="token punctuation">;</span>    ssl_certificate_key /etc/nginx/ssl/ifa.crt<span class="token punctuation">;</span>    root /data/html/<span class="token punctuation">;</span>    index index.html index.html<span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p>到这里，就结束了。用同样的模板通过简单的if和变量设置就可以完成不同类型主机的Nginx conf配置，所以一方面在了解Ansible强大的模板功能的同时，也需要看到模板质量的重要性。</p>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Ansible </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ消息中间件</title>
      <link href="2019/04/16/sql/rabbitmq-xiao-xi-zhong-jian-jian/"/>
      <url>2019/04/16/sql/rabbitmq-xiao-xi-zhong-jian-jian/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="RabbitMQ-消息中间件"><a href="#RabbitMQ-消息中间件" class="headerlink" title="RabbitMQ 消息中间件"></a>RabbitMQ 消息中间件</h2><h3 id="1、消息中间件"><a href="#1、消息中间件" class="headerlink" title="1、消息中间件"></a>1、消息中间件</h3><h4 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h4><p>消息中间件也可以称消息队列，是指用高效可靠的消息传递机制进行与平台无关的数据交流，并基于数据通信来进行分布式系统的集成。通过提供消息传递和消息队列模型，可以在分布式环境下扩展进程的通信。</p><p>当下主流的消息中间件有RabbitMQ、Kafka、ActiveMQ、RocketMQ等。其能在不同平台之间进行通信，常用来屏蔽各种平台协议之间的特性，实现应用程序之间的协同。优点在于能够在客户端和服务器之间进行同步和异步的连接，并且在任何时刻都可以将消息进行传送和转发，是分布式系统中非常重要的组件，主要用来解决应用耦合、异步通信、流量削峰等问题。 </p><h4 id="2、作用"><a href="#2、作用" class="headerlink" title="2、作用"></a>2、作用</h4><h5 id="1、消息中间件主要作用"><a href="#1、消息中间件主要作用" class="headerlink" title="1、消息中间件主要作用"></a>1、消息中间件主要作用</h5><ul><li>解耦</li><li>冗余(存储)</li><li>扩展性</li><li>削峰</li><li>可恢复性</li><li>顺序保证</li><li>缓冲</li><li>异步通信</li></ul><h5 id="2、消息中间件的两种模式"><a href="#2、消息中间件的两种模式" class="headerlink" title="2、消息中间件的两种模式"></a>2、消息中间件的两种模式</h5><h6 id="1、P2P模式"><a href="#1、P2P模式" class="headerlink" title="1、P2P模式"></a>1、P2P模式</h6><p>P2P模式包含三个角色：消息队列（Queue）、发送者(Sender)、接收者(Receiver)。每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到它们被消费或超时。</p><p><strong>P2P的特点：</strong></p><ul><li>每个消息只有一个消费者（Consumer），即一旦被消费，消息就不再在消息队列中</li><li>发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行它不会影响到消息被发送到队列</li><li>接收者在成功接收消息之后需向队列应答成功</li><li>如果希望发送的每个消息都会被成功处理的话，那么需要P2P模 </li></ul><h6 id="2、Pub-Sub模式"><a href="#2、Pub-Sub模式" class="headerlink" title="2、Pub/Sub模式"></a>2、Pub/Sub模式</h6><p>Pub/Sub模式包含三个角色：主题（Topic）、发布者（Publisher）、订阅者（Subscriber） 。多个发布者将消息发送到Topic，系统将这些消息传递给多个订阅者。</p><p><strong>Pub/Sub的特点：</strong></p><ul><li>每个消息可以有多个消费者</li><li>发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息</li><li>为了消费消息，订阅者必须保持运行的状态</li><li>如果希望发送的消息可以不被做任何处理、或者只被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用Pub/Sub模型</li></ul><h5 id="3、常用中间件介绍与对比"><a href="#3、常用中间件介绍与对比" class="headerlink" title="3、常用中间件介绍与对比"></a>3、常用中间件介绍与对比</h5><h6 id="1、Kafka"><a href="#1、Kafka" class="headerlink" title="1、Kafka"></a>1、Kafka</h6><p>Kafka是LinkedIn开源的分布式发布-订阅消息系统，目前归属于Apache顶级项目。Kafka主要特点是基于Pull的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输。0.8版本开始支持复制，不支持事务，对消息的重复、丢失、错误没有严格要求，适合产生大量数据的互联网服务的数据收集业务。</p><h6 id="2、RabbitMQ"><a href="#2、RabbitMQ" class="headerlink" title="2、RabbitMQ"></a>2、RabbitMQ</h6><p>RabbitMQ是使用Erlang语言开发的开源消息队列系统，基于AMQP协议来实现。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。AMQP协议更多用在企业系统内对数据一致性、稳定性和可靠性要求很高的场景，对性能和吞吐量的要求还在其次。</p><h6 id="3、RocketMQ"><a href="#3、RocketMQ" class="headerlink" title="3、RocketMQ"></a>3、RocketMQ</h6><p>RocketMQ是阿里开源的消息中间件，它是纯Java开发，具有高吞吐量、高可用性、适合大规模分布式系统应用的特点。RocketMQ思路起源于Kafka，但并不是Kafka的一个Copy，它对消息的可靠传输及事务性做了优化，目前在阿里集团被广泛应用于交易、充值、流计算、消息推送、日志流式处理、binglog分发等场景。</p><p>RabbitMQ比Kafka可靠，Kafka更适合IO高吞吐的处理，一般应用在大数据日志处理或对实时性（少量延迟），可靠性（少量丢数据）要求稍低的场景使用，比如ELK日志收集。</p><h3 id="2、RabbitMQ-详解"><a href="#2、RabbitMQ-详解" class="headerlink" title="2、RabbitMQ 详解"></a>2、RabbitMQ 详解</h3><h4 id="1、RabbitMQ-介绍"><a href="#1、RabbitMQ-介绍" class="headerlink" title="1、RabbitMQ 介绍"></a>1、RabbitMQ 介绍</h4><p>RabbitMQ是一个在AMQP（Advanced Message Queuing Protocol ）基础上实现的，可复用的企业消息系统。它可以用于大型软件系统各个模块之间的高效通信，支持高并发，支持可扩展。它支持多种客户端如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX，持久化，用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。</p><p>RabbitMQ是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正是如此，使的它变的非常重量级，更适合于企业级的开发。它同时实现了一个Broker构架，这意味着消息在发送给客户端时先在中心队列排队，对路由(Routing)、负载均衡(Load balance)或者数据持久化都有很好的支持。</p><h4 id="2、RabbitMQ-特点"><a href="#2、RabbitMQ-特点" class="headerlink" title="2、RabbitMQ 特点"></a>2、RabbitMQ 特点</h4><ul><li>可靠性</li><li>灵活的路由</li><li>扩展性</li><li>高可用性</li><li>多种协议</li><li>多语言客户端</li><li>管理界面</li><li>插件机制</li></ul><h4 id="3、AMQP-介绍"><a href="#3、AMQP-介绍" class="headerlink" title="3、AMQP 介绍"></a>3、AMQP 介绍</h4><p>AMQP，即Advanced Message Queuing Protocol,一个提供统一消息服务的应用层标准<strong>高级消息队列协议</strong>,是应用层协议的一个开放标准,为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。</p><h4 id="4、什么和是消息队列"><a href="#4、什么和是消息队列" class="headerlink" title="4、什么和是消息队列"></a>4、什么和是消息队列</h4><p>MQ 全称为Message Queue, 消息队列。是一种应用程序对应用程序的通信方法。应用程序通过读写出入队列的消息（针对应用程序的数据）来通信，而无需专用连接来链接它们。</p><p><strong>消息传递</strong>指的是程序之间通过在消息中发送数据进行通信，而不是通过直接调用彼此来通信。队列的使用除去了接收和发送应用程序同时执行的要求。</p><p>在项目中，将一些无需即时返回且耗时的操作提取出来，进行了异步处理，而这种异步处理的方式大大的节省了服务器的请求响应时间，从而提高了系统的吞吐量。</p><p>消息队列的使用场景是怎样的？</p><h4 id="5、RabbitMQ-应用场景"><a href="#5、RabbitMQ-应用场景" class="headerlink" title="5、RabbitMQ 应用场景"></a>5、RabbitMQ 应用场景</h4><p>对于一个大型的软件系统来说，它会有很多的组件或者说模块或者说子系统或者（subsystem or Component or submodule）。那么这些模块的如何通信？这和传统的IPC有很大的区别。传统的IPC很多都是在单一系统上的，模块耦合性很大，不适合扩展（Scalability）；如果使用socket那么不同的模块的确可以部署到不同的机器上，但是还是有很多问题需要解决。比如：<br>1）信息的发送者和接收者如何维持这个连接，如果一方的连接中断，这期间的数据如何防止丢失？<br>2）如何降低发送者和接收者的耦合度？<br>3）如何让Priority高的接收者先接到数据？<br>4）如何做到load balance？有效均衡接收者的负载？<br>5）如何有效的将数据发送到相关的接收者？也就是说将接收者subscribe 不同的数据，如何做有效的filter。<br>6）如何做到可扩展，甚至将这个通信模块发到cluster上？<br>7）如何保证接收者接收到了完整，正确的数据？<br><strong>AMDQ</strong>协议解决了以上的问题，而RabbitMQ实现了<strong>AMQP</strong>。</p><h4 id="6、RabbitMQ-概念介绍"><a href="#6、RabbitMQ-概念介绍" class="headerlink" title="6、RabbitMQ 概念介绍"></a>6、RabbitMQ 概念介绍</h4><ul><li><strong>Broker</strong>：简单来说就是消息队列服务器实体。</li><li><strong>Exchange</strong>：消息交换机，它指定消息按什么规则，路由到哪个队列。</li><li><strong>Queue</strong>：消息队列载体，每个消息都会被投入到一个或多个队列。</li><li><strong>Binding</strong>：绑定，它的作用就是把exchange和queue按照路由规则绑定起来。</li><li><strong>Routing Key</strong>：路由关键字，exchange根据这个关键字进行消息投递。</li><li><strong>vhost</strong>：虚拟主机，一个broker里可以开设多个vhost，用作不同用户的权限分离。</li><li><strong>producer</strong>：消息生产者，就是投递消息的程序。</li><li><strong>consumer</strong>：消息消费者，就是接受消息的程序。</li><li><strong>channel</strong>：消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务。</li></ul><p>RabbitMQ从整体上来看是一个典型的生产者消费者模型，主要负责接收、存储和转发消息</p><p><img src="https://s1.ax1x.com/2020/04/26/JRegrq.png" alt="JRegrq.png"></p><h4 id="7、RabbitMQ-使用流程"><a href="#7、RabbitMQ-使用流程" class="headerlink" title="7、RabbitMQ 使用流程"></a>7、RabbitMQ 使用流程</h4><p>AMQP模型中，消息在producer中产生，发送到MQ的exchange上，exchange根据配置的路由方式发到相应的Queue上，Queue又将消息发送给consumer，消息从queue到consumer有push和pull两种方式。 消息队列的使用过程大概如下：</p><ol><li>客户端连接到消息队列服务器，打开一个channel。</li><li>客户端声明一个exchange，并设置相关属性。</li><li>客户端声明一个queue，并设置相关属性。</li><li>客户端使用routing key，在exchange和queue之间建立好绑定关系。</li><li>客户端投递消息到exchange。</li></ol><p>exchange接收到消息后，就根据消息的key和已经设置的binding，进行消息路由，将消息投递到一个或多个队列里。 exchange也有几个类型，完全根据key进行投递的叫做Direct交换机，例如，绑定时设置了routing key为”abc”，那么客户端提交的消息，只有设置了key为”abc”的才会投递到队列。</p><h3 id="3、RabbitMQ-单机安装部署"><a href="#3、RabbitMQ-单机安装部署" class="headerlink" title="3、RabbitMQ 单机安装部署"></a>3、RabbitMQ 单机安装部署</h3><h4 id="1、下载"><a href="#1、下载" class="headerlink" title="1、下载"></a>1、下载</h4><p>下载地址：<a href="http://www.rabbitmq.com/download.html" target="_blank" rel="noopener">http://www.rabbitmq.com/download.html</a></p><h4 id="2、Windows上安装"><a href="#2、Windows上安装" class="headerlink" title="2、Windows上安装"></a>2、Windows上安装</h4><h6 id="1、安装安装Erlang"><a href="#1、安装安装Erlang" class="headerlink" title="1、安装安装Erlang"></a>1、安装安装Erlang</h6><p>下载erlang：<a href="http://www.erlang.org/download/otp_win64_17.3.exe" target="_blank" rel="noopener">http://www.erlang.org/download/otp_win64_17.3.exe</a></p><p>安装：</p><p><img src="https://s1.ax1x.com/2020/04/26/JRe5iF.png" alt="JRe5iF.png"></p><p><img src="https://s1.ax1x.com/2020/04/26/JRmiLt.png" alt="JRmiLt.png"></p><p><img src="https://s1.ax1x.com/2020/04/26/JRmEo8.png" alt="JRmEo8.png"></p><p><img src="https://s1.ax1x.com/2020/04/26/JRmnzj.png" alt="JRmnzj.png"></p><p>erlang安装完成。</p><h6 id="2、安装安装RabbitMQ"><a href="#2、安装安装RabbitMQ" class="headerlink" title="2、安装安装RabbitMQ"></a>2、安装安装RabbitMQ</h6><p><img src="https://s1.ax1x.com/2020/04/26/JRm1e0.png" alt="JRm1e0.png"></p><p><img src="https://s1.ax1x.com/2020/04/26/JRm8oT.png" alt="JRm8oT.png"></p><p>RabbitMQ安装完成。</p><p><img src="https://s1.ax1x.com/2020/04/26/JRmUSJ.png" alt="JRmUSJ.png"></p><p>启动、停止、重新安装等。</p><h6 id="3、启用管理工具"><a href="#3、启用管理工具" class="headerlink" title="3、启用管理工具"></a>3、启用管理工具</h6><p>第一步：点击打开RabbitMQ的命令窗口。如图：</p><p><img src="https://s1.ax1x.com/2020/04/26/JRmwO1.png" alt="JRmwO1.png"></p><p>第二步：输入命令rabbitmq-plugins enable rabbitmq_management</p><p>这个命令的意思是安装RabbitMQ的插件。</p><p>第三步：测试是否安装成功。</p><p>方法：访问地址：<a href="http://127.0.0.1:15672/" target="_blank" rel="noopener">http://127.0.0.1:15672/</a></p><p><img src="https://s1.ax1x.com/2020/04/26/JRmDw6.png" alt="JRmDw6.png"></p><p>默认账号：guest/guest</p><h4 id="3、Linux上安装"><a href="#3、Linux上安装" class="headerlink" title="3、Linux上安装"></a>3、Linux上安装</h4><h6 id="1、安装-erlang"><a href="#1、安装-erlang" class="headerlink" title="1、安装 erlang"></a>1、安装 erlang</h6><p>添加yum支持</p><pre><code>cd /usr/local/src/mkdir rabbitmqcd rabbitmqwget http://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpmrpm -ivh erlang-solutions-1.0-1.noarch.rpmrpm --import http://packages.erlang-solutions.com/rpm/erlang_solutions.ascyum install erlang</code></pre><h6 id="2、安装RabbitMQ"><a href="#2、安装RabbitMQ" class="headerlink" title="2、安装RabbitMQ"></a>2、安装RabbitMQ</h6><p>1、用 yum 安装 RabbitMQ</p><pre class=" language-bash"><code class="language-bash">rpm --import https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc<span class="token comment" spellcheck="true"># this example assumes the CentOS 7 version of the package</span>yum <span class="token function">install</span> rabbitmq-server-3.7.13-1.el7.noarch.rpm</code></pre><pre class=" language-bash"><code class="language-bash">rpm --import https://www.rabbitmq.com/rabbitmq-release-signing-key.asc<span class="token comment" spellcheck="true"># this example assumes the CentOS 7 version of the package</span>yum <span class="token function">install</span> rabbitmq-server-3.7.13-1.el7.noarch.rpm</code></pre><p>2、用 rpm 手动安装</p><p>下载：</p><pre><code>wget  https://github.com/rabbitmq/rabbitmq-server/releases/download/v3.7.13/rabbitmq-server-3.7.13-1.el7.noarch.rpm</code></pre><p>上传rabbitmq-server-3.7.13-1.el7.noarch.rpm文件到/usr/local/src/rabbitmq/</p><p>安装：</p><pre><code>rpm -ivh rabbitmq-server-3.7.13-1.el7.noarch.rpm</code></pre><p>几个常用命令：</p><pre><code>service rabbitmq-server startservice rabbitmq-server stopservice rabbitmq-server restart chkconfig rabbitmq-server on　　//设置开机自启</code></pre><p>设置配置文件：</p><pre><code>cd /etc/rabbitmqcp /usr/share/doc/rabbitmq-server-3.7.13/rabbitmq.config.example /etc/rabbitmq/mv rabbitmq.config.example rabbitmq.config</code></pre><p>设置用户远程访问：</p><pre><code>vim /etc/rabbitmq/rabbitmq.config</code></pre><p><img src="https://s1.ax1x.com/2020/04/26/JRmyFO.png" alt="JRmyFO.png"></p><p>去掉后面的逗号</p><p>开启web界面管理工具</p><pre><code>rabbitmq-plugins enable rabbitmq_managementservice rabbitmq-server restart</code></pre><p>防火墙开放15672端口(CentOS7 不用操作)</p><pre><code>/sbin/iptables -I INPUT -p tcp --dport 15672 -j ACCEPT/etc/rc.d/init.d/iptables save</code></pre><h6 id="4、客户端的简单介绍"><a href="#4、客户端的简单介绍" class="headerlink" title="4、客户端的简单介绍"></a>4、客户端的简单介绍</h6><p>1、界面的介绍</p><p><img src="https://s1.ax1x.com/2020/04/26/JRmcfe.png" alt="JRmcfe.png"></p><p>注意设置虚拟主机与添加用户这块。</p><p><img src="https://s1.ax1x.com/2020/04/26/JRmfOI.png" alt="JRmfOI.png"></p><pre><code>命令行添加用户，设置tagsrabbitmqctl list_usersrabbitmqctl add_user username passwordrabbitmqctl set_user_tags username  administrator</code></pre><p>关于虚拟主机，Virtual Host，其实是一个虚拟概念，类似于权限控制组，一个Virtual Host里面可以有若干个Exchange和Queue，但是权限控制的最小粒度是Virtual Host</p><p>用户角色有下面几种：</p><ol><li>超级管理员(administrator)</li></ol><p>可登陆管理控制台，可查看所有的信息，并且可以对用户，策略(policy)进行操作。</p><ol><li>监控者(monitoring)</li></ol><p>可登陆管理控制台，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等)</p><ol><li>策略制定者(policymaker)</li></ol><p>可登陆管理控制台, 同时可以对policy进行管理。但无法查看节点的相关信息(上图红框标识的部分)。</p><ol><li>普通管理者(management)</li></ol><p>仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理。</p><ol><li>其他</li></ol><p>无法登陆管理控制台，通常就是普通的生产者和消费者。</p><h4 id="4、Mac-安装教程"><a href="#4、Mac-安装教程" class="headerlink" title="4、Mac 安装教程"></a>4、Mac 安装教程</h4><h6 id="1、安装"><a href="#1、安装" class="headerlink" title="1、安装"></a>1、安装</h6><p>在Mac下安装RabbitMQ是非常简单的，一般默认RabbitMQ服务器依赖的Erlang已经安装，只需要用下面两个命令就可以完成RabbitMQ的安装（前提是homebrew已经被安装）：</p><pre><code>brew updatebrew install rabbitmq</code></pre><p>耐心等待，安装完成后需要将/usr/local/sbin添加到$PATH，可以将下面这两行加到~/.bash_profile：</p><pre><code># RabbitMQ Configexport PATH=$PATH:/usr/local/sbin</code></pre><p>编辑完后:wq保存退出，使环境变量立即生效。</p><pre><code>source ~/.bash_profile</code></pre><h6 id="2、启动RabbitMQ服务"><a href="#2、启动RabbitMQ服务" class="headerlink" title="2、启动RabbitMQ服务"></a>2、启动RabbitMQ服务</h6><p>上面配置完成后，需要关闭终端窗口，重新打开，然后输入下面命令即可启动RabbitMQ服务：</p><pre><code>rabbitmq-server</code></pre><h6 id="3、登录Web管理界面"><a href="#3、登录Web管理界面" class="headerlink" title="3、登录Web管理界面"></a>3、登录Web管理界面</h6><p>浏览器输入<code>localhost：15672</code>,账号密码全输入guest即可登录。</p><h4 id="5、RabbitMQ常用的命令"><a href="#5、RabbitMQ常用的命令" class="headerlink" title="5、RabbitMQ常用的命令"></a>5、RabbitMQ常用的命令</h4><h5 id="1、基本命令"><a href="#1、基本命令" class="headerlink" title="1、基本命令"></a>1、基本命令</h5><p>启动监控管理器：rabbitmq-plugins enable rabbitmq_management<br>关闭监控管理器：rabbitmq-plugins disable rabbitmq_management<br>启动rabbitmq：rabbitmq-service start<br>关闭rabbitmq：rabbitmq-service stop<br>查看所有的队列：rabbitmqctl list_queues<br>清除所有的队列：rabbitmqctl reset<br>关闭应用：rabbitmqctl stop_app<br>启动应用：rabbitmqctl start_app</p><h5 id="2、用户和权限设置"><a href="#2、用户和权限设置" class="headerlink" title="2、用户和权限设置"></a>2、用户和权限设置</h5><p>添加用户：rabbitmqctl add_user username password<br>分配角色：rabbitmqctl set_user_tags username administrator<br>新增虚拟主机：rabbitmqctl add_vhost vhost_name<br>将新虚拟主机授权给新用户：<code>rabbitmqctl set_permissions -p vhost_name username “.*” “.*” “.*”</code>(后面三个”*”代表用户拥有配置、写、读全部权限)</p><h5 id="3、角色说明"><a href="#3、角色说明" class="headerlink" title="3、角色说明"></a>3、角色说明</h5><ul><li>超级管理员(administrator)<br>可登陆管理控制台，可查看所有的信息，并且可以对用户，策略(policy)进行操作。</li><li>监控者(monitoring)<br>可登陆管理控制台，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等)</li><li>策略制定者(policymaker)<br>可登陆管理控制台, 同时可以对policy进行管理。但无法查看节点的相关信息(上图红框标识的部分)。</li><li>普通管理者(management)<br>仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理。</li><li>其他<br>无法登陆管理控制台，通常就是普通的生产者和消费者。</li></ul><h3 id="4、RabbitMQ-集群部署及配置"><a href="#4、RabbitMQ-集群部署及配置" class="headerlink" title="4、RabbitMQ 集群部署及配置"></a>4、RabbitMQ 集群部署及配置</h3><p>消息中间件RabbitMQ，一般以集群方式部署，主要提供消息的接受和发送，实现各微服务之间的消息异步。以下将介绍RabbitMQ+HA方式进行部署。</p><h4 id="1、原理介绍"><a href="#1、原理介绍" class="headerlink" title="1、原理介绍"></a>1、原理介绍</h4><p>RabbitMQ是依据erlang的分布式特性（RabbitMQ底层是通过Erlang架构来实现的，所以rabbitmqctl会启动Erlang节点，并基于Erlang节点来使用Erlang系统连接RabbitMQ节点，在连接过程中需要正确的Erlang Cookie和节点名称，Erlang节点通过交换Erlang Cookie以获得认证）来实现的，所以部署Rabbitmq分布式集群时要先安装Erlang，并把其中一个服务的cookie复制到另外的节点。</p><p>RabbitMQ集群中，各个RabbitMQ为对等节点，即每个节点均提供给客户端连接，进行消息的接收和发送。节点分为内存节点和磁盘节点，一般的，均应建立为磁盘节点，为了防止机器重启后的消息消失；</p><p>RabbitMQ的Cluster集群模式一般分为两种，普通模式和镜像模式。消息队列通过RabbitMQ HA镜像队列进行消息队列实体复制。</p><p>普通模式下，以两个节点（rabbit01、rabbit02）为例来进行说明。对于Queue来说，消息实体只存在于其中一个节点rabbit01（或者rabbit02），rabbit01和rabbit02两个节点仅有相同的元数据，即队列的结构。当消息进入rabbit01节点的Queue后，consumer从rabbit02节点消费时，RabbitMQ会临时在rabbit01、rabbit02间进行消息传输，把A中的消息实体取出并经过B发送给consumer。所以consumer应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理Queue。否则无论consumer连rabbit01或rabbit02，出口总在rabbit01，会产生瓶颈。</p><p>镜像模式下，将需要消费的队列变为镜像队列，存在于多个节点，这样就可以实现RabbitMQ的HA高可用性。作用就是消息实体会主动在镜像节点之间实现同步，而不是像普通模式那样，在consumer消费数据时临时读取。缺点就是，集群内部的同步通讯会占用大量的网络带宽。</p><h4 id="2、部署-RabbitMQ-Cluster"><a href="#2、部署-RabbitMQ-Cluster" class="headerlink" title="2、部署 RabbitMQ Cluster"></a>2、部署 RabbitMQ Cluster</h4><p>多台机器部署RabbitMQ的cluster，</p><h5 id="1、环境要求"><a href="#1、环境要求" class="headerlink" title="1、环境要求"></a>1、环境要求</h5><p>1、所有节点需要再同一个局域网内；</p><p>2、所有节点需要有相同的 erlang cookie，否则不能正常通信，为了实现cookie内容一致，采用scp的方式进行。</p><p>3、准备三台虚拟机，配置相同</p><p>rabbitmq01 192.168.101.11   </p><p>rabbitmq02 192.168.101.12  </p><p>rabbitmq03 192.168.101.13</p><p>操作系统：centos7.5</p><h5 id="2、部署过程"><a href="#2、部署过程" class="headerlink" title="2、部署过程"></a>2、部署过程</h5><h6 id="1、所有节点配置-etc-hosts"><a href="#1、所有节点配置-etc-hosts" class="headerlink" title="1、所有节点配置/etc/hosts"></a>1、所有节点配置/etc/hosts</h6><p>node1 192.168.101.11   </p><p>node2 192.168.101.12  </p><p>node3 192.168.101.13</p><h6 id="2、所有节点安装-erLang-和-rabbitmq"><a href="#2、所有节点安装-erLang-和-rabbitmq" class="headerlink" title="2、所有节点安装 erLang 和 rabbitmq"></a>2、所有节点安装 erLang 和 rabbitmq</h6><p><strong>1、安装erlang</strong></p><p>安装依赖包</p><pre><code>yum install -y *epel* gcc-c++ unixODBC unixODBC-devel openssl-devel ncurses-devel</code></pre><p>编译安装</p><pre><code>wget http://erlang.org/download/otp_src_21.3.tar.gztar -zxvf otp_src_21.3.tar.gzcd otp_src_21.3./configure --prefix=/usr/local/bin/erlang --without-javacmake &amp;&amp; make installecho &quot;export PATH=$PATH:/usr/local/bin/erlang/bin:/usr/local/bin/rabbitmq_server-3.6.15/sbin&quot; &gt;&gt; /etc/profilesource /etc/profile</code></pre><p>出现 erl 命令则说明安装成功；</p><p><strong>2、安装rabbitmq</strong></p><p>编译安装</p><pre><code>wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.6.15/rabbitmq-server-generic-unix-3.6.15.tar.xzyum install -y xzxz -d rabbitmq-server-generic-unix-3.6.15.tar.xztar -xvf rabbitmq-server-generic-unix-3.6.15.tar -C /usr/local/bin/echo &quot;export PATH=$PATH:/usr/local/bin/erlang/bin:/usr/local/bin/rabbitmq_server-3.6.15/sbin&quot; &gt;&gt; /etc/profilesource /etc/profile</code></pre><p><strong>3、导入 rabbitmq 的管理界面</strong></p><pre><code>rabbitmq-plugins enable rabbitmq_management</code></pre><p><strong>4、设置 erlang</strong></p><p>找到erlang cookie文件的位置，官方在介绍集群的文档中提到过.erlang.cookie 一般会存在这两个地址：第一个是<code>home/.erlang.cookie</code>；第二个地方就是<code>/var/lib/rabbitmq/.erlang.cookie</code>。如果我们使用解压缩方式安装部署的rabbitmq，那么这个文件会在{home}目录下，也就是<code>$home/.erlang.cookie</code>。如果我们使用rpm等安装包方式进行安装的，那么这个文件会在<code>/var/lib/rabbitmq</code>目录下。</p><p>这里将 node1 的该文件复制到 node2、node3，注意这个文件的权限是 400（默认即是400），因此采用scp的方式只拷贝内容即可；</p><p>可以通过<code>cat  $home/.erlang.cookie</code>来查看三台机器的cookie是否一致，设置erlang的目的是要保证集群内的cookie内容一致。</p><p><strong>使用-detached参数运行各节点</strong></p><pre><code>rabbitmqctl stoprabbitmq-server -detached</code></pre><p>然后可以通过 <code>rabbitmqctl cluster_status</code>查看节点状态。</p><p>注意：要先拷贝cookie到另外两台机器上，保证三台机器上的cookie是一致的，然后再启动服务。</p><p>由于guest这个用户,只能在本地访问,所以我们要新增一个用户并赋予权限:</p><p>添加用户并设置密码:</p><pre><code>rabbitmqctl add_user  admin 123456</code></pre><p>添加权限（使admin用户对虚拟主机“/” 具有所有权限）:</p><pre><code>rabbitmqctl set_permissions -p &quot;/&quot; admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;</code></pre><p>修改用户角色（加入administrator用户组）</p><pre><code>rabbitmqctl set_user_tags admin administrator</code></pre><p>然后就可以远程访问了，然后可直接配置用户权限等信息。到此,就可以通过<a href="http://ip:15672" target="_blank" rel="noopener">http://ip:15672</a> 使用admin 123456 进行登陆了。</p><p>到这里的话，每个节点是作为单独的一台RabbitMQ存在的，也可以正常提供服务了</p><h5 id="3、组成集群"><a href="#3、组成集群" class="headerlink" title="3、组成集群"></a>3、组成集群</h5><p>rabbitmq-server 启动时，会一起启动节点和应用，它预先设置RabbitMQ应用为standalone模式。要将一个节点加入到现有的集群中，你需要停止这个应用，并将节点设置为原始状态。如果使用./rabbitmqctl stop，应用和节点都将被关闭。所以使用rabbitmqctl stop_app仅仅关闭应用。</p><p>1、将 node2、node3与 node1 组成集群，这里以node2为例</p><pre><code>node2# rabbitmqctl stop_app      node2# rabbitmqctl join_cluster rabbit@node1               ####这里集群的名字一定不要写错了node2# rabbitmqctl start_app</code></pre><p>2、将node3重复上述操作，也加入node1的集群。</p><pre><code>node3# rabbitmqctl stop_app      node3# rabbitmqctl join_cluster rabbit@node1               ####这里集群的名字一定不要写错了node3# rabbitmqctl start_app</code></pre><p>则此时 node2 与 node3 也会自动建立连接，集群配置完毕；</p><pre><code>#使用内存节点加入集群node2 # rabbitmqctl join_cluster --ram rabbit@node1</code></pre><p>3、在 RabbitMQ 集群任意节点上执行 <code>rabbitmqctl cluster_status</code>来查看是否集群配置成功。</p><pre><code>node3# rabbitmqctl cluster_statusCluster status of node rabbit@node3 ...[{nodes,[{disc,[rabbit@node1,rabbit@node2,rabbit@node3]}]}, {running_nodes,[rabbit@node1,rabbit@node2,rabbit@node3]}, {cluster_name,&lt;&quot;rabbit@node1&quot;&gt;},      #集群的名称默认为 rabbit@node1 {partitions,[]}, {alarms,[{rabbit@node1,[]},{rabbit@node2,[]},{rabbit@node3,[]}]}]</code></pre><p>4、也可通过在web页面上的“Queues”的列表中，查看有如下显示为“同步镜像到node2”，则也表示集群配置成功</p><p><img src="https://s1.ax1x.com/2020/04/26/JRmHfg.png" alt="JRmHfg.png"></p><p>5、设置镜像队列策略</p><p>在任意一个节点上执行如下操作（这里在node1上执行）</p><p>首先，在web界面，登陆后，点击“Admin–Virtual Hosts（页面右侧）”，在打开的页面上的下方的“Add a new virtual host”处增加一个虚拟主机，同时给用户“admin”和“guest”均加上权限（在页面直接设置、点点点即可）；</p><p>然后，在linux中执行如下命令</p><pre><code>rabbitmqctl set_policy -p coresystem  ha-all &quot;^&quot; &#39;{&quot;ha-mode&quot;:&quot;all&quot;}&#39;</code></pre><p>“coresystem” vhost名称， “^”匹配所有的队列， ha-all 策略名称为ha-all, ‘{“ha-mode”:”all”}’ 策略模式为 all 即复制到所有节点，包含新增节点。</p><p>则此时镜像队列设置成功。（这里的虚拟主机coresystem是代码中需要用到的虚拟主机，虚拟主机的作用是做一个消息的隔离，本质上可认为是一个rabbitmq-server，是否增加虚拟主机，增加几个，这是由开发中的业务决定，即有哪几类服务，哪些服务用哪一个虚拟主机，这是一个规划）。</p><p>6、镜像队列策略设置说明</p><pre><code>rabbitmqctl set_policy [-p Vhost] Name Pattern Definition [Priority]-p Vhost： 可选参数，针对指定vhost下的queue进行设置Name: policy的名称Pattern: queue的匹配模式(正则表达式)Definition：镜像定义，包括三个部分ha-mode, ha-params, ha-sync-mode    ha-mode:指明镜像队列的模式，有效值为 all/exactly/nodes        all：表示在集群中所有的节点上进行镜像        exactly：表示在指定个数的节点上进行镜像，节点的个数由ha-params指定        nodes：表示在指定的节点上进行镜像，节点名称通过ha-params指定    ha-params：ha-mode模式需要用到的参数    ha-sync-mode：进行队列中消息的同步方式，有效值为automatic和manualpriority：可选参数，policy的优先级</code></pre><p>将所有队列设置为镜像队列，即队列会被复制到各个节点，各个节点状态保持一直。完成这 6 个步骤后，RabbitMQ 高可用集群搭建完成，最后一个步骤就是搭建均衡器。</p><p>7、安装并配置负载均衡器HA</p><p>注意：如果使用阿里云，可以使用阿里云的内网slb来实现负载均衡，不用自己搭建HA。</p><p>1、在192.168.101.11安装HAProxy</p><pre><code>yum -y install HAProxy</code></pre><p>2、修改 /etc/haproxy/haproxy.cfg</p><pre><code>vim /etc/haproxy/haproxy.cfgglobal     log         127.0.0.1 local2    chroot      /var/lib/haproxy    pidfile     /var/run/haproxy.pid    maxconn     4000    user        haproxy    group       haproxy    daemon    stats socket /var/lib/haproxy/statsdefaults        log        global        mode       tcp        option     tcplog        option     dontlognull        retries    3        option redispatch        maxconn 2000        contimeout      5s        clitimeout      120s        srvtimeout      120s listen rabbitmq_cluster 192.168.101.11:5670       mode      tcp        balance roundrobin        server rabbit1  192.168.101.11:5672 check inter 5000 rise 2 fall 2        server rabbit2  192.168.101.12:5672 check inter 5000 rise 2 fall 2        </code></pre><p>3、重启HAProxy</p><pre><code>service haproxy restart</code></pre><p>登录浏览器输入地址<a href="http://192.168.101.11:8100/rabbitmqstats查看HAProxy的状态" target="_blank" rel="noopener">http://192.168.101.11:8100/rabbitmqstats查看HAProxy的状态</a></p><p>三、常见问题</p><p>常见错误：</p><p>1、使用 rabbitmq-server -detached命令启动rabbitmq时，出现以下提示Warning: PID file not written; -detached was passed，此时使用rabbitmqctl status提示服务已启动，可知此问题不用解决。</p><p>2、由于更改hostname文件，在每次rabbitmqctl stop或者rabbitmqctl cluster_status等，只要是rabbitmq的命令就报错，提示大概如下</p><pre><code>Cluster status of node rabbit@web2 ...Error: unable to connect to node rabbit@web2: nodedownDIAGNOSTICS===========attempted to contact: [rabbit@web2]rabbit@web2:  * connected to epmd (port 4369) on web2  * epmd reports node &#39;rabbit&#39; running on port 25672  * TCP connection succeeded but Erlang distribution failed  * Hostname mismatch: node &quot;rabbit@mq2&quot; believes its host is different. Please ensure that hostnames resolve the same way locally and on &quot;rabbit@mq2&quot;current node details:- node name: &#39;rabbitmq-cli-11@web2&#39;- home dir: /root- cookie hash: SGwxMdJ3PjEXG1asIEFpBg==</code></pre><p>此时先<code>ps aux | grep mq</code>，然后<code>kill -9</code> 该进程，然后再<code>rabbitmq-server -detached</code>即可解决。（即先强杀，再重新启动）</p><p>3、使用<code>rabbitmqctl stop</code>，<code>rabbitmq-server -detached</code>重新启动后，原先添加的用户admin、虚拟主机coresystem等均丢失，还需要重新添加。</p><p>采用脚本启动，在脚本中写好启动好需要加载的各配置项（创建admin用户并授权，创建虚拟主机并授权，配置镜像队列）。</p><p>4、命令</p><pre><code>rabbitmqctl stop_app         #仅关闭应用，不关闭节点rabbitmqctl start_app         #开启应用rabbitmq--server -detached     #启动节点和应用rabbitmqctl    stop             #关闭节点和应用</code></pre><p>4、常用命令：</p><p>Rabbitmq服务器的主要通过rabbitmqctl和rabbimq-plugins两个工具来管理，以下是一些常用功能。</p><p>1、 服务器启动与关闭</p><pre><code>  启动: rabbitmq-server –detached  关闭: rabbitmqctl stop  若单机有多个实例，则在rabbitmqctl后加 –n 指定名称</code></pre><p>2、插件管理</p><pre><code>  开启某个插件：rabbitmq-plugins enable  xxx  关闭某个插件：rabbitmq-plugins disable xxx  注意：重启服务器后生效。</code></pre><p>3、virtual_host管理</p><pre><code>  新建virtual_host:rabbitmqctl add_vhost  xxx  撤销virtual_host:rabbitmqctl  delete_vhost xxx </code></pre><p>4、用户管理</p><pre><code>  新建用户：rabbitmqctl add_user xxxpwd  删除用户: rabbitmqctl delete_user xxx  查看用户：rabbitmqctl list_users  改密码: rabbimqctl change_password {username} {newpassword}  设置用户角色：rabbitmqctlset_user_tags {username} {tag ...}          Tag可以为 administrator,monitoring, management       </code></pre><p>5、 权限管理</p><pre><code>  权限设置：set_permissions [-pvhostpath] {user} {conf} {write} {read}  Vhostpath: Vhost路径  user: 用户名  Conf: 一个正则表达式match哪些配置资源能够被该用户访问。  Write: 一个正则表达式match哪些配置资源能够被该用户读。  Read: 一个正则表达式match哪些配置资源能够被该用户访问。</code></pre><p>6、获取服务器状态信息</p><pre><code> 服务器状态：rabbitmqctl status     ##其中可查看rabbitmq的版本信息</code></pre><p>7、获取集群状态信息</p><pre><code>rabbitmqctl cluster_status</code></pre>]]></content>
      
      
      <categories>
          
          <category> SQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx编译安装</title>
      <link href="2019/03/27/linux/nginx-bian-yi-an-zhuang/"/>
      <url>2019/03/27/linux/nginx-bian-yi-an-zhuang/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h4 id="nginx-编译安装与配置使用"><a href="#nginx-编译安装与配置使用" class="headerlink" title="nginx 编译安装与配置使用"></a>nginx 编译安装与配置使用</h4><h5 id="1、安装编译环境"><a href="#1、安装编译环境" class="headerlink" title="1、安装编译环境"></a>1、安装编译环境</h5><p>yum -y install gcc gcc-c++</p><h5 id="2、安装pcre软件包（使nginx支持http-rewrite模块）"><a href="#2、安装pcre软件包（使nginx支持http-rewrite模块）" class="headerlink" title="2、安装pcre软件包（使nginx支持http rewrite模块）"></a>2、安装pcre软件包（使nginx支持http rewrite模块）</h5><p>yum install -y pcre pcre-devel</p><h5 id="3、安装openssl-devel（使nginx支持ssl）"><a href="#3、安装openssl-devel（使nginx支持ssl）" class="headerlink" title="3、安装openssl-devel（使nginx支持ssl）"></a>3、安装openssl-devel（使nginx支持ssl）</h5><p>yum install -y openssl openssl-devel </p><h5 id="4、安装zlib"><a href="#4、安装zlib" class="headerlink" title="4、安装zlib"></a>4、安装zlib</h5><p>yum install -y zlib zlib-devel</p><h5 id="5、创建用户nginx"><a href="#5、创建用户nginx" class="headerlink" title="5、创建用户nginx"></a>5、创建用户nginx</h5><p>useradd nginx </p><p>passwd nginx</p><h5 id="6、安装nginx"><a href="#6、安装nginx" class="headerlink" title="6、安装nginx"></a>6、安装nginx</h5><pre class=" language-shell"><code class="language-shell">[root@localhost ～]#wget http://192.168.233.100/nginx.org/download/nginx-1.14.2.tar.gz</code></pre><pre class=" language-shell"><code class="language-shell">[root@localhost ～]#tar -vzxf nginx-1.14.2.tar.gz -C /usr/local[root@localhost ～]#cd nginx-1.14.2/ [root@localhost nginx-1.14.2]# ./configure \ --group=nginx \ --user=nginx \ --prefix=/usr/local/nginx \ --sbin-path=/usr/sbin/nginx \ --conf-path=/etc/nginx/nginx.conf \ --error-log-path=/var/log/nginx/error.log \ --http-log-path=/var/log/nginx/access.log \ --http-client-body-temp-path=/tmp/nginx/client_body \ --http-proxy-temp-path=/tmp/nginx/proxy \ --http-fastcgi-temp-path=/tmp/nginx/fastcgi \ --pid-path=/var/run/nginx.pid \ --lock-path=/var/lock/nginx \ --with-http_stub_status_module \ --with-http_ssl_module \ --with-http_gzip_static_module \ --with-pcre [root@localhost nginx-1.11.3]# make &&make install</code></pre><h5 id="7、Nginx-编译参数"><a href="#7、Nginx-编译参数" class="headerlink" title="7、Nginx 编译参数"></a>7、Nginx 编译参数</h5><pre class=" language-shell"><code class="language-shell"># 查看 nginx 安装的模块[root@tianyun ~]# nginx -V# 模块参数具体功能 --with-cc-opt='-g -O2 -fPIE -fstack-protector    //设置额外的参数将被添加到CFLAGS变量。（FreeBSD或者ubuntu使用）--param=ssp-buffer-size=4 -Wformat -Werror=format-security -D_FORTIFY_SOURCE=2' --with-ld-opt='-Wl,-Bsymbolic-functions -fPIE -pie -Wl,-z,relro -Wl,-z,now' --prefix=/usr/share/nginx                        //指向安装目录--conf-path=/etc/nginx/nginx.conf                //指定配置文件--http-log-path=/var/log/nginx/access.log        //指定访问日志--error-log-path=/var/log/nginx/error.log        //指定错误日志--lock-path=/var/lock/nginx.lock                 //指定lock文件--pid-path=/run/nginx.pid                        //指定pid文件--http-client-body-temp-path=/var/lib/nginx/body    //设定http客户端请求临时文件路径--http-fastcgi-temp-path=/var/lib/nginx/fastcgi     //设定http fastcgi临时文件路径--http-proxy-temp-path=/var/lib/nginx/proxy         //设定http代理临时文件路径--http-scgi-temp-path=/var/lib/nginx/scgi           //设定http scgi临时文件路径--http-uwsgi-temp-path=/var/lib/nginx/uwsgi         //设定http uwsgi临时文件路径--with-debug                                        //启用debug日志--with-pcre-jit                                     //编译PCRE包含“just-in-time compilation”--with-ipv6                                         //启用ipv6支持--with-http_ssl_module                              //启用ssl支持--with-http_stub_status_module                      //获取nginx自上次启动以来的状态--with-http_realip_module                 //允许从请求标头更改客户端的IP地址值，默认为关--with-http_auth_request_module           //实现基于一个子请求的结果的客户端授权。如果该子请求返回的2xx响应代码，所述接入是允许的。如果它返回401或403中，访问被拒绝与相应的错误代码。由子请求返回的任何其他响应代码被认为是一个错误。--with-http_addition_module               //作为一个输出过滤器，支持不完全缓冲，分部分响应请求--with-http_dav_module                    //增加PUT,DELETE,MKCOL：创建集合,COPY和MOVE方法 默认关闭，需编译开启--with-http_geoip_module                  //使用预编译的MaxMind数据库解析客户端IP地址，得到变量值--with-http_gunzip_module                 //它为不支持“gzip”编码方法的客户端解压具有“Content-Encoding: gzip”头的响应。--with-http_gzip_static_module            //在线实时压缩输出数据流--with-http_image_filter_module           //传输JPEG/GIF/PNG 图片的一个过滤器）（默认为不启用。gd库要用到）--with-http_spdy_module                   //SPDY可以缩短网页的加载时间--with-http_sub_module                    //允许用一些其他文本替换nginx响应中的一些文本--with-http_xslt_module                   //过滤转换XML请求--with-mail                               //启用POP3/IMAP4/SMTP代理模块支持--with-mail_ssl_module                    //启用ngx_mail_ssl_module支持启用外部模块支持</code></pre><h5 id="8、修改配置文件-etc-nginx-nginx-conf"><a href="#8、修改配置文件-etc-nginx-nginx-conf" class="headerlink" title="8、修改配置文件/etc/nginx/nginx.conf"></a>8、修改配置文件/etc/nginx/nginx.conf</h5><pre class=" language-shell"><code class="language-shell"># 全局参数设置 worker_processes  1;          #设置nginx启动进程的数量，一般设置成与逻辑cpu数量相同 error_log  logs/error.log;    #指定错误日志 worker_rlimit_nofile 102400;  #设置一个nginx进程能打开的最大文件数 pid        /var/run/nginx.pid; events {     worker_connections  1024; #设置一个进程的最大并发连接数 } # http 服务相关设置 http {     include      mime.types;     default_type  application/octet-stream;     log_format  main  'remote_addr - remote_user [time_local] "request" '                      'status body_bytes_sent "$http_referer" '                      '"http_user_agent" "http_x_forwarded_for"';     access_log  /var/log/nginx/access.log  main;    #设置访问日志的位置和格式     sendfile          on; #是否调用sendfile函数输出文件，一般设置为on，若nginx是用来进行磁盘IO负载应用时，可以设置为off，降低系统负载     gzip              on;      #是否开启gzip压缩     keepalive_timeout  65;     #设置长连接的超时时间 # 虚拟服务器的相关设置     server {         listen      80;        #设置监听的端口         server_name  localhost;        #设置绑定的主机名、域名或ip地址         charset koi8-r;        # 设置编码字符         location / {             root  /var/www/nginx;           #设置服务器默认网站的根目录位置             index  index.html index.htm;    #设置默认打开的文档             }         error_page  500 502 503 504  /50x.html; #设置错误信息返回页面         location = /50x.html {             root  html;        #这里的绝对位置是/var/www/nginx/html         }     }  }</code></pre><h5 id="9、检测-nginx-配置文件是否正确"><a href="#9、检测-nginx-配置文件是否正确" class="headerlink" title="9、检测 nginx 配置文件是否正确"></a>9、检测 nginx 配置文件是否正确</h5><pre class=" language-shell"><code class="language-shell">[root@localhost ~]#/usr/local/nginx/sbin/nginx -t</code></pre><h5 id="10、启动nginx服务"><a href="#10、启动nginx服务" class="headerlink" title="10、启动nginx服务"></a>10、启动nginx服务</h5><pre class=" language-shell"><code class="language-shell">/usr/local/nginx/sbin/nginx</code></pre><h5 id="11、通过-nginx-命令控制-nginx-服务"><a href="#11、通过-nginx-命令控制-nginx-服务" class="headerlink" title="11、通过 nginx 命令控制 nginx 服务"></a>11、通过 nginx 命令控制 nginx 服务</h5><pre class=" language-shell"><code class="language-shell">nginx -c /path/to/nginx.conf       # 以特定目录下的配置文件启动nginx:nginx -s reload                      # 修改配置后重新加载生效nginx -s reopen                     # 重新打开日志文件nginx -s stop                        # 快速停止nginxnginx -s quit                         # 完整有序的停止nginxnginx -t                         # 测试当前配置文件是否正确nginx -t -c /path/to/nginx.conf  # 测试特定的nginx配置文件是否正确</code></pre><h5 id="12、实现nginx开机自启"><a href="#12、实现nginx开机自启" class="headerlink" title="12、实现nginx开机自启"></a>12、实现nginx开机自启</h5><p> a、添加启动脚本  vim /etc/init.d/nginx</p><pre class=" language-shell"><code class="language-shell">#!/bin/sh # # nginx - this script starts and stops the nginx daemon # # chkconfig:  - 85 15  # description:  Nginx is an HTTP(S) server, HTTP(S) reverse \ #              proxy and IMAP/POP3 proxy server # processname: nginx # config:      /etc/nginx/nginx.conf # config:      /etc/sysconfig/nginx # pidfile:    /var/run/nginx.pid # Source function library. . /etc/rc.d/init.d/functions# Source networking configuration. . /etc/sysconfig/network# Check that networking is up. [ "$NETWORKING" = "no" ] && exit 0 nginx="/usr/sbin/nginx"prog=$(basename $nginx) NGINX_CONF_FILE="/etc/nginx/nginx.conf"[ -f /etc/sysconfig/nginx ] && . /etc/sysconfig/nginxlockfile=/var/lock/subsys/nginxmake_dirs() {   # make required directories   user=`nginx -V 2>&1 | grep "configure arguments:" | sed 's/[^*]*--user=\([^ ]*\).*/\1/g' -`   options=`$nginx -V 2>&1 | grep 'configure arguments:'`   for opt in $options; do      if [ `echo $opt | grep '.*-temp-path'` ]; then          value=`echo $opt | cut -d "=" -f 2`           if [ ! -d "$value" ]; then              # echo "creating" $value               mkdir -p $value && chown -R $user $value           fi      fi  done} start() {     [ -x $nginx ] || exit 5     [ -f $NGINX_CONF_FILE ] || exit 6     make_dirs     echo -n $"Starting $prog: "    daemon $nginx -c $NGINX_CONF_FILE     retval=$?     echo    [ $retval -eq 0 ] && touch $lockfile     return $retval } stop() {     echo -n $"Stopping $prog: "    killproc $prog -QUIT     retval=$?     echo    [ $retval -eq 0 ] && rm -f $lockfile     return $retval } restart() {     configtest || return $?     stop     sleep 1     start } reload() {     configtest || return $?     echo -n $"Reloading $prog: "    killproc $nginx -HUP     RETVAL=$?     echo} force_reload() {     restart } configtest() {   $nginx -t -c $NGINX_CONF_FILE } rh_status() {     status $prog } rh_status_q() {     rh_status >/dev/null 2>&1 } case "$1" in    start)         rh_status_q && exit 0         $1         ;;     stop)         rh_status_q || exit 0         $1         ;;     restart|configtest)         $1         ;;     reload)         rh_status_q || exit 7         $1         ;;     force-reload)         force_reload         ;;     status)         rh_status         ;;     condrestart|try-restart)         rh_status_q || exit 0             ;;     *)         echo $"Usage: $0 {start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest}"        exit 2 esac</code></pre><p>b、添加权限</p><pre class=" language-shell"><code class="language-shell">chmod +x /etc/init.d/nginx</code></pre><p>c、重载系统启动文件</p><pre class=" language-shell"><code class="language-shell">systemctl daemon-reload</code></pre><p>d、设置开机自启</p><pre class=" language-shell"><code class="language-shell">systemctl start nginx</code></pre><p>10、nginx 日志文件详解</p><p>​    nginx 日志文件分为 <strong>log_format</strong> 和 <strong>access_log</strong> 两部分</p><p>​    log_format 定义记录的格式，其语法格式为</p><p>​    log_format        样式名称        样式详情</p><p>​    配置文件中默认有</p><pre><code>log_format  main  &#39;remote_addr - remote_user [time_local] &quot;request&quot; &#39;                  &#39;status body_bytes_sent &quot;$http_referer&quot; &#39;                  &#39;&quot;http_user_agent&quot; &quot;http_x_forwarded_for&quot;&#39;;</code></pre><table><thead><tr><th>点击这里</th><th>点击这里</th></tr></thead><tbody><tr><td>变量</td><td>说明</td></tr><tr><td>$remote_addr和$http_x_forwarded_for</td><td>客户端的ip</td></tr><tr><td>$remote_user</td><td>客户端的名称</td></tr><tr><td>$time_local</td><td>访问时的本地时间</td></tr><tr><td>$request</td><td>请求的URL和http协议</td></tr><tr><td>$status</td><td>访问的状态码</td></tr><tr><td>$body_bytes_sent</td><td>发送给客户端的主体内容大小</td></tr><tr><td>$http_referer</td><td>记录客户端是从哪个页面链接访问过来的，若没有链接，则访问‘-’</td></tr><tr><td>$http_user_agent</td><td>记录客户端使用的浏览器的相关信息</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>KVM笔记</title>
      <link href="2019/03/14/container/kvm-bi-ji/"/>
      <url>2019/03/14/container/kvm-bi-ji/</url>
      
        <content type="html"><![CDATA[<h2 id="私有云容器化架构运维"><a href="#私有云容器化架构运维" class="headerlink" title="私有云容器化架构运维"></a>私有云容器化架构运维</h2><h3 id="私有云-虚拟化技术"><a href="#私有云-虚拟化技术" class="headerlink" title="私有云:虚拟化技术"></a>私有云:虚拟化技术</h3><p><img src="http://i.loli.net/2019/06/04/5cf61b854224d74429.png" alt=""></p><h4 id="虚拟化技术概述"><a href="#虚拟化技术概述" class="headerlink" title="虚拟化技术概述"></a>虚拟化技术概述</h4><pre><code>虚拟化（Virtualization）技术最早出现在 20 世纪 60 年代的 IBM 大型机系统，在70年代的 System 370 系列中逐渐流行起来，这些机器通过一种叫虚拟机监控器（Virtual Machine Monitor，VMM）的程序在物理硬件之上生成许多可以运行独立操作系统软件的虚拟机（Virtual Machine）实例。随着近年多核系统、集群、网格甚至云计算的广泛部署，虚拟化技术在商业应用上的优势日益体现，不仅降低了 IT 成本，而且还增强了系统安全性和可靠性，虚拟化的概念也逐渐深入到人们日常的工作与生活中。虚拟化是一个广义的术语，对于不同的人来说可能意味着不同的东西，这要取决他们所处的环境。在计算机科学领域中，虚拟化代表着对计算资源的抽象，而不仅仅局限于虚拟机的概念。例如对物理内存的抽象，产生了虚拟内存技术，使得应用程序认为其自身拥有连续可用的地址空间（Address Space），而实际上，应用程序的代码和数据可能是被分隔成多个碎片页或段），甚至被交换到磁盘、闪存等外部存储器上，即使物理内存不足，应用程序也能顺利执行。</code></pre><h4 id="主流虚拟化方案介绍"><a href="#主流虚拟化方案介绍" class="headerlink" title="主流虚拟化方案介绍"></a>主流虚拟化方案介绍</h4><pre><code>虚拟化技术主要分为以下几个大类：平台虚拟化（Platform Virtualization），针对计算机和操作系统的虚拟化。资源虚拟化（Resource Virtualization），针对特定的系统资源的虚拟化，比如内存、存储、网络资源等。应用程序虚拟化（Application Virtualization），包括仿真、模拟、解释技术等。    我们通常所说的虚拟化主要是指平台虚拟化技术，通过使用控制程序（Control Program，也被称为 Virtual Machine Monitor 或Hypervisor），隐藏特定计算平台的实际物理特性，为用户提供抽象的、统一的、模拟的计算环境（称为虚拟机）。虚拟机中运行的操作系统被称为客户机操作系统（Guest OS），运行虚拟机监控器的操作系统被称为主机操作系统（Host OS），当然某些虚拟机监控器可以脱离操作系统直接运行在硬件之上（如 VMWARE 的 ESX 产品）。运行虚拟机的真实系统我们称之为主机系统。平台虚拟化技术又可以细分为如下几个子类：操作系统级虚拟化（Operating System Level Virtualization）     在传统操作系统中，所有用户的进程本质上是在同一个操作系统的实例中运行，因此内核或应用程序的缺陷可能影响到其它进程。操作系统级虚拟化是一种在服务器操作系统中使用的轻量级的虚拟化技术，内核通过创建多个虚拟的操作系统实例（内核和库）来隔离不同的进程，不同实例中的进程完全不了解对方的存在。比较著名的有 Solaris Container，FreeBSD Jail 和 OpenVZ 等。     比如OPENVZ：这个平台是最便宜的VPS平台，在各个vps商哪里都是价格最低的。OPENVZ本身运行在linux之上，它通过自己的虚拟化技术把一个服务器虚拟化成多个可以分别安装操作系统的实例，这样的每一个实体就是一个VPS，从客户的角度来看这就是一个虚拟的服务器，可以等同看做一台独立的服务器。OPENVZ虚拟化出来的VPS只能安装linux操作系统，不能安装windows系统，比如Centos、Fedora、Gentoo、Debian等。不能安装windows操作系统是openvz的第一个缺点，需要使用windows平台的用户不能使用OPENVZVPS。OPENVZ的第二个缺点是OPENVZ不是完全的虚拟化，每个VPS账户共用母机内核，不能单独修改内核。好在绝大多少用户根本不需要修改内核，所以这个缺点对多数人可以忽略不计。而这一点也正是openvz的优点，这一共用内核特性使得openvz的效率最高，超过KVM、Xen、VMware等平台。在不超售的情况下，openvz是最快速效率最高的VPS平台。部分虚拟化（Partial Virtualization）     VMM 只模拟部分底层硬件，因此客户机操作系统不做修改是无法在虚拟机中运行的，其它程序可能也需要进行修改。在历史上，部分虚拟化是通往全虚拟化道路上的重要里程碑,最早出现在第一代的分时系统 CTSS 和 IBM M44/44X 实验性的分页系统中。全虚拟化（Full Virtualization）     全虚拟化是指虚拟机模拟了完整的底层硬件，包括处理器、物理内存、时钟、外设等，使得为原始硬件设计的操作系统或其它系统软件完全不做任何修改就可以在虚拟机中运行。操作系统与真实硬件之间的交互可以看成是通过一个预先规定的硬件接口进行的。全虚拟化 VMM 以完整模拟硬件的方式提供全部接口（同时还必须模拟特权指令的执行过程）。举例而言，x86 体系结构中，对于操作系统切换进程页表的操作，真实硬件通过提供一个特权 CR3 寄存器来实现该接口，操作系统只需执行 &quot;mov pgtable,%%cr3&quot;汇编指令即可。全虚拟化 VMM 必须完整地模拟该接口执行的全过程。如果硬件不提供虚拟化的特殊支持，那么这个模拟过程将会十分复杂：一般而言，VMM 必须运行在最高优先级来完全控制主机系统，而 Guest OS 需要降级运行，从而不能执行特权操作。当 Guest OS 执行前面的特权汇编指令时，主机系统产生异常（General Protection Exception），执行控制权重新从 Guest OS 转到 VMM 手中。VMM 事先分配一个变量作为影子 CR3 寄存器给 Guest OS，将 pgtable 代表的客户机物理地址（Guest Physical Address）填入影子 CR3 寄存器，然后 VMM 还需要 pgtable 翻译成主机物理地址（Host Physical Address）并填入物理 CR3 寄存器，最后返回到 Guest OS中。随后 VMM 还将处理复杂的 Guest OS 缺页异常（Page Fault）。比较著名的全虚拟化 VMM 有 Microsoft Virtual PC、VMware Workstation、Sun Virtual Box、Parallels Desktop for Mac 和 QEMU。超虚拟化（Paravirtualization）     这是一种修改 Guest OS 部分访问特权状态的代码以便直接与 VMM 交互的技术。在超虚拟化虚拟机中，部分硬件接口以软件的形式提供给客户机操作系统，这可以通过 Hypercall（VMM 提供给 Guest OS 的直接调用，与系统调用类似）的方式来提供。例如，Guest OS 把切换页表的代码修改为调用 Hypercall 来直接完成修改影子 CR3 寄存器和翻译地址的工作。由于不需要产生额外的异常和模拟部分硬件执行流程，超虚拟化可以大幅度提高性能，比较著名的 VMM 有 Denali、Xen。硬件辅助虚拟化（Hardware-Assisted Virtualization）     硬件辅助虚拟化是指借助硬件（主要是主机处理器）的支持来实现高效的全虚拟化。例如有了 Intel-VT 技术的支持，Guest OS 和 VMM 的执行环境自动地完全隔离开来，Guest OS 有自己的&quot;&quot;套寄存器&quot;，可以直接运行在最高级别。因此在上面的例子中，Guest OS 能够执行修改页表的汇编指令。Intel-VT 和 AMD-V 是目前 x86 体系结构上可用的两种硬件辅助虚拟化技术。这种分类并不是绝对的，一个优秀的虚拟化软件往往融合了多项技术。例如 VMware Workstation 是一个著名的全虚拟化的 VMM，但是它使用了一种被称为动态二进制翻译的技术把对特权状态的访问转换成对影子状态的操作，从而避免了低效的 Trap-And-Emulate 的处理方式，这与超虚拟化相似，只不过超虚拟化是静态地修改程序代码。对于超虚拟化而言，如果能利用硬件特性，那么虚拟机的管理将会大大简化，同时还能保持较高的性能。</code></pre><h4 id="KVM虚拟化技术简介"><a href="#KVM虚拟化技术简介" class="headerlink" title="KVM虚拟化技术简介"></a>KVM虚拟化技术简介</h4><h5 id="kvm架构图"><a href="#kvm架构图" class="headerlink" title="kvm架构图"></a>kvm架构图</h5><p><img src="http://i.loli.net/2019/06/04/5cf61ba84b46f24553.jpeg" alt=""></p><pre><code>    从rhel6开始使用 直接把kvm的模块做成了内核的一部分    xen用在rhel6之前的企业版中 默认内核不支持，需要重新安装带xen功能的内核    KVM 针对运行在 x86 硬件上的、驻留在内核中的虚拟化基础结构。KVM 是第一个成为原生 Linux 内核（2.6.20）的一部分的 hypervisor，它是由 Avi Kivity 开发和维护的，现在归 Red Hat 所有。    这个 hypervisor 提供 x86 虚拟化，同时拥有到 PowerPC® 和 IA64 的通道。另外，KVM 最近还添加了对对称多处理（SMP）主机（和来宾）的支持，并且支持企业级特性，比如活动迁移（允许来宾操作系统在物理服务器之间迁移）。    KVM 是作为内核模块实现的，因此 Linux 只要加载该模块就会成为一个hypervisor。KVM 为支持 hypervisor  指令的硬件平台提供完整的虚拟化（比如 Intel® Virtualization Technology [Intel VT] 或 AMD  Virtualization [AMD-V] 产品）。KVM 还支持准虚拟化来宾操作系统，包括 Linux 和 Windows®。    这种技术由两个组件实现。第一个是可加载的 KVM 模块，当在 Linux 内核安装该模块之后，它就可以管理虚拟化硬件，并通过 /proc  文件系统公开其功能。第二个组件用于 PC 平台模拟，它是由修改版 QEMU 提供的。QEMU  作为用户空间进程执行，并且在来宾操作系统请求方面与内核协调。     当新的操作系统在 KVM 上启动时（通过一个称为 kvm 的实用程序），它就成为宿主操作系统的一个进程，因此就可以像其他进程一样调度它。但与传统的 Linux 进程不一样，来宾操作系统被 hypervisor 标识为处于 &quot;来宾&quot; 模式（独立于内核和用户模式）。    每个来宾操作系统都是通过 /dev/kvm 设备映射的，它们拥有自己的虚拟地址空间，该空间映射到主机内核的物理地址空间。如前所述，KVM 使用底层硬件的虚拟化支持来提供完整的（原生）虚拟化。I/O 请求通过主机内核映射到在主机上（hypervisor）执行的 QEMU 进程。    KVM 在 Linux 环境中以主机的方式运行，不过只要底层硬件虚拟化支持，它就能够支持大量的来宾操作系统.</code></pre><h4 id="KVM安装"><a href="#KVM安装" class="headerlink" title="KVM安装"></a>KVM安装</h4><pre><code>查看CPU是否支持VT技术:     #cat /proc/cpuinfo | grep -E &#39;vmx|svm&#39;        flags : fpu vme de pse tsc msr pae mce cx8 apicmtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2     ss ht tm pbe syscall nx lm constant_tsc arch_perfmon pebs bts rep_good aperfmperf pni dtes64 monitor ds_cpl vmx tm2 ssse3 cx16     xtpr pdcm dca sse4_1 lahf_lm dts tpr_shadow vnmi flexpriority需求内核(rhel6以上):       # uname  -r    2.6.32-358.el6.x86_64 升级系统：(在安装虚拟机出错的情况下)    # yum upgrade安装软件:    # yum install *qemu*  *virt*  librbd1-devel -y    qemu-kvm libvirt virt-manager    启动服务:        centos7:    # systemctl start libvirtd查看kvm模块加载:    # lsmod | grep kvm        kvm_intel              53484  3         kvm                   316506  1 kvm_intel</code></pre><h4 id="KVM-gustos部署安装"><a href="#KVM-gustos部署安装" class="headerlink" title="KVM gustos部署安装"></a>KVM gustos部署安装</h4><pre><code>图形模式安装guest os    #virt-manager====================完全文本方式安装:#virt-install --connect qemu:///system -n vm9 -r 2050 --disk path=/var/lib/libvirt/images/vm9.img,size=7  --os-type=linux --os-variant=centos7.0 --vcpus=1  --location=ftp://10.3.145.114/centos7u3 -x console=ttyS0 --nographicsqemu:///system  If running on a bare metal kernel as root (needed for KVM installs)-n name-r  以M为单位指定分配给虚拟机的内存大小--disk 指定作为客户机存储的媒介 size以G为单位的存储--os-type   针对一类操作系统优化虚拟机配置--os-variant 针对特定操作系统变体进一步优化虚拟机配置--vcpus--location  客户虚拟机kernel+initrd 安装源，必须为镜像挂载在ftp目录下-x 当执行从”–location”选项指定位置的客户机安装时，附加内核命令行参数到安装程序--nographics 指定没有控制台被分配给客户机。缺点：纯文本安装的输入时大小写莫名的变换，远程ssh没问题     内存必须大于2048排错:    安装过程中：        手动配置IP地址        到url位置找不到路径，要返回去手动选择url，重新配置url为ftp://192.168.100.230/rhel6u4,这里的ip不要写127.0.0.1而是br0的ip====================模板镜像+配置文件 方式创建虚拟机# virsh define /etc/libvirt/qemu/vm2.xml1.拷贝模板镜像和配置文件[root@kvm ~]# cp /var/lib/libvirt/images/vm2.img /var/lib/libvirt/images/vm3.img[root@kvm ~]# cp /etc/libvirt/qemu/vm2.xml /etc/libvirt/qemu/vm3.xml2.修改配置文件# vim /etc/libvirt/qemu/vm3.xml&lt;domain type=&#39;kvm&#39;&gt;  &lt;name&gt;vm3&lt;/name&gt;  &lt;uuid&gt;a2f62549-c6b7-4b8f-a8e2-c14edda35a78&lt;/uuid&gt;  &lt;memory unit=&#39;KiB&#39;&gt;2099200&lt;/memory&gt;  &lt;currentMemory unit=&#39;KiB&#39;&gt;2099200&lt;/currentMemory&gt;  &lt;vcpu placement=&#39;static&#39;&gt;2&lt;/vcpu&gt;  &lt;os&gt;    &lt;type arch=&#39;x86_64&#39; machine=&#39;pc-i440fx-rhel7.0.0&#39;&gt;hvm&lt;/type&gt;    &lt;boot dev=&#39;hd&#39;/&gt;  &lt;/os&gt;  &lt;features&gt;    &lt;acpi/&gt;    &lt;apic/&gt;  &lt;/features&gt;  &lt;cpu mode=&#39;custom&#39; match=&#39;exact&#39; check=&#39;partial&#39;&gt;    &lt;model fallback=&#39;allow&#39;&gt;Haswell-noTSX&lt;/model&gt;  &lt;/cpu&gt;  &lt;clock offset=&#39;utc&#39;&gt;    &lt;timer name=&#39;rtc&#39; tickpolicy=&#39;catchup&#39;/&gt;    &lt;timer name=&#39;pit&#39; tickpolicy=&#39;delay&#39;/&gt;    &lt;timer name=&#39;hpet&#39; present=&#39;no&#39;/&gt;  &lt;/clock&gt;  &lt;on_poweroff&gt;destroy&lt;/on_poweroff&gt;  &lt;on_reboot&gt;restart&lt;/on_reboot&gt;  &lt;on_crash&gt;destroy&lt;/on_crash&gt;  &lt;pm&gt;    &lt;suspend-to-mem enabled=&#39;no&#39;/&gt;    &lt;suspend-to-disk enabled=&#39;no&#39;/&gt;  &lt;/pm&gt;  &lt;devices&gt;    &lt;emulator&gt;/usr/libexec/qemu-kvm&lt;/emulator&gt;    &lt;disk type=&#39;file&#39; device=&#39;disk&#39;&gt;      &lt;driver name=&#39;qemu&#39; type=&#39;qcow2&#39;/&gt;      &lt;source file=&#39;/var/lib/libvirt/images/vm3.img&#39;/&gt;      &lt;target dev=&#39;vda&#39; bus=&#39;virtio&#39;/&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x06&#39; function=&#39;0x0&#39;/&gt;    &lt;/disk&gt;    &lt;controller type=&#39;usb&#39; index=&#39;0&#39; model=&#39;ich9-ehci1&#39;&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x04&#39; function=&#39;0x7&#39;/&gt;    &lt;/controller&gt;    &lt;controller type=&#39;usb&#39; index=&#39;0&#39; model=&#39;ich9-uhci1&#39;&gt;      &lt;master startport=&#39;0&#39;/&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x04&#39; function=&#39;0x0&#39; multifunction=&#39;on&#39;/&gt;    &lt;/controller&gt;    &lt;controller type=&#39;usb&#39; index=&#39;0&#39; model=&#39;ich9-uhci2&#39;&gt;      &lt;master startport=&#39;2&#39;/&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x04&#39; function=&#39;0x1&#39;/&gt;    &lt;/controller&gt;    &lt;controller type=&#39;usb&#39; index=&#39;0&#39; model=&#39;ich9-uhci3&#39;&gt;      &lt;master startport=&#39;4&#39;/&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x04&#39; function=&#39;0x2&#39;/&gt;    &lt;/controller&gt;    &lt;controller type=&#39;pci&#39; index=&#39;0&#39; model=&#39;pci-root&#39;/&gt;    &lt;controller type=&#39;virtio-serial&#39; index=&#39;0&#39;&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x05&#39; function=&#39;0x0&#39;/&gt;    &lt;/controller&gt;    &lt;interface type=&#39;network&#39;&gt;      &lt;mac address=&#39;52:54:00:f2:28:6f&#39;/&gt;      &lt;source network=&#39;default&#39;/&gt;      &lt;model type=&#39;virtio&#39;/&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x03&#39; function=&#39;0x0&#39;/&gt;    &lt;/interface&gt;    &lt;serial type=&#39;pty&#39;&gt;      &lt;target type=&#39;isa-serial&#39; port=&#39;0&#39;&gt;        &lt;model name=&#39;isa-serial&#39;/&gt;      &lt;/target&gt;    &lt;/serial&gt;    &lt;console type=&#39;pty&#39;&gt;      &lt;target type=&#39;serial&#39; port=&#39;0&#39;/&gt;    &lt;/console&gt;    &lt;channel type=&#39;unix&#39;&gt;      &lt;target type=&#39;virtio&#39; name=&#39;org.qemu.guest_agent.0&#39;/&gt;      &lt;address type=&#39;virtio-serial&#39; controller=&#39;0&#39; bus=&#39;0&#39; port=&#39;1&#39;/&gt;    &lt;/channel&gt;    &lt;input type=&#39;mouse&#39; bus=&#39;ps2&#39;/&gt;    &lt;input type=&#39;keyboard&#39; bus=&#39;ps2&#39;/&gt;    &lt;memballoon model=&#39;virtio&#39;&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x07&#39; function=&#39;0x0&#39;/&gt;    &lt;/memballoon&gt;  &lt;/devices&gt;&lt;/domain&gt;</code></pre><h4 id="KVM虚拟机管理"><a href="#KVM虚拟机管理" class="headerlink" title="KVM虚拟机管理"></a>KVM虚拟机管理</h4><pre><code>==================虚拟机的组成部分1.虚拟机配置文件[root@localhost qemu]# ls /etc/libvirt/qemunetworks  vm1.xml2.储存虚拟机的介质[root@localhost qemu]# ls /var/lib/libvirt/images/vm1.img==================虚拟机的基本管理命令：查看启动关闭重启重置 查看:查看虚拟机:    # virsh list      Id    Name                           State    ----------------------------------------------------     2     vm1                            running    # virsh list --all     Id    Name                           State    ----------------------------------------------------     2     vm1                            running查看kvm虚拟机配置文件：#virsh dumpxml name将node4虚拟机的配置文件保存至node6.xml#virsh dumpxml node4 &gt; /etc/libvirt/qemu/node6.xml修改node6的配置文件：#virsh edit node6      如果直接用vim编辑器修改配置文件的话，需要重启libvirtd服务启动:[root@localhost ~]# virsh start vm1Domain vm1 started暂停虚拟机：   #virsh suspend vm_name  恢复虚拟机：  #virsh resume vm_name    关闭：    方法1：    # virsh shutdown vm1    Domain vm1 is being shutdown    方法2：    # virsh destroy vm1    Domain vm1 destroyed重启：    [root@localhost ~]# virsh reboot vm1    Domain vm1 is being reboote重置:    [root@localhost ~]# virsh reset vm1    Domain vm1 was reset删除虚拟机:# virsh undefine vm2Domain vm2 has been undefined注意:虚拟机在开启的情况下undefine是无法删除的，但是如果再destroy会直接被删除掉======================虚拟机开机自动启动:    # virsh autostart vm1        域 vm1标记为自动开始    # ls /etc/libvirt/qemu/autostart/     //此目录默认不存在，在有开机启动的虚拟机时自动创建        vm1.xml    # virsh autostart --disable vm1        域 vm1取消标记为自动开始    # ls /etc/libvirt/qemu/autostart/</code></pre><h4 id="虚拟机添加设备"><a href="#虚拟机添加设备" class="headerlink" title="虚拟机添加设备"></a>虚拟机添加设备</h4><pre><code>给虚拟机添加新硬件：图形方式:    首先，关闭要添加硬件的虚拟机    双击虚拟机，在打开的对话框点击上方的View，点击Details，点击Add Hardware可以选择要添加的虚拟硬件修改配置文件方式:&lt;domain type=&#39;kvm&#39;&gt;  &lt;name&gt;vm2&lt;/name&gt;  &lt;uuid&gt;d0bc50b6-6acc-432b-9953-bc47b2b4aa87&lt;/uuid&gt;  &lt;memory unit=&#39;KiB&#39;&gt;1024000&lt;/memory&gt;  &lt;currentMemory unit=&#39;KiB&#39;&gt;1024000&lt;/currentMemory&gt;  &lt;vcpu placement=&#39;static&#39;&gt;2&lt;/vcpu&gt;  &lt;os&gt;    &lt;type arch=&#39;x86_64&#39; machine=&#39;pc-i440fx-rhel7.0.0&#39;&gt;hvm&lt;/type&gt;    &lt;boot dev=&#39;hd&#39;/&gt;  &lt;/os&gt;  &lt;features&gt;    &lt;acpi/&gt;    &lt;apic/&gt;  &lt;/features&gt;  &lt;cpu mode=&#39;custom&#39; match=&#39;exact&#39; check=&#39;partial&#39;&gt;    &lt;model fallback=&#39;allow&#39;&gt;Haswell-noTSX&lt;/model&gt;  &lt;/cpu&gt;  &lt;clock offset=&#39;utc&#39;&gt;    &lt;timer name=&#39;rtc&#39; tickpolicy=&#39;catchup&#39;/&gt;    &lt;timer name=&#39;pit&#39; tickpolicy=&#39;delay&#39;/&gt;    &lt;timer name=&#39;hpet&#39; present=&#39;no&#39;/&gt;  &lt;/clock&gt;  &lt;on_poweroff&gt;destroy&lt;/on_poweroff&gt;  &lt;on_reboot&gt;restart&lt;/on_reboot&gt;  &lt;on_crash&gt;destroy&lt;/on_crash&gt;  &lt;pm&gt;    &lt;suspend-to-mem enabled=&#39;no&#39;/&gt;    &lt;suspend-to-disk enabled=&#39;no&#39;/&gt;  &lt;/pm&gt;  &lt;devices&gt;    &lt;emulator&gt;/usr/libexec/qemu-kvm&lt;/emulator&gt;    &lt;disk type=&#39;file&#39; device=&#39;disk&#39;&gt;      &lt;driver name=&#39;qemu&#39; type=&#39;qcow2&#39;/&gt;      &lt;source file=&#39;/var/lib/libvirt/images/vm2.qcow2&#39;/&gt;      &lt;target dev=&#39;vda&#39; bus=&#39;virtio&#39;/&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x07&#39; function=&#39;0x0&#39;/&gt;    &lt;/disk&gt;    &lt;disk type=&#39;file&#39; device=&#39;disk&#39;&gt;      &lt;driver name=&#39;qemu&#39; type=&#39;qcow2&#39;/&gt;      &lt;source file=&#39;/var/lib/libvirt/images/vm2-1.qcow2&#39;/&gt;      &lt;target dev=&#39;vda&#39; bus=&#39;virtio&#39;/&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x17&#39; function=&#39;0x0&#39;/&gt;    &lt;/disk&gt;        &lt;disk type=&#39;file&#39; device=&#39;cdrom&#39;&gt;      &lt;driver name=&#39;qemu&#39; type=&#39;raw&#39;/&gt;      &lt;target dev=&#39;hda&#39; bus=&#39;ide&#39;/&gt;      &lt;readonly/&gt;      &lt;address type=&#39;drive&#39; controller=&#39;0&#39; bus=&#39;0&#39; target=&#39;0&#39; unit=&#39;0&#39;/&gt;    &lt;/disk&gt;    &lt;controller type=&#39;usb&#39; index=&#39;0&#39; model=&#39;ich9-ehci1&#39;&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x05&#39; function=&#39;0x7&#39;/&gt;    &lt;/controller&gt;    &lt;controller type=&#39;usb&#39; index=&#39;0&#39; model=&#39;ich9-uhci1&#39;&gt;      &lt;master startport=&#39;0&#39;/&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x05&#39; function=&#39;0x0&#39; multifunction=&#39;on&#39;/&gt;    &lt;/controller&gt;    &lt;controller type=&#39;usb&#39; index=&#39;0&#39; model=&#39;ich9-uhci2&#39;&gt;      &lt;master startport=&#39;2&#39;/&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x05&#39; function=&#39;0x1&#39;/&gt;    &lt;/controller&gt;    &lt;controller type=&#39;usb&#39; index=&#39;0&#39; model=&#39;ich9-uhci3&#39;&gt;      &lt;master startport=&#39;4&#39;/&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x05&#39; function=&#39;0x2&#39;/&gt;    &lt;/controller&gt;    &lt;controller type=&#39;pci&#39; index=&#39;0&#39; model=&#39;pci-root&#39;/&gt;    &lt;controller type=&#39;ide&#39; index=&#39;0&#39;&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x01&#39; function=&#39;0x1&#39;/&gt;    &lt;/controller&gt;    &lt;controller type=&#39;virtio-serial&#39; index=&#39;0&#39;&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x06&#39; function=&#39;0x0&#39;/&gt;    &lt;/controller&gt;    &lt;interface type=&#39;network&#39;&gt;      &lt;mac address=&#39;52:54:00:04:63:6a&#39;/&gt;      &lt;source network=&#39;default&#39;/&gt;      &lt;model type=&#39;virtio&#39;/&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x03&#39; function=&#39;0x0&#39;/&gt;    &lt;/interface&gt;    &lt;interface type=&#39;network&#39;&gt;      &lt;mac address=&#39;52:54:00:04:63:6&#39;/&gt;      &lt;source network=&#39;default&#39;/&gt;      &lt;model type=&#39;virtio&#39;/&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x13&#39; function=&#39;0x0&#39;/&gt;    &lt;/interface&gt;    &lt;serial type=&#39;pty&#39;&gt;      &lt;target type=&#39;isa-serial&#39; port=&#39;0&#39;&gt;        &lt;model name=&#39;isa-serial&#39;/&gt;      &lt;/target&gt;    &lt;/serial&gt;    &lt;console type=&#39;pty&#39;&gt;      &lt;target type=&#39;serial&#39; port=&#39;0&#39;/&gt;    &lt;/console&gt;    &lt;channel type=&#39;unix&#39;&gt;      &lt;target type=&#39;virtio&#39; name=&#39;org.qemu.guest_agent.0&#39;/&gt;      &lt;address type=&#39;virtio-serial&#39; controller=&#39;0&#39; bus=&#39;0&#39; port=&#39;1&#39;/&gt;    &lt;/channel&gt;    &lt;channel type=&#39;spicevmc&#39;&gt;      &lt;target type=&#39;virtio&#39; name=&#39;com.redhat.spice.0&#39;/&gt;      &lt;address type=&#39;virtio-serial&#39; controller=&#39;0&#39; bus=&#39;0&#39; port=&#39;2&#39;/&gt;    &lt;/channel&gt;    &lt;input type=&#39;tablet&#39; bus=&#39;usb&#39;&gt;      &lt;address type=&#39;usb&#39; bus=&#39;0&#39; port=&#39;1&#39;/&gt;    &lt;/input&gt;    &lt;input type=&#39;mouse&#39; bus=&#39;ps2&#39;/&gt;    &lt;input type=&#39;keyboard&#39; bus=&#39;ps2&#39;/&gt;    &lt;graphics type=&#39;spice&#39; autoport=&#39;yes&#39;&gt;      &lt;listen type=&#39;address&#39;/&gt;      &lt;image compression=&#39;off&#39;/&gt;    &lt;/graphics&gt;    &lt;sound model=&#39;ich6&#39;&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x04&#39; function=&#39;0x0&#39;/&gt;    &lt;/sound&gt;    &lt;video&gt;      &lt;model type=&#39;qxl&#39; ram=&#39;65536&#39; vram=&#39;65536&#39; vgamem=&#39;16384&#39; heads=&#39;1&#39; primary=&#39;yes&#39;/&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x02&#39; function=&#39;0x0&#39;/&gt;    &lt;/video&gt;    &lt;redirdev bus=&#39;usb&#39; type=&#39;spicevmc&#39;&gt;      &lt;address type=&#39;usb&#39; bus=&#39;0&#39; port=&#39;2&#39;/&gt;    &lt;/redirdev&gt;    &lt;redirdev bus=&#39;usb&#39; type=&#39;spicevmc&#39;&gt;      &lt;address type=&#39;usb&#39; bus=&#39;0&#39; port=&#39;3&#39;/&gt;    &lt;/redirdev&gt;    &lt;memballoon model=&#39;virtio&#39;&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x08&#39; function=&#39;0x0&#39;/&gt;    &lt;/memballoon&gt;  &lt;/devices&gt;&lt;/domain&gt;</code></pre><pre><code>修改配置文件方式:[root@kvm images]# cd /etc/libvirt/qemu/[root@kvm qemu]# cp vm1.xml vm10.xml[root@kvm qemu]# vim vm10.xml必须要修改的部分：guest os的名称：  &lt;name&gt;vm1&lt;/name&gt;uuid:  &lt;uuid&gt;78e98d16-a0d0-4002-9dc4-b8ca7d538457&lt;/uuid&gt;磁盘：     &lt;disk type=&#39;file&#39; device=&#39;disk&#39;&gt;       &lt;driver name=&#39;qemu&#39; type=&#39;qcow2&#39;/&gt;        &lt;source file=&#39;/var/lib/libvirt/images/vm1.qcow2&#39;/&gt;        &lt;target dev=&#39;vda&#39; bus=&#39;virtio&#39;/&gt;        &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x07&#39; function=&#39;0x0&#39;/&gt;     &lt;/disk&gt;网卡：         &lt;interface type=&#39;network&#39;&gt;      &lt;mac address=&#39;52:54:00:fc:c6:0b&#39;/&gt;      &lt;source network=&#39;default&#39;/&gt;      &lt;model type=&#39;virtio&#39;/&gt;      &lt;address type=&#39;pci&#39; domain=&#39;0x0000&#39; bus=&#39;0x00&#39; slot=&#39;0x03&#39; function=&#39;0x0&#39;/&gt;    &lt;/interface&gt;可选部分：内存：&lt;memory unit=&#39;KiB&#39;&gt;2048000&lt;/memory&gt;  &lt;currentMemory unit=&#39;KiB&#39;&gt;2048000&lt;/currentMemory&gt;cpu个数:  &lt;vcpu placement=&#39;static&#39;&gt;2&lt;/vcpu&gt;</code></pre><pre><code>1.使用配置文件方式生成一个新虚机2.修改配置文件给新生成的虚机添加一块硬盘，添加一块网卡3.使修改的配置文件生效    方法1：重启libvirtd    方法2：# virsh define 配置文件创建空的磁盘文件：#qemu-img create -f qcow2 /var/lib/libvirt/images/vm11.qcow2 5G</code></pre><h4 id="虚拟机克隆"><a href="#虚拟机克隆" class="headerlink" title="虚拟机克隆"></a>虚拟机克隆</h4><pre><code>虚拟机克隆1.图形界面：Applications （左上角）-----&gt; System Tools ------&gt;Virtual Machine Manager   关闭要克隆的虚拟机，右键点击虚拟机选择Clone2.字符终端，命令克隆    # virt-clone -o vm1 --auto-clone        WARNING  设置图形设备端口为自动端口，以避免相互冲突。        正在分配 &#39;vm1-clone.qcow2&#39;            | 6.0 GB  00:00:05             成功克隆 &#39;vm1-clone&#39;。    -o       origin        # virt-clone -o vm1 -n vm2 --auto-clone        WARNING  设置图形设备端口为自动端口，以避免相互冲突。        正在分配 &#39;vm2.qcow2&#39;                                                | 6.0 GB  00:00:06             成功克隆 &#39;vm2&#39;。    # virt-clone -o vm1 -n vm2 -f /var/lib/libvirt/images/vm2.img        正在克隆                vm1.img              | 8.0 GB     01:03             Clone &#39;vm2&#39; created successfully.</code></pre><h4 id="高级命令"><a href="#高级命令" class="headerlink" title="高级命令"></a>高级命令</h4><pre><code>建立虚拟机磁盘镜像文件：磁盘镜像文件格式:    raw     原始格式，性能最好 直接占用你一开始给多少 系统就占多少 不支持快照    qcow  先去网上了解一下cow(写时拷贝copy on write) ，性能远不能和raw相比，所以很快夭折了，所以出现了qcow2（性能低下 早就被抛弃）    qcow2 性能上还是不如raw，但是raw不支持快照，qcow2支持快照。现在默认安装好的用的是raw格式，所有做快照要把他转换成qcow2格式什么叫写时拷贝？raw立刻分配空间，不管你有没有用到那么多空间qcow2只是承诺给你分配空间，但是只有当你需要用空间的时候，才会给你空间。最多只给你承诺空间的大小，避免空间浪费工作当中用哪个？看你用不用快照。工作当中虚拟机会有多个备份，一个坏了，再起一个就行了，所有没必要用快照。当然也不一定。数据绝对不会存储到本地。qemu-kvm  qemu是早先的一个模拟器，kvm是基于qemu发展出来的。建立qcow2格式磁盘文件:#qemu-img create -f qcow2 test.qcow2 20G 建立raw格式磁盘文件:#qemu-img create -f raw test.raw 20G  查看已经创建的虚拟磁盘文件:#qemu-img info test.qcow2 ==============================作为虚拟化环境管理员，你肯定遇到过虚拟机无法启动的情况。实施排错时，你需要对虚拟机的内部进行检查。而Libguestfs Linux工具集可以在这种情况下为你提供帮助。利用Libguestfs找出损坏的虚拟机文件Libguestfs允许在虚拟机上挂载任何类型的文件系统，以便修复启动故障。使用Libguestfs，首先需要使用Libvirt。Libvirt是一个管理接口，可以和KVM、Xen和其他一些基于Liunx的虚拟机相互连接。Libguestfs的功能更加强大，可以打开Windows虚拟机上的文件。但是首先你需要将虚拟机迁移到libguestfs可用的环境当中，也就是Linux环境。假如你是vmware的ESXI虚拟机，为了将虚拟机迁移到Linux当中，你可以使用SSH连接到ESXi主机，这意味着你首先需要启用ESXi主机上的SSH访问方式。完成之后，在Linux平台上运行下面的scp命令：1. scp –r 192.168.178.30:/vmfs/volumes/datastore1/Windows* 使用guestfish操作虚拟机磁盘镜像文件：完成虚拟机磁盘镜像文件的复制之后，可以在libguestfs中使用guestfish这样的工具将其打开，这样就可以直接在vmdk文件上进行操作了。使用命令来在虚拟机中创建一个连接到文件系统的交互式shell。在新出现的窗口中，你可以使用特定的命令来操作虚拟机文件。#guestfish --rw -a  /path/to/windows.vmdk第一个任务就是找到可用的文件系统：1. &gt;&lt;fs&gt; run                   //进入交互式shell之后第一个命令2. &gt;&lt;fs&gt; list-filesystems  //列出磁盘镜像文件内的文件系统/dev/vda1: ext4/dev/vdb1: iso9660/dev/VolGroup/lv_root: ext4/dev/VolGroup/lv_swap: swap3.&gt;&lt;fs&gt;  mount /dev/VolGroup/lv_root    /     //当你使用guestfish shell找到可用文件系统类型之后，就可以进行挂载了。将文件系统到guestfish根目录下4.&gt;&lt;fs&gt;  ls /                                               //ls命令查看文件/下内容 ，不能使用cd命令bin  boot dev etc home  lib lib64  lost+found5.&gt;&lt;fs&gt; cat /etc/passwd      //查看文件，不能像在其他shell环境中一样操作。目录所有路径必须从根开始root:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologin在guestfish  shell当中可以使用像ls、cat、more、download这样的命令，来查看和下载文件以及目录guestfish  读镜像mount  /dev/sda1  /cd /查看帮助：这两个帮助显示的内容不一样# guestfish --help # guestfish -hVirt-rescue提供直接访问方式：这种方式跟linux系统光盘的rescue模式几乎一样，进去之后首先需要查看文件系统，然后手动挂载到/sysroot目录下，进入/sysroot目录就可以随意操作虚拟磁盘镜像内的文件了# virt-rescue vm1         //进入修复模式，help查看帮助&gt;&lt;rescue&gt;fdisk -l&gt;&lt;rescue&gt;mount /dev/mapper/VolGroup-lv_root /sysroot/ &gt;&lt;rescue&gt;cd /sysroot/&gt;&lt;rescue&gt;touch aaaaaaaaaaaaa============================查看磁盘镜像分区信息:    # virt-df -h -d vm1    Filesystem                                Size       Used  Available  Use%    vm1:/dev/sda1                             484M        32M       428M    7%    vm1:/dev/sdb1                             3.5G       3.5G          0  100%    vm1:/dev/VolGroup/lv_root                 6.1G       1.1G       4.7G   18%    # virt-filesystems -d vm1    /dev/sda1    /dev/sdb1    /dev/VolGroup/lv_root挂载磁盘镜像分区:    # guestmount -d vm1 -m /dev/vda1 --rw /mnt</code></pre><h4 id="虚拟机使用半虚拟化驱动"><a href="#虚拟机使用半虚拟化驱动" class="headerlink" title="虚拟机使用半虚拟化驱动"></a>虚拟机使用半虚拟化驱动</h4><pre><code>KVM是必须使用硬件虚拟化辅助技术（如Intel VT-x、AMD-V）的hypervisor，在CPU运行效率方面有硬件支持，其效率是比较高的；在有Intel EPT特性支持的平台上，内存虚拟化的效率也较高。QEMU/KVM提供了全虚拟化环境，可以让客户机不经过任何修改就能运行在KVM环境中。不过，KVM在I/O虚拟化方面，传统的方式是使用QEMU纯软件的方式来模拟I/O设备（如第4章中提到模拟的网卡、磁盘、显卡等等），其效率并不非常高。在KVM中，可以在客户机中使用半虚拟化驱动（Paravirtualized Drivers，PV Drivers）来提高客户机的性能（特别是I/O性能）。目前，KVM中实现半虚拟化驱动的方式是采用了virtio这个Linux上的设备驱动标准框架。</code></pre><h4 id="KVM网络配置"><a href="#KVM网络配置" class="headerlink" title="KVM网络配置"></a>KVM网络配置</h4><p>桥接网络</p><p><img src="http://i.loli.net/2019/06/09/5cfd15ce11ad477500.jpg" alt=""></p><p>nat网络</p><p><img src="http://i.loli.net/2019/06/09/5cfd1582763a891926.jpg" alt=""></p><p>隔离网络</p><pre><code>可以通过查看mac地址是否一致来确定是不是一根线上的两个接口# brctl showbridge name    bridge id                        STP enabled     interfacesvirbr0                8000.5254003c2ba7    yes                 virbr0-nic                                                                                 vnet2                                                                                 vnet3从交换机上把vnet网卡删除：# brctl delif  virbr0 vnet0添加vnet网卡到交换机上：# brctl addif  virbr0 vnet0配置文件方式配置桥接：在宿主机上    1.修改配置文件    # cat ifcfg-br0     TYPE=Bridge    NAME=br0    DEVICE=br0    ONBOOT=&quot;yes&quot;    BOOTPROTO=static    IPADDR=10.18.44.251    GATEWAY=10.18.44.1    NETMASK=255.255.255.0    DNS1=10.18.44.100    DNS2=8.8.8.8    # cat ifcfg-enp3s0    TYPE=&quot;Ethernet&quot;    NAME=&quot;enp3s0&quot;    DEVICE=&quot;enp3s0&quot;    ONBOOT=&quot;yes&quot;    BRIDGE=br0    2.重启libvirtd服务    3.重启network服务     删除桥接网卡步骤：    1.删除br0的配置文件    2.修改正常网卡的配置文件    3.重启系统    配置文件方式创建nat网络：# cp /etc/libvirt/qemu/networks/nat2.xml /etc/libvirt/qemu/networks/nat3.xml# vim /etc/libvirt/qemu/networks/nat3.xml&lt;network&gt;  &lt;name&gt;nat3&lt;/name&gt;  &lt;uuid&gt;4d8b9b5c-748f-4e16-a509-848202b9c83b&lt;/uuid&gt;  &lt;forward mode=&#39;nat&#39;/&gt;             //和隔离模式的区别  &lt;bridge name=&#39;virbr4&#39; stp=&#39;on&#39; delay=&#39;0&#39;/&gt;  &lt;mac address=&#39;52:57:00:62:0c:d4&#39;/&gt;  &lt;domain name=&#39;nat3&#39;/&gt;  &lt;ip address=&#39;192.168.104.1&#39; netmask=&#39;255.255.255.0&#39;&gt;    &lt;dhcp&gt;      &lt;range start=&#39;192.168.104.128&#39; end=&#39;192.168.104.254&#39;/&gt;    &lt;/dhcp&gt;  &lt;/ip&gt;&lt;/network&gt;重启服务：# systemctl  restart libvirtd配置文件方式创建isolated网络：           &lt;network&gt;  &lt;name&gt;isolate1&lt;/name&gt;  &lt;uuid&gt;6341d3a6-7330-4e45-a8fe-164a6a68929a&lt;/uuid&gt;  &lt;bridge name=&#39;virbr2&#39; stp=&#39;on&#39; delay=&#39;0&#39;/&gt;  &lt;mac address=&#39;52:54:00:6b:39:0c&#39;/&gt;  &lt;domain name=&#39;isolate1&#39;/&gt;  &lt;ip address=&#39;192.168.101.1&#39; netmask=&#39;255.255.255.0&#39;&gt;    &lt;dhcp&gt;      &lt;range start=&#39;192.168.101.128&#39; end=&#39;192.168.101.254&#39;/&gt;    &lt;/dhcp&gt;  &lt;/ip&gt;&lt;/network&gt;            查看所有的网络：# virsh net-list启动网络：# virsh net-start isolated200开机自启动:# virsh net-autostart  isolated200 </code></pre><h4 id="KVM存储配置"><a href="#KVM存储配置" class="headerlink" title="KVM存储配置"></a>KVM存储配置</h4><pre><code>存储池概念：    kvm必须要配置一个目录当作他存储磁盘镜像(存储卷)的目录，我们称这个目录为存储池默认存储池：    /var/lib/libvirt/images/        1.创建基于文件夹的存储池（目录）       # mkdir -p /data/vmfs    2.定义存储池与其目录       # virsh pool-define-as vmdisk --type dir --target /data/vmfs    3.创建已定义的存储池        (1)创建已定义的存储池            # virsh pool-build vmdisk        (2)查看已定义的存储池，存储池不激活无法使用。            #virsh pool-list --all    4.激活并自动启动已定义的存储池        # virsh pool-start vmdisk        # virsh pool-autostart vmdisk                 这里vmdisk存储池就已经创建好了，可以直接在这个存储池中创建虚拟磁盘文件了。    5.在存储池中创建虚拟机存储卷         # virsh vol-create-as vmdisk oeltest03.qcow2 20G --format qcow2    注1:KVM存储池主要是体现一种管理方式，可以通过挂载存储目录，lvm逻辑卷的方式创建存储池，虚拟机存储卷创建完成后，剩下的操作与无存储卷的方式无任何区别了。    注2:KVM存储池也要用于虚拟机迁移任务。    6.存储池相关管理命令        (1)在存储池中删除虚拟机存储卷            # virsh vol-delete --pool vmdisk oeltest03.qcow2        (2)取消激活存储池            # virsh pool-destroy vmdisk        (3)删除存储池定义的目录/data/vmfs            # virsh pool-delete vmdisk        (4)取消定义存储池            # virsh pool-undefine vmdisk到此kvm存储池配置与管理操作完毕。   </code></pre><h4 id="kvm快照"><a href="#kvm快照" class="headerlink" title="kvm快照"></a>kvm快照</h4><pre><code>为虚拟机rhel5u8-1创建一个快照# virsh snapshot-create-as rhel5u8-1 rhel5u8-1.snaperror: unsupported configuration: internal snapshot for disk vda unsupported for storage type rawraw使用文件来模拟实际的硬盘(当然也可以使用一块真实的硬盘或一个分区)。由于原生的裸格式，不支持snapshot也是很正常的。但如果你使用LVM的裸设备，那就另当别论。说到LVM还是十分的犀利的目前来LVM的snapshot、性能、可扩展性方面都还是有相当的效果的。目前来看的话，备份的话也问题不大。就是在虚拟机迁移方面还是有很大的限制。但目前虚拟化的现状来看，真正需要热迁移的情况目前需求还不是是否的强烈。虽然使用LVM做虚拟机镜像的相关公开资料比较少，但目前来看牺牲一点灵活性，换取性能和便于管理还是不错的选择。qcow2现在比较主流的一种虚拟化镜像格式，经过一代的优化，目前qcow2的性能上接近raw裸格式的性能，这个也算是redhat的官方渠道了对于qcow2的格式，几点还是比较突出的，qcow2的snapshot，可以在镜像上做N多个快照：    •更小的存储空间    •Copy-on-write support    •支持多个snapshot，对历史snapshot进行管理    •支持zlib的磁盘压缩    •支持AES的加密查看镜像文件格式：# qemu-img info /var/lib/libvirt/images/rhel5u8-1.img image: /var/lib/libvirt/images/rhel5u8-1.imgfile format: rawvirtual size: 10G (10737418240 bytes)disk size: 10G格式转换：把raw格式转换成qcow2格式# qemu-img convert -f raw -O qcow2 /var/lib/libvirt/images/rhel5u8-1.img /var/lib/libvirt/images/rhel5u8-1_qcow2.img# ls -l /var/lib/libvirt/images/total 28381680-rw-------. 1 qemu qemu 10737418240 Aug 16 01:09 rhel5u8-1.img-rw-r--r--. 1 root root  3076521984 Aug 16 01:09 rhel5u8-1_qcow2.img# qemu-img info /var/lib/libvirt/images/rhel5u8-1_qcow2.img image: /var/lib/libvirt/images/rhel5u8-1_qcow2.imgfile format: qcow2virtual size: 10G (10737418240 bytes)disk size: 2.9Gcluster_size: 65536将虚拟机的硬盘指向转换后的qcow2 img在虚拟机中创建一个目录，但目录中是空的# mkdir /test# ls /test给虚拟机rhel5u8-1创建第一个镜像rhel5u8-1.snap1# virsh snapshot-create-as rhel5u8-1 rhel5u8-1.snap1# qemu-img info /var/lib/libvirt/images/rhel5u8-1_qcow2.img image: /var/lib/libvirt/images/rhel5u8-1_qcow2.imgfile format: qcow2virtual size: 10G (10737418240 bytes)disk size: 3.1Gcluster_size: 65536Snapshot list:ID        TAG                 VM SIZE                DATE       VM CLOCK1         rhel5u8-1.snap1        229M 2013-08-16 01:25:39   00:03:58.995在虚拟机中，给 /test 中复制2个文件# cp install.log anaconda-ks.cfg  /test# ls /testanaconda-ks.cfg  install.log给虚拟机rhel5u8-1创建第二个镜像rhel5u8-1.snap2# virsh snapshot-create-as rhel5u8-1 rhel5u8-1.snap2Domain snapshot rhel5u8-1.snap2 created# virsh snapshot-list rhel5u8-1关闭虚拟机，恢复到第一个快照# virsh shutdown rhel5u8-1# virsh snapshot-revert rhel5u8-1 rhel5u8-1.snap1在虚拟机中，发现 /test 目录为空# ls /test关闭虚拟机，恢复到第二个快照# virsh shutdown rhel5u8-1# virsh snapshot-revert rhel5u8-1 rhel5u8-1.snap2在虚拟机中，发现 /test 有拷贝的2个文件# ls /testanaconda-ks.cfg  install.log删除虚拟机快照# virsh snapshot-list rhel5u8-1# virsh snapshot-delete --snapshotname rhel5u8-1.snap2 rhel5u8-1# virsh snapshot-list rhel5u8-1</code></pre><h4 id="kvm迁移"><a href="#kvm迁移" class="headerlink" title="kvm迁移"></a>kvm迁移</h4><pre><code>10.18.42.202 10.18.42.46热迁移                   192.168.1.1/24                                       192.168.1.2/24                ++++++++++++                ++++++++++++                +            +                +            +                        +    KVM-A  +  =======&gt;     +    KVM-B     +                +            +                +            +                    ++++++++++++                ++++++++++++            images                              images        /var/lib/libvirt/images              /var/lib/libvirt/images                                                                            nfs系统环境:rhel6.4 x86_64 iptables and selinux off注意：    1.两台机器要做互相解析        2.同一个大版本的系统，从高版本系统上不可以往低版本系统上迁移，反过来可以比如从6.5不能迁移到6.4，但是从6.4可以迁移到6.5    3.两台机器的selinux全部开机关闭将 KVM-A 上的虚拟机镜像文件所在的目录共享出来[root@localhost ~]# getenforce Permissive[root@localhost ~]# iptables -F[root@localhost ~]# vim /etc/exports /var/lib/libvirt/images 192.168.1.2(rw,sync,no_root_squash)[root@localhost ~]# service nfs start将KVM-A上共享出来的目录挂载在到KVM-B的/var/lib/libvirt/images[root@localhost ~]# mount -t nfs 192.168.1.1:/var/lib/libvirt/images  /var/lib/libvirt/images在KVM-B配置/etc/libvirt/qemu.conf[root@localhost ~]# vim /etc/libvirt/qemu.conf          #取消下面选项的注释user = &quot;root&quot;        第198行group = &quot;root&quot;    第202行[root@localhost ~]# serivice libvirtd restart在KVM-A上用虚拟机管理器连接KVM-BFile---------&gt; Add Connection右键点击要迁移的虚拟机，选择 Migrate~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~3台机器：    10.18.41.159   kvmA    10.18.41.196   kvmB   csyf521    10.18.41.183   nfs</code></pre><h4 id="自动化脚本管理kvm"><a href="#自动化脚本管理kvm" class="headerlink" title="自动化脚本管理kvm"></a>自动化脚本管理kvm</h4><pre class=" language-shell"><code class="language-shell">#!/bin/bash#kvm batch create vm tool#version:0.1#author: cyylog#需要事先准备模板镜像和配置文件模板echo "1.创建自定义配置单个虚拟机2.批量创建自定义配置虚拟机3.批量创建默认配置虚拟机4.删除虚拟机"read -p "选取你的操作(1/2/3):" opbatch_self_define() {        kvmname=`openssl rand -hex 5`        sourceimage=/var/lib/libvirt/images/vmmodel.img        sourcexml=/etc/libvirt/qemu/vmmodel.xml        newimg=/var/lib/libvirt/images/${kvmname}.img        newxml=/etc/libvirt/qemu/${kvmname}.xml        cp $sourceimage  $newimg        cp $sourcexml $newxml        kvmuuid=`uuidgen`        kvmmem=${1}000000        kvmcpu=$2        kvmimg=$newimg        kvmmac=`openssl rand -hex 3 | sed -r 's/..\B/&:/g'`        sed -i "s@kvmname@$kvmname@;s@kvmuuid@$kvmuuid@;s@kvmmem@$kvmmem@;s@kvmcpu@$kvmcpu@;s@kvmimg@$kvmimg@;s@kvmmac@$kvmmac@" $newxml        virsh define $newxml        virsh list --all}self_define() {        read -p "请输入新虚机名称:" newname        read -p "请输入新虚机内存大小(G):" newmem        read -p "请输入新虚机cpu个数:" newcpu        sourceimage=/var/lib/libvirt/images/vmmodel.img        sourcexml=/etc/libvirt/qemu/vmmodel.xml        newimg=/var/lib/libvirt/images/${newname}.img        newxml=/etc/libvirt/qemu/${newname}.xml        cp $sourceimage  $newimg        cp $sourcexml $newxml        kvmname=$newname        kvmuuid=`uuidgen`        kvmmem=${newmem}000000        kvmcpu=$newcpu        kvmimg=$newimg        kvmmac=`openssl rand -hex 3 | sed -r 's/..\B/&:/g'`        sed -i "s@kvmname@$kvmname@;s@kvmuuid@$kvmuuid@;s@kvmmem@$kvmmem@;s@kvmcpu@$kvmcpu@;s@kvmimg@$kvmimg@;s@kvmmac@$kvmmac@" $newxml        virsh define $newxml        virsh list --all}case $op in1)self_define;;2)        read -p "请输入要创建的虚拟机的个数:" num        read -p "请输入新虚机内存大小(G):" newmem        read -p "请输入新虚机cpu个数:" newcpu        for((i=1;i<=$num;i++))        do                batch_self_define $newmem $newcpu        done;;3)        read -p "请输入要创建的虚拟机的个数:" num        for((i=1;i<=$num;i++))        do                batch_self_define 1 1        done;;*)echo "输入错误，请重新执行脚本"  exit;;esac</code></pre><hr>]]></content>
      
      
      <categories>
          
          <category> container </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>iptables笔记</title>
      <link href="2019/02/28/linux/iptables-bi-ji/"/>
      <url>2019/02/28/linux/iptables-bi-ji/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h3 id="防火墙之-iptables"><a href="#防火墙之-iptables" class="headerlink" title="防火墙之 iptables"></a>防火墙之 iptables</h3><h2 id="1-1-安全优化配置原则"><a href="#1-1-安全优化配置原则" class="headerlink" title="1.1 安全优化配置原则"></a>1.1 安全优化配置原则</h2><p>尽可能不给服务器配置外网ip ,可以通过代理转发或者通过防火墙映射.并发不是特别大情况有外网ip,可以开启防火墙服务.</p><p>大并发的情况，不能开iptables,影响性能，利用硬件防火墙提升架构安全</p><h3 id="1-1-1-生产中-iptables-的实际应用"><a href="#1-1-1-生产中-iptables-的实际应用" class="headerlink" title="1.1.1 生产中 iptables 的实际应用"></a>1.1.1 生产中 iptables 的实际应用</h3><p>主要应用方向</p><p>1、主机防火墙（filter表的INPUT链）。</p><p>2、局域网共享上网(nat 表的 POSTROUTING 链)。半个路由器，NAT功能。</p><p>3、端口及IP映射(nat 表的 PREROUTING 链)，硬防的NAT功能。</p><p>4、IP一对一映射。</p><p><strong>其他说明：</strong></p><blockquote><p> ①iptables是基于内核的防火墙，功能非常强大，基于数据包的过滤！特别是可以在一台非常低的硬件配置下跑的非常好。</p><p> 　　<strong>注：</strong>iptables主要工作在OSI七层的2.3.4层。七层的控制可以使用squid代理+iptables。</p><p> ②iptabes：生产中根据具体情况，一般，内网关闭，外网打开。大并发的情况不能开iptables，影响性能，iptables是要消耗CPU的，所以大并发的情况下，我们使用硬件防火墙的各方面做的很仔细。selinux：生产中也是关闭的。可以做ids的入侵检测。</p><p> ③实际生产中尽可能不给服务器配置外网IP。可以通过代理转发。比如，nagios就不需要外网。</p><p> ④并发不是很大的情况下，再外网的IP环境，开防火墙。</p><p> ⑤第一次直接默认规则生成配置文件，以后就在配置文件中进行修改（编辑添加删除）。</p><p> ⑥封掉IP：根据IP地址和网络连接数进行封杀。（定时任务，定时封掉，判断，存在就不再进行二次封杀）</p></blockquote><h3 id="1-1-2-常用案例功能小结："><a href="#1-1-2-常用案例功能小结：" class="headerlink" title="1.1.2 常用案例功能小结："></a>1.1.2 常用案例功能小结：</h3><p>1）linux主机防火墙，单机作为防火墙（表filter）。</p><p>2）局域网共享上网（表nat postrouting）。</p><p>3）外部地址映射为内部地址和端口（表nat prerouting）</p><h2 id="1-2-iptables-防火墙简介"><a href="#1-2-iptables-防火墙简介" class="headerlink" title="1.2 iptables 防火墙简介"></a>1.2 iptables 防火墙简介</h2><p>Netfilter/Iptables(以下简称Iptables)是unix/linux自带的一款优秀且开放源代码的完全自由的基于包过滤的防火墙工具，它的功能十分强大，使用非常灵活，可以对流入和流出服务器的数据包进行很精细的控制.特别是它可以在一台非常低的硬件配置服务器上跑的非常好（赛扬500HZ cpu 64M 内存的惲况下部署网关防火墙），提供近400人的上网服务丝毫不逊色专业路由器防火墙。 iptables + zebra + squid (常用网络开源产品）。</p><p>   iptables是linux2.4及2.6内核中集成的服务，其功能与安全性比其老一蜚ipfwadm，ipchains 强大的多，iptables主要工作在0SI七层的二、三、四层，如果重新编译内核，iptables也可以支持 7 层控制（squid代理+iptables）。</p><h3 id="1-2-1-iptables名词和术语"><a href="#1-2-1-iptables名词和术语" class="headerlink" title="1.2.1 iptables名词和术语"></a>1.2.1 iptables名词和术语</h3><p>不少刚接触到iptables的朋友可能会对iptables防火墙的相关名词搞的很晕，不知道其所云的具体意思，而是就最基本的能让大家容易快速理解和掌握的思路来描述：</p><p>容器：包含或者说属于的关系</p><h3 id="1-2-2-什么是容器"><a href="#1-2-2-什么是容器" class="headerlink" title="1.2.2 什么是容器"></a>1.2.2 什么是容器</h3><p>谁不知道啊，容器就是装东西的，如（箱、包、坛）。没错，恭喜你答对了.词典里解释说，容器就是用来包装或装载物品的贮存器（如箱、罐、坛）或者成形或柔软不成形的包覆材料.</p><p>在iptables里的呢，就是用来描述这种包含或者说属于的关系。</p><h3 id="1-2-3-什么是-Netfilter-iptables"><a href="#1-2-3-什么是-Netfilter-iptables" class="headerlink" title="1.2.3 什么是 Netfilter/iptables ?"></a>1.2.3 什么是 Netfilter/iptables ?</h3><p>Netfilter是表（tables）的容器，这样解释大家肯定还是晕。举个例子，如果把Netfilter看成是某个小区的一栋楼。那么表（tables)就是楼里的其中的一套房子。这套房子”表（tables)”属于这栋“Netfilter”。</p><h3 id="1-2-4-什么是表（tables）？"><a href="#1-2-4-什么是表（tables）？" class="headerlink" title="1.2.4 什么是表（tables）？"></a>1.2.4 什么是表（tables）？</h3><p>表（tables）是链的容器，即所有的链（chains）都属于其对应的表（tables）.如上，如果把Netfilter看成是某个小区的一栋楼.那么表（tables）就是楼里的其中的一套房子。</p><h3 id="1-2-5-什么是链（chains）？"><a href="#1-2-5-什么是链（chains）？" class="headerlink" title="1.2.5 什么是链（chains）？"></a>1.2.5 什么是链（chains）？</h3><p>链（chains）是规则（Policys）的容器。接上，如果把表（tables）当作有一套房子，那么链（chains）就可以说是房子里的家具（柜子等）。</p><h3 id="1-2-6-什么是规则（Policy）？"><a href="#1-2-6-什么是规则（Policy）？" class="headerlink" title="1.2.6 什么是规则（Policy）？"></a>1.2.6 什么是规则（Policy）？</h3><p>规则（Policy）就比较容易理解了，就是iptables系列过滤信息的规范和具体方法条款了.可以理解为柜子如何增加并摆放柜子东西等。</p><p>基本术语如下表格所示：</p><table><thead><tr><th><strong>Netfilter</strong></th><th><strong>表（tables**</strong>）**</th><th><strong>链（chains**</strong>）**</th><th><strong>规则（Policy**</strong>）**</th></tr></thead><tbody><tr><td><strong>一栋楼</strong></td><td>楼里的房子</td><td>房子里的柜子</td><td>柜子里衣服，摆放规则</td></tr></tbody></table><h2 id="1-3-iptables-表和链"><a href="#1-3-iptables-表和链" class="headerlink" title="1.3 iptables 表和链"></a>1.3 iptables 表和链</h2><p>描述完iptables术语后，相信大家对iptables的表和链有了初步的了解了，默认情况下，iptables根据功能和表的定义划分包含三个表，filter,nat,mangle,其每个表又包含不同的操作链（chains )。 实际iptables包含4张表和五个链,巧主要记住两张表即可filter和nat表即可。</p><p>下面表格展示了表和链的对应关系。</p><p><strong>四个表：</strong></p><table><thead><tr><th><strong>表（tables**</strong>）**</th><th><strong>链（chains**</strong>）**</th></tr></thead><tbody><tr><td><strong>Filter</strong> 1</td><td>这是默认表，实现防火墙数据过滤功能。</td></tr><tr><td>1-<strong>INPUT</strong></td><td>对于指定到本地套接字的包，即到达本地防火墙服务器的数据包。</td></tr><tr><td>1-<strong>FORWARD</strong></td><td>路由穿过的数据包，即经过本地防火墙服务器的数据包。</td></tr><tr><td>1-<strong>OUTPUT</strong></td><td>本地创建的数据包</td></tr><tr><td><strong>NAT</strong>2</td><td>当遇到新创建的数据包连接时将参考这个表</td></tr><tr><td>2-<strong>FREROUTING</strong></td><td>一进来就对数据包进行改变</td></tr><tr><td>2-<strong>OUTPUT</strong></td><td>本地创建的数据包在路由前进行改变</td></tr><tr><td>2-<strong>POSTROUTING</strong></td><td>在数据包即将出去时改变数据包信息</td></tr><tr><td><strong>Mangle</strong>3</td><td>这个表专门用于改变数据包</td></tr><tr><td>3-<strong>INPUT</strong></td><td>进入到设备本身的包</td></tr><tr><td>3-<strong>FORWARD</strong></td><td>对路由后的数据包信息进行修改</td></tr><tr><td>3-<strong>FREROUTING</strong></td><td>在路由之前更改传入的包</td></tr><tr><td>3-<strong>OUTPUT</strong></td><td>本地创建的数据包在路由之前改变</td></tr><tr><td>3-<strong>POSTROUTING</strong></td><td>在数据包即将离开时更改数据包信息</td></tr><tr><td><strong>raw</strong>4</td><td><strong>此表用处较少，可以忽略不计。</strong>This  table is used mainly for configuring exemptions from connection tracking in combination with the  NOTRACK  target.</td></tr><tr><td>4-<strong>PREROUTING</strong></td><td>for packets arriving via any network interface</td></tr><tr><td>4-<strong>OUTPUT</strong></td><td>for packets  generated by local processes</td></tr></tbody></table><p><strong>五个链</strong></p><table><thead><tr><th><strong>表（tables**</strong>）**</th><th><strong>链（chains**</strong>）**</th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>INPUT</td><td>FORWARD</td><td>OUTPUT</td><td>PREROUTING</td><td>POSTROUTING</td><td></td></tr><tr><td><strong>Filter</strong></td><td>√</td><td>√</td><td>√</td><td>×</td><td>×</td></tr><tr><td><strong>NAT</strong></td><td><strong>×</strong></td><td>×</td><td>√</td><td>√</td><td>√</td></tr><tr><td><strong>Managle</strong></td><td>√</td><td>√</td><td>√</td><td>√</td><td>√</td></tr><tr><td><strong>raw</strong></td><td>×</td><td>×</td><td>√</td><td>√</td><td>×</td></tr><tr><td>说明：√ 表示有，× 表示无。</td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><p><img src="https://s1.ax1x.com/2020/04/26/JRnutO.png" alt="JRnutO.png"></p><p>图 - iptables中的表与链的结构关系</p><h3 id="1-3-1-filter表的详细介绍"><a href="#1-3-1-filter表的详细介绍" class="headerlink" title="1.3.1 filter表的详细介绍"></a>1.3.1 filter表的详细介绍</h3><table><thead><tr><th><strong>filter**</strong>表**</th><th>主要和主机自身相关，真正负责主机防火墙功能的（过滤流入流出主机的数据包）filter表是iptables默认使用的表，这个表定义了三个链（chains）<strong>工作场景:**</strong>主机防火墙**</th></tr></thead><tbody><tr><td><strong>INPUT</strong></td><td>负责过滤所有目标是本机地址的数据包通俗来说：就是过滤进入主机的数据包</td></tr><tr><td><strong>FORWARD</strong></td><td>负责转发流经主机的数据包。起到转发的作用，和NAT关系很大。LVS NAT 模式，net.ipv4.ip_forward=0</td></tr><tr><td><strong>OUTPUT</strong></td><td>处理所有源地址是本机地址的数据包通俗的讲：就是处理从主机发出的数据包</td></tr></tbody></table><p>   对于filter表的控制是我们实现本机防火墙功能的重要手段，特别是INPUT链的控制。</p><h3 id="1-3-2-NAT表信息详细介绍"><a href="#1-3-2-NAT表信息详细介绍" class="headerlink" title="1.3.2 NAT表信息详细介绍"></a>1.3.2 NAT表信息详细介绍</h3><table><thead><tr><th>NAT表</th><th>负责网络地址转换的，即来源与目的的IP地址和port的转换。应用：和主机本身无关，一般用于局域网共享上网或者特殊的端口转换相关.<strong>工作场景：</strong>1、用于路由(zebra)或网关(iptables),共享上网(POSTROUTING)2、做内部外部IP地址一对一映射(dmz),硬件防火墙映射IP到内部服务器，FTP服务(PREROUTING)3、WEB,单个端口的映射，直接映射80端口(PREROUTING)这个表定义了3个链，nat功能相当于网络的acl控制。和网络交换机acl类似。</th></tr></thead><tbody><tr><td><strong>OUTPUT</strong></td><td>和主机放出去的数据包有关，改变主机发出数据包的目的地址。</td></tr><tr><td><strong>PREROUTING</strong></td><td>在数据包到达防火墙时，进行路由判断之前执行的规则，作用是改变数据包的目的地址、目的端口等就是收信时，根据规则重写收件人的地址例如：把公网IP： xxx.xxx.xxx.xxx 映射到局域网的 x.x.x.x 服务器如果是web服务，可以把80转换为局域网的服务器9000端口上。</td></tr><tr><td><strong>POSTROUTING</strong></td><td>在数据包离开防火墙时进行路由判断之后执行的规则，作用改变数据包的源地址，源端口等。写好收件人的地址，要让家人回信时能够有地址可回。例如。默认笔记本和虚拟机都是局域网地址，在出网的时候被路由器将源地址改为公网地址。<strong>生产应用：</strong>局域网共享上网。</td></tr></tbody></table><h3 id="1-3-3-Mangle表信息详细介绍"><a href="#1-3-3-Mangle表信息详细介绍" class="headerlink" title="1.3.3 Mangle表信息详细介绍"></a>1.3.3 Mangle表信息详细介绍</h3><table><thead><tr><th>Mangle表</th><th>主要负责修改数据包中特殊的路由标记，如TTL,TOS,MARK等，这个表定义了5个链(chains).</th></tr></thead><tbody><tr><td></td><td></td></tr></tbody></table><p>由于这个表与特殊标记相关，一般倩况下，我们用不到这个mangle表。</p><p>这里就不做详细介绍了。</p><h2 id="1-4-iptables工作流程"><a href="#1-4-iptables工作流程" class="headerlink" title="1.4 iptables工作流程"></a>1.4 iptables工作流程</h2><h3 id="1-4-1-工作流程说明"><a href="#1-4-1-工作流程说明" class="headerlink" title="1.4.1 工作流程说明"></a>1.4.1 工作流程说明</h3><p>前面介绍已经提到，iptables是采用数据包过滤机制工作的，所以它会对请求的数据包的包头数据进行分析，并根据我们预先设定的规则进行匹配来决定是否可以进入主机。</p><p>iptables是采用数据包过滤机制工作的，所以它会对请求的数据包的包头数据进行分析，并根据我们预先设定的规则进行匹配来决定是否可以进入主机。</p><p>数据包的流向是从左向右的。</p><p><img src="https://s1.ax1x.com/2020/04/26/JRnXCD.png" alt="JRnXCD.png">图 - iptables包处理流程图</p><p> <img src="https://s1.ax1x.com/2020/04/26/JRupDI.png" alt="JRupDI.png"></p><p>图 - iptables包处理流程图(简化)</p><p><strong>抽象说明：</strong>上图可以用北京地铁1,2号线来描述：</p><p>1号线：主要是NAT功能</p><blockquote><p> 案例：</p><p> 　　1)局域网上网共享（路由和网关），使用NAT的POSTROUTING链。</p><p> 　　2)外部IP和端口映射为内部IP和端口（DMZ功能），使用NAT的PREROUTING链</p></blockquote><p>2号线：主要是FILTER功能，即防火墙功能FILTER INPUT FORWARD</p><blockquote><p>案例：</p><p>　　主要应用就是主机服务器防火墙，使用FILTER的INPUT链</p></blockquote><p> <img src="https://s1.ax1x.com/2020/04/26/JRuPVP.png" alt="JRuPVP.png"></p><p>图 - iptables数据包转发流程图</p><h3 id="1-4-2-iptables工作流程小结"><a href="#1-4-2-iptables工作流程小结" class="headerlink" title="1.4.2 iptables工作流程小结"></a>1.4.2 iptables工作流程小结</h3><blockquote><p>1、防火墙是一层层过滤的。实际是按照配置规则的顺序从上到下，从前到后进行过滤的。</p><p>2、如果匹配上了规则，即明确表明是阻止还是通过，此时数据包就不在向下匹配新规则了。</p><p>3、如果所有规则中没有明确表明是阻止还是通过这个数据包，也就是没有匹配上规则，向下进行匹配，直到匹配默认规则得到明确的阻止还是通过。</p><p>4、防火墙的默认规则是对应链的所有的规则执行完以后才会执行的（最后执行的规则）。</p></blockquote><h2 id="1-5-iptables操作"><a href="#1-5-iptables操作" class="headerlink" title="1.5 iptables操作"></a>1.5 iptables操作</h2><p>系统环境说明</p><pre><code>[root@clsn ~]# cat /etc/redhat-release CentOS release 6.9 (Final)[root@clsn ~]# hostname -I10.0.0.188 172.16.1.188</code></pre><p>软件版本</p><pre><code>[root@clsn ~]# iptables -Viptables v1.4.7</code></pre><h3 id="1-5-1-iptables参数说明"><a href="#1-5-1-iptables参数说明" class="headerlink" title="1.5.1 iptables参数说明"></a>1.5.1 iptables参数说明</h3><table><thead><tr><th><strong>参数</strong></th><th><strong>参数说明</strong></th><th></th><th></th></tr></thead><tbody><tr><td><strong>显示相关参数</strong></td><td></td><td></td><td></td></tr><tr><td><strong>-n/–numeric</strong></td><td>以数字的方式显示地址或端口信息</td><td></td><td></td></tr><tr><td><strong>-L/ –list</strong></td><td>列出一个链或所有链中的规则信息</td><td></td><td></td></tr><tr><td><strong>–list-rules/-S</strong></td><td>Print the rules in a chain or all chains</td><td></td><td></td></tr><tr><td><strong>–line-number</strong></td><td>当列出规则信息时，打印规则行号</td><td></td><td></td></tr><tr><td><strong>-v</strong></td><td>显示详细信息，可以叠加</td><td></td><td></td></tr><tr><td><strong>-h</strong></td><td>显示帮助信息</td><td></td><td></td></tr><tr><td><strong>初始化相关参数</strong></td><td></td><td></td><td></td></tr><tr><td><strong>iptables -F</strong></td><td>清除所有规则，不会处理默认的规则</td><td></td><td></td></tr><tr><td><strong>iptables -X</strong></td><td>删除用户自定义的链</td><td></td><td></td></tr><tr><td><strong>iptables -Z</strong></td><td>链的计数器清零（数据包计数器与数据包字节计数器）</td><td></td><td></td></tr><tr><td><strong>配置常用参数</strong></td><td></td><td></td><td></td></tr><tr><td><strong>-t</strong> <strong>表名称</strong></td><td>指定配置哪个表，指定配置表名称。</td><td></td><td></td></tr><tr><td><strong>–append/-A</strong> <strong>链名称</strong></td><td>附加或追加上相应规则策略，到指定链(链名称必须大写)，默认将配置的规则插入到最后一条。</td><td></td><td></td></tr><tr><td><strong>–check/-C</strong></td><td>Check for the existence of a rule</td><td></td><td></td></tr><tr><td><strong>–insert/-I</strong> <strong>链名称</strong></td><td>插入相应规则策略，到指定链上，默认将配置的规则插入到第一条（可以根据规则序号插入到指定位置）–封IP地址使用。</td><td></td><td></td></tr><tr><td><strong>–delete/-D</strong> <strong>链名称</strong></td><td>删除指定的规则(可以根据规则序号进行删除)</td><td></td><td></td></tr><tr><td><strong>–replace/-R</strong></td><td>Replace rule rulenum (1 = first) in chain</td><td></td><td></td></tr><tr><td><strong>-P(**</strong>大写)<strong>**链名称</strong></td><td>改变链上的最终默认规则策略</td><td></td><td></td></tr><tr><td><strong>–new/-N</strong></td><td>创建新的用户定义链</td><td></td><td></td></tr><tr><td><strong>-p</strong> <strong>协议名称**</strong>[!] –proto**</td><td>指定规则的协议名称 all tcp udp icmp</td><td></td><td></td></tr><tr><td><strong>–dport</strong></td><td>指定匹配的目标端口信息</td><td></td><td></td></tr><tr><td><strong>–sport</strong></td><td>指定匹配的源端口信息</td><td></td><td></td></tr><tr><td><strong>-j</strong> <strong>动作</strong></td><td>匹配数据包后的动作</td><td></td><td></td></tr><tr><td><strong>ACCEPT</strong></td><td>允许</td><td></td><td></td></tr><tr><td><strong>DROP</strong></td><td>丢弃(没有响应)</td><td></td><td></td></tr><tr><td><strong>REJECT</strong></td><td>拒绝(回应请求者明确的拒绝)</td><td></td><td></td></tr><tr><td><strong>MASQUERADE</strong></td><td>伪装上网时使用</td><td></td><td></td></tr><tr><td><strong>SNAT</strong></td><td>共享地址上网</td><td></td><td></td></tr><tr><td><strong>DNAT</strong></td><td>目的地址改写</td><td></td><td></td></tr><tr><td><strong>-i**</strong>[!] –in-interface**</td><td>在INPUT链配置规则中，指定从哪一个网卡接口进入的流量（只能配置在INPUT链上）</td><td></td><td></td></tr><tr><td><strong>-o**</strong>[!] –out-interface**</td><td>在OUTPUT链配置规则中，指定从哪一个网接口出去的流量（只能配置在OUTPUT链上）</td><td></td><td></td></tr><tr><td><strong>-s</strong> <strong>[!] –source</strong></td><td>指定源IP地址或源网段信息</td><td></td><td></td></tr><tr><td><strong>-d**</strong>[!] –destination**</td><td>指定目标IP地址或目标网段信息</td><td></td><td></td></tr><tr><td><strong>扩展参数</strong></td><td></td><td></td><td></td></tr><tr><td><strong>-m</strong> <strong>模块</strong></td><td>表示增加扩展，匹配功能扩展匹配（可以加载扩展参数）</td><td></td><td></td></tr><tr><td><strong>multiport</strong></td><td>实现不连续多端口扩展匹配</td><td></td><td></td></tr><tr><td><strong>icmp</strong></td><td>使用icmp的扩展</td><td></td><td></td></tr><tr><td><strong>state</strong></td><td>状态模块扩展</td><td></td><td></td></tr><tr><td><strong>–icmp-type</strong></td><td>只有类型8是真正会影响ping，或者也可以采用any；了解很多icmp类型<em>iptables -p icmp -h</em></td><td></td><td></td></tr><tr><td><strong>–limit n/{second/minute/hour}</strong></td><td>指定时间内的请求速率”n”为速率，后面为时间分别为：秒分 时</td><td></td><td></td></tr><tr><td><strong>–limit-burst [n]</strong></td><td>在同一时间内允许通过的请求”n”为数字，不指定默认为5</td><td></td><td></td></tr><tr><td><strong>–exact/-x</strong></td><td>扩展数字（显示精确数值）</td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr></tbody></table><p><strong>!**</strong>的使用实例**</p><pre><code>[root@clsn ~]# iptables ! -VNot 1.4.7 ;-)[root@clsn ~]# iptables  -Viptables v1.4.7</code></pre><p>注意：在iptables中所有链名必须大写，表明必须小写，动作必须大写，匹配必须小写。</p><h3 id="1-5-2-配置前准备"><a href="#1-5-2-配置前准备" class="headerlink" title="1.5.2 配置前准备"></a>1.5.2 配置前准备</h3><p>在配置防火墙首先要其中防火墙</p><pre><code>[root@clsn ~]# /etc/init.d/iptables start iptables: Applying firewall rules:                         [  OK  ]</code></pre><p>清除iptables所有规则</p><pre><code>[root@clsn ~]# iptables -Z[root@clsn ~]# iptables -X[root@clsn ~]# iptables -F</code></pre><p>查看iptables的规则</p><pre><code>[root@clsn ~]# iptables -nvLChain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target     prot opt in     out     source               destination         Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target     prot opt in     out     source               destination         Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target     prot opt in     out     source               destination</code></pre><p>查看其他的表配置（-t 参数）</p><pre><code>[root@clsn ~]# iptables -nL -t rawChain PREROUTING (policy ACCEPT)target     prot opt source               destination         Chain OUTPUT (policy ACCEPT)target     prot opt source               destination</code></pre><p>查看配置规则的顺序号</p><pre><code>[root@clsn ~]# iptables -nvL -line-number--line-number #  显示规则的序号</code></pre><h2 id="1-6-iptables-filter表配置实例"><a href="#1-6-iptables-filter表配置实例" class="headerlink" title="1.6 iptables filter表配置实例"></a>1.6 iptables filter表配置实例</h2><h3 id="1-6-1-基础配置"><a href="#1-6-1-基础配置" class="headerlink" title="1.6.1 基础配置"></a>1.6.1 基础配置</h3><p><strong>配置实例一：</strong>配置22/ssh端口访问控制规则</p><pre><code>iptables -A INPUT -p tcp --dprot 22 -j DROP     # 禁止所有人访问22端口iptables -I INPUT -p tcp --dprot 22 -j ACCEPT   # 恢复连接方法iptables -I INPUT 2 -p tcp --dprot 22 -j ACCEPT # 通过插入指定行号信息，指定将规则插入到第几行iptables -D INPUT -p tcp --dport 22 -j ACCEPT   # 删除指定规则iptables -D INPUT 2                             # 根据规则行号，删除相应的规则</code></pre><p>只允许10.0.0.1的ip通过ssh连接这台服务器</p><pre><code>iptables -I INPUT -s 10.0.0.1 -p tcp --dport 22 -j ACCEPT </code></pre><p>配置实例二：禁止网段连入（禁止172.16.1.0网段访问172.16.1.188）</p><pre><code>iptables -A INPUT  -s 172.16.1.0/24 -d 172.16.1.188  -j DROP</code></pre><p>配置实例三：禁止某个172.16.1.0网段访问服务器主机的22端口</p><pre><code>iptables -A INPUT -s 172.16.1.0/24 -d 172.16.1.188  -p tcp --dport 22 -j DROP</code></pre><p>方向说明：</p><pre><code># 在入方向控制iptables -I INPUT -i eth0  -p tcp --dport 22 -j ACCEPT# 在出方向控制iptables -I OUTPUT -o eth0  -p tcp --sport 22 -j DROP</code></pre><h3 id="1-6-2-配置实例四：除10-0-0-0网段可以进行连接服务器主机意外，其余网段都禁止"><a href="#1-6-2-配置实例四：除10-0-0-0网段可以进行连接服务器主机意外，其余网段都禁止" class="headerlink" title="1.6.2 配置实例四：除10.0.0.0网段可以进行连接服务器主机意外，其余网段都禁止"></a>1.6.2 配置实例四：除10.0.0.0网段可以进行连接服务器主机意外，其余网段都禁止</h3><p>  <em>第一种方式：</em></p><pre><code>iptables -A INPUT -s 10.0.0.0/24 -d 172.16.1.8  -j ACCEPT</code></pre><p>   修改默认规则，将默认规则改为拒绝</p><p><em>第二种方式：</em></p><p>   ！  — 表示对规则信息进行取反</p><pre><code>iptables -A INPUT ! -s 10.0.0.0/24 -d 172.16.1.8  -j DROP   --- centos6用法iptables -A INPUT -s ! 10.0.0.0/24 -d 172.16.1.8  -j DROP   --- centos5用法</code></pre><p>说明：只有iptables帮助手册中指定的参数可以用取反符号（iptables –help）</p><h3 id="1-6-3-配置实例五：测试匹配列举端口范围。"><a href="#1-6-3-配置实例五：测试匹配列举端口范围。" class="headerlink" title="1.6.3 配置实例五：测试匹配列举端口范围。"></a>1.6.3 配置实例五：测试匹配列举端口范围。</h3><pre><code>iptables -A INPUT -p tcp --dport 22:80 -j DROP                 # 设置连续多端口控制策略iptables -A INPUT -p tcp -m multiport  --dport 22,80 -j DROP   # 设置不连续多端口控制策略</code></pre><p>   -m 参数表示增加扩展匹配功能，multiport 实现不连续多端口扩展匹配</p><h3 id="1-6-4-配置实例六：匹配ICMP类型"><a href="#1-6-4-配置实例六：匹配ICMP类型" class="headerlink" title="1.6.4 配置实例六：匹配ICMP类型"></a>1.6.4 配置实例六：匹配ICMP类型</h3><p>   禁止ping策略原则</p><p>   iptables服务器是ping命令发起者或是接受者</p><p><strong>发起者：</strong></p><p>input链： 禁止icmp-type 0        0 Echo Reply——回显应答（Ping应答)</p><pre><code>iptables -A INPUT -i eth0 -p icmp --icmp-type 0 -j DROP</code></pre><p>output链： 禁止icmp-type 8     8 Echo request——回显请求（Ping请求）</p><pre><code>iptables -A OUTPUT -o eth0 -p icmp --icmp-type 8 -j DROP</code></pre><p>   <strong>接受者：</strong></p><p>input链： 禁止icmp-type 8      8 Echo request——回显请求（Ping请求）</p><pre><code>iptables -A INPUT -i eth0 -p icmp --icmp-type 8 -j DROP </code></pre><p>output链： 禁止icmp-type 0     0 Echo Reply——回显应答（Ping应答)</p><pre><code>iptables -A OUTPUT -o eth0 -p icmp --icmp-type 0 -j DROP</code></pre><p>简化配置：</p><pre><code>iptables -A INPUT -i eth0 -p icmp -m icmp --icmp-type any -j DROP  #禁止所有类型的icmp</code></pre><p>   指定类型禁止icmp</p><pre><code>iptables -A INPUT -p icmp --icmp-type 8iptables -A INPUT -p icmp --icmp-type 8 -j DROPiptables -A INPUT -p icmp -m icmp --icmp-type any -j ACCEPTiptables -A FORWARD -s 192.168.1.0/24 -p icmp -m icmp --icmp-type any -j ACCEPT</code></pre><p>   说明：只有类型8是真正会影响ping，或者也可以采用any；了解很多icmp类型iptables -p icmp -h</p><p><strong>ICMP**</strong>类型的说明**</p><table><thead><tr><th>TYPE</th><th>CODE</th><th>Description</th><th>Query</th><th>Error</th></tr></thead><tbody><tr><td><strong>0</strong></td><td>0</td><td>Echo Reply——回显应答（Ping应答）</td><td>x</td><td></td></tr><tr><td><strong>3</strong></td><td>0</td><td>Network Unreachable——网络不可达</td><td></td><td>x</td></tr><tr><td><strong>3</strong></td><td>1</td><td>Host Unreachable——主机不可达</td><td></td><td>x</td></tr><tr><td><strong>3</strong></td><td>2</td><td>Protocol Unreachable——协议不可达</td><td></td><td>x</td></tr><tr><td><strong>3</strong></td><td>3</td><td>Port Unreachable——端口不可达</td><td></td><td>x</td></tr><tr><td><strong>3</strong></td><td>4</td><td>Fragmentation needed but no frag. bit set——需要进行分片但设置不分片比特</td><td></td><td>x</td></tr><tr><td><strong>3</strong></td><td>5</td><td>Source routing failed——源站选路失败</td><td></td><td>x</td></tr><tr><td><strong>3</strong></td><td>6</td><td>Destination network unknown——目的网络未知</td><td></td><td>x</td></tr><tr><td><strong>3</strong></td><td>7</td><td>Destination host unknown——目的主机未知</td><td></td><td>x</td></tr><tr><td><strong>3</strong></td><td>8</td><td>Source host isolated (obsolete)——源主机被隔离（作废不用）</td><td></td><td>x</td></tr><tr><td><strong>3</strong></td><td>9</td><td>Destination network administratively prohibited——目的网络被强制禁止</td><td></td><td>x</td></tr><tr><td><strong>3</strong></td><td>10</td><td>Destination host administratively prohibited——目的主机被强制禁止</td><td></td><td>x</td></tr><tr><td><strong>3</strong></td><td>11</td><td>Network unreachable for TOS——由于服务类型TOS，网络不可达</td><td></td><td>x</td></tr><tr><td><strong>3</strong></td><td>12</td><td>Host unreachable for TOS——由于服务类型TOS，主机不可达</td><td></td><td>x</td></tr><tr><td><strong>3</strong></td><td>13</td><td>Communication administratively prohibited by filtering——由于过滤，通信被强制禁止</td><td></td><td>x</td></tr><tr><td><strong>3</strong></td><td>14</td><td>Host precedence violation——主机越权</td><td></td><td>x</td></tr><tr><td><strong>3</strong></td><td>15</td><td>Precedence cutoff in effect——优先中止生效</td><td></td><td>x</td></tr><tr><td><strong>4</strong></td><td>0</td><td>Source quench——源端被关闭（基本流控制）</td><td></td><td></td></tr><tr><td><strong>5</strong></td><td>0</td><td>Redirect for network——对网络重定向</td><td></td><td></td></tr><tr><td><strong>5</strong></td><td>1</td><td>Redirect for host——对主机重定向</td><td></td><td></td></tr><tr><td><strong>5</strong></td><td>2</td><td>Redirect for TOS and network——对服务类型和网络重定向</td><td></td><td></td></tr><tr><td><strong>5</strong></td><td>3</td><td>Redirect for TOS and host——对服务类型和主机重定向</td><td></td><td></td></tr><tr><td><strong>8</strong></td><td>0</td><td>Echo request——回显请求（Ping请求）</td><td>x</td><td></td></tr><tr><td><strong>9</strong></td><td>0</td><td>Router advertisement——路由器通告</td><td></td><td></td></tr><tr><td><strong>10</strong></td><td>0</td><td>Route solicitation——路由器请求</td><td></td><td></td></tr><tr><td><strong>11</strong></td><td>0</td><td>TTL equals 0 during transit——传输期间生存时间为0</td><td></td><td>x</td></tr><tr><td><strong>11</strong></td><td>1</td><td>TTL equals 0 during reassembly——在数据报组装期间生存时间为0</td><td></td><td>x</td></tr><tr><td><strong>12</strong></td><td>0</td><td>IP header bad (catchall error)——坏的IP首部（包括各种差错）</td><td></td><td>x</td></tr><tr><td><strong>12</strong></td><td>1</td><td>Required options missing——缺少必需的选项</td><td></td><td>x</td></tr><tr><td><strong>13</strong></td><td>0</td><td>Timestamp request (obsolete)——时间戳请求（作废不用）</td><td>x</td><td></td></tr><tr><td><strong>14</strong></td><td></td><td>Timestamp reply (obsolete)——时间戳应答（作废不用）</td><td>x</td><td></td></tr><tr><td><strong>15</strong></td><td>0</td><td>Information request (obsolete)——信息请求（作废不用）</td><td>x</td><td></td></tr><tr><td><strong>16</strong></td><td>0</td><td>Information reply (obsolete)——信息应答（作废不用）</td><td>x</td><td></td></tr><tr><td><strong>17</strong></td><td>0</td><td>Address mask request——地址掩码请求</td><td>x</td><td></td></tr><tr><td><strong>18</strong></td><td>0</td><td>Address mask reply——地址掩码应答</td><td></td><td></td></tr></tbody></table><p>数据来源：<a href="http://www.cnitblog.com/yang55xiaoguang/articles/59581.html" target="_blank" rel="noopener">http://www.cnitblog.com/yang55xiaoguang/articles/59581.html</a></p><h3 id="1-6-5-防火墙状态机制配置"><a href="#1-6-5-防火墙状态机制配置" class="headerlink" title="1.6.5 防火墙状态机制配置"></a>1.6.5 防火墙状态机制配置</h3><p>状态集简单说明:</p><table><thead><tr><th><strong>状态集</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td><strong>NEW</strong></td><td>表示新建立连接的数据包状态</td></tr><tr><td><strong>ESTABLISHED</strong></td><td>表示新建立连接数据包发送之后，回复响应的数据包状态</td></tr><tr><td><strong>RELATED</strong></td><td>表示借助已经建立的链路，发送新的连接数据包</td></tr><tr><td><strong>INVALID</strong></td><td>无效无法识别的数据包</td></tr></tbody></table><p>注意：允许关联的状态包通过（web服务不要使用FTP服务）</p><p>防火墙服务配置在FTP服务器上时，需要配置以下策略</p><pre><code>iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPTiptables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT</code></pre><p>实现发现sent_syn状态</p><pre><code>iptables -A INPUT -m state --state NEW -j DROP    # 防火墙所连接客户端上配置</code></pre><p>实现发现sent_rcvd状态</p><pre><code>iptables -I INPUT -i eth0 -s 10.0.0.201 -m state --state ESTABLISHED -j DROP  # 防护墙上配置的</code></pre><h3 id="1-6-6-使用iptables实现限速功能"><a href="#1-6-6-使用iptables实现限速功能" class="headerlink" title="1.6.6 使用iptables实现限速功能"></a>1.6.6 使用iptables实现限速功能</h3><p>limit是iptables的一个匹配模块，用它结合iptables的其它命令可以实现限速的功能。</p><p>不过首先必须明确，limit本身只是一个“匹配”模块。我们知道，iptables的基本原理是“匹配–处理”，limit在这个工作过程中只能起到匹配的作用，它本身是无法对网络数据包进行任何处理的。我看到网上有些limit的例子里面说只 用一条包含limit匹配规则的iptables语句就可以实现限速，那是错误的。</p><p>实际上，利用imit来限速需要包括两个步骤:</p><p>1.对符合limit匹配规则包放行</p><p>2.丢弃/拒绝未放行的包</p><p>示例：</p><pre><code>iptables -I INPUT -s 10.0.0.7 -p icmp --icmp-type 8 -m limit --limit 6/min --limit-burst 5 -j ACCEPT iptables -I INPUT -s 10.0.0.7 -p icmp --icmp-type 8 -j DROP</code></pre><p>   语句含义：当来自10.0.0.7 的ping包超过5个时进行限速，限制为每10s一个。</p><p>参数说明：</p><table><thead><tr><th><strong>参数</strong></th><th><strong>参数含义</strong></th></tr></thead><tbody><tr><td><strong>–limit n/{second/minute/hour}</strong></td><td>指定时间内的请求速率”n”为速率，后面为时间分别为：秒 分 时</td></tr><tr><td><strong>–limit-burst [n]</strong></td><td>在同一时间内允许通过的请求”n”为数字，不指定默认为5</td></tr></tbody></table><p><strong>limit</strong> <strong>模块具体是如何工作的。？</strong></p><p>limit的匹配是基于令牌桶 (Token bucket）模型的。</p><p>令牌桶是一种网络通讯中常见的缓冲区工作原理，它有两个重要的参数，令牌桶容量n和令牌产生速率s。</p><blockquote><p>我们可以把令牌当成是门票，而令牌桶则是负责制作和发放门票的管理员，它手里最多有n张令牌。一开始，管理员开始手里有n张令牌。每当一个数据包到达后，管理员就看看手里是否还有可用的令牌。如果有，就把令牌发给这个数据包，limit就告诉iptables，这个数据包被匹配了。而当管理员把手上所有的令牌都发完了，再来的数据包就拿不到令牌了。这时，limit模块就告诉iptables，这个数据包不能被匹配。除了发放令牌之外，只要令牌桶中的令牌数量少于n，它就会以速率s来产生新的令牌，直到令牌数量到达n为止。</p></blockquote><p>通过令牌桶机制，即可以有效的控制单位时间内通过（匹配）的数据包数量，又可以容许短时间内突发的大量数据包的通过（只要数据包数量不超过令牌桶n）。</p><p>limit模块提供了两个参数–limit和–limit-burst，分别对应于令牌产生速率和令牌桶容量。除了令牌桶模型外，limit匹配的另外一个重要概念是匹配项。在limit中，每个匹配项拥有一个单独的令牌桶，执行独立的匹配计算。</p><h3 id="1-6-7防火墙配置"><a href="#1-6-7防火墙配置" class="headerlink" title="1.6.7防火墙配置"></a>1.6.7防火墙配置</h3><p>清除防火墙规则</p><pre><code>[root@clsn ~]# iptables -F[root@clsn ~]# iptables -X[root@clsn ~]# iptables -Z</code></pre><p>修改默认规则为拒绝（修改前先放行22端口，保证自己能够连上主机）</p><pre><code>[root@clsn ~]# iptables -A INPUT -p tcp --dport  22 -j ACCEPT[root@clsn ~]# iptables -P INPUT DROP [root@clsn ~]# iptables -P FORWARD DROP</code></pre><p>放行指定的端口</p><pre><code>[root@clsn ~]# iptables -A INPUT -i lo -j ACCEPT[root@clsn ~]# iptables -A INPUT  -p tcp  -m multiport --dport  80,443 -j ACCEPT [root@clsn ~]# iptables -A INPUT -s 172.16.1.0/24 -j ACCEPT[root@clsn ~]# iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT#multiport多个不连续   21:25,80,443</code></pre><p><strong>保存iptables**</strong>配置**</p><p>\01. 第一种方式</p><pre><code>[root@clsn ~]# /etc/init.d/iptables saveiptables: Saving firewall rules to /etc/sysconfig/iptables:[  OK  ][root@clsn ~]# cat /etc/sysconfig/iptables# Generated by iptables-save v1.4.7 on Tue Apr  4 12:24:43 2017*filter:INPUT DROP [0:0]:FORWARD DROP [0:0]:OUTPUT ACCEPT [159:10664]-A INPUT -s 10.0.0.0/24 -j ACCEPT -A INPUT -p tcp -m tcp --dport 22 -j ACCEPT -A INPUT -p tcp -m multiport --dports 80,443 -j ACCEPT -A INPUT -s 172.16.1.0/24 -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT COMMIT# Completed on Tue Apr  4 12:24:43 2017</code></pre><p>\02. 第二种方式</p><pre><code>iptables-save &gt;/etc/sysconfig/iptables</code></pre><h2 id="1-7-iptables-nat表配置实例-理论"><a href="#1-7-iptables-nat表配置实例-理论" class="headerlink" title="1.7 iptables nat表配置实例(理论)"></a>1.7 iptables nat表配置实例(理论)</h2><p>(理论掌握)</p><h3 id="1-7-1-iptables实现共享上网"><a href="#1-7-1-iptables实现共享上网" class="headerlink" title="1.7.1 iptables实现共享上网"></a>1.7.1 iptables实现共享上网</h3><p> <img src="https://s1.ax1x.com/2020/04/26/JRuF58.png" alt="JRuF58.png"></p><p>图 - SNAT 配置原理图</p><p>第一个里程碑：配置内网服务器，设置网关地址</p><pre><code>/etc/init.d/iptables stop      # 内网服务器停止防火墙服务ifdown eth0                    # 模拟关闭内网服务器外网网卡setup                          # 修改内网网卡网关和DNS地址信息</code></pre><p>也可以使用命令添加默认网关</p><pre><code>route add default gw 172.16.1.188</code></pre><p>查看默认的路由信息</p><pre><code>[root@test ~]# route -nKernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Iface172.16.1.0      0.0.0.0         255.255.255.0   U     0      0        0 eth1169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0 eth10.0.0.0         172.16.1.188    0.0.0.0         UG    0      0        0 eth1</code></pre><p>说明：内网服务器网关地址指定为共享上网服务器内网网卡地址</p><p>第二个里程碑：配置共享上网服务器，开启共享上网服务器路由转发功能</p><pre><code>[root@clsn ~]# vim /etc/sysctl.conf [root@clsn ~]# sysctl -p~~~net.ipv4.ip_forward = 1~~~</code></pre><p>第三个里程碑：配置共享上网服务器，实现内网访问外网的NAT映射</p><pre><code>iptables -t nat -A POSTROUTING -s 172.16.1.0/24 -o eth0 -j SNAT --to-source 10.0.0.188</code></pre><p>参数详解：</p><table><thead><tr><th><strong>参数</strong></th><th><strong>参数说明</strong></th></tr></thead><tbody><tr><td><strong>-s 172.16.1.0/24</strong></td><td>指定将哪些内网网段进行映射转换</td></tr><tr><td><strong>-o eth0</strong></td><td>指定在共享上网哪个网卡接口上做NAT地址转换</td></tr><tr><td><strong>-j SNAT</strong></td><td>将源地址进行转换变更</td></tr><tr><td><strong>-j DNAT</strong></td><td>将目标地址进行转换变更</td></tr><tr><td><strong>–to-source ip**</strong>地址**</td><td>将源地址映射为什么IP地址</td></tr><tr><td><strong>–to-destination ip**</strong>地址**</td><td>将目标地址映射为什么IP地址</td></tr></tbody></table><p>当filter表中的forward默认为drop策略时，如何配置forward链？</p><p> <img src="https://s1.ax1x.com/2020/04/26/JRuubq.png" alt="JRuubq.png"></p><p>图 - forward工作原理</p><p>   <strong>配置示例</strong></p><pre><code>iptables -A FORWARD -i eth1 -s 172.16.1.0/24 -j ACCEPT# iptables -A FORWARD -o eth0 -s 172.16.1.0/24 -j ACCEPT  # 可以不进行配置iptables -A FORWARD -i eth0 -d 172.16.1.0/24 -j ACCEPT# iptables -A FORWARD -o eth1 -d 172.16.1.0/24 -j ACCEPT   # 可以不进行配置</code></pre><p>当外网ip不固定时如何配置？</p><pre><code>iptables -t nat -A POSTROUTING -s 172.16.1.0/24 -o eth0 -j MASQUERADE   # 伪装共享上网</code></pre><p>说明：在工作中如何没有固定外网IP地址，可以采取以上伪装映射的方式进行共享上网</p><p><strong>配置映射方法小结</strong></p><blockquote><p> \01. 指定哪些网段需要进行映射     -s 172.16.1.0/24</p><p> \02. 指定在哪做映射               -o eth0</p><p> \03. 用什么方法做映射             -j SNAT/DNAT MASQUERADE</p><p> \04. 映射成什么地址               –to-source  ip地址/–to-destination ip地址</p></blockquote><h3 id="1-7-2-iptables实现外网IP的端口映射到内网IP的端口"><a href="#1-7-2-iptables实现外网IP的端口映射到内网IP的端口" class="headerlink" title="1.7.2 iptables实现外网IP的端口映射到内网IP的端口"></a>1.7.2 iptables实现外网IP的端口映射到内网IP的端口</h3><p>实际需求：将网关的IP和9000端口映射到内网服务器的22端口</p><p>端口映射 10.0.0.188:9000 –&gt;172.16.1.180:22</p><p>配置实例：</p><pre><code>iptables -t nat -A PREROUTING -d 10.0.0.188 -p tcp --dport 9000 -i eth0 -j DNAT --to-destination 172.16.1.7:22</code></pre><p>参数说明:</p><table><thead><tr><th><strong>参数</strong></th><th><strong>参数说明</strong></th></tr></thead><tbody><tr><td><strong>-d 10.0.0.188</strong></td><td>目标地址。</td></tr><tr><td><strong>-j DNAT</strong></td><td>目的地址改写。</td></tr></tbody></table><h3 id="1-7-3-IP一对一映射"><a href="#1-7-3-IP一对一映射" class="headerlink" title="1.7.3 IP一对一映射"></a>1.7.3 IP一对一映射</h3><p><img src="https://s1.ax1x.com/2020/04/26/JRu3PU.png" alt="JRu3PU.png"></p><p>图 - DNAT 映射原理</p><p>   实际需求：将ip 地址172.16.1.180 映射到10.0.0.188</p><p>通过辅助IP配置：</p><pre><code>ip addr add 10.0.0.81/24 dev eth0 label eth0:0   # 添加辅助IPiptables  -t nat -I PREROUTING -d 10.0.0.81 -j DNAT --to-destination 172.16.1.51iptables  -t nat -I POSTROUTING -s 172.16.1.51 -o eth0 -j SNAT --to-source 10.0.0.81</code></pre><p>适合内网的机器访问NAT外网的IP</p><pre><code>iptables  -t nat -I POSTROUTING -s 172.16.1.0/255.255.240.0 -d 10.0.0.81 -j SNAT --to-source 172.16.1.8</code></pre><p>检查配置：</p><pre><code>ping 10.0.0.81 -ttcpdump|grep -i icmp（两台机器上分别监测）telnet 10.0.0.81 22</code></pre><h3 id="1-7-4-映射多个外网IP上网"><a href="#1-7-4-映射多个外网IP上网" class="headerlink" title="1.7.4 映射多个外网IP上网"></a>1.7.4 映射多个外网IP上网</h3><p>   方法1：</p><pre><code>iptables -t nat -A POSTROUTING -s 10.0.1.0/255.255.240.0 -o eth0 -j SNAT --to-source 124.42.60.11-124.42.60.16</code></pre><p>​      在三层交换机或路由器，划分VLAN。</p><p>   方法2：</p><pre><code>iptables -t nat -A POSTROUTING -s 10.0.1.0/22 -o eth0 -j SNAT --to-source 124.42.60.11iptables -t nat -A POSTROUTING -s 10.0.2.0/22 -o eth0 -j SNAT --to-source 124.42.60.12</code></pre><p>​      扩大子网，会增加广播风暴。</p><h3 id="1-7-5-系统防火墙与网络内核优化标准参数"><a href="#1-7-5-系统防火墙与网络内核优化标准参数" class="headerlink" title="1.7.5 系统防火墙与网络内核优化标准参数"></a>1.7.5 系统防火墙与网络内核优化标准参数</h3><p>有关iptables的内核优化</p><p>调整内核参数文件/etc/sysctl.conf</p><p>以下是我的生产环境的某个服务器的配置：</p><p><strong>解决time-wait**</strong>过多**的解决办法：</p><pre><code>net.ipv4.tcp_fin_timeout = 2net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_syncookies = 1net.ipv4.tcp_keepalive_time = 600net.ipv4.tcp_max_tw_buckets = 36000net.ipv4.ip_local_port_range = 4000  65000net.ipv4.tcp_max_syn_backlog = 16384net.ipv4.route.gc_timeout = 100net.ipv4.tcp_syn_retries = 1net.ipv4.tcp_synack_retries = 1</code></pre><p>在dmesg中显示  ip_conntrack: table full, dropping packet. 的错误提示，什么原因？</p><p>如何解决？</p><p>   #iptables优化</p><pre><code>net.nf_conntrack_max = 25000000net.netfilter.nf_conntrack_max = 25000000net.netfilter.nf_conntrack_tcp_timeout_established = 180net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120net.netfilter.nf_conntrack_tcp_timeout_close_wait = 60net.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120</code></pre><h2 id="1-8-自定义链的配置-了解"><a href="#1-8-自定义链的配置-了解" class="headerlink" title="1.8 自定义链的配置(了解)"></a>1.8 自定义链的配置(了解)</h2><p> <img src="https://s1.ax1x.com/2020/04/26/JRuG24.png" alt="JRuG24.png"></p><p>图 - 自定义链原理</p><p>创建自定义链</p><pre><code>#示例：在filter表中创建NOICMP自定义链iptables -t filter -N NOICMP</code></pre><p>引用自定义链</p><pre><code>#示例：在INPUT链中引用刚才创建的自定义链iptables -t filter -I INPUT -p icmp  -j NOICMP</code></pre><p>重命名自定义链</p><pre><code>#示例：将IN_WEB自定义链重命名为WEBiptables -E NOICMP ACCEPTICMP</code></pre><p>删除自定义链</p><blockquote><p> 删除自定义链需要满足两个条件</p><p> 　　1、自定义链没有被引用</p><p> 　　2、自定义链中没有任何规则</p></blockquote><pre><code># 示例： 删除引用数为0且不包含任何规则的ACCEPTICMP链iptables -X ACCEPTICMP</code></pre><h2 id="1-9-附录-防火墙状态机制"><a href="#1-9-附录-防火墙状态机制" class="headerlink" title="1.9 附录-防火墙状态机制"></a>1.9 附录-防火墙状态机制</h2><p>状态机制是iptables中较为特殊的一部分，这也是iptables和比较老的ipchains的一个比较大的区別之一，运行状态机制（连接跟踪）的防火墙称作带有状态机制的防火墙，以下简称为状态防火墙.状态防火墙比非状态防火墙要安全，因为它允许我们编写更严密的规则。</p><p>在iptables上一共有四种状态，分别被称为NEW、ESTABLISHED、INVALID、RELATED,这四种状态对于TCP、UDP、ICMP三种协议均有效。下面，我们来分别阐述四种状态的特性.</p><p><strong>🔔 NEW</strong></p><p>meaning that the packet has started a new connection, or otherwise associated with a connection which has not seen packets in both directions</p><p>NEW说明这个包是我们看到的第一个包。意思就是，这是conntrack模块看到的某个连接的第一个包，它即格被匹配了。比如，我们看到一个SYN包，是我们所留意的连接的第一个包，就要匹配它。</p><p><img src="https://s1.ax1x.com/2020/04/26/JRutM9.png" alt="JRutM9.png"> </p><p><strong>🔔 ESTABLISHED</strong></p><p>meaning that the packet is associated with a connection which has seen packets in both directions</p><p>ESTABLISHED已经注意到两个方向上的数据传输，而且会继续匹配这个连接的包.处于ESTABLISHED状态的连接是非常容易理解的.只要发送并接到应答，连接就是ESTABLISHED的了。一个连接要从NEW变为ESTABLISHED,只需要接到应答包即可，不管这个包是发往防火墙的，还是要由防火墙转发的.ICMP的错误和重定向等信息包也被看作是ESTABLISHED,只要它们是我们所发出的信息的应答。</p><p> <img src="https://s1.ax1x.com/2020/04/26/JRuUq1.png" alt="JRuUq1.png"></p><p><strong>🔔</strong> RELATED</p><p>meaning that the packet is starting a new connection, but is associated with an existing connection, such as an FTP data transfer, or an ICMP error.</p><p>RELATED是个比较麻烦的状态.当一个连接和某个已处于ESTABLISHED状态的连接有关系时，就被认为是RELATED的了，换句话说，一个连接要想是RELATED的，首先要有一个ESTABLISHED的连接。这个ESTABLISHED连接再产生一个主连接之外的连接，这个新的连接就是RELATED的了，当然前提是conntrack模块要能理解RELATED。ftp是个很好的例子，FTP-data连接就是和FTP-control有关联的，如果没有在iptables的策略中配RELATED状态，FTP-data的连接是无法正确建立的，还有其他的例子，比如，通过IRC的DCC连接#有了这个状态，ICMP应答、FTP传输、DCC等才能穿过防火墙正常工作.注意，大部分还有一些UDP协议都依赖这个机制。这些协议是很复杂的，它们把连接信息放在数据包里，并且要求这些信息能被正确理解。</p><p><img src="https://s1.ax1x.com/2020/04/26/JRudVx.png" alt="JRudVx.png"> </p><p><strong>🔔 INVALID</strong></p><p>meaning that the packet is associated with no known connection</p><p>INVALID说明数据包不能被识别属于哪个连接或没有任何状态.有几个原因可以产生这种情况，比如，内存溢出，收到不知厲于哪个连接的ICMP错误信息。一般地，我们DROP这个状态的任何东西，因为防火墙认为这是不安全的东西</p><p> <img src="https://s1.ax1x.com/2020/04/26/JRuwa6.png" alt="JRuwa6.png"></p><h3 id="1-9-1-iptables配置哲学"><a href="#1-9-1-iptables配置哲学" class="headerlink" title="1.9.1 iptables配置哲学"></a>1.9.1 iptables配置哲学</h3><p>如何防止自己被关在门外？</p><blockquote><p> 01、去机房重启系统或者登陆服努器删除刚才的禁止规则。</p><p> 02、让机房人员重启服务器或者让机房人员拿用户密码登录进去。</p><p> 03、通过服务器的远程管理卡管理（推荐）。</p><p> 04、先写一个定时任务，每5分钟就停止防火墙。</p><p> 05、测试环境测试好，写成脚本，批置执行</p></blockquote><p>配置禁用22端口策略:</p><pre><code>iptables -I INPUT -p tcp - dport 22 -j DROP# 说明：利用-I参数，实现强行阻止访问22端口，将Jffc规则放在第一位</code></pre><p>删除配置的禁止连接22端口的规则</p><pre><code>iptables -t filter -D INPUT -p tcp —dport 22 -j DROPiptables -F/etc/init.d/iptables restart</code></pre><p> 1.10 参考文献</p><blockquote><p> [1]  <a href="http://www.aichengxu.com/linux/3122717.htm" target="_blank" rel="noopener">http://www.aichengxu.com/linux/3122717.htm</a></p><p> [2]  <a href="http://blog.csdn.net/huguohu2006/article/details/6453522" target="_blank" rel="noopener">http://blog.csdn.net/huguohu2006/article/details/6453522</a></p><p> [3]  <a href="http://blog.csdn.net/lin_credible/article/details/8614907" target="_blank" rel="noopener">http://blog.csdn.net/lin_credible/article/details/8614907</a></p><p> [4]  <a href="http://blog.chinaunix.net/uid-27057175-id-5179329.html" target="_blank" rel="noopener">http://blog.chinaunix.net/uid-27057175-id-5179329.html</a></p><p> [5]  <a href="http://blog.51cto.com/oldboy/974194" target="_blank" rel="noopener">http://blog.51cto.com/oldboy/974194</a></p><p> [6]  <a href="http://blog.sina.com.cn/s/blog_773d9b6701018rwo.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_773d9b6701018rwo.html</a></p><p> [7]  <a href="http://www.zsythink.net/archives/1625" target="_blank" rel="noopener">http://www.zsythink.net/archives/1625</a></p></blockquote><pre><code># iptables  -t  表名  动作(命令)   链名   匹配条件  -j  目标动作        -t 表名  raw mangle nat filter  （如果不写-t 默认使用filter表） 链名(各表对应的链)raw(PROROUTING、OUPUT)mangle(PROROUTING、FORWARD、OUTPUT、POSTROUTING)nat(PREROUTING、INPUT、FORWARD、OUTPUT、POSTROUING)filter(INPUT、FORWARD、OUTPUT)      动作(官方叫命令)：-A  添加规则：  (append追加)  # iptables -t filter -A INPUT -p icmp -j REJECT(拒绝)     //拒绝所有的icmp，即任何人不能ping同你   # iptables -t filter -A INPUT -p tcp --dport 22 -s 10.18.44.158  -j REJECT    拒绝源地址10.18.44.158的tcp协议的22端口   -I 插入规则  ：     #   iptables -t filter -I INPUT 2  -p tcp --dport 22 -s 10.18.44.171  -j REJECT   //INPUT不加数字默认是第一行，数字代表插入到哪一行前边-R 替换规则：      #  iptables -t filter -R INPUT 1 -p tcp --dport 22 -s 10.18.44.181  -j REJECT    //替换的时候 INPUT必须跟上行号-D 删除规则      #  iptables -t filter -D INPUT -p icmp -j REJECT      #  iptables -D INPUT 2-P 修改默认策略：只能使用DROP和ACCEPT       #  iptables -P INPUT DROP         #  iptables -P INPUT ACCEPT -N 添加自定义链          #iptables -N tiger        #iptables -A tiger -p tcp --dport 22 -s 10.18.44.208 -j REJECT     存储规则         自定义链里的规则在没有被调用的情况下不生效 使用自定义链(关联自定义链) #iptables -A INPUT -j tiger 修改自定义链名称  #iptables -E tiger TIGER删掉自定义链：    1.不能被关联    2.必须是空链     #iptables  -X  链名-F  清空规则     # iptables  -F 链名             //指定链的所有规则     #iptables -F                     //所有的规则-Z  计数清零      字节数        数据包个数      #iptables -Z                          //喜爱嗯看到计数用#iptables -L -n -v   (v可有号多个)-L  查看规则  -n以数字的形式显示ip和端口协议 --line 显示规则行号  -v流量计数(verbose 数据包的计数)  #iptables  -L   #iptables  -L -n  #iptables -L -n --line    #iptables  -L -n   -v                       匹配条件：基本匹配    在使用协议的时候不必非得写端口，但是使用端口是必须跟协议    协议                          /etc/protocols  ---icmp协议簇    /etc/servers --TCP/IP协议簇        -p            tcp udp  icmp           -ptcp    端口                                  --sport    //源端口                 # iptables -A INPUT -p tcp --sport 22 -s 10.18.44.208 -j REJECT                            # iptables _A INPUT -p tcp --sport 22:30 -s 10.18.44.208,10.18.44.209,10.18.44.210 -j REJECT              --dport    //目标端口                # iptables -A INPUT -p tcp --dport 22 -s 10.18.44.208 -j REJECT    ip          -s                  #iptables -A INPUT -p tcp --dport 20:30 -s 10.18.44.208/24 -j REJECT   // 在iptables中  10.18.44.208/24  其实是10.18.44.0/24          -d</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> iptables </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis-简介</title>
      <link href="2018/12/05/sql/redis/"/>
      <url>2018/12/05/sql/redis/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h2 id="redis"><a href="#redis" class="headerlink" title="redis"></a>redis</h2><p><img src="https://i.loli.net/2019/05/03/5ccc19cfabc71.jpg" alt=""></p><h3 id="redis简介"><a href="#redis简介" class="headerlink" title="redis简介"></a>redis简介</h3><pre><code>什么是redisREmote DIctionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统。Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Hash), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。redis是一个开源的、使用C语言编写的、支持网络交互的、可基于内存也可持久化的Key-Value数据库。redis的官网：redis.io注:域名后缀io属于国家域名，是british Indian Ocean territory，即英属印度洋领地1.Redis是一个key-value存储系统。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set –有序集合)和hash（哈希类型）。这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。2.在此基础上，redis支持各种不同方式的排序。与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。 Redis 是一个高性能的key-value数据库。 redis的出现，很大程度补偿了memcached这类key/value存储的不足，在部 分场合可以对关系数据库起到很好的补充作用。它提供了Java，C/C++，C#，PHP，JavaScript，Perl，Object-C，Python，Ruby，Erlang等客户端，使用很方便。3.Redis支持主从同步。数据可以从主服务器向任意数量的从服务器上同步，从服务器可以是关联其他从服务器的主服务器。这使得Redis可执行单层树复制。存盘可以有意无意的对数据进行写操作。由于完全实现了发布/订阅机制，使得从数据库在任何地方同步树时，可订阅一个频道并接收主服务器完整的消息发布记录。同步对读取操作的可扩展性和数据冗余很有帮助。</code></pre><pre><code>Redis 与其他 key - value 缓存产品有以下三个特点：- Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。- Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。- Redis支持数据的备份，即master-slave模式的数据备份。</code></pre><h3 id="redis优势"><a href="#redis优势" class="headerlink" title="redis优势"></a>redis优势</h3><pre><code>- 性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。- 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。- 原子 – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。- 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。</code></pre><h3 id="redis安装"><a href="#redis安装" class="headerlink" title="redis安装"></a>redis安装</h3><pre><code>下载地址http://redis.io/download，下载最新稳定版本。$ wget http://download.redis.io/releases/redis-5.0.4.tar.gz$ tar xzf redis-5.0.4.tar.gz$ cd redis-5.0.4.tar.gz$ yum install -y make gcc$ make</code></pre><h3 id="redis简单配置"><a href="#redis简单配置" class="headerlink" title="redis简单配置"></a>redis简单配置</h3><pre><code># cp redis.conf redis.conf.bak# vim redis.conf     ---修改如下bind 127.0.0.1　　#只监听内网IPdaemonize yes　　　　　#开启后台模式将on改为yestimeout 300　　　　　　#连接超时时间port 6379                      #端口号databases 0                 存储Session的Redis库编号dir ./　　#本地数据库存放目录该目录需要存在pidfile /var/run/redis_6379.pid　　#定义pid文件logfile /var/log/redis_6379.log　　#定义log文件requirepass cyy     # 设置密码</code></pre><h3 id="配置redis为systemctl启动"><a href="#配置redis为systemctl启动" class="headerlink" title="配置redis为systemctl启动"></a>配置redis为systemctl启动</h3><pre><code># cd /lib/systemd/system# vim /lib/systemd/system/redis.service[Unit]Description=RedisAfter=network.target[Service]ExecStart=/usr/local/redis-5.0.4/src/redis-server /usr/local/redis-5.0.4/redis.conf  --daemonize noExecStop=/usr/local/redis-5.0.4/src/redis-cli -h 127.0.0.1 -p 6379 shutdown[Install]WantedBy=multi-user.target=====================参数详解:• [Unit] 表示这是基础信息 • Description 是描述• After 是在那个服务后面启动，一般是网络服务启动后启动• [Service] 表示这里是服务信息 • ExecStart 是启动服务的命令• ExecStop 是停止服务的指令• [Install] 表示这是是安装相关信息 • WantedBy 是以哪种方式启动：multi-user.target表明当系统以多用户方式（默认的运行级别）启动时，这个服务需要被自动运行。</code></pre><h3 id="redis启动"><a href="#redis启动" class="headerlink" title="redis启动"></a>redis启动</h3><pre><code>make完后 redis-5.0.4目录下会出现编译后的redis服务程序redis-server,还有用于测试的客户端程序redis-cli,两个程序位于安装目录 src 目录下：下面启动redis服务.</code></pre><p><img src="https://i.loli.net/2019/05/07/5cd186575317a.jpg" alt=""></p><pre><code>$ src/redis-server注意这种方式启动redis 使用的是默认配置。也可以通过启动参数告诉redis使用指定配置文件使用下面命令启动。$ cd src$ ./redis-server ../redis.confredis.conf 是一个默认的配置文件。我们可以根据需要使用自己的配置文件。</code></pre><h3 id="redis客户端测试"><a href="#redis客户端测试" class="headerlink" title="redis客户端测试"></a>redis客户端测试</h3><pre><code>$ src/redis-cli127.0.0.1:6379&gt; set 2020 GZOK127.0.0.1:6379&gt; get 2020&quot;GZ&quot;127.0.0.1:6379&gt; pingPONG</code></pre><h3 id="redis配置"><a href="#redis配置" class="headerlink" title="redis配置"></a>redis配置</h3><pre><code>redis的配置默认位于redis安装目录下，文件名未redis.confRedis CONFIG 命令格式如下：redis 127.0.0.1:6379&gt; CONFIG GET CONFIG_SETTING_NAME也可以通过命令查看或设置相关配置127.0.0.1:6379&gt; config get loglevel1) &quot;loglevel&quot;2) &quot;notice&quot;通过* 查看所有配置127.0.0.1:6379&gt; config get *  1) &quot;dbfilename&quot;  2) &quot;dump.rdb&quot;  3) &quot;requirepass&quot;  4) &quot;&quot;  5) &quot;masterauth&quot;  6) &quot;&quot;  7) &quot;cluster-announce-ip&quot;  8) &quot;&quot;  9) &quot;unixsocket&quot; 10) &quot;&quot; 11) &quot;logfile&quot; 12) &quot;&quot; 13) &quot;pidfile&quot; 14) &quot;&quot; 15) &quot;slave-announce-ip&quot; 16) &quot;&quot; 17) &quot;replica-announce-ip&quot; 18) &quot;&quot; 19) &quot;maxmemory&quot; 20) &quot;0&quot; 21) &quot;proto-max-bulk-len&quot; 22) &quot;536870912&quot; 23) &quot;client-query-buffer-limit&quot; 24) &quot;1073741824&quot; 25) &quot;maxmemory-samples&quot; 26) &quot;5&quot; 27) &quot;lfu-log-factor&quot; 28) &quot;10&quot; 29) &quot;lfu-decay-time&quot; 30) &quot;1&quot; 31) &quot;timeout&quot; 32) &quot;0&quot; 33) &quot;active-defrag-threshold-lower&quot; 34) &quot;10&quot; 35) &quot;active-defrag-threshold-upper&quot; 36) &quot;100&quot; 37) &quot;active-defrag-ignore-bytes&quot; 38) &quot;104857600&quot; 39) &quot;active-defrag-cycle-min&quot; 40) &quot;5&quot; 41) &quot;active-defrag-cycle-max&quot; 42) &quot;75&quot; 43) &quot;active-defrag-max-scan-fields&quot; 44) &quot;1000&quot; 45) &quot;auto-aof-rewrite-percentage&quot; 46) &quot;100&quot; 47) &quot;auto-aof-rewrite-min-size&quot; 48) &quot;67108864&quot; 49) &quot;hash-max-ziplist-entries&quot; 50) &quot;512&quot; 51) &quot;hash-max-ziplist-value&quot; 52) &quot;64&quot; 53) &quot;stream-node-max-bytes&quot; 54) &quot;4096&quot; 55) &quot;stream-node-max-entries&quot; 56) &quot;100&quot; 57) &quot;list-max-ziplist-size&quot; 58) &quot;-2&quot; 59) &quot;list-compress-depth&quot; 60) &quot;0&quot; 61) &quot;set-max-intset-entries&quot; 62) &quot;512&quot; 63) &quot;zset-max-ziplist-entries&quot; 64) &quot;128&quot; 65) &quot;zset-max-ziplist-value&quot; 66) &quot;64&quot; 67) &quot;hll-sparse-max-bytes&quot; 68) &quot;3000&quot; 69) &quot;lua-time-limit&quot; 70) &quot;5000&quot; 71) &quot;slowlog-log-slower-than&quot; 72) &quot;10000&quot; 73) &quot;latency-monitor-threshold&quot; 74) &quot;0&quot; 75) &quot;slowlog-max-len&quot; 76) &quot;128&quot; 77) &quot;port&quot; 78) &quot;6379&quot; 79) &quot;cluster-announce-port&quot; 80) &quot;0&quot;。。。</code></pre><p>编辑配置</p><p>可以通过修改redis.conf文件或者使用 CONFIG setm命令修改配置</p><pre><code>CONFIG set 语法如下redis 127.0.0.1:6379&gt; CONFIG SET CONFIG_SETTING_NAME NEW_CONFIG_VALUE示例redis 127.0.0.1:6379&gt; CONFIG SET loglevel &quot;notice&quot;OKredis 127.0.0.1:6379&gt; CONFIG GET loglevel1) &quot;loglevel&quot;2) &quot;notice&quot;</code></pre><p>相关配置参数详解</p><pre><code> Redis配置文件参数说明:1. Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程daemonize no2. 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定pidfile /var/run/redis.pid3. 指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字port 63794. 绑定的主机地址bind 127.0.0.15.当 客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能timeout 3006. 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verboseloglevel verbose7. 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/nulllogfile stdout8. 设置数据库的数量，默认数据库为0，可以使用SELECT &lt;dbid&gt;命令在连接上指定数据库iddatabases 169. 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合save &lt;seconds&gt; &lt;changes&gt;Redis默认配置文件中提供了三个条件：save 900 1save 300 10save 60 10000分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。10. 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大rdbcompression yes11. 指定本地数据库文件名，默认值为dump.rdbdbfilename dump.rdb12. 指定本地数据库存放目录dir ./13. 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步slaveof &lt;masterip&gt; &lt;masterport&gt;14. 当master服务设置了密码保护时，slav服务连接master的密码masterauth &lt;master-password&gt;15. 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH &lt;password&gt;命令提供密码，默认关闭requirepass foobared16. 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息maxclients 12817. 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区maxmemory &lt;bytes&gt;18. 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为noappendonly no19. 指定更新日志文件名，默认为appendonly.aofappendfilename appendonly.aof20. 指定更新日志条件，共有3个可选值：no：表示等操作系统进行数据缓存同步到磁盘（快）always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）everysec：表示每秒同步一次（折衷，默认值）appendfsync everysec21. 指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析Redis的VM机制）vm-enabled no22. 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享vm-swap-file /tmp/redis.swap23. 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0vm-max-memory 024. Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值vm-page-size 3225. 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。vm-pages 13421772826. 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4vm-max-threads 427. 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启glueoutputbuf yes28. 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法hash-max-zipmap-entries 64hash-max-zipmap-value 51229. 指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍）activerehashing yes</code></pre><h3 id="redis数据类型"><a href="#redis数据类型" class="headerlink" title="redis数据类型"></a>redis数据类型</h3><pre><code>Redis支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合)。</code></pre><h4 id="string"><a href="#string" class="headerlink" title="string"></a>string</h4><pre><code>string 是 redis 最基本的类型，你可以理解成与 Memcached 一模一样的类型，一个 key 对应一个 value。string 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据。比如jpg图片或者序列化的对象。string 类型是 Redis 最基本的数据类型，string 类型的值最大能存储 512MB127.0.0.1:6379&gt; set name cyylogOK127.0.0.1:6379&gt; get name&quot;cyylog&quot;我们使用了 Redis 的 SET 和 GET 命令。键为 name，对应的值为 cyylog</code></pre><h4 id="hash"><a href="#hash" class="headerlink" title="hash"></a>hash</h4><pre><code>Redis hash 是一个键值(key=&gt;value)对集合。Redis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。示例:127.0.0.1:6379&gt; hmset myhash name tiger name2 fiveOK127.0.0.1:6379&gt; hget myhash name&quot;tiger&quot;127.0.0.1:6379&gt; hget myhash name2&quot;five&quot;实例中我们使用了 Redis HMSET, HGET 命令，HMSET 设置了两个 field=&gt;value 对, HGET 获取对应 field 对应的 value。每个 hash 可以存储 232 -1 键值对（40多亿）。</code></pre><h4 id="List"><a href="#List" class="headerlink" title="List"></a>List</h4><pre><code>Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。示例127.0.0.1:6379&gt; lpush mylist redis1(integer) 1127.0.0.1:6379&gt; lpush mylist redis2 redis3 redis4(integer) 4127.0.0.1:6379&gt; lpush mylist tiger 2020(integer) 6127.0.0.1:6379&gt; lrange mylist 0 31) &quot;2020&quot;2) &quot;tiger&quot;3) &quot;redis4&quot;4) &quot;redis3&quot;127.0.0.1:6379&gt; lrange mylist 0 101) &quot;2020&quot;2) &quot;tiger&quot;3) &quot;redis4&quot;4) &quot;redis3&quot;5) &quot;redis2&quot;6) &quot;redis1&quot;上述示例我们通过 lpush 创建list并添加数据，通过lrange获取列表中的数据列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储40多亿)。</code></pre><h4 id="set"><a href="#set" class="headerlink" title="set"></a>set</h4><pre><code>Redis的Set是string类型的无序集合。集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。sadd 命令添加一个 string 元素到 key 对应的 set 集合中，成功返回1，如果元素已经在集合中返回 0，如果 key 对应的 set 不存在则返回错误。示例127.0.0.1:6379&gt; sadd myset GZ BJ ZZ BK(integer) 4127.0.0.1:6379&gt; sadd myset TJ(integer) 1127.0.0.1:6379&gt; sadd myset TJ(integer) 0127.0.0.1:6379&gt; smembers myset 1) &quot;BJ&quot;2) &quot;BK&quot;3) &quot;TJ&quot;4) &quot;GZ&quot;5) &quot;ZZ&quot;127.0.0.1:6379&gt; sadd myset SZ(integer) 1127.0.0.1:6379&gt; smembers myset 1) &quot;BJ&quot;2) &quot;BK&quot;3) &quot;TJ&quot;4) &quot;GZ&quot;5) &quot;ZZ&quot;6) &quot;SZ&quot;注意：以上实例中 TJ 添加了两次，但根据集合内元素的唯一性，第二次插入的元素将被忽略。集合中最大的成员数为 232 - 1(4294967295, 每个集合可存储40多亿个成员)。</code></pre><h4 id="zset"><a href="#zset" class="headerlink" title="zset"></a>zset</h4><pre><code>Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复。zadd 命令添加元素到集合，元素在集合中存在则更新对应score示例127.0.0.1:6379&gt; zadd myzset 0 GZ(integer) 1127.0.0.1:6379&gt; zadd myzset 0 BJ(integer) 1127.0.0.1:6379&gt; zadd myzset 0 ZZ(integer) 1127.0.0.1:6379&gt; zrangebyscore myzset 0 51) &quot;BJ&quot;2) &quot;GZ&quot;3) &quot;ZZ&quot;</code></pre><pre><code>注意：Redis支持多个数据库，并且每个数据库的数据是隔离的不能共享，并且基于单机才有，如果是集群就没有数据库的概念。Redis是一个字典结构的存储服务器，而实际上一个Redis实例提供了多个用来存储数据的字典，客户端可以指定将数据存储在哪个字典中。这与我们熟知的在一个关系数据库实例中可以创建多个数据库类似，所以可以将其中的每个字典都理解成一个独立的数据库。每个数据库对外都是一个从0开始的递增数字命名，Redis默认支持16个数据库（可以通过配置文件支持更多，无上限），可以通过配置databases来修改这一数字。客户端与Redis建立连接后会自动选择0号数据库，不过可以随时使用SELECT命令更换数据库，如要选择1号数据库：示例:127.0.0.1:6379&gt; select 1OK127.0.0.1:6379[1]&gt; get name(nil)127.0.0.1:6379[1]&gt; get myzset(nil)127.0.0.1:6379[1]&gt; select 0OK127.0.0.1:6379&gt; get name&quot;cyylog&quot;127.0.0.1:6379&gt; zrangebyscore myzset 0 21) &quot;BJ&quot;2) &quot;GZ&quot;3) &quot;ZZ&quot;然而这些以数字命名的数据库又与我们理解的数据库有所区别。首先Redis不支持自定义数据库的名字，每个数据库都以编号命名，开发者必须自己记录哪些数据库存储了哪些数据。另外Redis也不支持为每个数据库设置不同的访问密码，所以一个客户端要么可以访问全部数据库，要么连一个数据库也没有权限访问。最重要的一点是多个数据库之间并不是完全隔离的，比如FLUSHALL命令可以清空一个Redis实例中所有数据库中的数据。综上所述，这些数据库更像是一种命名空间，而不适宜存储不同应用程序的数据。比如可以使用0号数据库存储某个应用生产环境中的数据，使用1号数据库存储测试环境中的数据，但不适宜使用0号数据库存储A应用的数据而使用1号数据库B应用的数据，不同的应用应该使用不同的Redis实例存储数据。由于Redis非常轻量级，一个空Redis实例占用的内在只有1M左右，所以不用担心多个Redis实例会额外占用很多内存。</code></pre><h3 id="redis命令"><a href="#redis命令" class="headerlink" title="redis命令"></a>redis命令</h3><pre><code>Redis 命令用于在 redis 服务上执行操作。要在 redis 服务上执行命令需要一个 redis 客户端。Redis 客户端在我们之前下载的的 redis 的安装包中。语法Redis 客户端的基本语法为：$ redis-cli在远程服务上执行命令如果需要在远程 redis 服务上执行命令，同样我们使用的也是 redis-cli 命令。语法$ redis-cli -h host -p port -a password</code></pre><h3 id="redis数据备份和恢复"><a href="#redis数据备份和恢复" class="headerlink" title="redis数据备份和恢复"></a>redis数据备份和恢复</h3><pre><code>Redis SAVE 命令用于创建当前数据库的备份。语法redis Save 命令基本语法如下：127.0.0.1:6379&gt; saveOK该命令会在redis安装目录下创建dump.rdb文件恢复数据如果需要恢复数据，只需将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可。获取 redis 目录可以使用 CONFIG 命令，如下所示：127.0.0.1:6379&gt; config get dir1) &quot;dir&quot;2) &quot;/usr/local/redis/src&quot;以上命令 CONFIG GET dir 输出的 redis 安装目录为/usr/local/redis/srcBgsave创建 redis 备份文件也可以使用命令 BGSAVE，该命令在后台执行。127.0.0.1:6379&gt; BGSAVEBackground saving started</code></pre><h3 id="redis安全"><a href="#redis安全" class="headerlink" title="redis安全"></a>redis安全</h3><pre><code>我们可以通过 redis 的配置文件设置密码参数，这样客户端连接到 redis 服务就需要密码验证，这样可以让你的 redis 服务更安全。127.0.0.1:6379&gt; CONFIG get requirepass1) &quot;requirepass&quot;2) &quot;&quot;默认情况下 requirepass 参数是空的，这就意味着你无需通过密码验证就可以连接到 redis 服务。你可以通过以下命令来修改该参数：127.0.0.1:6379&gt; CONFIG set requirepass &quot;tiger&quot;OK127.0.0.1:6379&gt; CONFIG get requirepass1) &quot;requirepass&quot;2) &quot;tiger&quot;登录redis-cli -h 127.0.0.1 -p 6379 -a tiger或者登陆后认证127.0.0.1:6379&gt; AUTH &quot;tiger&quot;OK127.0.0.1:6379&gt; SET name &quot;Test value&quot;OK127.0.0.1:6379&gt; GET name&quot;Test value&quot;</code></pre><h3 id="redis持久化"><a href="#redis持久化" class="headerlink" title="redis持久化"></a>redis持久化</h3><pre><code>redis持久化 – 两种方式开启持久化功能后，重启redis后，数据会自动通过持久化文件恢复！！redis提供了两种持久化的方式，分别是RDB（Redis DataBase）和AOF（Append Only File）。RDB，是在不同的时间点，将redis存储的数据生成快照并存储到磁盘等介质上；AOF，则是换了一个角度来实现持久化，那就是将redis执行过的所有写指令记录下来，在下次redis重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了。RDB和AOF两种方式也可以同时使用，在这种情况下，如果redis重启的话，则会优先采用AOF方式来进行数据恢复，这是因为AOF方式的数据恢复完整度更高。如果你没有数据持久化的需求，也完全可以关闭RDB和AOF方式，这样的话，redis将变成一个纯内存数据库，就像memcache一样。redis持久化 – RDBRDB方式，是将redis某一时刻的数据持久化到磁盘中，是一种快照式的持久化方法。redis在进行数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程都结束了，才会用这个临时文件替换上次持久化好的文件。正是这种特性，让我们可以随时来进行备份，因为快照文件总是完整可用的。                -------------&gt;----------&gt;------------------&gt;                1 2 3 4 5  6 7 8 9  10 11 12 13  14 15 16                              -----------&gt;                   --------&gt;                              1 2 3 4 5                  1 2 3 4 5  6 7 8 9  10 11 12 13对于RDB方式，redis会单独创建（fork）一个子进程来进行持久化，而主进程是不会进行任何IO操作的，这样就确保了redis极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。虽然RDB有不少优点，但它的缺点也是不容忽视的。如果你对数据的完整性非常敏感，那么RDB方式就不太适合你，因为即使你每5分钟都持久化一次，当redis故障时，仍然会有近5分钟的数据丢失。所以，redis还提供了另一种持久化方式，那就是AOF。redis持久化 – AOFAOF，英文是Append Only File，即只允许追加不允许改写的文件。AOF方式是将执行过的写指令记录下来，在数据恢复时按照从前到后的顺序再将指令都执行一遍，就这么简单。通过配置redis.conf中的appendonly yes就可以打开AOF功能。如果有写操作（如SET等），redis就会被追加到AOF文件的末尾。默认的AOF持久化策略是每秒钟fsync一次（fsync是指把缓存中的写指令记录到磁盘中），因为在这种情况下，redis仍然可以保持很好的处理性能，即使redis故障，也只会丢失最近1秒钟的数据。如果在追加日志时，恰好遇到磁盘空间满、inode满或断电等情况导致日志写入不完整，也没有关系，redis提供了redis-check-aof工具，可以用来进行日志修复。因为采用了追加方式，如果不做任何处理的话，AOF文件会变得越来越大，为此，redis提供了AOF文件重写（rewrite）机制，即当AOF文件的大小超过所设定的阈值时，redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。举个例子或许更形象，假如我们调用了100次INCR指令，在AOF文件中就要存储100条指令，但这明显是很低效的，完全可以把这100条指令合并成一条SET指令，这就是重写机制的原理。在进行AOF重写时，仍然是采用先写临时文件，全部完成后再替换的流程，所以断电、磁盘满等问题都不会影响AOF文件的可用性，这点可以放心。AOF方式的另一个好处，我们通过一个“场景再现”来说明。某同学在操作redis时，不小心执行了FLUSHALL，导致redis内存中的数据全部被清空了，这是很悲剧的事情。不过这也不是世界末日，只要redis配置了AOF持久化方式，且AOF文件还没有被重写（rewrite），我们就可以用最快的速度暂停redis并编辑AOF文件，将最后一行的FLUSHALL命令删除，然后重启redis，就可以恢复redis的所有数据到FLUSHALL之前的状态了。是不是很神奇，这就是AOF持久化方式的好处之一。但是如果AOF文件已经被重写了，那就无法通过这种方法来恢复数据了。虽然优点多多，但AOF方式也同样存在缺陷，比如在同样数据规模的情况下，AOF文件要比RDB文件的体积大。而且，AOF方式的恢复速度也要慢于RDB方式。1 2 3 4 5 6     6zi0如果你直接执行BGREWRITEAOF命令，那么redis会生成一个全新的AOF文件，其中便包括了可以恢复现有数据的最少的命令集。如果运气比较差，AOF文件出现了被写坏的情况，也不必过分担忧，redis并不会贸然加载这个有问题的AOF文件，而是报错退出。这时可以通过以下步骤来修复出错的文件：1.备份被写坏的AOF文件2.运行redis-check-aof –fix进行修复3.用diff -u来看下两个文件的差异，确认问题点4.重启redis，加载修复后的AOF文件redis持久化 – AOF重写AOF重写的内部运行原理，有必要了解一下。在重写即将开始之际，redis会创建（fork）一个“重写子进程”，这个子进程会首先读取现有的AOF文件，并将其包含的指令进行分析压缩并写入到一个临时文件中。与此同时，主工作进程会将新接收到的写指令一边累积到内存缓冲区中，一边继续写入到原有的AOF文件中，这样做是保证原有的AOF文件的可用性，避免在重写过程中出现意外。当“重写子进程”完成重写工作后，它会给父进程发一个信号，父进程收到信号后就会将内存中缓存的写指令追加到新AOF文件中。当追加结束后，redis就会用新AOF文件来代替旧AOF文件，之后再有新的写指令，就都会追加到新的AOF文件中了。redis持久化 – 如何选择RDB和AOF对于我们应该选择RDB还是AOF，官方的建议是两个同时使用。这样可以提供更可靠的持久化方案。写入速度快 AOF写入速度慢 RDBredis的事务处理众所周知，事务是指“一个完整的动作，要么全部执行，要么什么也没有做”。在聊redis事务处理之前，要先和大家介绍四个redis指令，即MULTI、EXEC、DISCARD、WATCH。这四个指令构成了redis事务处理的基础。1.MULTI用来组装一个事务；2.EXEC用来执行一个事务；3.DISCARD用来取消一个事务；4.WATCH用来监视一些key，一旦这些key在事务执行之前被改变，则取消事务的执行。一个MULTI和EXEC的例子：redis&gt; MULTI //标记事务开始OKredis&gt; INCR user_id //多条命令按顺序入队QUEUEDredis&gt; INCR user_idQUEUEDredis&gt; INCR user_idQUEUEDredis&gt; PINGQUEUEDredis&gt; EXEC //执行1) (integer) 12) (integer) 23) (integer) 34) PONG在上面的例子中，看到了QUEUED的字样，这表示我们在用MULTI组装事务时，每一个命令都会进入到内存队列中缓存起来，如果出现QUEUED则表示我们这个命令成功插入了缓存队列，在将来执行EXEC时，这些被QUEUED的命令都会被组装成一个事务来执行。对于事务的执行来说，如果redis开启了AOF持久化的话，那么一旦事务被成功执行，事务中的命令就会通过write命令一次性写到磁盘中去，如果在向磁盘中写的过程中恰好出现断电、硬件故障等问题，那么就可能出现只有部分命令进行了AOF持久化，这时AOF文件就会出现不完整的情况，这时，可以使用redis-check-aof工具来修复这一问题，这个工具会将AOF文件中不完整的信息移除，确保AOF文件完整可用。有关事务，经常会遇到的是两类错误：1.调用EXEC之前的错误2.调用EXEC之后的错误“调用EXEC之前的错误”，有可能是由于语法有误导致的，也可能时由于内存不足导致的。只要出现某个命令无法成功写入缓冲队列的情况，redis都会进行记录，在客户端调用EXEC时，redis会拒绝执行这一事务。（这时2.6.5版本之后的策略。在2.6.5之前的版本中，redis会忽略那些入队失败的命令，只执行那些入队成功的命令）。我们来看一个这样的例子：127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; haha //一个明显错误的指令(error) ERR unknown command &#39;haha&#39;127.0.0.1:6379&gt; pingQUEUED127.0.0.1:6379&gt; exec//redis无情的拒绝了事务的执行，原因是“之前出现了错误”(error) EXECABORT Transaction discarded because of previous errors.而对于“调用EXEC之后的错误”，redis则采取了完全不同的策略，即redis不会理睬这些错误，而是继续向下执行事务中的其他命令。这是因为，对于应用层面的错误，并不是redis自身需要考虑和处理的问题，所以一个事务中如果某一条命令执行失败，并不会影响接下来的其他命令的执行。我们也来看一个例子：127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set age 23QUEUED//age不是集合，所以如下是一条明显错误的指令127.0.0.1:6379&gt; sadd age 15 QUEUED127.0.0.1:6379&gt; set age 29QUEUED127.0.0.1:6379&gt; exec //执行事务时，redis不会理睬第2条指令执行错误1) OK2) (error) WRONGTYPE Operation against a key holding the wrong kind of value3) OK127.0.0.1:6379&gt; get age&quot;29&quot; //可以看出第3条指令被成功执行了最后一个指令“WATCH”，这是一个很好用的指令，它可以帮我们实现类似于“乐观锁”的效果，即CAS（check and set）。WATCH本身的作用是“监视key是否被改动过”，而且支持同时监视多个key，只要还没真正触发事务，WATCH都会尽职尽责的监视，一旦发现某个key被修改了，在执行EXEC时就会返回nil，表示事务无法触发。127.0.0.1:6379&gt; set age 23OK127.0.0.1:6379&gt; watch age //开始监视ageOK127.0.0.1:6379&gt; set age 24 //在EXEC之前，age的值被修改了OK127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set age 25QUEUED127.0.0.1:6379&gt; get ageQUEUED127.0.0.1:6379&gt; exec //触发EXEC(nil) //事务无法被执行</code></pre><h2 id="redis主从-哨兵"><a href="#redis主从-哨兵" class="headerlink" title="redis主从  + 哨兵"></a>redis主从  + 哨兵</h2><h3 id="主从-用法"><a href="#主从-用法" class="headerlink" title="主从 - 用法"></a>主从 - 用法</h3><pre><code>像MySQL一样，redis是支持主从同步的，而且也支持一主多从以及多级从结构。主从结构，一是为了纯粹的冗余备份，二是为了提升读性能，比如很消耗性能的SORT就可以由从服务器来承担。redis的主从同步是异步进行的，这意味着主从同步不会影响主逻辑，也不会降低redis的处理性能。主从架构中，可以考虑关闭主服务器的数据持久化功能，只让从服务器进行持久化，这样可以提高主服务器的处理性能。在主从架构中，从服务器通常被设置为只读模式，这样可以避免从服务器的数据被误修改。但是从服务器仍然可以接受CONFIG等指令，所以还是不应该将从服务器直接暴露到不安全的网络环境中。如果必须如此，那可以考虑给重要指令进行重命名，来避免命令被外人误执行。</code></pre><h3 id="主从-同步原理"><a href="#主从-同步原理" class="headerlink" title="主从 - 同步原理"></a>主从 - 同步原理</h3><pre><code>从服务器会向主服务器发出SYNC指令，当主服务器接到此命令后，就会调用BGSAVE指令来创建一个子进程专门进行数据持久化工作，也就是将主服务器的数据写入RDB文件中。在数据持久化期间，主服务器将执行的写指令都缓存在内存中。在BGSAVE指令执行完成后，主服务器会将持久化好的RDB文件发送给从服务器，从服务器接到此文件后会将其存储到磁盘上，然后再将其读取到内存中。这个动作完成后，主服务器会将这段时间缓存的写指令再以redis协议的格式发送给从服务器。另外，要说的一点是，即使有多个从服务器同时发来SYNC指令，主服务器也只会执行一次BGSAVE，然后把持久化好的RDB文件发给多个下游。在redis2.8版本之前，如果从服务器与主服务器因某些原因断开连接的话，都会进行一次主从之间的全量的数据同步；而在2.8版本之后，redis支持了效率更高的增量同步策略，这大大降低了连接断开的恢复成本。主服务器会在内存中维护一个缓冲区，缓冲区中存储着将要发给从服务器的内容。从服务器在与主服务器出现网络瞬断之后，从服务器会尝试再次与主服务器连接，一旦连接成功，从服务器就会把“希望同步的主服务器ID”和“希望请求的数据的偏移位置（replication offset）”发送出去。主服务器接收到这样的同步请求后，首先会验证主服务器ID是否和自己的ID匹配，其次会检查“请求的偏移位置”是否存在于自己的缓冲区中，如果两者都满足的话，主服务器就会向从服务器发送增量内容。增量同步功能，需要服务器端支持全新的PSYNC指令。这个指令，只有在redis-2.8之后才具有。</code></pre><h3 id="sentinel介绍"><a href="#sentinel介绍" class="headerlink" title="sentinel介绍"></a><strong>sentinel介绍</strong></h3><pre><code>Sentinel(哨兵)是用于监控redis集群中Master状态的工具，其已经被集成在redis2.4+的版本中Sentinel作用： 1)：Master状态检测 2)：如果Master异常，则会进行Master-Slave切换，将其中一个Slave作为Master，将之前的Master作为Slave 3)：Master-Slave切换后，master_redis.conf、slave_redis.conf和sentinel.conf的内容都会发生改变，即master_redis.conf中会多一行slaveof的配置，sentinel.conf的监控目标会随之调换 Sentinel工作方式： 1)：每个Sentinel以每秒钟一次的频率向它所知的Master，Slave以及其他 Sentinel 实例发送一个 PING 命令 2)：如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel 标记为主观下线。 3)：如果一个Master被标记为主观下线，则正在监视这个Master的所有 Sentinel 要以每秒一次的频率确认Master的确进入了主观下线状态。 4)：当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认Master的确进入了主观下线状态， 则Master会被标记为客观下线 5)：在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率向它已知的所有Master，Slave发送 INFO 命令 6)：当Master被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次 7)：若没有足够数量的 Sentinel 同意 Master 已经下线， Master 的客观下线状态就会被移除。 若 Master 重新向 Sentinel 的 PING 命令返回有效回复， Master 的主观下线状态就会被移除。=============================================================主观下线和客观下线 主观下线：Subjectively Down，简称 SDOWN，指的是当前 Sentinel 实例对某个redis服务器做出的下线判断。 客观下线：Objectively Down， 简称 ODOWN，指的是多个 Sentinel 实例在对Master Server做出 SDOWN  判断，并且通过 SENTINEL is-master-down-by-addr 命令互相交流之后，得出的Master  Server下线判断，然后开启failover.</code></pre><h3 id="主从同步部署"><a href="#主从同步部署" class="headerlink" title="主从同步部署"></a>主从同步部署</h3><pre><code>测试环境:centos7.4redis-master:192.168.19.129   vm1redis-slave1:192.168.19.136   vm4redis-slave2:192.168.19.135   vm51.首先三台服务器将redis单机部署完成。编辑master的redis配置文件:[root@redis-master ~]# cd /usr/local/redis-5.0.4[root@redis-master redis]# vim redis.conf</code></pre><img src="https://i.loli.net/2019/05/07/5cd19e2caa3bf.jpg" /><p>2.修改slave1的配置文件：<br>[root@redis-slave1 ~]# cd /data/application/redis/<br>[root@redis-slave1 redis]# vim redis.conf      —修改如下：</p><img src="https://i.loli.net/2019/05/07/5cd19e5ea0f84.jpg" /><img src="https://i.loli.net/2019/05/07/5cd19e838e43e.jpg" /><p>3.配置slave2的配置文件:<br>[root@redis-slave2 ~]# cd /data/application/redis/<br>[root@redis-slave2 redis]# vim redis.conf       —修改如下  和slave1 相同</p><p>4.重启三台redis</p><img src="https://i.loli.net/2019/05/07/5cd19ebbe787b.jpg" /><p>5.测试主从</p><img src="https://i.loli.net/2019/05/07/5cd19f3641529.jpg" /><p><img src="C:%5CUsers%5Cw%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1557241701339.png" alt="1557241701339"></p><p>三台均测试无误，主从同步部署完成</p><h3 id="配置哨兵模式"><a href="#配置哨兵模式" class="headerlink" title="配置哨兵模式"></a>配置哨兵模式</h3><pre><code>1.每台机器上修改redis主配置文件redis.conf文件设置：bind 0.0.0.0       ---配置主从时已经完成2.每台机器上修改sentinel.conf配置文件：修改如下配置[root@redis-master src]# cd ..[root@redis-master redis]# vim sentinel.conf        sentinel monitor mymaster 192.168.233.10 6379 2 (slave上面写的是master的ip，master写自己ip)        sentinel down-after-milliseconds mymaster 3000        sentinel failover-timeout mymaster 10000        protected-mode no</code></pre><pre><code>关闭加密protected-mode no构成master客观下线的前提，至少有两个sentinel(哨兵)主观认为master已经下线sentinel monitor mymaster 192.168.19.129 6379 2 sentinel每隔一定时间向其已知的master发送ping指令，在设置的这个时间内如果没有收master返回的数据包，就会把master标记为主观下线。单位为毫秒sentinel down-after-milliseconds mymaster 3000在这个时间内如果主从切换没有完成就停止切换。单位毫秒sentinel failover-timeout mymaster 10000</code></pre><pre><code>3.每台机器启动哨兵服务：        # ./src/redis-sentinel sentinel.conf注意:在生产环境下将哨兵模式启动放到后台执行:         ./src/redis-sentinel sentinel.conf &amp;在master上面执行这是启动成功的！</code></pre><img src="https://i.loli.net/2019/05/07/5cd1a228086b6.jpg" /><img src="https://i.loli.net/2019/05/07/5cd1a2797a3e7.jpg" /><p>将master的哨兵模式退出，再将redis服务stop了，在两台slave上面查看其中一台是否切换为master:(没有优先级，为随机切换)</p><p>master 192.168.19.129</p><img src="https://i.loli.net/2019/05/07/5cd1a2ef82487.jpg" /><p>slave 192.168.19.136</p><p><img src="C:%5CUsers%5Cw%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1557242911037.png" alt="1557242911037"></p><p>​               主从+哨兵模式测试部署完成！</p><p>==========================================================</p><p>了解</p><p>主从+哨兵+lvs  制作redis主从的高科用</p><p>redis切片等</p>]]></content>
      
      
      <categories>
          
          <category> SQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>找出Java中CPU使用率最高的线程，并打印这些线程的堆栈。</title>
      <link href="2018/09/28/linux/zhao-chu-java-zhong-cpu-shi-yong-lu-zui-gao-de-xian-cheng-bing-da-yin-zhe-xie-xian-cheng-de-dui-zhan/"/>
      <url>2018/09/28/linux/zhao-chu-java-zhong-cpu-shi-yong-lu-zui-gao-de-xian-cheng-bing-da-yin-zhe-xie-xian-cheng-de-dui-zhan/</url>
      
        <content type="html"><![CDATA[<h5 id="1"><a href="#1" class="headerlink" title="1"></a>1</h5><pre class=" language-shell"><code class="language-shell">#!/bin/bash# @Function# Find out the highest cpu consumed threads of java, and print the stack of these threads.## @Usage#   $ ./show-busy-java-threads.sh## @author Jerry Leereadonly PROG=`basename $0`readonly -a COMMAND_LINE=("$0" "$@")usage() {    cat <<EOFUsage: ${PROG} [OPTION]...Find out the highest cpu consumed threads of java, and print the stack of these threads.Example: ${PROG} -c 10Options:    -p, --pid       find out the highest cpu consumed threads from the specifed java process,                    default from all java process.    -c, --count     set the thread count to show, default is 5    -h, --help      display this help and exitEOF    exit $1}readonly ARGS=`getopt -n "$PROG" -a -o c:p:h -l count:,pid:,help -- "$@"`[ $? -ne 0 ] && usage 1eval set -- "${ARGS}"while true; do    case "$1" in    -c|--count)        count="$2"        shift 2        ;;    -p|--pid)        pid="$2"        shift 2        ;;    -h|--help)        usage        ;;    --)        shift        break        ;;    esacdonecount=${count:-5}redEcho() {    [ -c /dev/stdout ] && {        # if stdout is console, turn on color output.        echo -ne "\033[1;31m"        echo -n "$@"        echo -e "\033[0m"    } || echo "$@"}yellowEcho() {    [ -c /dev/stdout ] && {        # if stdout is console, turn on color output.        echo -ne "\033[1;33m"        echo -n "$@"        echo -e "\033[0m"    } || echo "$@"}blueEcho() {    [ -c /dev/stdout ] && {        # if stdout is console, turn on color output.        echo -ne "\033[1;36m"        echo -n "$@"        echo -e "\033[0m"    } || echo "$@"}# Check the existence of jstack command!if ! which jstack &> /dev/null; then    [ -z "$JAVA_HOME" ] && {        redEcho "Error: jstack not found on PATH!"        exit 1    }    ! [ -f "$JAVA_HOME/bin/jstack" ] && {        redEcho "Error: jstack not found on PATH and $JAVA_HOME/bin/jstack file does NOT exists!"        exit 1    }    ! [ -x "$JAVA_HOME/bin/jstack" ] && {        redEcho "Error: jstack not found on PATH and $JAVA_HOME/bin/jstack is NOT executalbe!"        exit 1    }    export PATH="$JAVA_HOME/bin:$PATH"fireadonly uuid=`date +%s`_${RANDOM}_$$cleanupWhenExit() {    rm /tmp/${uuid}_* &> /dev/null}trap "cleanupWhenExit" EXITprintStackOfThread() {    local line    local count=1    while IFS=" " read -a line ; do        local pid=${line[0]}        local threadId=${line[1]}        local threadId0x=`printf %x ${threadId}`        local user=${line[2]}        local pcpu=${line[4]}        local jstackFile=/tmp/${uuid}_${pid}        [ ! -f "${jstackFile}" ] && {            {                if [ "${user}" == "${USER}" ]; then                    jstack ${pid} > ${jstackFile}                else                    if [ $UID == 0 ]; then                        sudo -u ${user} jstack ${pid} > ${jstackFile}                    else                        redEcho "[$((count++))] Fail to jstack Busy(${pcpu}%) thread(${threadId}/0x${threadId0x}) stack of java process(${pid}) under user(${user})."                        redEcho "User of java process($user) is not current user($USER), need sudo to run again:"                        yellowEcho "    sudo ${COMMAND_LINE[@]}"                        echo                        continue                    fi                fi            } || {                redEcho "[$((count++))] Fail to jstack Busy(${pcpu}%) thread(${threadId}/0x${threadId0x}) stack of java process(${pid}) under user(${user})."                echo                rm ${jstackFile}                continue            }        }        blueEcho "[$((count++))] Busy(${pcpu}%) thread(${threadId}/0x${threadId0x}) stack of java process(${pid}) under user(${user}):"        sed "/nid=0x${threadId0x} /,/^$/p" -n ${jstackFile}    done}ps -Leo pid,lwp,user,comm,pcpu --no-headers | {    [ -z "${pid}" ] &&    awk '$4=="java"{print $0}' ||    awk -v "pid=${pid}" '$1==pid,$4=="java"{print $0}'} | sort -k5 -r -n | head --lines "${count}" | printStackOfThread</code></pre><p>原文地址：<a href="https://files-cdn.cnblogs.com/files/clsn/show-busy-java-threads.sh" target="_blank" rel="noopener">https://files-cdn.cnblogs.com/files/clsn/show-busy-java-threads.sh</a></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>监控体系</title>
      <link href="2018/06/05/monitor/jian-kong-ti-xi/"/>
      <url>2018/06/05/monitor/jian-kong-ti-xi/</url>
      
        <content type="html"><![CDATA[<h6 id="监控对象："><a href="#监控对象：" class="headerlink" title="监控对象："></a>监控对象：</h6><p>　　　　1. 监控对象的理解：CPU是怎么工作的，原理<br>　　　　2. 监控对象的指标：CPU使用率 CPU负载 CPU个数 上下文切换<br>　　　　　　　　3. 确定性能基准线：怎么样才算故障？CPU负载多上才算高<br>　　　　监控范围：<br>　　　　　　　　1.硬件监控服务器的硬件故障<br>　　　　　　　　2.操作系统监控 CPU、内存、硬盘、IO、进程<br>　　　　　　　　3.应用服务监控 nginx、MySQL、等服务<br>　　　　　　　　4.业务监控</p><hr><h3 id="硬件监控："><a href="#硬件监控：" class="headerlink" title="硬件监控："></a>硬件监控：</h3><p>　　1.使用IPMI<br>　　2.机房巡检<br>远程控制卡：<br>　　　　DELL服务器：iDRAC<br>　　　　HP服务器：ILO ————-Linux就可以使用IPMI（依赖于BMC控制器）<br>　　　　IBM服务器：IMM |<br>　　　　Linux是管理IPMI工具<br>　　　　‘ipmitool’（监控和控制）</p><h4 id="1-硬件要支持"><a href="#1-硬件要支持" class="headerlink" title="1.硬件要支持"></a>1.硬件要支持</h4><h4 id="2-操作系统-‘Linux-IPMI’"><a href="#2-操作系统-‘Linux-IPMI’" class="headerlink" title="2.操作系统 ‘Linux IPMI’"></a>2.操作系统 ‘Linux IPMI’</h4><p>ipmitool安装:</p><pre><code>[root@localhost ~]# yum install OpenIPMI ipmitool -y[root@localhost ~]# rpm -qa OpenIPMI ipmitoolipmitool-1.8.13-8.el7_1.x86_64OpenIPMI-2.0.19-11.el7.x86_64</code></pre><p>使用IPMI有两种方式<br>1、本地进行调用<br>2、远程调用 （IP地址 用户名和密码）</p><pre><code>[root@localhost ~]# systemctl start ipmi  #启动本次以Centos7进行演示</code></pre><p>IPMI相关命令</p><pre><code>[root@localhost ~]# ipmitool --helpipmitool: invalid option -- &#39;-&#39;ipmitool version 1.8.13usage: ipmitool [options...] &lt;command&gt;       -h             This help       -V             Show version information       -v             Verbose (can use multiple times)       -c             Display output in comma separated format       -d N           Specify a /dev/ipmiN device to use (default=0)       -I intf        Interface to use       -H hostname    Remote host name for LAN interface       -p port        Remote RMCP port [default=623]       -U username    Remote session username       -f file        Read remote session password from file       -z size        Change Size of Communication Channel (OEM)       -S sdr         Use local file for remote SDR cache       -D tty:b[:s]   Specify the serial device, baud rate to use                      and, optionally, specify that interface is the system one       -a             Prompt for remote password       -Y             Prompt for the Kg key for IPMIv2 authentication       -e char        Set SOL escape character       -C ciphersuite Cipher suite to be used by lanplus interface       -k key         Use Kg key for IPMIv2 authentication       -y hex_key     Use hexadecimal-encoded Kg key for IPMIv2 authentication       -L level       Remote session privilege level [default=ADMINISTRATOR]                      Append a &#39;+&#39; to use name/privilege lookup in RAKP1       -A authtype    Force use of auth type NONE, PASSWORD, MD2, MD5 or OEM       -P password    Remote session password       -E             Read password from IPMI_PASSWORD environment variable       -K             Read kgkey from IPMI_KGKEY environment variable       -m address     Set local IPMB address       -b channel     Set destination channel for bridged request       -t address     Bridge request to remote target address       -B channel     Set transit channel for bridged request (dual bridge)       -T address     Set transit address for bridge request (dual bridge)       -l lun         Set destination lun for raw commands       -o oemtype     Setup for OEM (use &#39;list&#39; to see available OEM types)       -O seloem      Use file for OEM SEL event descriptions       -N seconds     Specify timeout for lan [default=2] / lanplus [default=1] interface       -R retry       Set the number of retries for lan/lanplus interface [default=4]Interfaces:    open          Linux OpenIPMI Interface [default]    imb           Intel IMB Interface     lan           IPMI v1.5 LAN Interface     lanplus       IPMI v2.0 RMCP+ LAN Interface     serial-terminal  Serial Interface, Terminal Mode     serial-basic  Serial Interface, Basic Mode Commands:    raw           Send a RAW IPMI request and print response    i2c           Send an I2C Master Write-Read command and print response    spd           Print SPD info from remote I2C device    lan           Configure LAN Channels    chassis       Get chassis status and set power state    power         Shortcut to chassis power commands    event         Send pre-defined events to MC    mc            Management Controller status and global enables    sdr           Print Sensor Data Repository entries and readings    sensor        Print detailed sensor information    fru           Print built-in FRU and scan SDR for FRU locators    gendev        Read/Write Device associated with Generic Device locators sdr    sel           Print System Event Log (SEL)    pef           Configure Platform Event Filtering (PEF)    sol           Configure and connect IPMIv2.0 Serial-over-LAN    tsol          Configure and connect with Tyan IPMIv1.5 Serial-over-LAN    isol          Configure IPMIv1.5 Serial-over-LAN    user          Configure Management Controller users    channel       Configure Management Controller channels    session       Print session information    dcmi          Data Center Management Interface    sunoem        OEM Commands for Sun servers    kontronoem    OEM Commands for Kontron devices    picmg         Run a PICMG/ATCA extended cmd    fwum          Update IPMC using Kontron OEM Firmware Update Manager    firewall      Configure Firmware Firewall    delloem       OEM Commands for Dell systems    shell         Launch interactive IPMI shell    exec          Run list of commands from file    set           Set runtime variable for shell and exec    hpm           Update HPM components using PICMG HPM.1 file    ekanalyzer    run FRU-Ekeying analyzer using FRU files    ime           Update Intel Manageability Engine Firmware</code></pre><p>IPMI配置网络，有两种方式：<br>ipmi over lan（大体意思是通过网卡来进行连接）<br>独立 （给服务器单独插一个网线） DELL服务器可以在小面板中设置ipmi 云主机我们不需要考虑IPMI</p><p>对于路由器和交换机：SNMP<br>对于这些设备，就不做具体描述了，毕竟没有接触过</p><h3 id="系统监控"><a href="#系统监控" class="headerlink" title="系统监控"></a>系统监控</h3><p>做为系统运维来说系统监控是重点</p><pre><code>- CPU- 内存- IO Input/Ouput（网络、磁盘）</code></pre><h4 id="CPU三个重要的概念："><a href="#CPU三个重要的概念：" class="headerlink" title="CPU三个重要的概念："></a>CPU三个重要的概念：</h4><p>　　1.上下文切换：CPU调度器实施的进程的切换过程，上下文切换<br>　　2.运行队列（负载）：运行队列，排队 可以参考我是一个进程文章<br>　　3.使用率<br>监控CPU需要确定服务类型：<br>（1） IO密集型 （数据库）<br>（2） CPU密集型（Web/mail）</p><p>确定性能的基准线<br>　　运行队列：1-3个线程 1CPU 4核 负载不超过12<br>　　CPU使用：65%-70%用户态利用率<br>　　　　　　　30%-35%内核态利用率<br>　　　　　　　0%-5% 空闲<br>　　上下文切换： 越少越好<br>所有的监控都要根据业务来考虑</p><h4 id="常见的系统监控工具"><a href="#常见的系统监控工具" class="headerlink" title="常见的系统监控工具"></a>常见的系统监控工具</h4><p>Top、sysstat、mpstat</p><p>工具的使用方法<br>TOP参数解释</p><p>top的详细可以参考我在51cto的这篇文章 <a href="http://blog.51cto.com/12419955/2052642" target="_blank" rel="noopener">http://blog.51cto.com/12419955/2052642</a></p><p>其实对于Top，现在我更喜欢htop和gtop，gtop虽然色彩和功能更强大，但是因为gtop不在epel源里，导致gtop的使用没有htop用的广泛</p><p>当然gtop这么好用，当然要用一下，这是另一片关于gtop的文章 <a href="https://tigerfivegit.github.io/2018/12/14/Linux性能监控工具-gtop/" target="_blank" rel="noopener">https://tigerfivegit.github.io/2018/12/14/Linux%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7-gtop/</a></p><p>第一行 分别显示：系统当前时间 系统运行时间 当前用户登陆数 系统负载。<br>　　系统负载（load average），这里有三个数值，分别是系统最近1分钟，5分钟，15分钟的平均负载。一般对于单个处理器来说，负载在0 — 1.00 之间是正常的，超过1.00就要引起注意了。在多核处理器中，你的系统均值不应该高于处理器核心的总数。</p><p>第二行 分别显示：total进程总数、 running正在运行的进程数、 sleeping睡眠的进程数、stopped停止的进程数、 zombie僵尸进程数。</p><p>第三行<br>分别显示：<br>%us用户空间占用CPU百分比、<br>%sy内核空间占用CPU百分比、<br>%ni用户进程空间内改变过优先级的进程占用CPU百分比、<br>%id空闲CPU百分比、<br>%wa等待输入输出（I/O）的CPU时间百分比 、<br>%hi指的是cpu处理硬件中断的时间、%si指的是cpu处理软中断的时间 、<br>%st用于有虚拟cpu的情况，用来指示被虚拟机偷掉的cpu时间。<br>通常id%值可以反映一个系统cpu的闲忙程度。</p><p>第四行 MEM ：total 物理内存总量、 used 使用的物理内存总量、free 空闲内存总量、 buffers 用作内核缓存的内存量。</p><p>第五行 SWAP：total 交换区总量、 used使用的交换区总量、free 空闲交换区总量、 cached缓冲的交换区总量。<br>buffers和cached的区别需要说明一下，buffers指的是块设备的读写缓冲区，cached指的是文件系统本身的页面缓存。它们都是linux操作系统底层的机制，目的就是为了加速对磁盘的访问。</p><p>第六行 PID(进程号)、 USER（运行用户）、PR（优先级）、NI（任务nice值）、VIRT（虚拟内存用量）VIRT=SWAP+RES 、RES（物理内存用量）、SHR（共享内存用量）、S（进程状态）、%CPU（CPU占用比）、%MEM（物理内存占用比）、TIME+（累计CPU占 用时间)、　COMMAND 命令名/命令行。</p><p>下面简单介绍top命令的使用方法：<br>top [-] [d]</p><p>[q] [c] [C] [S] [n]<br>运维必会！<br>参数说明<br>d指定每两次屏幕信息刷新之间的时间间隔。当然用户可以使用s交互命令来改变之。<br>p通过指定监控进程ID来仅仅监控某个进程的状态。<br>q该选项将使top没有任何延迟的进行刷新。如果调用程序有超级用户权限，那么top将以尽可能高的优先级运行。<br>S指定累计模式。<br>s使top命令在安全模式中运行。这将去除交互命令所带来的潜在危险。<br>i使top不显示任何闲置或者僵死进程。<br>c显示整个命令行而不只是显示命令名。<br>下面介绍在top命令执行过程中可以使用的一些交互命令<br>　　从使用角度来看，熟练的掌握这些命令比掌握选项还重要一些。<br>　　这些命令都是单字母的，如果在命令行选项中使用了s选项，则可能其中一些命令会被屏蔽掉。<br>Ctrl+L 擦除并且重写屏幕。<br>h或者? 显示帮助画面，给出一些简短的命令总结说明。<br>k 终止一个进程。系统将提示用户输入需要终止的进程PID，以及需要发送给该进程什么样的信号。一般的终止进程可以使用15信号；如果不能正常结束那就使用信号9强制结束该进程。默认值是信号15。在安全模式中此命令被屏蔽。<br>i 忽略闲置和僵死进程。这是一个开关式命令。<br>q 退出程序。<br>r 重新安排一个进程的优先级别。系统提示用户输入需要改变的进程PID以及需要设置的进程优先级值。输入一个正值将使优先级降低，反之则可以使该进程拥有更高的优先权。默认值是10。<br>s 改变两次刷新之间的延迟时间。系统将提示用户输入新的时间，单位为s。如果有小数，就换算成m s。输入0值则系统将不断刷新，默认值是5 s。需要注意的是如果设置太小的时间，很可能会引起不断刷新，从而根本来不及看清显示的情况，而且系统负载也会大大增加。<br>f或者F 从当前显示中添加或者删除项目。<br>o或者O 改变显示项目的顺序。<br>l 切换显示平均负载和启动时间信息。<br>m 切换显示内存信息。<br>t 切换显示进程和CPU状态信息。<br>c 切换显示命令名称和完整命令行。<br>M 根据驻留内存大小进行排序。<br>P 根据CPU使用百分比大小进行排序。<br>T 根据时间/累计时间进行排序。<br>W 将当前设置写入~/.toprc文件中。这是写top配置文件的推荐方法。<br>Shift+M 可按内存占用情况进行排序。</p><h4 id="sysstat-说明"><a href="#sysstat-说明" class="headerlink" title="sysstat 说明"></a>sysstat 说明</h4><pre><code>yum install sysstat -yvmstat --helpusage: vmstat [-V] [-n] [delay [count]]              -V prints version.              -n causes the headers not to be reprinted regularly.              -a print inactive/active page stats.              -d prints disk statistics              -D prints disk table              -p prints disk partition statistics              -s prints vm table              -m prints slabinfo              -t add timestamp to output              -S unit size              delay is the delay between updates in seconds.               unit size k:1000 K:1024 m:1000000 M:1048576 (default is K)              count is the number of updates.</code></pre><p>例子：每隔1秒获取1次，次数不限</p><pre><code># vmstat 1procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st 0  0      0 547332 177544 535336    0    0     1     6    5   41  1  0 98  0  0     0  0      0 547324 177544 535336    0    0     0     0  210  445  1  0 99  0  0     0  0      0 547324 177544 535336    0    0     0     0  195  435  0  0 100  0  0 0  0      0 547324 177544 535336    0    0     0     0  208  440  1  0 99  0  0     0  0      0 547332 177544 535336    0    0     0     0  209  446  0  0 100  0  0 0  0      0 547332 177544 535336    0    0     0     0  207  442  1  1 98  0  0     0  0      0 547332 177544 535336    0    0     0     0  201  438  0  0 100  0  0</code></pre><p>#r表示CPU排队的情况，b代表 进程堵塞，等待io<br>每隔1秒获取1次，次数10次</p><pre><code># vmstat 1 10procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st 1  0      0 547340 177544 535344    0    0     1     6    5   41  1  0 98  0  0     0  0      0 547332 177544 535344    0    0     0    28  210  453  1  1 97  1  0     0  0      0 547332 177544 535344    0    0     0     0  200  433  0  0 100  0  0 0  0      0 547332 177544 535344    0    0     0     0  211  445  1  0 99  0  0     0  0      0 547332 177544 535344    0    0     0     0  201  439  0  1 99  0  0     0  0      0 547332 177544 535344    0    0     0     0  197  436  0  0 100  0  0 0  0      0 547332 177544 535344    0    0     0     0  201  442  1  0 99  0  0     0  0      0 547324 177544 535348    0    0     0     0  240  484  2  1 97  0  0     0  0      0 547324 177544 535348    0    0     0     0  203  438  0  0 100  0  0 0  0      0 547324 177544 535348    0    0     0     0  197  430  1  0 99  0  0</code></pre><p>mpstat<br>查看所有CPU的平均值</p><pre><code>mpstat 1Linux 2.6.32-431.23.3.el6.x86_64 (www)  08/30/2016  _x86_64_    (1 CPU)05:13:22 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest   %idle05:13:23 PM  all    1.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.00105:13:24 PM  all    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.0005:13:25 PM  all    2.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00   97.0005:13:26 PM  all    1.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.00</code></pre><pre><code>mpstat 1 10Linux 2.6.32-431.23.3.el6.x86_64 (www)  08/30/2016  _x86_64_    (1 CPU)05:13:38 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest   %idle05:13:39 PM  all    2.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.0005:13:40 PM  all    0.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00   99.0005:13:41 PM  all    1.01    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.99</code></pre><p>上述是CPU监控，CPU监控主要靠经验。因为业务不同指标不同，指标越低越好是不变的道理</p><p>sar命令也有类似的功能，但是sar命令更能看到历史的信息，对于问题排查有更好的作用<br>当然对于我这种喜欢骚操作的人，sar命令不可能不搞啊，这里放个链接 <a href="https://tigerfivegit.github.io/2018/11/21/sar/" target="_blank" rel="noopener">https://tigerfivegit.github.io/2018/11/21/sar/</a></p><h4 id="内存硬盘监控："><a href="#内存硬盘监控：" class="headerlink" title="内存硬盘监控："></a>内存硬盘监控：</h4><p>硬盘格式化后分成块（blog）<br>内存默认是页（大小4kb）读取按照页来进行读取<br>内存：free vmstat</p><pre><code>free -m             total       used       free     shared    buffers     cachedMem:          1875       1338        537          0        173        523-/+ buffers/cache:        640       1234Swap:            0          0          0</code></pre><p>total 总内存<br>used 已使用内存<br>free 空闲内存<br>shared 共享内存（进程间相互通信使用共享内存）<br>buffers 缓冲<br>cached 缓存<br>Centos7 会有一个available，活动内存</p><p>#云服务器一般不分配swap分区，物理机能不使用交换分区就不使用交换分区</p><pre><code>vmstat 1procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st 0  0      0 550628 177684 536324    0    0     1     6    7   46  1  0 98  0  0     0  0      0 550620 177684 536324    0    0     0    40  187  429  0  0 100  0  0 0  0      0 550620 177684 536324    0    0     0     0  183  427  1  0 99  0  0     0  0      0 550620 177684 536324    0    0     0     0  197  436  0  1 99  0  0</code></pre><p>swpd交换分区的大小<br>free可用的物理内存大小<br>buff 缓冲区的大小<br>cache 缓存区的大小<br>si 数据从交换分区读取到内存的大小<br>so 数据从内存到交换分区<br>bi 从交换分区读到内存（block）<br>bo 内存写到硬盘的</p><pre><code>内存达到多少报警呢？ 80%</code></pre><h4 id="硬盘：IOPS-IO’s-Per-Second-iotop-df-h-iostat"><a href="#硬盘：IOPS-IO’s-Per-Second-iotop-df-h-iostat" class="headerlink" title="硬盘：IOPS IO’s Per Second iotop df -h iostat"></a>硬盘：IOPS IO’s Per Second iotop df -h iostat</h4><p>　　顺序IO（快）<br>　　随机IO（慢）<br>查看磁盘剩余空间</p><pre><code>df -hFilesystem      Size  Used Avail Use% Mounted on/dev/xvda1       40G  4.1G   34G  11% /tmpfs           938M     0  938M   0% /dev/shm</code></pre><p>监控磁盘IO iotop</p><pre><code>yum install iotop -y</code></pre><p><img src="https://i.loli.net/2018/12/14/5c139a40ccaac.jpg" alt="htop"></p><pre><code>可以使用dd命令生成一个文件夹进行测试 生成命令如下：# dd if=/dev/zero of=/tmp/1.txt bs=1M count=10001000+0 records in1000+0 records out1048576000 bytes (1.0 GB) copied, 20.509 s, 51.1 MB/s[root@www ~]# ls -lh /tmp/1.txt -rw-r--r-- 1 root root 1000M Aug 30 19:48 /tmp/1.txt</code></pre><p>此时IO写入如下图<br><img src="https://i.loli.net/2018/12/14/5c139a7dbf4d3.jpg" alt="IO写如图"><br>iostat命令，可以看到那块磁盘，比iotop更加细致</p><pre><code># iostat 1 2Linux 2.6.32-431.23.3.el6.x86_64 (www)  08/30/2016  _x86_64_    (1 CPU)avg-cpu:  %user   %nice %system %iowait  %steal   %idle           1.10    0.00    0.27    0.16    0.00   98.46Device:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtnxvda              1.51         2.26        17.09     986748    7467560avg-cpu:  %user   %nice %system %iowait  %steal   %idle           1.02    0.00    0.00    0.00    0.00   98.98Device:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtnxvda              0.00         0.00         0.00          0          0</code></pre><p>tps 设备每秒的传输次数（每秒多少的io请求）<br>Blk_read/s 每秒从设备读取的数据量<br>Blk_wrtn/s 每秒像设备写入的数据量<br>Blk_read 写入数据的总数<br>Blk_wrtn 读取数据的总数</p><h4 id="网络监控：iftop"><a href="#网络监控：iftop" class="headerlink" title="网络监控：iftop"></a>网络监控：iftop</h4><pre><code># yum install iftop -y# iftop -n    #-n不做域名解析</code></pre><p><img src="https://i.loli.net/2018/12/14/5c139adfd7ab3.jpg" alt="iftop"></p><p>正常监控只需要监控网卡带宽即可<br>其中网络监控是最复杂的，ping监控网络延迟网络丢包等。但是此类的网络监控只是监控自己到客户端是否丢包，并不能保证客户端到服务器这边不丢包<br>　其中就产生了如：阿里测、奇云测、站长工具等一系列多节点的监控工具</p><p>性能测试常用工具：IBM nmon （nmon analyser—生成AIX性能报告的免费工具）<br><a href="http://nmon.sourceforge.net/pmwiki.php" target="_blank" rel="noopener">http://nmon.sourceforge.net/pmwiki.php</a> #下载地址（需要翻墙工具）<br>所以我们提供了百度云下载<br>链接：<a href="http://pan.baidu.com/s/1boXV6R9" target="_blank" rel="noopener">http://pan.baidu.com/s/1boXV6R9</a> 密码：sblf<br>只需要下载对应的版本，给执行权限。执行即可</p><pre><code># chmod +x nmon16e_x86_rhel72 # ./nmon16e_x86_rhel72</code></pre><p><img src="https://i.loli.net/2018/12/14/5c139b3a8ece4.jpg" alt="nmon"></p><p>我们可以直接输入一个c 一个m一个d。这个是实时的一个状态</p><p><img src="https://i.loli.net/2018/12/14/5c139b6978986.jpg" alt="nmon1"></p><pre><code>./nmon16e_x86_rhel72 --help./nmon16e_x86_rhel72: invalid option -- &#39;-&#39;Hint for nmon16e_x86_rhel72 version 16e    Full Help Info : nmon16e_x86_rhel72 -h    On-screen Stats: nmon16e_x86_rhel72    Data Collection: nmon16e_x86_rhel72 -f [-s &lt;seconds&gt;] [-c &lt;count&gt;] [-t|-T]    Capacity Plan  : nmon16e_x86_rhel72 -xInteractive-Mode:    Read the Welcome screen &amp; at any time type: &quot;h&quot; for more help    Type &quot;q&quot; to exit nmonFor Data-Collect-Mode    -f            Must be the first option on the line (switches off interactive mode)                  Saves data to a CSV Spreadsheet format .nmon file in then local directory                  Note: -f sets a defaults -s300 -c288    which you can then modify    Further Data Collection Options:    -s &lt;seconds&gt;  time between data snapshots    -c &lt;count&gt;    of snapshots before exiting    -t            Includes Top Processes stats (-T also collects command arguments)    -x            Capacity Planning=15 min snapshots for 1 day. (nmon -ft -s 900 -c 96)---- End of Hints-c  采集的次数-s  采集的间隔时间-f  生成一个文件-m  指定生成文件位置</code></pre><p>采集10次 间隔10秒</p><pre><code># ./nmon16e_x86_rhel72 -c 10 -s 10 -f -m /tmp/# lslocalhost_160831_0435.nmon  nmon16e_x86_rhel72</code></pre><p>前面为主机名后面是日期（年月日时分）<br>因为测试可能需要，我们要制作成表格，所以现在将文件上传到桌面上</p><h1 id="sz-localhost-160831-0435-nmon"><a href="#sz-localhost-160831-0435-nmon" class="headerlink" title="sz localhost_160831_0435.nmon"></a>sz localhost_160831_0435.nmon</h1><p>我们打开下载的工具</p><p><img src="https://i.loli.net/2018/12/14/5c139bd30d9d5.jpg" alt="img"></p><p>解压文件夹，打开nmon analyser v34a.xls</p><p><img src="https://i.loli.net/2018/12/14/5c139be8400bd.jpg" alt="img"></p><p>点击Analyse nmon data找到我们刚刚复制出来的文件，就可以看到了。</p><p><img src="https://i.loli.net/2018/12/14/5c139bf883548.jpg" alt="img"></p><h4 id="应用服务监控："><a href="#应用服务监控：" class="headerlink" title="应用服务监控："></a>应用服务监控：</h4><p>举例：Nginx<br>安装nginx</p><pre><code># yum install -y gcc glibc gcc-c++ prce-devel openssl-devel pcre-devel</code></pre><p>提示：nginx可以使用稳定版的最新版，因为安全性会不断的提高。如果是特别老的版本会有一些漏洞和功能<br>　　要想监控nginx需要在编译时添加如下参数</p><pre><code>--with-http_stub_status_module</code></pre><p>下载Nginx</p><pre><code>wget http://nginx.org/download/nginx-1.10.1.tar.gz</code></pre><p>解压，后面步骤太简单不说了<br>安装</p><pre><code>[root@localhost nginx-1.10.1]# useradd -s /sbin/nologin www[root@localhost nginx-1.10.1]# ./configure --prefix=/usr/local/nginx-1.10.1 --user=www --group=www --with-http_ssl_module --with-http_stub_status_module</code></pre><p>#configure 是一个shell脚本，执行它的作用是生成MAKEFILE（编译make需要）</p><pre><code>[root@localhost nginx-1.10.1]# make &amp;&amp; make install[root@localhost nginx-1.10.1]# lltotal 676drwxr-xr-x 6 1001 1001   4096 Aug 31 06:02 auto-rw-r--r-- 1 1001 1001 262898 May 31 09:47 CHANGES-rw-r--r-- 1 1001 1001 400701 May 31 09:47 CHANGES.rudrwxr-xr-x 2 1001 1001   4096 Aug 31 06:02 conf-rwxr-xr-x 1 1001 1001   2481 May 31 09:47 configuredrwxr-xr-x 4 1001 1001     68 Aug 31 06:02 contribdrwxr-xr-x 2 1001 1001     38 Aug 31 06:02 html-rw-r--r-- 1 1001 1001   1397 May 31 09:47 LICENSE-rw-r--r-- 1 root root    404 Aug 31 07:46 Makefiledrwxr-xr-x 2 1001 1001     20 Aug 31 06:02 mandrwxr-xr-x 3 root root    119 Aug 31 07:46 objs-rw-r--r-- 1 1001 1001     49 May 31 09:47 READMEdrwxr-xr-x 9 1001 1001     84 Aug 31 06:02 src</code></pre><p>#make是生成文件，make install是将生成的文件拷贝到不同的地方<br>make install 完成之后可以直接将当前目录拷贝到其他服务器上，安装相同的依赖就可以进行使用。</p><pre><code>[root@localhost nginx-1.10.1]# ln -s /usr/local/nginx-1.10.1/ /usr/local/nginx[root@localhost nginx-1.10.1]# netstat -lntp|grep nginxtcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      7058/nginx: master</code></pre><p>修改nginx.conf配置文件</p><pre><code>    location /status {    stub_status on;    access_log off;        allow 192.168.56.0/24;    deny all;}</code></pre><p>设置只允许56网段访问，并开启日志和状态模块</p><p>#这个比较基础，如果不知道怎么添加。可以参考<a href="http://www.nginx.org/" target="_blank" rel="noopener">www.nginx.org</a> 状态模块<br>浏览器访问：<a href="http://192.168.56.11/status" target="_blank" rel="noopener">http://192.168.56.11/status</a></p><pre><code>Active connections: 1 server accepts handled requests 3 3 163 Reading: 0 Writing: 1 Waiting: 0</code></pre><p>Active connections: 当前活跃的连接数<br>3—-&gt; 一共处理了多少个链接（请求）<br>3—-&gt; 成功创建多少次握手<br>163–&gt; 总共创建了多少个请求<br>Reading:当前读取客户端heardr的数量<br>Writing:当前返回给客户端heardr的数量 　#如果这个指标飙升，说明是后面的节点挂掉了，例如数据库等。<br>Waiting:大体意思是已经处理完，等待下次请求的数量<br>提示：我们只需要关注活动链接即可</p><p>监控最基础的功能<br>采集 存储 展示 告警</p><p>几款监控软件说明：<br>几款监控软件大家都知道应该是zabbix，这个入门和部署比较简单，对于中小企业都是友好的，但是难以细化和深入化。<br>后来因业务需求从zabbix逐渐转用小米的开源监控open-falcon，这个对于新手不太友好，但是后期的添加和细化都是特别友好的，模块化、分支化</p>]]></content>
      
      
      <categories>
          
          <category> monitor </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux日志切割工具Logrotate配置详解</title>
      <link href="2018/04/05/linux/linux-ri-zhi-qie-ge-gong-ju-logrotate-pei-zhi-xiang-jie/"/>
      <url>2018/04/05/linux/linux-ri-zhi-qie-ge-gong-ju-logrotate-pei-zhi-xiang-jie/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><h1 id="Linux日志切割工具Logrotate配置详解"><a href="#Linux日志切割工具Logrotate配置详解" class="headerlink" title="[Linux日志切割工具Logrotate配置详解]"></a>[Linux日志切割工具Logrotate配置详解]</h1><p>文章目录</p><p>[TOC]</p><p>Logrotate 程序是一个日志文件管理工具。用于分割日志文件，压缩转存、删除旧的日志文件，并创建新的日志文件，下面就对logrotate日志轮转的记录：</p><h2 id="1-Logrotate配置文件介绍"><a href="#1-Logrotate配置文件介绍" class="headerlink" title="1. Logrotate配置文件介绍"></a>1. Logrotate配置文件介绍</h2><p><a href="https://www.centos.bz/tag/linux/" target="_blank" rel="noopener">Linux</a>系统默认安装logrotate，默认的配置文件：</p><ul><li><code>/etc/logrotate.conf</code></li><li><code>/etc/logrotate.d/</code></li><li><code>logrotate.conf</code>：为主配置文件</li><li><code>logrotate.d</code>：为配置相关子系统，用于隔离每个应用配置（<a href="https://www.centos.bz/category/web-server/nginx/" target="_blank" rel="noopener">Nginx</a>、PHP、<a href="https://www.centos.bz/category/web-server/tomcat/" target="_blank" rel="noopener">Tomcat</a>…）</li></ul><p>Logrotate是基于CRON来运行的，其脚本是/etc/cron.daily/logrotate，日志轮转是系统自动完成的。<br>实际运行时，Logrotate会调用配置文件/etc/logrotate.conf。</p><p>Logrotate可以由自动或者手动触发日志轮转：</p><pre class=" language-shell"><code class="language-shell">logrotate -f /etc/logrotate.d/nginxlogrotate -f /etc/logrotate.d/php</code></pre><p>不过正式执行前最好通过<a href="https://www.centos.bz/tag/debug/" target="_blank" rel="noopener">Debug</a>选项来验证一下（-d参数）<br>具体logrotate命令格式如下：</p><pre class=" language-shell"><code class="language-shell">logrotate [OPTION...] <configfile></code></pre><ul><li><code>-d</code>, <code>--debug</code> ：debug模式，测试配置文件是否有错误。</li><li><code>-f</code>, <code>--force</code> ：强制转储文件。</li><li><code>-m</code>, <code>--mail=command</code> ：压缩日志后，发送日志到指定邮箱。</li><li><code>-s</code>, <code>--state=statefile</code> ：使用指定的状态文件。</li><li><code>-v</code>, <code>--verbose</code> ：显示转储过程。</li></ul><h2 id="2-Logrotater日志文件切割策略"><a href="#2-Logrotater日志文件切割策略" class="headerlink" title="2. Logrotater日志文件切割策略"></a>2. Logrotater日志文件切割策略</h2><p>查看logrotate.conf配置：</p><pre class=" language-shell"><code class="language-shell">cat /etc/logrotate.confweekly //默认每一周执行一次rotate轮转工作rotate 4 //保留多少个日志文件(轮转几次).默认保留四个.就是指定日志文件删除之前轮转的次数，0 指没有备份create //自动创建新的日志文件，新的日志文件具有和原来的文件相同的权限；因为日志被改名,因此要创建一个新的来继续存储之前的日志dateext //这个参数很重要！就是切割后的日志文件以当前日期为格式结尾，如xxx.log-20131216这样,如果注释掉,切割出来是按数字递增,即前面说的 xxx.log-1这种格式compress //是否通过gzip压缩转储以后的日志文件，如xxx.log-20131216.gz ；如果不需要压缩，注释掉就行include /etc/logrotate.d //导入/etc/logrotate.d/ 目录中的各个应用配置/var/log/wtmp { //仅针对 /var/log/wtmp 所设定的参数monthly //每月一次切割,取代默认的一周minsize 1M //文件大小超过 1M 后才会切割create 0664 root utmp //指定新建的日志文件权限以及所属用户和组rotate 1 //只保留一个日志.}#这个 wtmp 可记录用户登录系统及系统重启的时间#因为有 minsize 的参数，因此不见得每个月一定会执行一次喔.要看文件大小。</code></pre><p>Logrotate中其他可配置参数，具体如下：</p><pre class=" language-shell"><code class="language-shell">compress //通过gzip 压缩转储以后的日志nocompress //不做gzip压缩处理copytruncate //用于还在打开中的日志文件，把当前日志备份并截断；是先拷贝再清空的方式，拷贝和清空之间有一个时间差，可能会丢失部分日志数据。nocopytruncate //备份日志文件不过不截断create mode owner group //轮转时指定创建新文件的属性，如create 0777 nobody nobodynocreate //不建立新的日志文件delaycompress //和compress 一起使用时，转储的日志文件到下一次转储时才压缩nodelaycompress //覆盖 delaycompress 选项，转储同时压缩。missingok //如果日志丢失，不报错继续滚动下一个日志errors address //专储时的错误信息发送到指定的Email 地址ifempty //即使日志文件为空文件也做轮转，这个是logrotate的缺省选项。notifempty //当日志文件为空时，不进行轮转mail address //把转储的日志文件发送到指定的E-mail 地址nomail //转储时不发送日志文件olddir directory //转储后的日志文件放入指定的目录，必须和当前日志文件在同一个文件系统noolddir //转储后的日志文件和当前日志文件放在同一个目录下sharedscripts //运行postrotate脚本，作用是在所有日志都轮转后统一执行一次脚本。如果没有配置这个，那么每个日志轮转后都会执行一次脚本prerotate //在logrotate转储之前需要执行的指令，例如修改文件的属性等动作；必须独立成行postrotate //在logrotate转储之后需要执行的指令，例如重新启动 (kill -HUP) 某个服务！必须独立成行daily //指定转储周期为每天weekly //指定转储周期为每周monthly //指定转储周期为每月rotate count //指定日志文件删除之前转储的次数，0 指没有备份，5 指保留5 个备份dateext //使用当期日期作为命名格式dateformat .%s //配合dateext使用，紧跟在下一行出现，定义文件切割后的文件名，必须配合dateext使用，只支持 %Y %m %d %s 这四个参数size(或minsize) log-size //当日志文件到达指定的大小时才转储，log-size能指定bytes(缺省)及KB (sizek)或MB(sizem).当日志文件 >= log-size 的时候就转储。 以下为合法格式：（其他格式的单位大小写没有试过）size = 5 或 size 5 （>= 5 个字节就转储）size = 100k 或 size 100ksize = 100M 或 size 100M</code></pre><h2 id="3-NGINX日志的配置实例参考"><a href="#3-NGINX日志的配置实例参考" class="headerlink" title="3. NGINX日志的配置实例参考:"></a>3. NGINX日志的配置实例参考:</h2><pre class=" language-shell"><code class="language-shell">vim /etc/logrotate.d/nginx/var/log/weblog/*.log {    daily  //指定转储周期为每天    compress  //通过gzip 压缩转储以后的日志    rotate 7  //保存7天的日志    missingok  //如果日志文件丢失，不要显示错误    notifempty  //当日志文件为空时，不进行轮转    dateext  //使用当期日期作为命名格式，exp: nginx_access.log-20190120    sharedscripts  //运行postrotate脚本    postrotate  //执行的指令            if [ -f /run/nginx.pid ]; then                    kill -USR1 `cat /run/nginx.pid`            fi    endscript  //结束指令}</code></pre><h2 id="4-PHP-FPM日志的配置实例参考"><a href="#4-PHP-FPM日志的配置实例参考" class="headerlink" title="4. PHP-FPM日志的配置实例参考:"></a>4. PHP-FPM日志的配置实例参考:</h2><pre class=" language-shell"><code class="language-shell">vim /etc/logrotate.d/nginx/usr/local/php/var/log/*.log {dailycompressrotate 7missingoknotifemptydateextsharedscriptspostrotate    if [ -f /usr/local/php/var/run/php-fpm.pid ]; then        kill -USR2 `cat /usr/local/php/var/run/php-fpm.pid`    fiendscript}</code></pre><h2 id="5-Logrotater日志切割轮询"><a href="#5-Logrotater日志切割轮询" class="headerlink" title="5. Logrotater日志切割轮询"></a>5. Logrotater日志切割轮询</h2><p>由于Logrotate是基于CRON运行的，所以这个日志轮转的时间是由CRON控制的，具体可以查询CRON的配置文件/etc/anacrontab，过往的老版本的文件为（/etc/crontab）</p><p>查看轮转文件：/etc/anacrontab</p><pre class=" language-shell"><code class="language-shell">cat /etc/anacrontab    SHELL=/bin/sh    PATH=/sbin:/bin:/usr/sbin:/usr/bin    MAILTO=root    RANDOM_DELAY=45    START_HOURS_RANGE=3-22    1   5   cron.daily      nice run-parts /etc/cron.daily    7   25  cron.weekly     nice run-parts /etc/cron.weekly    @monthly 45 cron.monthly        nice run-parts /etc/cron.monthly</code></pre><p>使用anacrontab轮转的配置文件，日志切割的生效时间是在凌晨3点到22点之间，而且随机延迟时间是45分钟，但是这样配置无法满足我们在现实中的应用</p><p>现在的需求是将切割时间调整到每天的晚上12点，即每天切割的日志是前一天的0-24点之间的内容，操作如下：</p><pre class=" language-shell"><code class="language-shell">mv /etc/anacrontab /etc/anacrontab.bak          //取消日志自动轮转的设置</code></pre><p>使用crontab来作为日志轮转的触发容器来修改Logrotate默认执行时间</p><pre class=" language-shell"><code class="language-shell">vi /etc/crontab SHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=rootHOME=/# run-parts01 * * * * root run-parts /etc/cron.hourly59 23 * * * root run-parts /etc/cron.daily22 4 * * 0 root run-parts /etc/cron.weekly42 4 1 * * root run-parts /etc/cron.monthly</code></pre><h2 id="6-解决logrotate无法自动轮询日志的办法"><a href="#6-解决logrotate无法自动轮询日志的办法" class="headerlink" title="6. 解决logrotate无法自动轮询日志的办法"></a>6. 解决logrotate无法自动轮询日志的办法</h2><p>现象说明：</p><p>使用logrotate轮询nginx日志，配置好之后，发现nginx日志连续两天没被切割，检查后确定配置文件一切正常，这是为什么呢？？</p><p>强行启动记录文件维护操作，纵使logrotate指令认为没有需要，应该有可能是logroate认为nginx日志太小，不进行轮询。<br>故需要强制轮询，即在/etc/cron.daily/logrotate脚本中将 -t 参数替换成 -f 参数</p><pre class=" language-shell"><code class="language-shell">vim /etc/cron.daily/logrotate #!/bin/sh/usr/sbin/logrotate /etc/logrotate.confEXITVALUE=$?if [ $EXITVALUE != 0 ]; then    /usr/bin/logger -f logrotate "ALERT exited abnormally with [$EXITVALUE]"fiexit 0</code></pre><p>最后最后重启下cron服务：</p><pre class=" language-shell"><code class="language-shell">/etc/init.d/crond restartStopping crond: [ OK ]Starting crond: [ OK ]</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
